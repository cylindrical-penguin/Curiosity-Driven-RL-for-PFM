{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color = \"blue\">Curiosity Driven Exploration to Optimize Structure-Property Learning in Microscopy</font>\n",
    "\n",
    "### Aditya Vatsavai<sup>1,2</sup> Ganesh Narasimha<sup>1</sup>, Yongtao Liu<sup>1</sup>, Jan-Chi Yang<sup>3</sup>, Hiroshi Funakubo<sup>4</sup>, Maxim Ziatdinov<sup>5</sup> and Rama Vasudevan<sup>1</sup>\n",
    "\n",
    "<sup>1</sup>Center for Nanophase Materials Sciences, Oak Ridge National Laboratory, Oak Ridge, TN, USA <br>\n",
    "<sup>2</sup>Department of Physics, University of North Carolina, Charlotte <br>\n",
    "<sup>3</sup>Department of Physics, National Cheng Kung University, Tianan, Taiwan <br>\n",
    "<sup>4</sup>Tokyo Institute of Technology\n",
    "<sup>5</sup>Physical Sciences Division, Pacific Northwest National Laboratory, Richland, WA, USA\n",
    "\n",
    "This notebook contains the code requried to run the curiosity algorithm on a Cypher AFM utilizing our AEcroscopy control software. AEcroscopy can be found <a href =\"https://yongtaoliu.github.io/aecroscopy.pyae/welcome_intro.html\">here</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/cloud/ipynb_files/im2spec\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, os.path.join(os.getcwd(), 'im2spec'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "from gym import spaces\n",
    "import numpy as np\n",
    "\n",
    "import scipy\n",
    "import gdown\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "from copy import deepcopy as dc\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from im2spec.models import im2spec, spec2im, conv_block, dilated_block\n",
    "from im2spec.utils import create_training_set, predict, encode, decode\n",
    "from im2spec.train_utils import trainer\n",
    "\n",
    "import random\n",
    "from collections import namedtuple, deque\n",
    "from typing import List, Tuple\n",
    "import math\n",
    "\n",
    "import aecroscopy\n",
    "from aecroscopy.acquisition.AEBE import AEBE   # include the Acquistion_v0.py in the same directory\n",
    "from aecroscopy.acquisition.AECypher import AECypher\n",
    "\n",
    "from functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Some additional helper functions\n",
    "\n",
    "def err_train(X, reward, criterion, optimizer, autoencoder):\n",
    "    data = feature_extractor(autoencoder, np.array(X)).float().to(device = device)\n",
    "       \n",
    "    targets = torch.tensor(reward).float().to(device = device)\n",
    "\n",
    "    scores = error_predictor(data)\n",
    "\n",
    "    loss = criterion(scores, targets.reshape(targets.shape[0], 1))\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "def coord(pos, image_size):\n",
    "    return(np.array([[2*pos[0]/image_size - 1], [2*pos[1]/image_size - 1]]))\n",
    "\n",
    "class rewards_model(nn.Module):\n",
    "\n",
    "    def __init__(self, n_observations):\n",
    "        super(rewards_model, self).__init__()\n",
    "        #self.dropout = nn.Dropout(0.5)\n",
    "        self.layer1 = nn.Linear(n_observations, 128)\n",
    "        self.layer2 = nn.Linear(128, 1)\n",
    "        #self.layer3 = nn.Linear(128, 1)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        #x = self.dropout(x)\n",
    "        x = F.relu(self.layer1(x))\n",
    "        #x = F.relu(self.layer2(x))\n",
    "        #return self.layer3(x)\n",
    "        return self.layer2(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 100 #size of the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Starting up the Automated Controls for the Cypher AFM in AEcroscopy\n",
    "newexp1 = AECypher()\n",
    "newexp = AEBE(exe_path = \"C:\\STAFF Software\\Yongtao_AE\\BEPyAE 060523 01\\\\BEPyAE.exe\")\n",
    "newexp.init_BEPyAE(offline_development = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newexp.define_be_parms(be_parms_dict = {\"center_frequency_Hz_00\": 360, \"band_width_Hz_01\": image_size,\n",
    "                                       \"amplitude_V_02\": 2, \"phase_variation_03\": 1,\n",
    "                                       \"repeats_04\": 4, \"req_pulse_duration_s_05\": 4,\n",
    "                                       \"auto_smooth_ring_06\": 1}, \n",
    "                      do_create_be_waveform = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dset_pfm, dset_chns, dset_cs = newexp.raster_scan(raster_parms_dict = {\"scan_pixel\": 256, \"scan_x_start\": -1,\n",
    "                                                                       \"scan_y_start\": -1,\"scan_x_stop\": 1,\n",
    "                                                                 \"\"      \"scan_y_stop\":1}, file_name = \"vpfmm\")\n",
    "\n",
    "pola = dset_pfm[:,:,0] * np.cos(dset_pfm[:,:,3])\n",
    "image = 2/(pola.max() - pola.min()) * pola - 2/(pola.max() - pola.min()) * pola.min() - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newexp.define_BEPS_parameters(beps_parms_dict = {\"amplitude_V_00\": 8, \"step_per_cycle_03\": 128, \"num_cycles_04\": 2, \n",
    "                                                 \"measure_loops_07\": 0, \"transition_time_s_08\": 1E-3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = [50, 50]\n",
    "initialize = 30\n",
    "image_patch = 5\n",
    "image, spectra = norm_pola[:,:,0], norm_pola[:,:,::2][:,:,:64]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Train the autoencoder\n",
    "radius = int((image_patch - 1)/2)\n",
    "pos_X = []\n",
    "X = []\n",
    "y = []\n",
    "for i in range(radius, image_size - radius):\n",
    "    for j in range(radius, image_size - radius):\n",
    "        pos_X.append([i, j])\n",
    "        ind = pos_X[-1]\n",
    "        X.append( get_image_patch(image, ind, image_patch))\n",
    "        y.append(spectra[ind[0], ind[1]])\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "X = X.reshape([X.shape[0], 1, image_patch, image_patch])\n",
    "y = y.reshape([y.shape[0], 1, 64])\n",
    "\n",
    "autoencoder = im2im((image_patch, image_patch), 10)\n",
    "autoencoder = trainer(autoencoder, X[::10], X[::10], X, X, num_epochs=100, savename=\"im2spec_lv{}\".format(10)).run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1... Training loss: 1.04106... Test loss: 0.18565\n",
      "Epoch: 1... Training loss: 0.48533... Test loss: 0.07294\n",
      "Epoch: 1... Training loss: 0.34235... Test loss: 0.05664\n",
      "Epoch: 1... Training loss: 0.23398... Test loss: 0.0308\n",
      "Epoch: 1... Training loss: 0.16398... Test loss: 0.02233\n",
      "Epoch: 1... Training loss: 0.12011... Test loss: 0.03155\n",
      "Epoch: 1... Training loss: 0.09039... Test loss: 0.01073\n",
      "Epoch: 1... Training loss: 0.07274... Test loss: 0.02393\n",
      "Epoch: 1... Training loss: 0.06073... Test loss: 0.02399\n",
      "Epoch: 1... Training loss: 0.05487... Test loss: 0.00547\n",
      "Epoch: 1... Training loss: 0.05036... Test loss: 0.02497\n",
      "Epoch: 1... Training loss: 0.04548... Test loss: 0.00371\n",
      "Epoch: 1... Training loss: 0.04186... Test loss: 0.01884\n",
      "Epoch: 1... Training loss: 0.04038... Test loss: 0.00897\n",
      "Epoch: 1... Training loss: 0.03359... Test loss: 0.01327\n",
      "Epoch: 1... Training loss: 0.03238... Test loss: 0.00755\n",
      "Epoch: 1... Training loss: 0.02901... Test loss: 0.01697\n",
      "Epoch: 1... Training loss: 0.02736... Test loss: 0.00412\n",
      "Epoch: 1... Training loss: 0.02533... Test loss: 0.01732\n",
      "Epoch: 1... Training loss: 0.02442... Test loss: 0.00595\n",
      "Epoch: 1... Training loss: 0.02244... Test loss: 0.01616\n",
      "Epoch: 1... Training loss: 0.02179... Test loss: 0.00617\n",
      "Epoch: 1... Training loss: 0.02067... Test loss: 0.01669\n",
      "Epoch: 1... Training loss: 0.01904... Test loss: 0.00604\n",
      "Epoch: 1... Training loss: 0.01821... Test loss: 0.01538\n",
      "Epoch: 1... Training loss: 0.01725... Test loss: 0.00582\n",
      "Epoch: 1... Training loss: 0.01653... Test loss: 0.01413\n",
      "Epoch: 1... Training loss: 0.01568... Test loss: 0.01119\n",
      "Epoch: 1... Training loss: 0.01515... Test loss: 0.01006\n",
      "Epoch: 1... Training loss: 0.01432... Test loss: 0.01138\n",
      "Epoch: 1... Training loss: 0.01346... Test loss: 0.00922\n",
      "Epoch: 1... Training loss: 0.01303... Test loss: 0.01015\n",
      "Epoch: 1... Training loss: 0.0123... Test loss: 0.00826\n",
      "Epoch: 1... Training loss: 0.01224... Test loss: 0.00841\n",
      "Epoch: 1... Training loss: 0.01168... Test loss: 0.00614\n",
      "Epoch: 1... Training loss: 0.01154... Test loss: 0.01097\n",
      "Epoch: 1... Training loss: 0.01092... Test loss: 0.00468\n",
      "Epoch: 1... Training loss: 0.01061... Test loss: 0.00951\n",
      "Epoch: 1... Training loss: 0.01017... Test loss: 0.00504\n",
      "Epoch: 1... Training loss: 0.00989... Test loss: 0.00801\n",
      "Epoch: 1... Training loss: 0.00959... Test loss: 0.00469\n",
      "Epoch: 1... Training loss: 0.0094... Test loss: 0.00664\n",
      "Epoch: 1... Training loss: 0.00902... Test loss: 0.00463\n",
      "Epoch: 1... Training loss: 0.00874... Test loss: 0.00576\n",
      "Epoch: 1... Training loss: 0.00836... Test loss: 0.00449\n",
      "Epoch: 1... Training loss: 0.00811... Test loss: 0.00571\n",
      "Epoch: 1... Training loss: 0.0079... Test loss: 0.00523\n",
      "Epoch: 1... Training loss: 0.00775... Test loss: 0.00531\n",
      "Epoch: 1... Training loss: 0.00748... Test loss: 0.00484\n",
      "Epoch: 1... Training loss: 0.00711... Test loss: 0.00483\n",
      "Epoch: 1... Training loss: 0.00694... Test loss: 0.00463\n",
      "Epoch: 1... Training loss: 0.00671... Test loss: 0.00502\n",
      "Epoch: 1... Training loss: 0.00644... Test loss: 0.00443\n",
      "Epoch: 1... Training loss: 0.00619... Test loss: 0.00481\n",
      "Epoch: 1... Training loss: 0.00599... Test loss: 0.00438\n",
      "Epoch: 1... Training loss: 0.00571... Test loss: 0.00502\n",
      "Epoch: 1... Training loss: 0.0056... Test loss: 0.00459\n",
      "Epoch: 1... Training loss: 0.00538... Test loss: 0.00465\n",
      "Epoch: 1... Training loss: 0.00531... Test loss: 0.00524\n",
      "Epoch: 1... Training loss: 0.00513... Test loss: 0.00461\n",
      "Epoch: 1... Training loss: 0.00497... Test loss: 0.00479\n",
      "Epoch: 1... Training loss: 0.00475... Test loss: 0.00552\n",
      "Epoch: 1... Training loss: 0.00464... Test loss: 0.00428\n",
      "Epoch: 1... Training loss: 0.00448... Test loss: 0.00573\n",
      "Epoch: 1... Training loss: 0.0095... Test loss: 0.01332\n",
      "Epoch: 1... Training loss: 0.00889... Test loss: 0.01303\n",
      "Epoch: 1... Training loss: 0.00856... Test loss: 0.01391\n",
      "Epoch: 1... Training loss: 0.00781... Test loss: 0.0136\n",
      "Epoch: 1... Training loss: 0.00782... Test loss: 0.01279\n",
      "Epoch: 1... Training loss: 0.00761... Test loss: 0.00928\n",
      "Epoch: 1... Training loss: 0.00722... Test loss: 0.01457\n",
      "Epoch: 1... Training loss: 0.00744... Test loss: 0.01085\n",
      "Epoch: 1... Training loss: 0.0066... Test loss: 0.01282\n",
      "Epoch: 1... Training loss: 0.00663... Test loss: 0.00994\n",
      "Epoch: 1... Training loss: 0.00614... Test loss: 0.00976\n",
      "Epoch: 1... Training loss: 0.00597... Test loss: 0.00678\n",
      "Epoch: 1... Training loss: 0.0058... Test loss: 0.01001\n",
      "Epoch: 1... Training loss: 0.00549... Test loss: 0.00715\n",
      "Epoch: 1... Training loss: 0.00532... Test loss: 0.00948\n",
      "Epoch: 1... Training loss: 0.00522... Test loss: 0.00604\n",
      "Epoch: 1... Training loss: 0.00539... Test loss: 0.00737\n",
      "Epoch: 1... Training loss: 0.0049... Test loss: 0.00496\n",
      "Epoch: 1... Training loss: 0.00471... Test loss: 0.00481\n",
      "Epoch: 1... Training loss: 0.00478... Test loss: 0.00702\n",
      "Epoch: 1... Training loss: 0.00437... Test loss: 0.00542\n",
      "Epoch: 1... Training loss: 0.0043... Test loss: 0.00524\n",
      "Epoch: 1... Training loss: 0.00429... Test loss: 0.00433\n",
      "Epoch: 1... Training loss: 0.0042... Test loss: 0.00577\n",
      "Epoch: 1... Training loss: 0.00394... Test loss: 0.00583\n",
      "Epoch: 1... Training loss: 0.00392... Test loss: 0.00415\n",
      "Epoch: 1... Training loss: 0.00361... Test loss: 0.00483\n",
      "Epoch: 1... Training loss: 0.00356... Test loss: 0.00443\n",
      "Epoch: 1... Training loss: 0.00352... Test loss: 0.00444\n",
      "Epoch: 1... Training loss: 0.00331... Test loss: 0.00426\n",
      "Epoch: 1... Training loss: 0.00336... Test loss: 0.00364\n",
      "Epoch: 1... Training loss: 0.00336... Test loss: 0.00461\n",
      "Epoch: 1... Training loss: 0.00319... Test loss: 0.00303\n",
      "Epoch: 1... Training loss: 0.00311... Test loss: 0.00362\n",
      "Epoch: 1... Training loss: 0.00306... Test loss: 0.00358\n",
      "Epoch: 1... Training loss: 0.003... Test loss: 0.00372\n",
      "Epoch: 1... Training loss: 0.00282... Test loss: 0.0035\n",
      "Epoch: 1... Training loss: 0.00287... Test loss: 0.00297\n",
      "Epoch: 1... Training loss: 0.00284... Test loss: 0.00374\n",
      "Epoch: 1... Training loss: 0.00275... Test loss: 0.00286\n",
      "Epoch: 1... Training loss: 0.00273... Test loss: 0.00332\n",
      "Epoch: 1... Training loss: 0.00265... Test loss: 0.00356\n",
      "Epoch: 1... Training loss: 0.00251... Test loss: 0.00312\n",
      "Epoch: 1... Training loss: 0.00247... Test loss: 0.00312\n",
      "Epoch: 1... Training loss: 0.00244... Test loss: 0.00326\n",
      "Epoch: 1... Training loss: 0.00228... Test loss: 0.00285\n",
      "Epoch: 1... Training loss: 0.00239... Test loss: 0.00263\n",
      "Epoch: 1... Training loss: 0.00233... Test loss: 0.00281\n",
      "Epoch: 1... Training loss: 0.00218... Test loss: 0.00246\n",
      "Epoch: 1... Training loss: 0.00217... Test loss: 0.00272\n",
      "Epoch: 1... Training loss: 0.00206... Test loss: 0.00266\n",
      "Epoch: 1... Training loss: 0.00206... Test loss: 0.00212\n",
      "Epoch: 1... Training loss: 0.00197... Test loss: 0.00221\n",
      "Epoch: 1... Training loss: 0.0019... Test loss: 0.00237\n",
      "Epoch: 1... Training loss: 0.00192... Test loss: 0.00244\n",
      "Epoch: 1... Training loss: 0.00188... Test loss: 0.00184\n",
      "Epoch: 1... Training loss: 0.00182... Test loss: 0.00221\n",
      "Epoch: 1... Training loss: 0.0018... Test loss: 0.00196\n",
      "Epoch: 1... Training loss: 0.00167... Test loss: 0.00246\n",
      "Epoch: 1... Training loss: 0.00172... Test loss: 0.00218\n",
      "Epoch: 1... Training loss: 0.00158... Test loss: 0.00221\n",
      "Epoch: 1... Training loss: 0.00163... Test loss: 0.00192\n",
      "Epoch: 1... Training loss: 0.00157... Test loss: 0.00175\n",
      "Epoch: 1... Training loss: 0.00148... Test loss: 0.00165\n",
      "Epoch: 1... Training loss: 0.00146... Test loss: 0.0015\n",
      "Epoch: 1... Training loss: 0.00136... Test loss: 0.00163\n",
      "Epoch: 1... Training loss: 0.00135... Test loss: 0.0016\n",
      "Epoch: 1... Training loss: 0.00128... Test loss: 0.00182\n",
      "Epoch: 1... Training loss: 0.00126... Test loss: 0.00173\n",
      "Epoch: 1... Training loss: 0.00121... Test loss: 0.00161\n",
      "Epoch: 1... Training loss: 0.00121... Test loss: 0.00198\n",
      "Epoch: 1... Training loss: 0.00116... Test loss: 0.00123\n",
      "Epoch: 1... Training loss: 0.00109... Test loss: 0.00164\n",
      "Epoch: 1... Training loss: 0.00104... Test loss: 0.00124\n",
      "Epoch: 1... Training loss: 0.00105... Test loss: 0.00168\n",
      "Epoch: 1... Training loss: 0.00103... Test loss: 0.00108\n",
      "Epoch: 1... Training loss: 0.00097... Test loss: 0.00144\n",
      "Epoch: 1... Training loss: 0.00092... Test loss: 0.00103\n",
      "Epoch: 1... Training loss: 0.00088... Test loss: 0.0015\n",
      "Epoch: 1... Training loss: 0.00088... Test loss: 0.00086\n",
      "Epoch: 1... Training loss: 0.0009... Test loss: 0.00128\n",
      "Epoch: 1... Training loss: 0.00086... Test loss: 0.00071\n",
      "Epoch: 1... Training loss: 0.00083... Test loss: 0.00084\n",
      "Epoch: 1... Training loss: 0.00077... Test loss: 0.00073\n",
      "Epoch: 1... Training loss: 0.00078... Test loss: 0.00095\n",
      "Epoch: 1... Training loss: 0.00073... Test loss: 0.00076\n",
      "Epoch: 1... Training loss: 0.0007... Test loss: 0.001\n",
      "Epoch: 1... Training loss: 0.00073... Test loss: 0.0007\n",
      "Epoch: 1... Training loss: 0.00069... Test loss: 0.00091\n",
      "Epoch: 1... Training loss: 0.00068... Test loss: 0.00064\n",
      "Epoch: 1... Training loss: 0.00067... Test loss: 0.00088\n",
      "Epoch: 1... Training loss: 0.00066... Test loss: 0.00046\n",
      "Epoch: 1... Training loss: 0.00064... Test loss: 0.00083\n",
      "Epoch: 1... Training loss: 0.00059... Test loss: 0.00063\n",
      "Epoch: 1... Training loss: 0.00059... Test loss: 0.00085\n",
      "Epoch: 1... Training loss: 0.00057... Test loss: 0.00076\n",
      "Epoch: 1... Training loss: 0.0006... Test loss: 0.00073\n",
      "Epoch: 1... Training loss: 0.00054... Test loss: 0.00074\n",
      "Epoch: 1... Training loss: 0.00055... Test loss: 0.00054\n",
      "Epoch: 1... Training loss: 0.00052... Test loss: 0.00075\n",
      "Epoch: 1... Training loss: 0.00049... Test loss: 0.00059\n",
      "Epoch: 1... Training loss: 0.00048... Test loss: 0.00054\n",
      "Epoch: 1... Training loss: 0.0005... Test loss: 0.0005\n",
      "Epoch: 1... Training loss: 0.00047... Test loss: 0.00046\n",
      "Epoch: 1... Training loss: 0.00051... Test loss: 0.00059\n",
      "Epoch: 1... Training loss: 0.00046... Test loss: 0.00052\n",
      "Epoch: 1... Training loss: 0.00046... Test loss: 0.0005\n",
      "Epoch: 1... Training loss: 0.00042... Test loss: 0.00038\n",
      "Epoch: 1... Training loss: 0.00037... Test loss: 0.00038\n",
      "Epoch: 1... Training loss: 0.00038... Test loss: 0.00039\n",
      "Epoch: 1... Training loss: 0.00037... Test loss: 0.00031\n",
      "Epoch: 1... Training loss: 0.00037... Test loss: 0.0004\n",
      "Epoch: 1... Training loss: 0.00035... Test loss: 0.00037\n",
      "Epoch: 1... Training loss: 0.00035... Test loss: 0.0003\n",
      "Epoch: 1... Training loss: 0.00031... Test loss: 0.00039\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00028\n",
      "Epoch: 1... Training loss: 0.00029... Test loss: 0.00037\n",
      "Epoch: 1... Training loss: 0.00029... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00041\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00026... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.0003\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00024\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00012\n",
      "279.5870104462374\n",
      "Epoch: 1... Training loss: 1.07043... Test loss: 0.38962\n",
      "Epoch: 1... Training loss: 0.54673... Test loss: 0.17179\n",
      "Epoch: 1... Training loss: 0.33381... Test loss: 0.10247\n",
      "Epoch: 1... Training loss: 0.22961... Test loss: 0.0661\n",
      "Epoch: 1... Training loss: 0.17084... Test loss: 0.04697\n",
      "Epoch: 1... Training loss: 0.13671... Test loss: 0.04379\n",
      "Epoch: 1... Training loss: 0.10736... Test loss: 0.02674\n",
      "Epoch: 1... Training loss: 0.09035... Test loss: 0.02588\n",
      "Epoch: 1... Training loss: 0.07858... Test loss: 0.02272\n",
      "Epoch: 1... Training loss: 0.0696... Test loss: 0.04126\n",
      "Epoch: 1... Training loss: 0.06232... Test loss: 0.01822\n",
      "Epoch: 1... Training loss: 0.05673... Test loss: 0.0327\n",
      "Epoch: 1... Training loss: 0.05408... Test loss: 0.02377\n",
      "Epoch: 1... Training loss: 0.04486... Test loss: 0.03301\n",
      "Epoch: 1... Training loss: 0.04288... Test loss: 0.01327\n",
      "Epoch: 1... Training loss: 0.03759... Test loss: 0.0221\n",
      "Epoch: 1... Training loss: 0.0366... Test loss: 0.01139\n",
      "Epoch: 1... Training loss: 0.03326... Test loss: 0.02401\n",
      "Epoch: 1... Training loss: 0.03242... Test loss: 0.0196\n",
      "Epoch: 1... Training loss: 0.03022... Test loss: 0.01551\n",
      "Epoch: 1... Training loss: 0.02825... Test loss: 0.02391\n",
      "Epoch: 1... Training loss: 0.0276... Test loss: 0.01218\n",
      "Epoch: 1... Training loss: 0.02513... Test loss: 0.0231\n",
      "Epoch: 1... Training loss: 0.02333... Test loss: 0.01619\n",
      "Epoch: 1... Training loss: 0.02114... Test loss: 0.02572\n",
      "Epoch: 1... Training loss: 0.02146... Test loss: 0.01131\n",
      "Epoch: 1... Training loss: 0.01981... Test loss: 0.0216\n",
      "Epoch: 1... Training loss: 0.01856... Test loss: 0.01124\n",
      "Epoch: 1... Training loss: 0.01797... Test loss: 0.01443\n",
      "Epoch: 1... Training loss: 0.0172... Test loss: 0.01759\n",
      "Epoch: 1... Training loss: 0.01694... Test loss: 0.00981\n",
      "Epoch: 1... Training loss: 0.01544... Test loss: 0.0174\n",
      "Epoch: 1... Training loss: 0.01495... Test loss: 0.01552\n",
      "Epoch: 1... Training loss: 0.01458... Test loss: 0.00878\n",
      "Epoch: 1... Training loss: 0.01385... Test loss: 0.0149\n",
      "Epoch: 1... Training loss: 0.01335... Test loss: 0.00963\n",
      "Epoch: 1... Training loss: 0.01332... Test loss: 0.01291\n",
      "Epoch: 1... Training loss: 0.01262... Test loss: 0.01323\n",
      "Epoch: 1... Training loss: 0.01225... Test loss: 0.01102\n",
      "Epoch: 1... Training loss: 0.0117... Test loss: 0.01096\n",
      "Epoch: 1... Training loss: 0.0112... Test loss: 0.01147\n",
      "Epoch: 1... Training loss: 0.01082... Test loss: 0.00964\n",
      "Epoch: 1... Training loss: 0.01055... Test loss: 0.01146\n",
      "Epoch: 1... Training loss: 0.01035... Test loss: 0.00835\n",
      "Epoch: 1... Training loss: 0.0099... Test loss: 0.01137\n",
      "Epoch: 1... Training loss: 0.00957... Test loss: 0.00771\n",
      "Epoch: 1... Training loss: 0.00929... Test loss: 0.01034\n",
      "Epoch: 1... Training loss: 0.00892... Test loss: 0.00836\n",
      "Epoch: 1... Training loss: 0.00849... Test loss: 0.01153\n",
      "Epoch: 1... Training loss: 0.00826... Test loss: 0.00711\n",
      "Epoch: 1... Training loss: 0.00786... Test loss: 0.01136\n",
      "Epoch: 1... Training loss: 0.00776... Test loss: 0.00738\n",
      "Epoch: 1... Training loss: 0.00729... Test loss: 0.00986\n",
      "Epoch: 1... Training loss: 0.00727... Test loss: 0.00675\n",
      "Epoch: 1... Training loss: 0.00691... Test loss: 0.00944\n",
      "Epoch: 1... Training loss: 0.00678... Test loss: 0.00756\n",
      "Epoch: 1... Training loss: 0.00656... Test loss: 0.00838\n",
      "Epoch: 1... Training loss: 0.00644... Test loss: 0.00763\n",
      "Epoch: 1... Training loss: 0.00628... Test loss: 0.00615\n",
      "Epoch: 1... Training loss: 0.0061... Test loss: 0.0096\n",
      "Epoch: 1... Training loss: 0.00595... Test loss: 0.00784\n",
      "Epoch: 1... Training loss: 0.00588... Test loss: 0.0071\n",
      "Epoch: 1... Training loss: 0.00554... Test loss: 0.00654\n",
      "Epoch: 1... Training loss: 0.00546... Test loss: 0.00632\n",
      "Epoch: 1... Training loss: 0.00935... Test loss: 0.02213\n",
      "Epoch: 1... Training loss: 0.00968... Test loss: 0.01294\n",
      "Epoch: 1... Training loss: 0.00899... Test loss: 0.01265\n",
      "Epoch: 1... Training loss: 0.00996... Test loss: 0.01025\n",
      "Epoch: 1... Training loss: 0.00861... Test loss: 0.01883\n",
      "Epoch: 1... Training loss: 0.0102... Test loss: 0.01334\n",
      "Epoch: 1... Training loss: 0.00901... Test loss: 0.01242\n",
      "Epoch: 1... Training loss: 0.00825... Test loss: 0.00914\n",
      "Epoch: 1... Training loss: 0.00785... Test loss: 0.01741\n",
      "Epoch: 1... Training loss: 0.00805... Test loss: 0.00963\n",
      "Epoch: 1... Training loss: 0.00785... Test loss: 0.01483\n",
      "Epoch: 1... Training loss: 0.00691... Test loss: 0.0113\n",
      "Epoch: 1... Training loss: 0.00682... Test loss: 0.01143\n",
      "Epoch: 1... Training loss: 0.00636... Test loss: 0.01136\n",
      "Epoch: 1... Training loss: 0.00647... Test loss: 0.0089\n",
      "Epoch: 1... Training loss: 0.00565... Test loss: 0.01001\n",
      "Epoch: 1... Training loss: 0.00591... Test loss: 0.0073\n",
      "Epoch: 1... Training loss: 0.00547... Test loss: 0.00838\n",
      "Epoch: 1... Training loss: 0.00529... Test loss: 0.00638\n",
      "Epoch: 1... Training loss: 0.00493... Test loss: 0.00908\n",
      "Epoch: 1... Training loss: 0.0051... Test loss: 0.00533\n",
      "Epoch: 1... Training loss: 0.00485... Test loss: 0.00724\n",
      "Epoch: 1... Training loss: 0.0045... Test loss: 0.00608\n",
      "Epoch: 1... Training loss: 0.00459... Test loss: 0.00651\n",
      "Epoch: 1... Training loss: 0.00437... Test loss: 0.00542\n",
      "Epoch: 1... Training loss: 0.00421... Test loss: 0.00611\n",
      "Epoch: 1... Training loss: 0.00397... Test loss: 0.00458\n",
      "Epoch: 1... Training loss: 0.00375... Test loss: 0.00516\n",
      "Epoch: 1... Training loss: 0.00378... Test loss: 0.00384\n",
      "Epoch: 1... Training loss: 0.0036... Test loss: 0.00429\n",
      "Epoch: 1... Training loss: 0.00356... Test loss: 0.00307\n",
      "Epoch: 1... Training loss: 0.00343... Test loss: 0.00421\n",
      "Epoch: 1... Training loss: 0.00332... Test loss: 0.00311\n",
      "Epoch: 1... Training loss: 0.0032... Test loss: 0.0049\n",
      "Epoch: 1... Training loss: 0.00315... Test loss: 0.00348\n",
      "Epoch: 1... Training loss: 0.00302... Test loss: 0.00378\n",
      "Epoch: 1... Training loss: 0.0028... Test loss: 0.0034\n",
      "Epoch: 1... Training loss: 0.00276... Test loss: 0.00373\n",
      "Epoch: 1... Training loss: 0.00259... Test loss: 0.00323\n",
      "Epoch: 1... Training loss: 0.00269... Test loss: 0.00295\n",
      "Epoch: 1... Training loss: 0.00237... Test loss: 0.00357\n",
      "Epoch: 1... Training loss: 0.00236... Test loss: 0.00311\n",
      "Epoch: 1... Training loss: 0.0023... Test loss: 0.00347\n",
      "Epoch: 1... Training loss: 0.00226... Test loss: 0.00225\n",
      "Epoch: 1... Training loss: 0.00219... Test loss: 0.00316\n",
      "Epoch: 1... Training loss: 0.00205... Test loss: 0.0025\n",
      "Epoch: 1... Training loss: 0.00199... Test loss: 0.00293\n",
      "Epoch: 1... Training loss: 0.00189... Test loss: 0.00203\n",
      "Epoch: 1... Training loss: 0.00182... Test loss: 0.00256\n",
      "Epoch: 1... Training loss: 0.00181... Test loss: 0.00202\n",
      "Epoch: 1... Training loss: 0.00169... Test loss: 0.00211\n",
      "Epoch: 1... Training loss: 0.00167... Test loss: 0.0019\n",
      "Epoch: 1... Training loss: 0.00171... Test loss: 0.00232\n",
      "Epoch: 1... Training loss: 0.00154... Test loss: 0.00188\n",
      "Epoch: 1... Training loss: 0.00149... Test loss: 0.00173\n",
      "Epoch: 1... Training loss: 0.00135... Test loss: 0.00184\n",
      "Epoch: 1... Training loss: 0.00132... Test loss: 0.00161\n",
      "Epoch: 1... Training loss: 0.00133... Test loss: 0.0017\n",
      "Epoch: 1... Training loss: 0.00123... Test loss: 0.00119\n",
      "Epoch: 1... Training loss: 0.00126... Test loss: 0.0015\n",
      "Epoch: 1... Training loss: 0.00115... Test loss: 0.00112\n",
      "Epoch: 1... Training loss: 0.00117... Test loss: 0.00134\n",
      "Epoch: 1... Training loss: 0.00111... Test loss: 0.00134\n",
      "Epoch: 1... Training loss: 0.00101... Test loss: 0.00123\n",
      "Epoch: 1... Training loss: 0.00102... Test loss: 0.00124\n",
      "Epoch: 1... Training loss: 0.00098... Test loss: 0.00119\n",
      "Epoch: 1... Training loss: 0.00095... Test loss: 0.00124\n",
      "Epoch: 1... Training loss: 0.00091... Test loss: 0.00092\n",
      "Epoch: 1... Training loss: 0.00082... Test loss: 0.00097\n",
      "Epoch: 1... Training loss: 0.00082... Test loss: 0.0009\n",
      "Epoch: 1... Training loss: 0.00079... Test loss: 0.00097\n",
      "Epoch: 1... Training loss: 0.00073... Test loss: 0.00076\n",
      "Epoch: 1... Training loss: 0.00068... Test loss: 0.00093\n",
      "Epoch: 1... Training loss: 0.00068... Test loss: 0.00068\n",
      "Epoch: 1... Training loss: 0.00062... Test loss: 0.00088\n",
      "Epoch: 1... Training loss: 0.00058... Test loss: 0.00055\n",
      "Epoch: 1... Training loss: 0.00057... Test loss: 0.00086\n",
      "Epoch: 1... Training loss: 0.00057... Test loss: 0.0005\n",
      "Epoch: 1... Training loss: 0.00047... Test loss: 0.00063\n",
      "Epoch: 1... Training loss: 0.00048... Test loss: 0.0005\n",
      "Epoch: 1... Training loss: 0.00041... Test loss: 0.00055\n",
      "Epoch: 1... Training loss: 0.00042... Test loss: 0.00042\n",
      "Epoch: 1... Training loss: 0.00039... Test loss: 0.00049\n",
      "Epoch: 1... Training loss: 0.00039... Test loss: 0.0004\n",
      "Epoch: 1... Training loss: 0.00039... Test loss: 0.00037\n",
      "Epoch: 1... Training loss: 0.00038... Test loss: 0.00043\n",
      "Epoch: 1... Training loss: 0.00038... Test loss: 0.00039\n",
      "Epoch: 1... Training loss: 0.00034... Test loss: 0.00043\n",
      "Epoch: 1... Training loss: 0.00034... Test loss: 0.0003\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00037\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00039\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.00032... Test loss: 0.00034\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00035\n",
      "Epoch: 1... Training loss: 0.00026... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00026... Test loss: 0.00043\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00034\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00031\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00024\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 8e-05\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 8e-05... Test loss: 0.00014\n",
      "268.1097382977605\n",
      "Epoch: 1... Training loss: 1.21278... Test loss: 0.52708\n",
      "Epoch: 1... Training loss: 0.57239... Test loss: 0.20537\n",
      "Epoch: 1... Training loss: 0.30535... Test loss: 0.11285\n",
      "Epoch: 1... Training loss: 0.19808... Test loss: 0.07622\n",
      "Epoch: 1... Training loss: 0.13971... Test loss: 0.06307\n",
      "Epoch: 1... Training loss: 0.10963... Test loss: 0.04878\n",
      "Epoch: 1... Training loss: 0.09336... Test loss: 0.02536\n",
      "Epoch: 1... Training loss: 0.07729... Test loss: 0.045\n",
      "Epoch: 1... Training loss: 0.06993... Test loss: 0.01736\n",
      "Epoch: 1... Training loss: 0.05834... Test loss: 0.02628\n",
      "Epoch: 1... Training loss: 0.05308... Test loss: 0.01854\n",
      "Epoch: 1... Training loss: 0.04622... Test loss: 0.01856\n",
      "Epoch: 1... Training loss: 0.04162... Test loss: 0.02772\n",
      "Epoch: 1... Training loss: 0.03806... Test loss: 0.02255\n",
      "Epoch: 1... Training loss: 0.03585... Test loss: 0.02354\n",
      "Epoch: 1... Training loss: 0.0337... Test loss: 0.02156\n",
      "Epoch: 1... Training loss: 0.03262... Test loss: 0.01055\n",
      "Epoch: 1... Training loss: 0.03046... Test loss: 0.02507\n",
      "Epoch: 1... Training loss: 0.02748... Test loss: 0.0144\n",
      "Epoch: 1... Training loss: 0.0263... Test loss: 0.02619\n",
      "Epoch: 1... Training loss: 0.02496... Test loss: 0.0134\n",
      "Epoch: 1... Training loss: 0.02396... Test loss: 0.02088\n",
      "Epoch: 1... Training loss: 0.02322... Test loss: 0.01083\n",
      "Epoch: 1... Training loss: 0.02173... Test loss: 0.01348\n",
      "Epoch: 1... Training loss: 0.02066... Test loss: 0.01289\n",
      "Epoch: 1... Training loss: 0.01975... Test loss: 0.00829\n",
      "Epoch: 1... Training loss: 0.01895... Test loss: 0.01695\n",
      "Epoch: 1... Training loss: 0.01822... Test loss: 0.00663\n",
      "Epoch: 1... Training loss: 0.0174... Test loss: 0.01568\n",
      "Epoch: 1... Training loss: 0.01631... Test loss: 0.00772\n",
      "Epoch: 1... Training loss: 0.01584... Test loss: 0.011\n",
      "Epoch: 1... Training loss: 0.01534... Test loss: 0.01379\n",
      "Epoch: 1... Training loss: 0.0146... Test loss: 0.0098\n",
      "Epoch: 1... Training loss: 0.01424... Test loss: 0.01115\n",
      "Epoch: 1... Training loss: 0.01385... Test loss: 0.00993\n",
      "Epoch: 1... Training loss: 0.01343... Test loss: 0.00956\n",
      "Epoch: 1... Training loss: 0.01286... Test loss: 0.01009\n",
      "Epoch: 1... Training loss: 0.0123... Test loss: 0.00836\n",
      "Epoch: 1... Training loss: 0.01178... Test loss: 0.00998\n",
      "Epoch: 1... Training loss: 0.01155... Test loss: 0.00688\n",
      "Epoch: 1... Training loss: 0.01126... Test loss: 0.00977\n",
      "Epoch: 1... Training loss: 0.01115... Test loss: 0.00638\n",
      "Epoch: 1... Training loss: 0.01055... Test loss: 0.01019\n",
      "Epoch: 1... Training loss: 0.01011... Test loss: 0.00706\n",
      "Epoch: 1... Training loss: 0.00963... Test loss: 0.0091\n",
      "Epoch: 1... Training loss: 0.00936... Test loss: 0.0062\n",
      "Epoch: 1... Training loss: 0.009... Test loss: 0.00832\n",
      "Epoch: 1... Training loss: 0.00868... Test loss: 0.00646\n",
      "Epoch: 1... Training loss: 0.0084... Test loss: 0.00794\n",
      "Epoch: 1... Training loss: 0.00816... Test loss: 0.00701\n",
      "Epoch: 1... Training loss: 0.00793... Test loss: 0.00672\n",
      "Epoch: 1... Training loss: 0.00772... Test loss: 0.0067\n",
      "Epoch: 1... Training loss: 0.00746... Test loss: 0.00649\n",
      "Epoch: 1... Training loss: 0.00723... Test loss: 0.00609\n",
      "Epoch: 1... Training loss: 0.00709... Test loss: 0.00671\n",
      "Epoch: 1... Training loss: 0.00678... Test loss: 0.00545\n",
      "Epoch: 1... Training loss: 0.0067... Test loss: 0.00777\n",
      "Epoch: 1... Training loss: 0.00647... Test loss: 0.00576\n",
      "Epoch: 1... Training loss: 0.00627... Test loss: 0.00695\n",
      "Epoch: 1... Training loss: 0.00601... Test loss: 0.00535\n",
      "Epoch: 1... Training loss: 0.00592... Test loss: 0.00666\n",
      "Epoch: 1... Training loss: 0.00572... Test loss: 0.00576\n",
      "Epoch: 1... Training loss: 0.00557... Test loss: 0.00523\n",
      "Epoch: 1... Training loss: 0.00546... Test loss: 0.00622\n",
      "Epoch: 1... Training loss: 0.01004... Test loss: 0.00908\n",
      "Epoch: 1... Training loss: 0.01135... Test loss: 0.01398\n",
      "Epoch: 1... Training loss: 0.00961... Test loss: 0.01232\n",
      "Epoch: 1... Training loss: 0.01001... Test loss: 0.01123\n",
      "Epoch: 1... Training loss: 0.00893... Test loss: 0.01412\n",
      "Epoch: 1... Training loss: 0.00948... Test loss: 0.0117\n",
      "Epoch: 1... Training loss: 0.00819... Test loss: 0.01174\n",
      "Epoch: 1... Training loss: 0.00861... Test loss: 0.00969\n",
      "Epoch: 1... Training loss: 0.00812... Test loss: 0.01113\n",
      "Epoch: 1... Training loss: 0.00902... Test loss: 0.00867\n",
      "Epoch: 1... Training loss: 0.00743... Test loss: 0.0121\n",
      "Epoch: 1... Training loss: 0.00752... Test loss: 0.00779\n",
      "Epoch: 1... Training loss: 0.00717... Test loss: 0.01021\n",
      "Epoch: 1... Training loss: 0.00646... Test loss: 0.00888\n",
      "Epoch: 1... Training loss: 0.00638... Test loss: 0.00823\n",
      "Epoch: 1... Training loss: 0.00622... Test loss: 0.00745\n",
      "Epoch: 1... Training loss: 0.00626... Test loss: 0.00754\n",
      "Epoch: 1... Training loss: 0.00585... Test loss: 0.00723\n",
      "Epoch: 1... Training loss: 0.00542... Test loss: 0.00594\n",
      "Epoch: 1... Training loss: 0.00525... Test loss: 0.00676\n",
      "Epoch: 1... Training loss: 0.00541... Test loss: 0.00596\n",
      "Epoch: 1... Training loss: 0.00516... Test loss: 0.00568\n",
      "Epoch: 1... Training loss: 0.00511... Test loss: 0.0073\n",
      "Epoch: 1... Training loss: 0.00482... Test loss: 0.00632\n",
      "Epoch: 1... Training loss: 0.00466... Test loss: 0.00533\n",
      "Epoch: 1... Training loss: 0.00432... Test loss: 0.00597\n",
      "Epoch: 1... Training loss: 0.00416... Test loss: 0.00516\n",
      "Epoch: 1... Training loss: 0.00413... Test loss: 0.00571\n",
      "Epoch: 1... Training loss: 0.00406... Test loss: 0.00445\n",
      "Epoch: 1... Training loss: 0.00357... Test loss: 0.00468\n",
      "Epoch: 1... Training loss: 0.00357... Test loss: 0.00405\n",
      "Epoch: 1... Training loss: 0.00352... Test loss: 0.00398\n",
      "Epoch: 1... Training loss: 0.00332... Test loss: 0.00447\n",
      "Epoch: 1... Training loss: 0.00326... Test loss: 0.00371\n",
      "Epoch: 1... Training loss: 0.00317... Test loss: 0.00386\n",
      "Epoch: 1... Training loss: 0.003... Test loss: 0.00285\n",
      "Epoch: 1... Training loss: 0.003... Test loss: 0.00351\n",
      "Epoch: 1... Training loss: 0.00274... Test loss: 0.00338\n",
      "Epoch: 1... Training loss: 0.00274... Test loss: 0.00338\n",
      "Epoch: 1... Training loss: 0.0027... Test loss: 0.00303\n",
      "Epoch: 1... Training loss: 0.00259... Test loss: 0.00287\n",
      "Epoch: 1... Training loss: 0.00257... Test loss: 0.00318\n",
      "Epoch: 1... Training loss: 0.00248... Test loss: 0.00273\n",
      "Epoch: 1... Training loss: 0.00241... Test loss: 0.00305\n",
      "Epoch: 1... Training loss: 0.00226... Test loss: 0.00302\n",
      "Epoch: 1... Training loss: 0.00229... Test loss: 0.00248\n",
      "Epoch: 1... Training loss: 0.00215... Test loss: 0.00259\n",
      "Epoch: 1... Training loss: 0.00208... Test loss: 0.00203\n",
      "Epoch: 1... Training loss: 0.00194... Test loss: 0.0028\n",
      "Epoch: 1... Training loss: 0.00198... Test loss: 0.00176\n",
      "Epoch: 1... Training loss: 0.00185... Test loss: 0.00289\n",
      "Epoch: 1... Training loss: 0.00178... Test loss: 0.00224\n",
      "Epoch: 1... Training loss: 0.00172... Test loss: 0.00207\n",
      "Epoch: 1... Training loss: 0.00164... Test loss: 0.0021\n",
      "Epoch: 1... Training loss: 0.0017... Test loss: 0.00206\n",
      "Epoch: 1... Training loss: 0.00156... Test loss: 0.00183\n",
      "Epoch: 1... Training loss: 0.00152... Test loss: 0.00171\n",
      "Epoch: 1... Training loss: 0.00149... Test loss: 0.00181\n",
      "Epoch: 1... Training loss: 0.00142... Test loss: 0.00144\n",
      "Epoch: 1... Training loss: 0.00135... Test loss: 0.00166\n",
      "Epoch: 1... Training loss: 0.00132... Test loss: 0.00196\n",
      "Epoch: 1... Training loss: 0.00126... Test loss: 0.00142\n",
      "Epoch: 1... Training loss: 0.00119... Test loss: 0.00157\n",
      "Epoch: 1... Training loss: 0.00116... Test loss: 0.00132\n",
      "Epoch: 1... Training loss: 0.00117... Test loss: 0.00115\n",
      "Epoch: 1... Training loss: 0.00104... Test loss: 0.00124\n",
      "Epoch: 1... Training loss: 0.00116... Test loss: 0.001\n",
      "Epoch: 1... Training loss: 0.00095... Test loss: 0.00102\n",
      "Epoch: 1... Training loss: 0.00098... Test loss: 0.00102\n",
      "Epoch: 1... Training loss: 0.00089... Test loss: 0.00099\n",
      "Epoch: 1... Training loss: 0.00087... Test loss: 0.00088\n",
      "Epoch: 1... Training loss: 0.00079... Test loss: 0.00081\n",
      "Epoch: 1... Training loss: 0.0008... Test loss: 0.00091\n",
      "Epoch: 1... Training loss: 0.00076... Test loss: 0.00088\n",
      "Epoch: 1... Training loss: 0.00072... Test loss: 0.00104\n",
      "Epoch: 1... Training loss: 0.00068... Test loss: 0.00073\n",
      "Epoch: 1... Training loss: 0.00064... Test loss: 0.00108\n",
      "Epoch: 1... Training loss: 0.00062... Test loss: 0.00063\n",
      "Epoch: 1... Training loss: 0.0006... Test loss: 0.00066\n",
      "Epoch: 1... Training loss: 0.00056... Test loss: 0.00045\n",
      "Epoch: 1... Training loss: 0.00052... Test loss: 0.00071\n",
      "Epoch: 1... Training loss: 0.00052... Test loss: 0.00055\n",
      "Epoch: 1... Training loss: 0.0005... Test loss: 0.00054\n",
      "Epoch: 1... Training loss: 0.00057... Test loss: 0.0004\n",
      "Epoch: 1... Training loss: 0.00043... Test loss: 0.00057\n",
      "Epoch: 1... Training loss: 0.00043... Test loss: 0.00038\n",
      "Epoch: 1... Training loss: 0.00037... Test loss: 0.00044\n",
      "Epoch: 1... Training loss: 0.00042... Test loss: 0.00037\n",
      "Epoch: 1... Training loss: 0.00036... Test loss: 0.00055\n",
      "Epoch: 1... Training loss: 0.00037... Test loss: 0.00043\n",
      "Epoch: 1... Training loss: 0.00038... Test loss: 0.0005\n",
      "Epoch: 1... Training loss: 0.00033... Test loss: 0.0004\n",
      "Epoch: 1... Training loss: 0.00033... Test loss: 0.00045\n",
      "Epoch: 1... Training loss: 0.00029... Test loss: 0.0004\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00039\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.00037\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00036\n",
      "Epoch: 1... Training loss: 0.00026... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.00029... Test loss: 0.0003\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 8e-05\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 8e-05... Test loss: 8e-05\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 7e-05\n",
      "Epoch: 1... Training loss: 8e-05... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 8e-05\n",
      "Epoch: 1... Training loss: 8e-05... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 8e-05... Test loss: 8e-05\n",
      "Epoch: 1... Training loss: 8e-05... Test loss: 9e-05\n",
      "245.71763481904054\n",
      "Epoch: 1... Training loss: 0.90593... Test loss: 0.29892\n",
      "Epoch: 1... Training loss: 0.47028... Test loss: 0.14827\n",
      "Epoch: 1... Training loss: 0.2727... Test loss: 0.07516\n",
      "Epoch: 1... Training loss: 0.18307... Test loss: 0.0602\n",
      "Epoch: 1... Training loss: 0.14389... Test loss: 0.04798\n",
      "Epoch: 1... Training loss: 0.11266... Test loss: 0.05743\n",
      "Epoch: 1... Training loss: 0.08982... Test loss: 0.03375\n",
      "Epoch: 1... Training loss: 0.07518... Test loss: 0.03099\n",
      "Epoch: 1... Training loss: 0.06179... Test loss: 0.02416\n",
      "Epoch: 1... Training loss: 0.05571... Test loss: 0.0274\n",
      "Epoch: 1... Training loss: 0.05026... Test loss: 0.02164\n",
      "Epoch: 1... Training loss: 0.04592... Test loss: 0.03333\n",
      "Epoch: 1... Training loss: 0.04223... Test loss: 0.0242\n",
      "Epoch: 1... Training loss: 0.03855... Test loss: 0.02983\n",
      "Epoch: 1... Training loss: 0.03698... Test loss: 0.02019\n",
      "Epoch: 1... Training loss: 0.0344... Test loss: 0.02983\n",
      "Epoch: 1... Training loss: 0.03338... Test loss: 0.01197\n",
      "Epoch: 1... Training loss: 0.03103... Test loss: 0.03474\n",
      "Epoch: 1... Training loss: 0.02941... Test loss: 0.01632\n",
      "Epoch: 1... Training loss: 0.0273... Test loss: 0.01724\n",
      "Epoch: 1... Training loss: 0.02532... Test loss: 0.02872\n",
      "Epoch: 1... Training loss: 0.02441... Test loss: 0.00761\n",
      "Epoch: 1... Training loss: 0.02322... Test loss: 0.02026\n",
      "Epoch: 1... Training loss: 0.02227... Test loss: 0.00744\n",
      "Epoch: 1... Training loss: 0.02121... Test loss: 0.01711\n",
      "Epoch: 1... Training loss: 0.02017... Test loss: 0.00832\n",
      "Epoch: 1... Training loss: 0.01959... Test loss: 0.02022\n",
      "Epoch: 1... Training loss: 0.01885... Test loss: 0.00766\n",
      "Epoch: 1... Training loss: 0.01835... Test loss: 0.01536\n",
      "Epoch: 1... Training loss: 0.01744... Test loss: 0.00797\n",
      "Epoch: 1... Training loss: 0.01718... Test loss: 0.01511\n",
      "Epoch: 1... Training loss: 0.01658... Test loss: 0.0075\n",
      "Epoch: 1... Training loss: 0.01608... Test loss: 0.01378\n",
      "Epoch: 1... Training loss: 0.0154... Test loss: 0.00884\n",
      "Epoch: 1... Training loss: 0.0148... Test loss: 0.01338\n",
      "Epoch: 1... Training loss: 0.01436... Test loss: 0.00774\n",
      "Epoch: 1... Training loss: 0.01382... Test loss: 0.01346\n",
      "Epoch: 1... Training loss: 0.01346... Test loss: 0.01091\n",
      "Epoch: 1... Training loss: 0.01292... Test loss: 0.01017\n",
      "Epoch: 1... Training loss: 0.0127... Test loss: 0.0132\n",
      "Epoch: 1... Training loss: 0.01214... Test loss: 0.00883\n",
      "Epoch: 1... Training loss: 0.01188... Test loss: 0.01339\n",
      "Epoch: 1... Training loss: 0.01118... Test loss: 0.00833\n",
      "Epoch: 1... Training loss: 0.01104... Test loss: 0.0123\n",
      "Epoch: 1... Training loss: 0.01066... Test loss: 0.00829\n",
      "Epoch: 1... Training loss: 0.01028... Test loss: 0.01124\n",
      "Epoch: 1... Training loss: 0.00981... Test loss: 0.00821\n",
      "Epoch: 1... Training loss: 0.00968... Test loss: 0.00954\n",
      "Epoch: 1... Training loss: 0.0092... Test loss: 0.00984\n",
      "Epoch: 1... Training loss: 0.00898... Test loss: 0.00797\n",
      "Epoch: 1... Training loss: 0.00856... Test loss: 0.01031\n",
      "Epoch: 1... Training loss: 0.00847... Test loss: 0.00759\n",
      "Epoch: 1... Training loss: 0.00817... Test loss: 0.00975\n",
      "Epoch: 1... Training loss: 0.00793... Test loss: 0.00655\n",
      "Epoch: 1... Training loss: 0.00756... Test loss: 0.00835\n",
      "Epoch: 1... Training loss: 0.00745... Test loss: 0.00611\n",
      "Epoch: 1... Training loss: 0.00728... Test loss: 0.00811\n",
      "Epoch: 1... Training loss: 0.00704... Test loss: 0.00615\n",
      "Epoch: 1... Training loss: 0.00678... Test loss: 0.00808\n",
      "Epoch: 1... Training loss: 0.00647... Test loss: 0.00671\n",
      "Epoch: 1... Training loss: 0.00626... Test loss: 0.00673\n",
      "Epoch: 1... Training loss: 0.0062... Test loss: 0.0071\n",
      "Epoch: 1... Training loss: 0.00591... Test loss: 0.00566\n",
      "Epoch: 1... Training loss: 0.00578... Test loss: 0.00599\n",
      "Epoch: 1... Training loss: 0.00988... Test loss: 0.01051\n",
      "Epoch: 1... Training loss: 0.01199... Test loss: 0.01208\n",
      "Epoch: 1... Training loss: 0.00917... Test loss: 0.01213\n",
      "Epoch: 1... Training loss: 0.01017... Test loss: 0.0124\n",
      "Epoch: 1... Training loss: 0.01027... Test loss: 0.01179\n",
      "Epoch: 1... Training loss: 0.00884... Test loss: 0.01764\n",
      "Epoch: 1... Training loss: 0.00892... Test loss: 0.01384\n",
      "Epoch: 1... Training loss: 0.00845... Test loss: 0.01254\n",
      "Epoch: 1... Training loss: 0.00813... Test loss: 0.01295\n",
      "Epoch: 1... Training loss: 0.00761... Test loss: 0.01016\n",
      "Epoch: 1... Training loss: 0.00801... Test loss: 0.01314\n",
      "Epoch: 1... Training loss: 0.00801... Test loss: 0.01155\n",
      "Epoch: 1... Training loss: 0.00776... Test loss: 0.01025\n",
      "Epoch: 1... Training loss: 0.00689... Test loss: 0.01293\n",
      "Epoch: 1... Training loss: 0.00641... Test loss: 0.00929\n",
      "Epoch: 1... Training loss: 0.00598... Test loss: 0.01051\n",
      "Epoch: 1... Training loss: 0.00613... Test loss: 0.007\n",
      "Epoch: 1... Training loss: 0.00613... Test loss: 0.00824\n",
      "Epoch: 1... Training loss: 0.00579... Test loss: 0.00722\n",
      "Epoch: 1... Training loss: 0.00529... Test loss: 0.00712\n",
      "Epoch: 1... Training loss: 0.00574... Test loss: 0.00614\n",
      "Epoch: 1... Training loss: 0.00522... Test loss: 0.00685\n",
      "Epoch: 1... Training loss: 0.00502... Test loss: 0.0059\n",
      "Epoch: 1... Training loss: 0.00461... Test loss: 0.00564\n",
      "Epoch: 1... Training loss: 0.00459... Test loss: 0.0063\n",
      "Epoch: 1... Training loss: 0.00429... Test loss: 0.00521\n",
      "Epoch: 1... Training loss: 0.00408... Test loss: 0.00658\n",
      "Epoch: 1... Training loss: 0.00424... Test loss: 0.00436\n",
      "Epoch: 1... Training loss: 0.00402... Test loss: 0.00562\n",
      "Epoch: 1... Training loss: 0.00371... Test loss: 0.00392\n",
      "Epoch: 1... Training loss: 0.00379... Test loss: 0.0055\n",
      "Epoch: 1... Training loss: 0.00361... Test loss: 0.0041\n",
      "Epoch: 1... Training loss: 0.00345... Test loss: 0.00442\n",
      "Epoch: 1... Training loss: 0.00351... Test loss: 0.00397\n",
      "Epoch: 1... Training loss: 0.00327... Test loss: 0.00431\n",
      "Epoch: 1... Training loss: 0.00318... Test loss: 0.00385\n",
      "Epoch: 1... Training loss: 0.00313... Test loss: 0.00361\n",
      "Epoch: 1... Training loss: 0.00299... Test loss: 0.00389\n",
      "Epoch: 1... Training loss: 0.00289... Test loss: 0.00343\n",
      "Epoch: 1... Training loss: 0.00287... Test loss: 0.00351\n",
      "Epoch: 1... Training loss: 0.00276... Test loss: 0.00377\n",
      "Epoch: 1... Training loss: 0.00266... Test loss: 0.00315\n",
      "Epoch: 1... Training loss: 0.00252... Test loss: 0.00328\n",
      "Epoch: 1... Training loss: 0.00255... Test loss: 0.00308\n",
      "Epoch: 1... Training loss: 0.00251... Test loss: 0.0028\n",
      "Epoch: 1... Training loss: 0.00232... Test loss: 0.00269\n",
      "Epoch: 1... Training loss: 0.00227... Test loss: 0.00209\n",
      "Epoch: 1... Training loss: 0.00216... Test loss: 0.00304\n",
      "Epoch: 1... Training loss: 0.0022... Test loss: 0.00217\n",
      "Epoch: 1... Training loss: 0.00201... Test loss: 0.00304\n",
      "Epoch: 1... Training loss: 0.00185... Test loss: 0.00213\n",
      "Epoch: 1... Training loss: 0.00179... Test loss: 0.00255\n",
      "Epoch: 1... Training loss: 0.00182... Test loss: 0.00235\n",
      "Epoch: 1... Training loss: 0.00175... Test loss: 0.00208\n",
      "Epoch: 1... Training loss: 0.00164... Test loss: 0.00172\n",
      "Epoch: 1... Training loss: 0.00154... Test loss: 0.00228\n",
      "Epoch: 1... Training loss: 0.00171... Test loss: 0.0018\n",
      "Epoch: 1... Training loss: 0.00142... Test loss: 0.00194\n",
      "Epoch: 1... Training loss: 0.00143... Test loss: 0.00158\n",
      "Epoch: 1... Training loss: 0.00133... Test loss: 0.00175\n",
      "Epoch: 1... Training loss: 0.00132... Test loss: 0.00165\n",
      "Epoch: 1... Training loss: 0.00127... Test loss: 0.0015\n",
      "Epoch: 1... Training loss: 0.00119... Test loss: 0.00157\n",
      "Epoch: 1... Training loss: 0.00114... Test loss: 0.00149\n",
      "Epoch: 1... Training loss: 0.00112... Test loss: 0.00139\n",
      "Epoch: 1... Training loss: 0.00105... Test loss: 0.0011\n",
      "Epoch: 1... Training loss: 0.00102... Test loss: 0.0012\n",
      "Epoch: 1... Training loss: 0.00096... Test loss: 0.00123\n",
      "Epoch: 1... Training loss: 0.00093... Test loss: 0.00112\n",
      "Epoch: 1... Training loss: 0.00089... Test loss: 0.00119\n",
      "Epoch: 1... Training loss: 0.00087... Test loss: 0.00088\n",
      "Epoch: 1... Training loss: 0.0008... Test loss: 0.00108\n",
      "Epoch: 1... Training loss: 0.00077... Test loss: 0.00078\n",
      "Epoch: 1... Training loss: 0.00075... Test loss: 0.00095\n",
      "Epoch: 1... Training loss: 0.00069... Test loss: 0.00072\n",
      "Epoch: 1... Training loss: 0.00068... Test loss: 0.00085\n",
      "Epoch: 1... Training loss: 0.00064... Test loss: 0.00064\n",
      "Epoch: 1... Training loss: 0.00064... Test loss: 0.00075\n",
      "Epoch: 1... Training loss: 0.00064... Test loss: 0.00055\n",
      "Epoch: 1... Training loss: 0.00058... Test loss: 0.00071\n",
      "Epoch: 1... Training loss: 0.0006... Test loss: 0.00062\n",
      "Epoch: 1... Training loss: 0.00058... Test loss: 0.00057\n",
      "Epoch: 1... Training loss: 0.00051... Test loss: 0.00066\n",
      "Epoch: 1... Training loss: 0.00052... Test loss: 0.00053\n",
      "Epoch: 1... Training loss: 0.00049... Test loss: 0.00051\n",
      "Epoch: 1... Training loss: 0.0005... Test loss: 0.00046\n",
      "Epoch: 1... Training loss: 0.00049... Test loss: 0.00041\n",
      "Epoch: 1... Training loss: 0.00042... Test loss: 0.00044\n",
      "Epoch: 1... Training loss: 0.00039... Test loss: 0.00035\n",
      "Epoch: 1... Training loss: 0.00044... Test loss: 0.00043\n",
      "Epoch: 1... Training loss: 0.00041... Test loss: 0.00041\n",
      "Epoch: 1... Training loss: 0.00038... Test loss: 0.00034\n",
      "Epoch: 1... Training loss: 0.00032... Test loss: 0.00044\n",
      "Epoch: 1... Training loss: 0.00035... Test loss: 0.00028\n",
      "Epoch: 1... Training loss: 0.00035... Test loss: 0.00037\n",
      "Epoch: 1... Training loss: 0.00034... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.00031... Test loss: 0.00039\n",
      "Epoch: 1... Training loss: 0.00031... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.00031... Test loss: 0.0003\n",
      "Epoch: 1... Training loss: 0.00035... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00029... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00031... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.00029... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00033\n",
      "Epoch: 1... Training loss: 0.00026... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00026... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00015\n",
      "232.88962971407454\n",
      "Epoch: 1... Training loss: 0.919... Test loss: 0.21712\n",
      "Epoch: 1... Training loss: 0.47837... Test loss: 0.15389\n",
      "Epoch: 1... Training loss: 0.29194... Test loss: 0.10617\n",
      "Epoch: 1... Training loss: 0.20119... Test loss: 0.06343\n",
      "Epoch: 1... Training loss: 0.13852... Test loss: 0.04286\n",
      "Epoch: 1... Training loss: 0.11614... Test loss: 0.03331\n",
      "Epoch: 1... Training loss: 0.09708... Test loss: 0.02906\n",
      "Epoch: 1... Training loss: 0.08699... Test loss: 0.02462\n",
      "Epoch: 1... Training loss: 0.07114... Test loss: 0.0319\n",
      "Epoch: 1... Training loss: 0.05951... Test loss: 0.0222\n",
      "Epoch: 1... Training loss: 0.05516... Test loss: 0.01276\n",
      "Epoch: 1... Training loss: 0.05083... Test loss: 0.0185\n",
      "Epoch: 1... Training loss: 0.04841... Test loss: 0.02503\n",
      "Epoch: 1... Training loss: 0.03961... Test loss: 0.01033\n",
      "Epoch: 1... Training loss: 0.03657... Test loss: 0.01969\n",
      "Epoch: 1... Training loss: 0.03239... Test loss: 0.01229\n",
      "Epoch: 1... Training loss: 0.03026... Test loss: 0.02049\n",
      "Epoch: 1... Training loss: 0.0277... Test loss: 0.01778\n",
      "Epoch: 1... Training loss: 0.02642... Test loss: 0.01776\n",
      "Epoch: 1... Training loss: 0.02469... Test loss: 0.01667\n",
      "Epoch: 1... Training loss: 0.02291... Test loss: 0.0149\n",
      "Epoch: 1... Training loss: 0.02156... Test loss: 0.01399\n",
      "Epoch: 1... Training loss: 0.02039... Test loss: 0.01488\n",
      "Epoch: 1... Training loss: 0.01957... Test loss: 0.01051\n",
      "Epoch: 1... Training loss: 0.01794... Test loss: 0.01594\n",
      "Epoch: 1... Training loss: 0.01686... Test loss: 0.00943\n",
      "Epoch: 1... Training loss: 0.01614... Test loss: 0.01431\n",
      "Epoch: 1... Training loss: 0.01555... Test loss: 0.00796\n",
      "Epoch: 1... Training loss: 0.01459... Test loss: 0.01201\n",
      "Epoch: 1... Training loss: 0.01454... Test loss: 0.00664\n",
      "Epoch: 1... Training loss: 0.01362... Test loss: 0.01124\n",
      "Epoch: 1... Training loss: 0.01382... Test loss: 0.00664\n",
      "Epoch: 1... Training loss: 0.01286... Test loss: 0.01017\n",
      "Epoch: 1... Training loss: 0.01266... Test loss: 0.0058\n",
      "Epoch: 1... Training loss: 0.01225... Test loss: 0.00843\n",
      "Epoch: 1... Training loss: 0.01194... Test loss: 0.00697\n",
      "Epoch: 1... Training loss: 0.01147... Test loss: 0.00739\n",
      "Epoch: 1... Training loss: 0.01133... Test loss: 0.00709\n",
      "Epoch: 1... Training loss: 0.01089... Test loss: 0.00696\n",
      "Epoch: 1... Training loss: 0.01075... Test loss: 0.00724\n",
      "Epoch: 1... Training loss: 0.01029... Test loss: 0.008\n",
      "Epoch: 1... Training loss: 0.01003... Test loss: 0.00665\n",
      "Epoch: 1... Training loss: 0.00955... Test loss: 0.00807\n",
      "Epoch: 1... Training loss: 0.00931... Test loss: 0.0061\n",
      "Epoch: 1... Training loss: 0.00888... Test loss: 0.00711\n",
      "Epoch: 1... Training loss: 0.00872... Test loss: 0.00656\n",
      "Epoch: 1... Training loss: 0.00847... Test loss: 0.0066\n",
      "Epoch: 1... Training loss: 0.00836... Test loss: 0.00633\n",
      "Epoch: 1... Training loss: 0.00806... Test loss: 0.00706\n",
      "Epoch: 1... Training loss: 0.00793... Test loss: 0.00641\n",
      "Epoch: 1... Training loss: 0.00775... Test loss: 0.00689\n",
      "Epoch: 1... Training loss: 0.00764... Test loss: 0.00547\n",
      "Epoch: 1... Training loss: 0.00734... Test loss: 0.00632\n",
      "Epoch: 1... Training loss: 0.00727... Test loss: 0.0061\n",
      "Epoch: 1... Training loss: 0.00706... Test loss: 0.00583\n",
      "Epoch: 1... Training loss: 0.00684... Test loss: 0.00637\n",
      "Epoch: 1... Training loss: 0.00652... Test loss: 0.0067\n",
      "Epoch: 1... Training loss: 0.00643... Test loss: 0.00607\n",
      "Epoch: 1... Training loss: 0.0062... Test loss: 0.00641\n",
      "Epoch: 1... Training loss: 0.00613... Test loss: 0.00545\n",
      "Epoch: 1... Training loss: 0.00585... Test loss: 0.00669\n",
      "Epoch: 1... Training loss: 0.00573... Test loss: 0.00511\n",
      "Epoch: 1... Training loss: 0.00556... Test loss: 0.00721\n",
      "Epoch: 1... Training loss: 0.0055... Test loss: 0.00511\n",
      "Epoch: 1... Training loss: 0.01163... Test loss: 0.01637\n",
      "Epoch: 1... Training loss: 0.01487... Test loss: 0.01646\n",
      "Epoch: 1... Training loss: 0.01119... Test loss: 0.0155\n",
      "Epoch: 1... Training loss: 0.00791... Test loss: 0.0151\n",
      "Epoch: 1... Training loss: 0.00922... Test loss: 0.01179\n",
      "Epoch: 1... Training loss: 0.00983... Test loss: 0.01661\n",
      "Epoch: 1... Training loss: 0.00846... Test loss: 0.01293\n",
      "Epoch: 1... Training loss: 0.00878... Test loss: 0.01379\n",
      "Epoch: 1... Training loss: 0.00739... Test loss: 0.01079\n",
      "Epoch: 1... Training loss: 0.00787... Test loss: 0.00899\n",
      "Epoch: 1... Training loss: 0.00806... Test loss: 0.01258\n",
      "Epoch: 1... Training loss: 0.00682... Test loss: 0.0096\n",
      "Epoch: 1... Training loss: 0.0066... Test loss: 0.00982\n",
      "Epoch: 1... Training loss: 0.00642... Test loss: 0.00884\n",
      "Epoch: 1... Training loss: 0.00647... Test loss: 0.00959\n",
      "Epoch: 1... Training loss: 0.00632... Test loss: 0.00813\n",
      "Epoch: 1... Training loss: 0.00593... Test loss: 0.00715\n",
      "Epoch: 1... Training loss: 0.00548... Test loss: 0.00736\n",
      "Epoch: 1... Training loss: 0.00572... Test loss: 0.00972\n",
      "Epoch: 1... Training loss: 0.00492... Test loss: 0.00763\n",
      "Epoch: 1... Training loss: 0.00481... Test loss: 0.00762\n",
      "Epoch: 1... Training loss: 0.00484... Test loss: 0.0074\n",
      "Epoch: 1... Training loss: 0.00461... Test loss: 0.00572\n",
      "Epoch: 1... Training loss: 0.00489... Test loss: 0.00525\n",
      "Epoch: 1... Training loss: 0.00438... Test loss: 0.00605\n",
      "Epoch: 1... Training loss: 0.00437... Test loss: 0.00533\n",
      "Epoch: 1... Training loss: 0.00416... Test loss: 0.00469\n",
      "Epoch: 1... Training loss: 0.00393... Test loss: 0.0055\n",
      "Epoch: 1... Training loss: 0.00405... Test loss: 0.00458\n",
      "Epoch: 1... Training loss: 0.00361... Test loss: 0.00482\n",
      "Epoch: 1... Training loss: 0.00346... Test loss: 0.00444\n",
      "Epoch: 1... Training loss: 0.00354... Test loss: 0.00367\n",
      "Epoch: 1... Training loss: 0.00322... Test loss: 0.00496\n",
      "Epoch: 1... Training loss: 0.00327... Test loss: 0.00373\n",
      "Epoch: 1... Training loss: 0.00316... Test loss: 0.00441\n",
      "Epoch: 1... Training loss: 0.00293... Test loss: 0.0034\n",
      "Epoch: 1... Training loss: 0.00291... Test loss: 0.00411\n",
      "Epoch: 1... Training loss: 0.00272... Test loss: 0.00281\n",
      "Epoch: 1... Training loss: 0.0028... Test loss: 0.00439\n",
      "Epoch: 1... Training loss: 0.0026... Test loss: 0.00262\n",
      "Epoch: 1... Training loss: 0.00255... Test loss: 0.00404\n",
      "Epoch: 1... Training loss: 0.00243... Test loss: 0.00266\n",
      "Epoch: 1... Training loss: 0.00248... Test loss: 0.00384\n",
      "Epoch: 1... Training loss: 0.00223... Test loss: 0.00254\n",
      "Epoch: 1... Training loss: 0.00225... Test loss: 0.00312\n",
      "Epoch: 1... Training loss: 0.00215... Test loss: 0.0028\n",
      "Epoch: 1... Training loss: 0.00207... Test loss: 0.00259\n",
      "Epoch: 1... Training loss: 0.00202... Test loss: 0.00242\n",
      "Epoch: 1... Training loss: 0.0021... Test loss: 0.00258\n",
      "Epoch: 1... Training loss: 0.0019... Test loss: 0.00202\n",
      "Epoch: 1... Training loss: 0.00191... Test loss: 0.00203\n",
      "Epoch: 1... Training loss: 0.00183... Test loss: 0.00196\n",
      "Epoch: 1... Training loss: 0.00181... Test loss: 0.00209\n",
      "Epoch: 1... Training loss: 0.00173... Test loss: 0.00163\n",
      "Epoch: 1... Training loss: 0.00184... Test loss: 0.00247\n",
      "Epoch: 1... Training loss: 0.00179... Test loss: 0.00188\n",
      "Epoch: 1... Training loss: 0.00159... Test loss: 0.00234\n",
      "Epoch: 1... Training loss: 0.00151... Test loss: 0.00152\n",
      "Epoch: 1... Training loss: 0.00154... Test loss: 0.00187\n",
      "Epoch: 1... Training loss: 0.00143... Test loss: 0.00144\n",
      "Epoch: 1... Training loss: 0.00138... Test loss: 0.00163\n",
      "Epoch: 1... Training loss: 0.00131... Test loss: 0.00126\n",
      "Epoch: 1... Training loss: 0.00134... Test loss: 0.00154\n",
      "Epoch: 1... Training loss: 0.00134... Test loss: 0.00147\n",
      "Epoch: 1... Training loss: 0.00115... Test loss: 0.00124\n",
      "Epoch: 1... Training loss: 0.00112... Test loss: 0.00151\n",
      "Epoch: 1... Training loss: 0.00112... Test loss: 0.00119\n",
      "Epoch: 1... Training loss: 0.00105... Test loss: 0.00118\n",
      "Epoch: 1... Training loss: 0.00098... Test loss: 0.00131\n",
      "Epoch: 1... Training loss: 0.00097... Test loss: 0.00101\n",
      "Epoch: 1... Training loss: 0.00093... Test loss: 0.00096\n",
      "Epoch: 1... Training loss: 0.0009... Test loss: 0.00093\n",
      "Epoch: 1... Training loss: 0.00091... Test loss: 0.00095\n",
      "Epoch: 1... Training loss: 0.0008... Test loss: 0.00078\n",
      "Epoch: 1... Training loss: 0.00076... Test loss: 0.00095\n",
      "Epoch: 1... Training loss: 0.00074... Test loss: 0.00072\n",
      "Epoch: 1... Training loss: 0.00069... Test loss: 0.0008\n",
      "Epoch: 1... Training loss: 0.00069... Test loss: 0.0007\n",
      "Epoch: 1... Training loss: 0.00064... Test loss: 0.00081\n",
      "Epoch: 1... Training loss: 0.00066... Test loss: 0.00057\n",
      "Epoch: 1... Training loss: 0.00059... Test loss: 0.00068\n",
      "Epoch: 1... Training loss: 0.00063... Test loss: 0.00068\n",
      "Epoch: 1... Training loss: 0.00054... Test loss: 0.00049\n",
      "Epoch: 1... Training loss: 0.00052... Test loss: 0.00066\n",
      "Epoch: 1... Training loss: 0.00051... Test loss: 0.00054\n",
      "Epoch: 1... Training loss: 0.00043... Test loss: 0.00056\n",
      "Epoch: 1... Training loss: 0.00043... Test loss: 0.00039\n",
      "Epoch: 1... Training loss: 0.0004... Test loss: 0.00038\n",
      "Epoch: 1... Training loss: 0.00044... Test loss: 0.00037\n",
      "Epoch: 1... Training loss: 0.00036... Test loss: 0.00039\n",
      "Epoch: 1... Training loss: 0.00034... Test loss: 0.00047\n",
      "Epoch: 1... Training loss: 0.00036... Test loss: 0.00033\n",
      "Epoch: 1... Training loss: 0.00032... Test loss: 0.00044\n",
      "Epoch: 1... Training loss: 0.00031... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00036... Test loss: 0.00042\n",
      "Epoch: 1... Training loss: 0.00037... Test loss: 0.0003\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00033\n",
      "Epoch: 1... Training loss: 0.00032... Test loss: 0.00034\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00033\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00035\n",
      "Epoch: 1... Training loss: 0.00026... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00028\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 8e-05... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 7e-05... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 7e-05... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 8e-05... Test loss: 0.0001\n",
      "242.83044375129975\n",
      "Epoch: 1... Training loss: 0.96503... Test loss: 0.30278\n",
      "Epoch: 1... Training loss: 0.44042... Test loss: 0.09295\n",
      "Epoch: 1... Training loss: 0.25811... Test loss: 0.05353\n",
      "Epoch: 1... Training loss: 0.18036... Test loss: 0.03373\n",
      "Epoch: 1... Training loss: 0.14371... Test loss: 0.03038\n",
      "Epoch: 1... Training loss: 0.10985... Test loss: 0.02277\n",
      "Epoch: 1... Training loss: 0.09223... Test loss: 0.0203\n",
      "Epoch: 1... Training loss: 0.07789... Test loss: 0.0172\n",
      "Epoch: 1... Training loss: 0.06476... Test loss: 0.01568\n",
      "Epoch: 1... Training loss: 0.05752... Test loss: 0.01325\n",
      "Epoch: 1... Training loss: 0.0525... Test loss: 0.00944\n",
      "Epoch: 1... Training loss: 0.04858... Test loss: 0.01641\n",
      "Epoch: 1... Training loss: 0.04604... Test loss: 0.00892\n",
      "Epoch: 1... Training loss: 0.03984... Test loss: 0.01747\n",
      "Epoch: 1... Training loss: 0.03693... Test loss: 0.01035\n",
      "Epoch: 1... Training loss: 0.03376... Test loss: 0.01117\n",
      "Epoch: 1... Training loss: 0.03038... Test loss: 0.01076\n",
      "Epoch: 1... Training loss: 0.02861... Test loss: 0.01008\n",
      "Epoch: 1... Training loss: 0.02775... Test loss: 0.01248\n",
      "Epoch: 1... Training loss: 0.02558... Test loss: 0.01344\n",
      "Epoch: 1... Training loss: 0.02334... Test loss: 0.01526\n",
      "Epoch: 1... Training loss: 0.02156... Test loss: 0.00862\n",
      "Epoch: 1... Training loss: 0.02037... Test loss: 0.01426\n",
      "Epoch: 1... Training loss: 0.01957... Test loss: 0.00544\n",
      "Epoch: 1... Training loss: 0.01862... Test loss: 0.01144\n",
      "Epoch: 1... Training loss: 0.01734... Test loss: 0.0091\n",
      "Epoch: 1... Training loss: 0.01604... Test loss: 0.00784\n",
      "Epoch: 1... Training loss: 0.01565... Test loss: 0.0086\n",
      "Epoch: 1... Training loss: 0.0148... Test loss: 0.00835\n",
      "Epoch: 1... Training loss: 0.01497... Test loss: 0.00512\n",
      "Epoch: 1... Training loss: 0.01399... Test loss: 0.01038\n",
      "Epoch: 1... Training loss: 0.01357... Test loss: 0.00586\n",
      "Epoch: 1... Training loss: 0.0127... Test loss: 0.00929\n",
      "Epoch: 1... Training loss: 0.01249... Test loss: 0.00493\n",
      "Epoch: 1... Training loss: 0.01204... Test loss: 0.00721\n",
      "Epoch: 1... Training loss: 0.01148... Test loss: 0.00494\n",
      "Epoch: 1... Training loss: 0.01089... Test loss: 0.00568\n",
      "Epoch: 1... Training loss: 0.01066... Test loss: 0.00688\n",
      "Epoch: 1... Training loss: 0.01028... Test loss: 0.00548\n",
      "Epoch: 1... Training loss: 0.00994... Test loss: 0.00755\n",
      "Epoch: 1... Training loss: 0.00966... Test loss: 0.00603\n",
      "Epoch: 1... Training loss: 0.00946... Test loss: 0.00703\n",
      "Epoch: 1... Training loss: 0.00924... Test loss: 0.00584\n",
      "Epoch: 1... Training loss: 0.00901... Test loss: 0.00756\n",
      "Epoch: 1... Training loss: 0.00885... Test loss: 0.00592\n",
      "Epoch: 1... Training loss: 0.00851... Test loss: 0.00503\n",
      "Epoch: 1... Training loss: 0.00838... Test loss: 0.00716\n",
      "Epoch: 1... Training loss: 0.00811... Test loss: 0.00365\n",
      "Epoch: 1... Training loss: 0.00801... Test loss: 0.00671\n",
      "Epoch: 1... Training loss: 0.00751... Test loss: 0.00378\n",
      "Epoch: 1... Training loss: 0.00737... Test loss: 0.00627\n",
      "Epoch: 1... Training loss: 0.00708... Test loss: 0.00432\n",
      "Epoch: 1... Training loss: 0.0069... Test loss: 0.00575\n",
      "Epoch: 1... Training loss: 0.00665... Test loss: 0.00419\n",
      "Epoch: 1... Training loss: 0.00651... Test loss: 0.00526\n",
      "Epoch: 1... Training loss: 0.00632... Test loss: 0.00436\n",
      "Epoch: 1... Training loss: 0.00605... Test loss: 0.00446\n",
      "Epoch: 1... Training loss: 0.00599... Test loss: 0.00484\n",
      "Epoch: 1... Training loss: 0.00582... Test loss: 0.00372\n",
      "Epoch: 1... Training loss: 0.00575... Test loss: 0.00484\n",
      "Epoch: 1... Training loss: 0.0054... Test loss: 0.00347\n",
      "Epoch: 1... Training loss: 0.00536... Test loss: 0.0044\n",
      "Epoch: 1... Training loss: 0.0052... Test loss: 0.00398\n",
      "Epoch: 1... Training loss: 0.00513... Test loss: 0.00543\n",
      "Epoch: 1... Training loss: 0.00789... Test loss: 0.0089\n",
      "Epoch: 1... Training loss: 0.00937... Test loss: 0.01513\n",
      "Epoch: 1... Training loss: 0.00854... Test loss: 0.01484\n",
      "Epoch: 1... Training loss: 0.00881... Test loss: 0.00815\n",
      "Epoch: 1... Training loss: 0.00866... Test loss: 0.01536\n",
      "Epoch: 1... Training loss: 0.00762... Test loss: 0.00907\n",
      "Epoch: 1... Training loss: 0.00676... Test loss: 0.00936\n",
      "Epoch: 1... Training loss: 0.00937... Test loss: 0.01107\n",
      "Epoch: 1... Training loss: 0.00794... Test loss: 0.01192\n",
      "Epoch: 1... Training loss: 0.00698... Test loss: 0.00985\n",
      "Epoch: 1... Training loss: 0.00729... Test loss: 0.01016\n",
      "Epoch: 1... Training loss: 0.0067... Test loss: 0.01179\n",
      "Epoch: 1... Training loss: 0.00649... Test loss: 0.00825\n",
      "Epoch: 1... Training loss: 0.0058... Test loss: 0.00974\n",
      "Epoch: 1... Training loss: 0.00593... Test loss: 0.00639\n",
      "Epoch: 1... Training loss: 0.0059... Test loss: 0.00709\n",
      "Epoch: 1... Training loss: 0.00593... Test loss: 0.00694\n",
      "Epoch: 1... Training loss: 0.00525... Test loss: 0.00711\n",
      "Epoch: 1... Training loss: 0.00514... Test loss: 0.00525\n",
      "Epoch: 1... Training loss: 0.00484... Test loss: 0.00933\n",
      "Epoch: 1... Training loss: 0.00473... Test loss: 0.00555\n",
      "Epoch: 1... Training loss: 0.00449... Test loss: 0.00636\n",
      "Epoch: 1... Training loss: 0.00439... Test loss: 0.00519\n",
      "Epoch: 1... Training loss: 0.00434... Test loss: 0.00531\n",
      "Epoch: 1... Training loss: 0.00397... Test loss: 0.00594\n",
      "Epoch: 1... Training loss: 0.00388... Test loss: 0.00381\n",
      "Epoch: 1... Training loss: 0.00378... Test loss: 0.00539\n",
      "Epoch: 1... Training loss: 0.00367... Test loss: 0.00401\n",
      "Epoch: 1... Training loss: 0.00359... Test loss: 0.00411\n",
      "Epoch: 1... Training loss: 0.00343... Test loss: 0.00409\n",
      "Epoch: 1... Training loss: 0.00328... Test loss: 0.0036\n",
      "Epoch: 1... Training loss: 0.0031... Test loss: 0.00343\n",
      "Epoch: 1... Training loss: 0.00288... Test loss: 0.00433\n",
      "Epoch: 1... Training loss: 0.00285... Test loss: 0.00375\n",
      "Epoch: 1... Training loss: 0.00296... Test loss: 0.0037\n",
      "Epoch: 1... Training loss: 0.00271... Test loss: 0.00307\n",
      "Epoch: 1... Training loss: 0.00251... Test loss: 0.00423\n",
      "Epoch: 1... Training loss: 0.00255... Test loss: 0.00271\n",
      "Epoch: 1... Training loss: 0.00246... Test loss: 0.0028\n",
      "Epoch: 1... Training loss: 0.00246... Test loss: 0.00239\n",
      "Epoch: 1... Training loss: 0.00234... Test loss: 0.00301\n",
      "Epoch: 1... Training loss: 0.00232... Test loss: 0.00239\n",
      "Epoch: 1... Training loss: 0.00223... Test loss: 0.00287\n",
      "Epoch: 1... Training loss: 0.00224... Test loss: 0.00255\n",
      "Epoch: 1... Training loss: 0.0021... Test loss: 0.00252\n",
      "Epoch: 1... Training loss: 0.00198... Test loss: 0.00245\n",
      "Epoch: 1... Training loss: 0.00198... Test loss: 0.0024\n",
      "Epoch: 1... Training loss: 0.00186... Test loss: 0.00202\n",
      "Epoch: 1... Training loss: 0.00197... Test loss: 0.00227\n",
      "Epoch: 1... Training loss: 0.00173... Test loss: 0.00172\n",
      "Epoch: 1... Training loss: 0.00175... Test loss: 0.00198\n",
      "Epoch: 1... Training loss: 0.00158... Test loss: 0.00184\n",
      "Epoch: 1... Training loss: 0.00175... Test loss: 0.00208\n",
      "Epoch: 1... Training loss: 0.00155... Test loss: 0.00174\n",
      "Epoch: 1... Training loss: 0.00153... Test loss: 0.00143\n",
      "Epoch: 1... Training loss: 0.00147... Test loss: 0.00156\n",
      "Epoch: 1... Training loss: 0.00142... Test loss: 0.00164\n",
      "Epoch: 1... Training loss: 0.00141... Test loss: 0.00146\n",
      "Epoch: 1... Training loss: 0.00134... Test loss: 0.00152\n",
      "Epoch: 1... Training loss: 0.0013... Test loss: 0.00131\n",
      "Epoch: 1... Training loss: 0.0013... Test loss: 0.00141\n",
      "Epoch: 1... Training loss: 0.00125... Test loss: 0.00115\n",
      "Epoch: 1... Training loss: 0.00127... Test loss: 0.00145\n",
      "Epoch: 1... Training loss: 0.00119... Test loss: 0.00124\n",
      "Epoch: 1... Training loss: 0.00109... Test loss: 0.00139\n",
      "Epoch: 1... Training loss: 0.00109... Test loss: 0.00092\n",
      "Epoch: 1... Training loss: 0.00099... Test loss: 0.00142\n",
      "Epoch: 1... Training loss: 0.00114... Test loss: 0.001\n",
      "Epoch: 1... Training loss: 0.00096... Test loss: 0.00114\n",
      "Epoch: 1... Training loss: 0.00093... Test loss: 0.00103\n",
      "Epoch: 1... Training loss: 0.00088... Test loss: 0.00099\n",
      "Epoch: 1... Training loss: 0.00086... Test loss: 0.00097\n",
      "Epoch: 1... Training loss: 0.0008... Test loss: 0.00099\n",
      "Epoch: 1... Training loss: 0.00076... Test loss: 0.0011\n",
      "Epoch: 1... Training loss: 0.00076... Test loss: 0.00085\n",
      "Epoch: 1... Training loss: 0.0007... Test loss: 0.00103\n",
      "Epoch: 1... Training loss: 0.00069... Test loss: 0.00081\n",
      "Epoch: 1... Training loss: 0.00067... Test loss: 0.00088\n",
      "Epoch: 1... Training loss: 0.00063... Test loss: 0.00056\n",
      "Epoch: 1... Training loss: 0.00057... Test loss: 0.00091\n",
      "Epoch: 1... Training loss: 0.00059... Test loss: 0.00055\n",
      "Epoch: 1... Training loss: 0.00052... Test loss: 0.00069\n",
      "Epoch: 1... Training loss: 0.00055... Test loss: 0.0005\n",
      "Epoch: 1... Training loss: 0.0005... Test loss: 0.0006\n",
      "Epoch: 1... Training loss: 0.00046... Test loss: 0.00036\n",
      "Epoch: 1... Training loss: 0.00042... Test loss: 0.00051\n",
      "Epoch: 1... Training loss: 0.00048... Test loss: 0.0004\n",
      "Epoch: 1... Training loss: 0.00042... Test loss: 0.00057\n",
      "Epoch: 1... Training loss: 0.0004... Test loss: 0.00031\n",
      "Epoch: 1... Training loss: 0.00036... Test loss: 0.00043\n",
      "Epoch: 1... Training loss: 0.00038... Test loss: 0.00033\n",
      "Epoch: 1... Training loss: 0.00034... Test loss: 0.00039\n",
      "Epoch: 1... Training loss: 0.00033... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00029... Test loss: 0.00043\n",
      "Epoch: 1... Training loss: 0.00034... Test loss: 0.00024\n",
      "Epoch: 1... Training loss: 0.00029... Test loss: 0.00035\n",
      "Epoch: 1... Training loss: 0.00029... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00031\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00032\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00031\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 8e-05... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 8e-05\n",
      "225.62067437474616\n",
      "Epoch: 1... Training loss: 0.93465... Test loss: 0.16902\n",
      "Epoch: 1... Training loss: 0.41195... Test loss: 0.12785\n",
      "Epoch: 1... Training loss: 0.27199... Test loss: 0.08888\n",
      "Epoch: 1... Training loss: 0.17131... Test loss: 0.0556\n",
      "Epoch: 1... Training loss: 0.14363... Test loss: 0.0481\n",
      "Epoch: 1... Training loss: 0.11057... Test loss: 0.03737\n",
      "Epoch: 1... Training loss: 0.0822... Test loss: 0.02752\n",
      "Epoch: 1... Training loss: 0.0692... Test loss: 0.02148\n",
      "Epoch: 1... Training loss: 0.05835... Test loss: 0.01731\n",
      "Epoch: 1... Training loss: 0.05461... Test loss: 0.0137\n",
      "Epoch: 1... Training loss: 0.0478... Test loss: 0.01767\n",
      "Epoch: 1... Training loss: 0.0454... Test loss: 0.00941\n",
      "Epoch: 1... Training loss: 0.04138... Test loss: 0.01607\n",
      "Epoch: 1... Training loss: 0.03809... Test loss: 0.00722\n",
      "Epoch: 1... Training loss: 0.03578... Test loss: 0.01374\n",
      "Epoch: 1... Training loss: 0.03171... Test loss: 0.0065\n",
      "Epoch: 1... Training loss: 0.0297... Test loss: 0.01297\n",
      "Epoch: 1... Training loss: 0.02829... Test loss: 0.00577\n",
      "Epoch: 1... Training loss: 0.02639... Test loss: 0.01091\n",
      "Epoch: 1... Training loss: 0.02531... Test loss: 0.00577\n",
      "Epoch: 1... Training loss: 0.02404... Test loss: 0.01439\n",
      "Epoch: 1... Training loss: 0.02274... Test loss: 0.00709\n",
      "Epoch: 1... Training loss: 0.02055... Test loss: 0.01571\n",
      "Epoch: 1... Training loss: 0.02019... Test loss: 0.00728\n",
      "Epoch: 1... Training loss: 0.01893... Test loss: 0.01595\n",
      "Epoch: 1... Training loss: 0.01784... Test loss: 0.00815\n",
      "Epoch: 1... Training loss: 0.0171... Test loss: 0.0161\n",
      "Epoch: 1... Training loss: 0.01692... Test loss: 0.00818\n",
      "Epoch: 1... Training loss: 0.01562... Test loss: 0.01191\n",
      "Epoch: 1... Training loss: 0.01496... Test loss: 0.00877\n",
      "Epoch: 1... Training loss: 0.01427... Test loss: 0.00615\n",
      "Epoch: 1... Training loss: 0.0138... Test loss: 0.00996\n",
      "Epoch: 1... Training loss: 0.01308... Test loss: 0.00527\n",
      "Epoch: 1... Training loss: 0.01252... Test loss: 0.01002\n",
      "Epoch: 1... Training loss: 0.01197... Test loss: 0.00514\n",
      "Epoch: 1... Training loss: 0.01171... Test loss: 0.0096\n",
      "Epoch: 1... Training loss: 0.01126... Test loss: 0.0051\n",
      "Epoch: 1... Training loss: 0.01117... Test loss: 0.01001\n",
      "Epoch: 1... Training loss: 0.01051... Test loss: 0.00391\n",
      "Epoch: 1... Training loss: 0.01051... Test loss: 0.00884\n",
      "Epoch: 1... Training loss: 0.01025... Test loss: 0.00511\n",
      "Epoch: 1... Training loss: 0.00997... Test loss: 0.00897\n",
      "Epoch: 1... Training loss: 0.00962... Test loss: 0.0064\n",
      "Epoch: 1... Training loss: 0.00934... Test loss: 0.00955\n",
      "Epoch: 1... Training loss: 0.00908... Test loss: 0.00652\n",
      "Epoch: 1... Training loss: 0.00893... Test loss: 0.00857\n",
      "Epoch: 1... Training loss: 0.00881... Test loss: 0.0074\n",
      "Epoch: 1... Training loss: 0.00829... Test loss: 0.00723\n",
      "Epoch: 1... Training loss: 0.00792... Test loss: 0.00706\n",
      "Epoch: 1... Training loss: 0.00768... Test loss: 0.00667\n",
      "Epoch: 1... Training loss: 0.00752... Test loss: 0.00655\n",
      "Epoch: 1... Training loss: 0.00711... Test loss: 0.00694\n",
      "Epoch: 1... Training loss: 0.00692... Test loss: 0.00629\n",
      "Epoch: 1... Training loss: 0.00673... Test loss: 0.00727\n",
      "Epoch: 1... Training loss: 0.00659... Test loss: 0.00571\n",
      "Epoch: 1... Training loss: 0.00629... Test loss: 0.00693\n",
      "Epoch: 1... Training loss: 0.00613... Test loss: 0.00485\n",
      "Epoch: 1... Training loss: 0.00593... Test loss: 0.00699\n",
      "Epoch: 1... Training loss: 0.00576... Test loss: 0.00413\n",
      "Epoch: 1... Training loss: 0.00561... Test loss: 0.00647\n",
      "Epoch: 1... Training loss: 0.00542... Test loss: 0.00419\n",
      "Epoch: 1... Training loss: 0.00528... Test loss: 0.00641\n",
      "Epoch: 1... Training loss: 0.00515... Test loss: 0.00509\n",
      "Epoch: 1... Training loss: 0.005... Test loss: 0.00663\n",
      "Epoch: 1... Training loss: 0.01241... Test loss: 0.01061\n",
      "Epoch: 1... Training loss: 0.00862... Test loss: 0.0224\n",
      "Epoch: 1... Training loss: 0.0116... Test loss: 0.01363\n",
      "Epoch: 1... Training loss: 0.0083... Test loss: 0.0127\n",
      "Epoch: 1... Training loss: 0.00939... Test loss: 0.01291\n",
      "Epoch: 1... Training loss: 0.00761... Test loss: 0.01075\n",
      "Epoch: 1... Training loss: 0.00867... Test loss: 0.01034\n",
      "Epoch: 1... Training loss: 0.00803... Test loss: 0.01098\n",
      "Epoch: 1... Training loss: 0.0081... Test loss: 0.0105\n",
      "Epoch: 1... Training loss: 0.00707... Test loss: 0.0082\n",
      "Epoch: 1... Training loss: 0.00667... Test loss: 0.0068\n",
      "Epoch: 1... Training loss: 0.00656... Test loss: 0.00704\n",
      "Epoch: 1... Training loss: 0.00632... Test loss: 0.00799\n",
      "Epoch: 1... Training loss: 0.006... Test loss: 0.00803\n",
      "Epoch: 1... Training loss: 0.00648... Test loss: 0.0067\n",
      "Epoch: 1... Training loss: 0.00577... Test loss: 0.01068\n",
      "Epoch: 1... Training loss: 0.00584... Test loss: 0.00719\n",
      "Epoch: 1... Training loss: 0.0053... Test loss: 0.00671\n",
      "Epoch: 1... Training loss: 0.005... Test loss: 0.00712\n",
      "Epoch: 1... Training loss: 0.00495... Test loss: 0.00495\n",
      "Epoch: 1... Training loss: 0.00483... Test loss: 0.00853\n",
      "Epoch: 1... Training loss: 0.00456... Test loss: 0.00532\n",
      "Epoch: 1... Training loss: 0.0048... Test loss: 0.00564\n",
      "Epoch: 1... Training loss: 0.00475... Test loss: 0.00556\n",
      "Epoch: 1... Training loss: 0.00431... Test loss: 0.00455\n",
      "Epoch: 1... Training loss: 0.004... Test loss: 0.0054\n",
      "Epoch: 1... Training loss: 0.00375... Test loss: 0.0046\n",
      "Epoch: 1... Training loss: 0.00373... Test loss: 0.00475\n",
      "Epoch: 1... Training loss: 0.00349... Test loss: 0.00434\n",
      "Epoch: 1... Training loss: 0.00344... Test loss: 0.00392\n",
      "Epoch: 1... Training loss: 0.00344... Test loss: 0.00418\n",
      "Epoch: 1... Training loss: 0.00317... Test loss: 0.0038\n",
      "Epoch: 1... Training loss: 0.00314... Test loss: 0.00397\n",
      "Epoch: 1... Training loss: 0.00297... Test loss: 0.00303\n",
      "Epoch: 1... Training loss: 0.0029... Test loss: 0.00417\n",
      "Epoch: 1... Training loss: 0.00282... Test loss: 0.00266\n",
      "Epoch: 1... Training loss: 0.00284... Test loss: 0.00337\n",
      "Epoch: 1... Training loss: 0.00264... Test loss: 0.00268\n",
      "Epoch: 1... Training loss: 0.00261... Test loss: 0.00341\n",
      "Epoch: 1... Training loss: 0.00244... Test loss: 0.00246\n",
      "Epoch: 1... Training loss: 0.00233... Test loss: 0.00336\n",
      "Epoch: 1... Training loss: 0.00236... Test loss: 0.00202\n",
      "Epoch: 1... Training loss: 0.00228... Test loss: 0.00288\n",
      "Epoch: 1... Training loss: 0.00226... Test loss: 0.00204\n",
      "Epoch: 1... Training loss: 0.00225... Test loss: 0.00273\n",
      "Epoch: 1... Training loss: 0.00226... Test loss: 0.00222\n",
      "Epoch: 1... Training loss: 0.00207... Test loss: 0.00257\n",
      "Epoch: 1... Training loss: 0.00196... Test loss: 0.00207\n",
      "Epoch: 1... Training loss: 0.00181... Test loss: 0.00252\n",
      "Epoch: 1... Training loss: 0.00186... Test loss: 0.00231\n",
      "Epoch: 1... Training loss: 0.00186... Test loss: 0.00213\n",
      "Epoch: 1... Training loss: 0.00176... Test loss: 0.00205\n",
      "Epoch: 1... Training loss: 0.00161... Test loss: 0.00189\n",
      "Epoch: 1... Training loss: 0.00157... Test loss: 0.00174\n",
      "Epoch: 1... Training loss: 0.00147... Test loss: 0.00191\n",
      "Epoch: 1... Training loss: 0.00146... Test loss: 0.00167\n",
      "Epoch: 1... Training loss: 0.00127... Test loss: 0.00184\n",
      "Epoch: 1... Training loss: 0.00132... Test loss: 0.00145\n",
      "Epoch: 1... Training loss: 0.00132... Test loss: 0.00148\n",
      "Epoch: 1... Training loss: 0.00133... Test loss: 0.00162\n",
      "Epoch: 1... Training loss: 0.00131... Test loss: 0.00136\n",
      "Epoch: 1... Training loss: 0.00112... Test loss: 0.00149\n",
      "Epoch: 1... Training loss: 0.00113... Test loss: 0.00128\n",
      "Epoch: 1... Training loss: 0.00105... Test loss: 0.0017\n",
      "Epoch: 1... Training loss: 0.00107... Test loss: 0.0012\n",
      "Epoch: 1... Training loss: 0.00098... Test loss: 0.00143\n",
      "Epoch: 1... Training loss: 0.00102... Test loss: 0.00104\n",
      "Epoch: 1... Training loss: 0.00095... Test loss: 0.00109\n",
      "Epoch: 1... Training loss: 0.00096... Test loss: 0.0013\n",
      "Epoch: 1... Training loss: 0.00096... Test loss: 0.00086\n",
      "Epoch: 1... Training loss: 0.00087... Test loss: 0.00126\n",
      "Epoch: 1... Training loss: 0.00088... Test loss: 0.00075\n",
      "Epoch: 1... Training loss: 0.00084... Test loss: 0.00101\n",
      "Epoch: 1... Training loss: 0.00076... Test loss: 0.0008\n",
      "Epoch: 1... Training loss: 0.00078... Test loss: 0.00081\n",
      "Epoch: 1... Training loss: 0.00068... Test loss: 0.00075\n",
      "Epoch: 1... Training loss: 0.00066... Test loss: 0.0008\n",
      "Epoch: 1... Training loss: 0.00065... Test loss: 0.00063\n",
      "Epoch: 1... Training loss: 0.00057... Test loss: 0.00069\n",
      "Epoch: 1... Training loss: 0.00058... Test loss: 0.00059\n",
      "Epoch: 1... Training loss: 0.00052... Test loss: 0.00091\n",
      "Epoch: 1... Training loss: 0.00059... Test loss: 0.00059\n",
      "Epoch: 1... Training loss: 0.00055... Test loss: 0.00072\n",
      "Epoch: 1... Training loss: 0.00046... Test loss: 0.00048\n",
      "Epoch: 1... Training loss: 0.00044... Test loss: 0.00053\n",
      "Epoch: 1... Training loss: 0.0004... Test loss: 0.00043\n",
      "Epoch: 1... Training loss: 0.00042... Test loss: 0.00047\n",
      "Epoch: 1... Training loss: 0.0004... Test loss: 0.00046\n",
      "Epoch: 1... Training loss: 0.00037... Test loss: 0.00037\n",
      "Epoch: 1... Training loss: 0.00036... Test loss: 0.00038\n",
      "Epoch: 1... Training loss: 0.00037... Test loss: 0.00046\n",
      "Epoch: 1... Training loss: 0.00033... Test loss: 0.00033\n",
      "Epoch: 1... Training loss: 0.00031... Test loss: 0.0004\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.00024\n",
      "Epoch: 1... Training loss: 0.00029... Test loss: 0.00037\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00024\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00034\n",
      "Epoch: 1... Training loss: 0.00026... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.00026... Test loss: 0.00032\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 8e-05... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 8e-05\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 8e-05... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 8e-05... Test loss: 9e-05\n",
      "225.25080847670324\n",
      "Epoch: 1... Training loss: 1.23839... Test loss: 0.56861\n",
      "Epoch: 1... Training loss: 0.53321... Test loss: 0.19785\n",
      "Epoch: 1... Training loss: 0.30394... Test loss: 0.10686\n",
      "Epoch: 1... Training loss: 0.20831... Test loss: 0.06811\n",
      "Epoch: 1... Training loss: 0.14616... Test loss: 0.0485\n",
      "Epoch: 1... Training loss: 0.10151... Test loss: 0.04007\n",
      "Epoch: 1... Training loss: 0.07802... Test loss: 0.04359\n",
      "Epoch: 1... Training loss: 0.06675... Test loss: 0.02727\n",
      "Epoch: 1... Training loss: 0.05865... Test loss: 0.03909\n",
      "Epoch: 1... Training loss: 0.05007... Test loss: 0.02265\n",
      "Epoch: 1... Training loss: 0.04957... Test loss: 0.03514\n",
      "Epoch: 1... Training loss: 0.04434... Test loss: 0.02623\n",
      "Epoch: 1... Training loss: 0.04106... Test loss: 0.01969\n",
      "Epoch: 1... Training loss: 0.03811... Test loss: 0.0263\n",
      "Epoch: 1... Training loss: 0.03694... Test loss: 0.0272\n",
      "Epoch: 1... Training loss: 0.03255... Test loss: 0.01427\n",
      "Epoch: 1... Training loss: 0.03122... Test loss: 0.02082\n",
      "Epoch: 1... Training loss: 0.02867... Test loss: 0.02218\n",
      "Epoch: 1... Training loss: 0.0266... Test loss: 0.01525\n",
      "Epoch: 1... Training loss: 0.02507... Test loss: 0.02504\n",
      "Epoch: 1... Training loss: 0.02381... Test loss: 0.00875\n",
      "Epoch: 1... Training loss: 0.02215... Test loss: 0.02305\n",
      "Epoch: 1... Training loss: 0.02127... Test loss: 0.01134\n",
      "Epoch: 1... Training loss: 0.02024... Test loss: 0.01517\n",
      "Epoch: 1... Training loss: 0.01938... Test loss: 0.01814\n",
      "Epoch: 1... Training loss: 0.01841... Test loss: 0.00792\n",
      "Epoch: 1... Training loss: 0.01788... Test loss: 0.01889\n",
      "Epoch: 1... Training loss: 0.01704... Test loss: 0.00788\n",
      "Epoch: 1... Training loss: 0.0164... Test loss: 0.022\n",
      "Epoch: 1... Training loss: 0.01574... Test loss: 0.00888\n",
      "Epoch: 1... Training loss: 0.01506... Test loss: 0.01507\n",
      "Epoch: 1... Training loss: 0.01461... Test loss: 0.00787\n",
      "Epoch: 1... Training loss: 0.01419... Test loss: 0.01242\n",
      "Epoch: 1... Training loss: 0.01375... Test loss: 0.01173\n",
      "Epoch: 1... Training loss: 0.01317... Test loss: 0.01013\n",
      "Epoch: 1... Training loss: 0.01297... Test loss: 0.0099\n",
      "Epoch: 1... Training loss: 0.01233... Test loss: 0.0119\n",
      "Epoch: 1... Training loss: 0.01219... Test loss: 0.0058\n",
      "Epoch: 1... Training loss: 0.01175... Test loss: 0.01189\n",
      "Epoch: 1... Training loss: 0.01143... Test loss: 0.00604\n",
      "Epoch: 1... Training loss: 0.01059... Test loss: 0.01169\n",
      "Epoch: 1... Training loss: 0.01059... Test loss: 0.00667\n",
      "Epoch: 1... Training loss: 0.00992... Test loss: 0.01096\n",
      "Epoch: 1... Training loss: 0.00979... Test loss: 0.00653\n",
      "Epoch: 1... Training loss: 0.00937... Test loss: 0.01041\n",
      "Epoch: 1... Training loss: 0.00926... Test loss: 0.00504\n",
      "Epoch: 1... Training loss: 0.00894... Test loss: 0.00983\n",
      "Epoch: 1... Training loss: 0.00885... Test loss: 0.00559\n",
      "Epoch: 1... Training loss: 0.00833... Test loss: 0.0089\n",
      "Epoch: 1... Training loss: 0.00824... Test loss: 0.00514\n",
      "Epoch: 1... Training loss: 0.00794... Test loss: 0.00796\n",
      "Epoch: 1... Training loss: 0.00789... Test loss: 0.00496\n",
      "Epoch: 1... Training loss: 0.00769... Test loss: 0.00876\n",
      "Epoch: 1... Training loss: 0.00744... Test loss: 0.00605\n",
      "Epoch: 1... Training loss: 0.00713... Test loss: 0.00826\n",
      "Epoch: 1... Training loss: 0.00697... Test loss: 0.00567\n",
      "Epoch: 1... Training loss: 0.00677... Test loss: 0.00867\n",
      "Epoch: 1... Training loss: 0.00663... Test loss: 0.00718\n",
      "Epoch: 1... Training loss: 0.0065... Test loss: 0.00659\n",
      "Epoch: 1... Training loss: 0.00627... Test loss: 0.00697\n",
      "Epoch: 1... Training loss: 0.00608... Test loss: 0.00663\n",
      "Epoch: 1... Training loss: 0.00589... Test loss: 0.00634\n",
      "Epoch: 1... Training loss: 0.00579... Test loss: 0.00644\n",
      "Epoch: 1... Training loss: 0.00551... Test loss: 0.0056\n",
      "Epoch: 1... Training loss: 0.01447... Test loss: 0.01393\n",
      "Epoch: 1... Training loss: 0.01274... Test loss: 0.0112\n",
      "Epoch: 1... Training loss: 0.01399... Test loss: 0.02169\n",
      "Epoch: 1... Training loss: 0.01014... Test loss: 0.01587\n",
      "Epoch: 1... Training loss: 0.00821... Test loss: 0.01144\n",
      "Epoch: 1... Training loss: 0.00824... Test loss: 0.0108\n",
      "Epoch: 1... Training loss: 0.00922... Test loss: 0.01302\n",
      "Epoch: 1... Training loss: 0.00815... Test loss: 0.0144\n",
      "Epoch: 1... Training loss: 0.00857... Test loss: 0.01046\n",
      "Epoch: 1... Training loss: 0.00799... Test loss: 0.01281\n",
      "Epoch: 1... Training loss: 0.00745... Test loss: 0.00962\n",
      "Epoch: 1... Training loss: 0.00814... Test loss: 0.01252\n",
      "Epoch: 1... Training loss: 0.00726... Test loss: 0.01125\n",
      "Epoch: 1... Training loss: 0.00662... Test loss: 0.00955\n",
      "Epoch: 1... Training loss: 0.00586... Test loss: 0.0092\n",
      "Epoch: 1... Training loss: 0.00586... Test loss: 0.00931\n",
      "Epoch: 1... Training loss: 0.00599... Test loss: 0.00818\n",
      "Epoch: 1... Training loss: 0.00593... Test loss: 0.01096\n",
      "Epoch: 1... Training loss: 0.00502... Test loss: 0.00701\n",
      "Epoch: 1... Training loss: 0.00533... Test loss: 0.00965\n",
      "Epoch: 1... Training loss: 0.00523... Test loss: 0.00664\n",
      "Epoch: 1... Training loss: 0.00468... Test loss: 0.00822\n",
      "Epoch: 1... Training loss: 0.00485... Test loss: 0.00565\n",
      "Epoch: 1... Training loss: 0.00481... Test loss: 0.00649\n",
      "Epoch: 1... Training loss: 0.00455... Test loss: 0.0045\n",
      "Epoch: 1... Training loss: 0.00422... Test loss: 0.0064\n",
      "Epoch: 1... Training loss: 0.00413... Test loss: 0.00456\n",
      "Epoch: 1... Training loss: 0.00392... Test loss: 0.00535\n",
      "Epoch: 1... Training loss: 0.00378... Test loss: 0.00448\n",
      "Epoch: 1... Training loss: 0.00363... Test loss: 0.0053\n",
      "Epoch: 1... Training loss: 0.00359... Test loss: 0.0034\n",
      "Epoch: 1... Training loss: 0.00334... Test loss: 0.0051\n",
      "Epoch: 1... Training loss: 0.00327... Test loss: 0.00346\n",
      "Epoch: 1... Training loss: 0.00321... Test loss: 0.0043\n",
      "Epoch: 1... Training loss: 0.00302... Test loss: 0.00316\n",
      "Epoch: 1... Training loss: 0.003... Test loss: 0.00415\n",
      "Epoch: 1... Training loss: 0.00294... Test loss: 0.00331\n",
      "Epoch: 1... Training loss: 0.00285... Test loss: 0.00345\n",
      "Epoch: 1... Training loss: 0.00281... Test loss: 0.00375\n",
      "Epoch: 1... Training loss: 0.00266... Test loss: 0.00311\n",
      "Epoch: 1... Training loss: 0.00262... Test loss: 0.00353\n",
      "Epoch: 1... Training loss: 0.00254... Test loss: 0.00262\n",
      "Epoch: 1... Training loss: 0.00249... Test loss: 0.00332\n",
      "Epoch: 1... Training loss: 0.00249... Test loss: 0.00279\n",
      "Epoch: 1... Training loss: 0.00228... Test loss: 0.00289\n",
      "Epoch: 1... Training loss: 0.00233... Test loss: 0.00254\n",
      "Epoch: 1... Training loss: 0.00227... Test loss: 0.00232\n",
      "Epoch: 1... Training loss: 0.00225... Test loss: 0.00215\n",
      "Epoch: 1... Training loss: 0.00208... Test loss: 0.00271\n",
      "Epoch: 1... Training loss: 0.00199... Test loss: 0.00199\n",
      "Epoch: 1... Training loss: 0.002... Test loss: 0.00232\n",
      "Epoch: 1... Training loss: 0.00202... Test loss: 0.00242\n",
      "Epoch: 1... Training loss: 0.00182... Test loss: 0.00239\n",
      "Epoch: 1... Training loss: 0.00179... Test loss: 0.00204\n",
      "Epoch: 1... Training loss: 0.00166... Test loss: 0.00204\n",
      "Epoch: 1... Training loss: 0.00168... Test loss: 0.00189\n",
      "Epoch: 1... Training loss: 0.00155... Test loss: 0.00209\n",
      "Epoch: 1... Training loss: 0.00157... Test loss: 0.0017\n",
      "Epoch: 1... Training loss: 0.00151... Test loss: 0.00191\n",
      "Epoch: 1... Training loss: 0.0015... Test loss: 0.00168\n",
      "Epoch: 1... Training loss: 0.00145... Test loss: 0.00177\n",
      "Epoch: 1... Training loss: 0.00137... Test loss: 0.0016\n",
      "Epoch: 1... Training loss: 0.00126... Test loss: 0.00153\n",
      "Epoch: 1... Training loss: 0.00117... Test loss: 0.0018\n",
      "Epoch: 1... Training loss: 0.00115... Test loss: 0.00126\n",
      "Epoch: 1... Training loss: 0.00111... Test loss: 0.00139\n",
      "Epoch: 1... Training loss: 0.00108... Test loss: 0.00124\n",
      "Epoch: 1... Training loss: 0.00105... Test loss: 0.00136\n",
      "Epoch: 1... Training loss: 0.00098... Test loss: 0.00116\n",
      "Epoch: 1... Training loss: 0.00094... Test loss: 0.00137\n",
      "Epoch: 1... Training loss: 0.00095... Test loss: 0.00114\n",
      "Epoch: 1... Training loss: 0.00085... Test loss: 0.00111\n",
      "Epoch: 1... Training loss: 0.00078... Test loss: 0.00092\n",
      "Epoch: 1... Training loss: 0.00073... Test loss: 0.00089\n",
      "Epoch: 1... Training loss: 0.00066... Test loss: 0.0008\n",
      "Epoch: 1... Training loss: 0.00067... Test loss: 0.00097\n",
      "Epoch: 1... Training loss: 0.00067... Test loss: 0.00067\n",
      "Epoch: 1... Training loss: 0.00063... Test loss: 0.00091\n",
      "Epoch: 1... Training loss: 0.00059... Test loss: 0.00056\n",
      "Epoch: 1... Training loss: 0.00059... Test loss: 0.0008\n",
      "Epoch: 1... Training loss: 0.00058... Test loss: 0.00051\n",
      "Epoch: 1... Training loss: 0.00056... Test loss: 0.00069\n",
      "Epoch: 1... Training loss: 0.0005... Test loss: 0.00048\n",
      "Epoch: 1... Training loss: 0.00048... Test loss: 0.00056\n",
      "Epoch: 1... Training loss: 0.00049... Test loss: 0.0005\n",
      "Epoch: 1... Training loss: 0.00044... Test loss: 0.0005\n",
      "Epoch: 1... Training loss: 0.00042... Test loss: 0.00055\n",
      "Epoch: 1... Training loss: 0.00039... Test loss: 0.00036\n",
      "Epoch: 1... Training loss: 0.00035... Test loss: 0.00045\n",
      "Epoch: 1... Training loss: 0.00035... Test loss: 0.0004\n",
      "Epoch: 1... Training loss: 0.00035... Test loss: 0.00045\n",
      "Epoch: 1... Training loss: 0.00035... Test loss: 0.00037\n",
      "Epoch: 1... Training loss: 0.00034... Test loss: 0.0004\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.00033\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00032\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00031\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00024\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00024\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 8e-05\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 9e-05\n",
      "235.24067099840613\n",
      "Epoch: 1... Training loss: 0.9931... Test loss: 0.32414\n",
      "Epoch: 1... Training loss: 0.46344... Test loss: 0.11676\n",
      "Epoch: 1... Training loss: 0.26753... Test loss: 0.05301\n",
      "Epoch: 1... Training loss: 0.16465... Test loss: 0.03135\n",
      "Epoch: 1... Training loss: 0.12612... Test loss: 0.02188\n",
      "Epoch: 1... Training loss: 0.09824... Test loss: 0.01719\n",
      "Epoch: 1... Training loss: 0.08427... Test loss: 0.01409\n",
      "Epoch: 1... Training loss: 0.07417... Test loss: 0.01086\n",
      "Epoch: 1... Training loss: 0.06557... Test loss: 0.01024\n",
      "Epoch: 1... Training loss: 0.05541... Test loss: 0.01279\n",
      "Epoch: 1... Training loss: 0.04987... Test loss: 0.00739\n",
      "Epoch: 1... Training loss: 0.04607... Test loss: 0.01522\n",
      "Epoch: 1... Training loss: 0.04331... Test loss: 0.00641\n",
      "Epoch: 1... Training loss: 0.03872... Test loss: 0.01135\n",
      "Epoch: 1... Training loss: 0.03663... Test loss: 0.00883\n",
      "Epoch: 1... Training loss: 0.03317... Test loss: 0.0088\n",
      "Epoch: 1... Training loss: 0.03133... Test loss: 0.00594\n",
      "Epoch: 1... Training loss: 0.02961... Test loss: 0.01129\n",
      "Epoch: 1... Training loss: 0.02692... Test loss: 0.00389\n",
      "Epoch: 1... Training loss: 0.02602... Test loss: 0.01289\n",
      "Epoch: 1... Training loss: 0.02412... Test loss: 0.00469\n",
      "Epoch: 1... Training loss: 0.02266... Test loss: 0.0147\n",
      "Epoch: 1... Training loss: 0.02089... Test loss: 0.00703\n",
      "Epoch: 1... Training loss: 0.01996... Test loss: 0.01388\n",
      "Epoch: 1... Training loss: 0.01891... Test loss: 0.00617\n",
      "Epoch: 1... Training loss: 0.01869... Test loss: 0.01221\n",
      "Epoch: 1... Training loss: 0.01737... Test loss: 0.00909\n",
      "Epoch: 1... Training loss: 0.01657... Test loss: 0.01519\n",
      "Epoch: 1... Training loss: 0.01617... Test loss: 0.00585\n",
      "Epoch: 1... Training loss: 0.01551... Test loss: 0.01553\n",
      "Epoch: 1... Training loss: 0.01518... Test loss: 0.00634\n",
      "Epoch: 1... Training loss: 0.01454... Test loss: 0.01373\n",
      "Epoch: 1... Training loss: 0.01438... Test loss: 0.00797\n",
      "Epoch: 1... Training loss: 0.01378... Test loss: 0.01083\n",
      "Epoch: 1... Training loss: 0.01338... Test loss: 0.00637\n",
      "Epoch: 1... Training loss: 0.01286... Test loss: 0.01083\n",
      "Epoch: 1... Training loss: 0.01251... Test loss: 0.00596\n",
      "Epoch: 1... Training loss: 0.01214... Test loss: 0.00991\n",
      "Epoch: 1... Training loss: 0.01171... Test loss: 0.00626\n",
      "Epoch: 1... Training loss: 0.01155... Test loss: 0.0082\n",
      "Epoch: 1... Training loss: 0.01119... Test loss: 0.0052\n",
      "Epoch: 1... Training loss: 0.01096... Test loss: 0.008\n",
      "Epoch: 1... Training loss: 0.0105... Test loss: 0.00416\n",
      "Epoch: 1... Training loss: 0.01003... Test loss: 0.00917\n",
      "Epoch: 1... Training loss: 0.00976... Test loss: 0.004\n",
      "Epoch: 1... Training loss: 0.00949... Test loss: 0.00861\n",
      "Epoch: 1... Training loss: 0.00928... Test loss: 0.00522\n",
      "Epoch: 1... Training loss: 0.00899... Test loss: 0.00775\n",
      "Epoch: 1... Training loss: 0.00868... Test loss: 0.00579\n",
      "Epoch: 1... Training loss: 0.00842... Test loss: 0.00776\n",
      "Epoch: 1... Training loss: 0.00822... Test loss: 0.00617\n",
      "Epoch: 1... Training loss: 0.00787... Test loss: 0.00677\n",
      "Epoch: 1... Training loss: 0.00757... Test loss: 0.00644\n",
      "Epoch: 1... Training loss: 0.00742... Test loss: 0.00603\n",
      "Epoch: 1... Training loss: 0.00735... Test loss: 0.0062\n",
      "Epoch: 1... Training loss: 0.00709... Test loss: 0.00682\n",
      "Epoch: 1... Training loss: 0.00687... Test loss: 0.005\n",
      "Epoch: 1... Training loss: 0.0066... Test loss: 0.00664\n",
      "Epoch: 1... Training loss: 0.00637... Test loss: 0.00501\n",
      "Epoch: 1... Training loss: 0.00614... Test loss: 0.00648\n",
      "Epoch: 1... Training loss: 0.00599... Test loss: 0.0047\n",
      "Epoch: 1... Training loss: 0.00583... Test loss: 0.00632\n",
      "Epoch: 1... Training loss: 0.00562... Test loss: 0.00432\n",
      "Epoch: 1... Training loss: 0.0055... Test loss: 0.00608\n",
      "Epoch: 1... Training loss: 0.0135... Test loss: 0.00919\n",
      "Epoch: 1... Training loss: 0.0098... Test loss: 0.01912\n",
      "Epoch: 1... Training loss: 0.01024... Test loss: 0.01808\n",
      "Epoch: 1... Training loss: 0.01009... Test loss: 0.01783\n",
      "Epoch: 1... Training loss: 0.00917... Test loss: 0.01344\n",
      "Epoch: 1... Training loss: 0.00855... Test loss: 0.01375\n",
      "Epoch: 1... Training loss: 0.00788... Test loss: 0.01086\n",
      "Epoch: 1... Training loss: 0.00932... Test loss: 0.01124\n",
      "Epoch: 1... Training loss: 0.00807... Test loss: 0.01233\n",
      "Epoch: 1... Training loss: 0.00706... Test loss: 0.00973\n",
      "Epoch: 1... Training loss: 0.00842... Test loss: 0.00989\n",
      "Epoch: 1... Training loss: 0.00754... Test loss: 0.01206\n",
      "Epoch: 1... Training loss: 0.00663... Test loss: 0.00849\n",
      "Epoch: 1... Training loss: 0.00616... Test loss: 0.01028\n",
      "Epoch: 1... Training loss: 0.0066... Test loss: 0.00857\n",
      "Epoch: 1... Training loss: 0.00571... Test loss: 0.00853\n",
      "Epoch: 1... Training loss: 0.00605... Test loss: 0.00783\n",
      "Epoch: 1... Training loss: 0.00531... Test loss: 0.00787\n",
      "Epoch: 1... Training loss: 0.00566... Test loss: 0.00669\n",
      "Epoch: 1... Training loss: 0.00543... Test loss: 0.00795\n",
      "Epoch: 1... Training loss: 0.00514... Test loss: 0.00585\n",
      "Epoch: 1... Training loss: 0.00478... Test loss: 0.00747\n",
      "Epoch: 1... Training loss: 0.00471... Test loss: 0.00607\n",
      "Epoch: 1... Training loss: 0.00485... Test loss: 0.00648\n",
      "Epoch: 1... Training loss: 0.0047... Test loss: 0.00589\n",
      "Epoch: 1... Training loss: 0.00426... Test loss: 0.00543\n",
      "Epoch: 1... Training loss: 0.00413... Test loss: 0.00494\n",
      "Epoch: 1... Training loss: 0.00427... Test loss: 0.00528\n",
      "Epoch: 1... Training loss: 0.00398... Test loss: 0.00445\n",
      "Epoch: 1... Training loss: 0.00382... Test loss: 0.0053\n",
      "Epoch: 1... Training loss: 0.00348... Test loss: 0.00389\n",
      "Epoch: 1... Training loss: 0.00349... Test loss: 0.00567\n",
      "Epoch: 1... Training loss: 0.00337... Test loss: 0.00408\n",
      "Epoch: 1... Training loss: 0.0032... Test loss: 0.0041\n",
      "Epoch: 1... Training loss: 0.00321... Test loss: 0.00455\n",
      "Epoch: 1... Training loss: 0.00304... Test loss: 0.00343\n",
      "Epoch: 1... Training loss: 0.00278... Test loss: 0.00362\n",
      "Epoch: 1... Training loss: 0.00287... Test loss: 0.00364\n",
      "Epoch: 1... Training loss: 0.00272... Test loss: 0.00295\n",
      "Epoch: 1... Training loss: 0.00265... Test loss: 0.00323\n",
      "Epoch: 1... Training loss: 0.00256... Test loss: 0.00308\n",
      "Epoch: 1... Training loss: 0.00256... Test loss: 0.00304\n",
      "Epoch: 1... Training loss: 0.00234... Test loss: 0.00293\n",
      "Epoch: 1... Training loss: 0.00231... Test loss: 0.00342\n",
      "Epoch: 1... Training loss: 0.00223... Test loss: 0.00314\n",
      "Epoch: 1... Training loss: 0.0022... Test loss: 0.0027\n",
      "Epoch: 1... Training loss: 0.00207... Test loss: 0.00277\n",
      "Epoch: 1... Training loss: 0.002... Test loss: 0.00261\n",
      "Epoch: 1... Training loss: 0.00192... Test loss: 0.0026\n",
      "Epoch: 1... Training loss: 0.00197... Test loss: 0.00253\n",
      "Epoch: 1... Training loss: 0.00175... Test loss: 0.00231\n",
      "Epoch: 1... Training loss: 0.0018... Test loss: 0.00222\n",
      "Epoch: 1... Training loss: 0.00172... Test loss: 0.00238\n",
      "Epoch: 1... Training loss: 0.00153... Test loss: 0.00193\n",
      "Epoch: 1... Training loss: 0.00159... Test loss: 0.00226\n",
      "Epoch: 1... Training loss: 0.00146... Test loss: 0.00176\n",
      "Epoch: 1... Training loss: 0.00145... Test loss: 0.00189\n",
      "Epoch: 1... Training loss: 0.00141... Test loss: 0.00178\n",
      "Epoch: 1... Training loss: 0.0013... Test loss: 0.00166\n",
      "Epoch: 1... Training loss: 0.00134... Test loss: 0.00171\n",
      "Epoch: 1... Training loss: 0.00126... Test loss: 0.00154\n",
      "Epoch: 1... Training loss: 0.00115... Test loss: 0.00204\n",
      "Epoch: 1... Training loss: 0.00114... Test loss: 0.00124\n",
      "Epoch: 1... Training loss: 0.00104... Test loss: 0.00134\n",
      "Epoch: 1... Training loss: 0.00103... Test loss: 0.00106\n",
      "Epoch: 1... Training loss: 0.00096... Test loss: 0.0014\n",
      "Epoch: 1... Training loss: 0.00088... Test loss: 0.00099\n",
      "Epoch: 1... Training loss: 0.00082... Test loss: 0.00095\n",
      "Epoch: 1... Training loss: 0.00088... Test loss: 0.00103\n",
      "Epoch: 1... Training loss: 0.00087... Test loss: 0.0011\n",
      "Epoch: 1... Training loss: 0.00082... Test loss: 0.00097\n",
      "Epoch: 1... Training loss: 0.00074... Test loss: 0.00102\n",
      "Epoch: 1... Training loss: 0.00064... Test loss: 0.00072\n",
      "Epoch: 1... Training loss: 0.00063... Test loss: 0.00084\n",
      "Epoch: 1... Training loss: 0.00058... Test loss: 0.00051\n",
      "Epoch: 1... Training loss: 0.00054... Test loss: 0.0008\n",
      "Epoch: 1... Training loss: 0.00051... Test loss: 0.0006\n",
      "Epoch: 1... Training loss: 0.00052... Test loss: 0.0008\n",
      "Epoch: 1... Training loss: 0.00049... Test loss: 0.00062\n",
      "Epoch: 1... Training loss: 0.00049... Test loss: 0.00059\n",
      "Epoch: 1... Training loss: 0.00042... Test loss: 0.00042\n",
      "Epoch: 1... Training loss: 0.00044... Test loss: 0.00058\n",
      "Epoch: 1... Training loss: 0.00038... Test loss: 0.00057\n",
      "Epoch: 1... Training loss: 0.00043... Test loss: 0.00041\n",
      "Epoch: 1... Training loss: 0.00034... Test loss: 0.00042\n",
      "Epoch: 1... Training loss: 0.00035... Test loss: 0.00038\n",
      "Epoch: 1... Training loss: 0.00033... Test loss: 0.00032\n",
      "Epoch: 1... Training loss: 0.00036... Test loss: 0.0003\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00035\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00035\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.00043\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00032\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00032\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.0003\n",
      "Epoch: 1... Training loss: 0.00026... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00024\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 8e-05\n",
      "Epoch: 1... Training loss: 8e-05... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 8e-05... Test loss: 8e-05\n",
      "Epoch: 1... Training loss: 7e-05... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 7e-05... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 8e-05\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 7e-05\n",
      "Epoch: 1... Training loss: 7e-05... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 8e-05\n",
      "Epoch: 1... Training loss: 8e-05... Test loss: 8e-05\n",
      "Epoch: 1... Training loss: 8e-05... Test loss: 8e-05\n",
      "221.03903556091245\n",
      "Epoch: 1... Training loss: 1.27636... Test loss: 0.5987\n",
      "Epoch: 1... Training loss: 0.55176... Test loss: 0.2136\n",
      "Epoch: 1... Training loss: 0.32298... Test loss: 0.14822\n",
      "Epoch: 1... Training loss: 0.20108... Test loss: 0.11455\n",
      "Epoch: 1... Training loss: 0.16464... Test loss: 0.07759\n",
      "Epoch: 1... Training loss: 0.13439... Test loss: 0.1053\n",
      "Epoch: 1... Training loss: 0.10838... Test loss: 0.05466\n",
      "Epoch: 1... Training loss: 0.09453... Test loss: 0.07536\n",
      "Epoch: 1... Training loss: 0.07873... Test loss: 0.03341\n",
      "Epoch: 1... Training loss: 0.07089... Test loss: 0.0628\n",
      "Epoch: 1... Training loss: 0.05757... Test loss: 0.02568\n",
      "Epoch: 1... Training loss: 0.05214... Test loss: 0.05387\n",
      "Epoch: 1... Training loss: 0.04804... Test loss: 0.02548\n",
      "Epoch: 1... Training loss: 0.04406... Test loss: 0.04553\n",
      "Epoch: 1... Training loss: 0.03982... Test loss: 0.03042\n",
      "Epoch: 1... Training loss: 0.03738... Test loss: 0.04357\n",
      "Epoch: 1... Training loss: 0.03391... Test loss: 0.03316\n",
      "Epoch: 1... Training loss: 0.03245... Test loss: 0.03356\n",
      "Epoch: 1... Training loss: 0.02965... Test loss: 0.03899\n",
      "Epoch: 1... Training loss: 0.02992... Test loss: 0.03399\n",
      "Epoch: 1... Training loss: 0.0265... Test loss: 0.0314\n",
      "Epoch: 1... Training loss: 0.02476... Test loss: 0.03743\n",
      "Epoch: 1... Training loss: 0.02443... Test loss: 0.01491\n",
      "Epoch: 1... Training loss: 0.0229... Test loss: 0.03403\n",
      "Epoch: 1... Training loss: 0.02214... Test loss: 0.01579\n",
      "Epoch: 1... Training loss: 0.02046... Test loss: 0.02881\n",
      "Epoch: 1... Training loss: 0.0197... Test loss: 0.01494\n",
      "Epoch: 1... Training loss: 0.01898... Test loss: 0.02315\n",
      "Epoch: 1... Training loss: 0.0183... Test loss: 0.01903\n",
      "Epoch: 1... Training loss: 0.01755... Test loss: 0.01894\n",
      "Epoch: 1... Training loss: 0.01697... Test loss: 0.01862\n",
      "Epoch: 1... Training loss: 0.01627... Test loss: 0.02174\n",
      "Epoch: 1... Training loss: 0.01596... Test loss: 0.01172\n",
      "Epoch: 1... Training loss: 0.01509... Test loss: 0.02167\n",
      "Epoch: 1... Training loss: 0.01418... Test loss: 0.01011\n",
      "Epoch: 1... Training loss: 0.01375... Test loss: 0.01957\n",
      "Epoch: 1... Training loss: 0.01354... Test loss: 0.01215\n",
      "Epoch: 1... Training loss: 0.01296... Test loss: 0.01438\n",
      "Epoch: 1... Training loss: 0.01266... Test loss: 0.01187\n",
      "Epoch: 1... Training loss: 0.01217... Test loss: 0.01159\n",
      "Epoch: 1... Training loss: 0.01195... Test loss: 0.01202\n",
      "Epoch: 1... Training loss: 0.01162... Test loss: 0.00959\n",
      "Epoch: 1... Training loss: 0.01135... Test loss: 0.01307\n",
      "Epoch: 1... Training loss: 0.01099... Test loss: 0.00899\n",
      "Epoch: 1... Training loss: 0.01082... Test loss: 0.01254\n",
      "Epoch: 1... Training loss: 0.01017... Test loss: 0.00757\n",
      "Epoch: 1... Training loss: 0.00993... Test loss: 0.01159\n",
      "Epoch: 1... Training loss: 0.00938... Test loss: 0.00755\n",
      "Epoch: 1... Training loss: 0.00922... Test loss: 0.01021\n",
      "Epoch: 1... Training loss: 0.0089... Test loss: 0.01064\n",
      "Epoch: 1... Training loss: 0.00853... Test loss: 0.00786\n",
      "Epoch: 1... Training loss: 0.00824... Test loss: 0.01164\n",
      "Epoch: 1... Training loss: 0.00808... Test loss: 0.00751\n",
      "Epoch: 1... Training loss: 0.00785... Test loss: 0.01015\n",
      "Epoch: 1... Training loss: 0.00766... Test loss: 0.00738\n",
      "Epoch: 1... Training loss: 0.0075... Test loss: 0.0073\n",
      "Epoch: 1... Training loss: 0.00718... Test loss: 0.00633\n",
      "Epoch: 1... Training loss: 0.00695... Test loss: 0.00781\n",
      "Epoch: 1... Training loss: 0.00666... Test loss: 0.00668\n",
      "Epoch: 1... Training loss: 0.00647... Test loss: 0.00665\n",
      "Epoch: 1... Training loss: 0.00619... Test loss: 0.00665\n",
      "Epoch: 1... Training loss: 0.00601... Test loss: 0.00682\n",
      "Epoch: 1... Training loss: 0.00588... Test loss: 0.00745\n",
      "Epoch: 1... Training loss: 0.00566... Test loss: 0.00655\n",
      "Epoch: 1... Training loss: 0.0075... Test loss: 0.02682\n",
      "Epoch: 1... Training loss: 0.00978... Test loss: 0.01479\n",
      "Epoch: 1... Training loss: 0.00904... Test loss: 0.01156\n",
      "Epoch: 1... Training loss: 0.0105... Test loss: 0.01543\n",
      "Epoch: 1... Training loss: 0.0095... Test loss: 0.0175\n",
      "Epoch: 1... Training loss: 0.00817... Test loss: 0.01121\n",
      "Epoch: 1... Training loss: 0.00805... Test loss: 0.01735\n",
      "Epoch: 1... Training loss: 0.00909... Test loss: 0.01078\n",
      "Epoch: 1... Training loss: 0.0076... Test loss: 0.01431\n",
      "Epoch: 1... Training loss: 0.00764... Test loss: 0.00949\n",
      "Epoch: 1... Training loss: 0.00775... Test loss: 0.01415\n",
      "Epoch: 1... Training loss: 0.00723... Test loss: 0.00856\n",
      "Epoch: 1... Training loss: 0.007... Test loss: 0.01051\n",
      "Epoch: 1... Training loss: 0.00734... Test loss: 0.00972\n",
      "Epoch: 1... Training loss: 0.0067... Test loss: 0.01113\n",
      "Epoch: 1... Training loss: 0.0062... Test loss: 0.00889\n",
      "Epoch: 1... Training loss: 0.00642... Test loss: 0.0085\n",
      "Epoch: 1... Training loss: 0.00634... Test loss: 0.00799\n",
      "Epoch: 1... Training loss: 0.00564... Test loss: 0.00642\n",
      "Epoch: 1... Training loss: 0.00552... Test loss: 0.00825\n",
      "Epoch: 1... Training loss: 0.00547... Test loss: 0.00549\n",
      "Epoch: 1... Training loss: 0.00531... Test loss: 0.00618\n",
      "Epoch: 1... Training loss: 0.00523... Test loss: 0.00629\n",
      "Epoch: 1... Training loss: 0.00462... Test loss: 0.00621\n",
      "Epoch: 1... Training loss: 0.00489... Test loss: 0.00516\n",
      "Epoch: 1... Training loss: 0.00458... Test loss: 0.00605\n",
      "Epoch: 1... Training loss: 0.00425... Test loss: 0.00504\n",
      "Epoch: 1... Training loss: 0.00422... Test loss: 0.00471\n",
      "Epoch: 1... Training loss: 0.00408... Test loss: 0.005\n",
      "Epoch: 1... Training loss: 0.00382... Test loss: 0.00446\n",
      "Epoch: 1... Training loss: 0.00366... Test loss: 0.00519\n",
      "Epoch: 1... Training loss: 0.0036... Test loss: 0.00505\n",
      "Epoch: 1... Training loss: 0.00352... Test loss: 0.00436\n",
      "Epoch: 1... Training loss: 0.00337... Test loss: 0.00439\n",
      "Epoch: 1... Training loss: 0.0032... Test loss: 0.00471\n",
      "Epoch: 1... Training loss: 0.0032... Test loss: 0.00331\n",
      "Epoch: 1... Training loss: 0.00315... Test loss: 0.00376\n",
      "Epoch: 1... Training loss: 0.00315... Test loss: 0.00338\n",
      "Epoch: 1... Training loss: 0.00296... Test loss: 0.00358\n",
      "Epoch: 1... Training loss: 0.00282... Test loss: 0.00353\n",
      "Epoch: 1... Training loss: 0.00277... Test loss: 0.00364\n",
      "Epoch: 1... Training loss: 0.00261... Test loss: 0.00327\n",
      "Epoch: 1... Training loss: 0.00249... Test loss: 0.0033\n",
      "Epoch: 1... Training loss: 0.00243... Test loss: 0.00313\n",
      "Epoch: 1... Training loss: 0.00239... Test loss: 0.00297\n",
      "Epoch: 1... Training loss: 0.0024... Test loss: 0.00283\n",
      "Epoch: 1... Training loss: 0.00224... Test loss: 0.00336\n",
      "Epoch: 1... Training loss: 0.00233... Test loss: 0.00311\n",
      "Epoch: 1... Training loss: 0.00232... Test loss: 0.00299\n",
      "Epoch: 1... Training loss: 0.00199... Test loss: 0.00248\n",
      "Epoch: 1... Training loss: 0.00198... Test loss: 0.00297\n",
      "Epoch: 1... Training loss: 0.00188... Test loss: 0.00252\n",
      "Epoch: 1... Training loss: 0.00184... Test loss: 0.00247\n",
      "Epoch: 1... Training loss: 0.00168... Test loss: 0.0025\n",
      "Epoch: 1... Training loss: 0.00168... Test loss: 0.00237\n",
      "Epoch: 1... Training loss: 0.00165... Test loss: 0.002\n",
      "Epoch: 1... Training loss: 0.00162... Test loss: 0.00193\n",
      "Epoch: 1... Training loss: 0.0016... Test loss: 0.002\n",
      "Epoch: 1... Training loss: 0.00154... Test loss: 0.0017\n",
      "Epoch: 1... Training loss: 0.00155... Test loss: 0.00178\n",
      "Epoch: 1... Training loss: 0.00148... Test loss: 0.00133\n",
      "Epoch: 1... Training loss: 0.00136... Test loss: 0.00176\n",
      "Epoch: 1... Training loss: 0.00135... Test loss: 0.00133\n",
      "Epoch: 1... Training loss: 0.0013... Test loss: 0.0014\n",
      "Epoch: 1... Training loss: 0.00128... Test loss: 0.0011\n",
      "Epoch: 1... Training loss: 0.00119... Test loss: 0.00145\n",
      "Epoch: 1... Training loss: 0.00112... Test loss: 0.00101\n",
      "Epoch: 1... Training loss: 0.00113... Test loss: 0.00139\n",
      "Epoch: 1... Training loss: 0.00105... Test loss: 0.00121\n",
      "Epoch: 1... Training loss: 0.00105... Test loss: 0.00141\n",
      "Epoch: 1... Training loss: 0.00103... Test loss: 0.00129\n",
      "Epoch: 1... Training loss: 0.00104... Test loss: 0.00099\n",
      "Epoch: 1... Training loss: 0.00097... Test loss: 0.00104\n",
      "Epoch: 1... Training loss: 0.00091... Test loss: 0.00098\n",
      "Epoch: 1... Training loss: 0.0009... Test loss: 0.0008\n",
      "Epoch: 1... Training loss: 0.00081... Test loss: 0.00091\n",
      "Epoch: 1... Training loss: 0.00078... Test loss: 0.00084\n",
      "Epoch: 1... Training loss: 0.00077... Test loss: 0.00089\n",
      "Epoch: 1... Training loss: 0.00075... Test loss: 0.00075\n",
      "Epoch: 1... Training loss: 0.00076... Test loss: 0.00106\n",
      "Epoch: 1... Training loss: 0.00072... Test loss: 0.00086\n",
      "Epoch: 1... Training loss: 0.00072... Test loss: 0.00075\n",
      "Epoch: 1... Training loss: 0.00064... Test loss: 0.00079\n",
      "Epoch: 1... Training loss: 0.00059... Test loss: 0.00077\n",
      "Epoch: 1... Training loss: 0.00057... Test loss: 0.00062\n",
      "Epoch: 1... Training loss: 0.00057... Test loss: 0.00073\n",
      "Epoch: 1... Training loss: 0.00057... Test loss: 0.00049\n",
      "Epoch: 1... Training loss: 0.00052... Test loss: 0.00073\n",
      "Epoch: 1... Training loss: 0.00056... Test loss: 0.00048\n",
      "Epoch: 1... Training loss: 0.00055... Test loss: 0.00044\n",
      "Epoch: 1... Training loss: 0.00047... Test loss: 0.00048\n",
      "Epoch: 1... Training loss: 0.00047... Test loss: 0.00049\n",
      "Epoch: 1... Training loss: 0.00044... Test loss: 0.00045\n",
      "Epoch: 1... Training loss: 0.00044... Test loss: 0.0005\n",
      "Epoch: 1... Training loss: 0.00044... Test loss: 0.0005\n",
      "Epoch: 1... Training loss: 0.00051... Test loss: 0.00045\n",
      "Epoch: 1... Training loss: 0.00043... Test loss: 0.00031\n",
      "Epoch: 1... Training loss: 0.00049... Test loss: 0.00042\n",
      "Epoch: 1... Training loss: 0.00037... Test loss: 0.00042\n",
      "Epoch: 1... Training loss: 0.00041... Test loss: 0.00036\n",
      "Epoch: 1... Training loss: 0.0004... Test loss: 0.00034\n",
      "Epoch: 1... Training loss: 0.00037... Test loss: 0.00035\n",
      "Epoch: 1... Training loss: 0.00035... Test loss: 0.00041\n",
      "Epoch: 1... Training loss: 0.00037... Test loss: 0.00032\n",
      "Epoch: 1... Training loss: 0.00045... Test loss: 0.00032\n",
      "Epoch: 1... Training loss: 0.00037... Test loss: 0.0003\n",
      "Epoch: 1... Training loss: 0.00032... Test loss: 0.0004\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00029... Test loss: 0.00043\n",
      "Epoch: 1... Training loss: 0.00029... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.00032\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00024\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00024\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00024\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 0.00013\n",
      "213.27490581583697\n",
      "Epoch: 1... Training loss: 0.90242... Test loss: 0.21692\n",
      "Epoch: 1... Training loss: 0.45585... Test loss: 0.17794\n",
      "Epoch: 1... Training loss: 0.317... Test loss: 0.09211\n",
      "Epoch: 1... Training loss: 0.18689... Test loss: 0.07038\n",
      "Epoch: 1... Training loss: 0.14422... Test loss: 0.05312\n",
      "Epoch: 1... Training loss: 0.11464... Test loss: 0.03896\n",
      "Epoch: 1... Training loss: 0.09748... Test loss: 0.03265\n",
      "Epoch: 1... Training loss: 0.0826... Test loss: 0.02473\n",
      "Epoch: 1... Training loss: 0.06986... Test loss: 0.03082\n",
      "Epoch: 1... Training loss: 0.05728... Test loss: 0.02319\n",
      "Epoch: 1... Training loss: 0.05283... Test loss: 0.02991\n",
      "Epoch: 1... Training loss: 0.04714... Test loss: 0.01429\n",
      "Epoch: 1... Training loss: 0.04325... Test loss: 0.03359\n",
      "Epoch: 1... Training loss: 0.04042... Test loss: 0.01191\n",
      "Epoch: 1... Training loss: 0.03659... Test loss: 0.03\n",
      "Epoch: 1... Training loss: 0.03518... Test loss: 0.01145\n",
      "Epoch: 1... Training loss: 0.03212... Test loss: 0.02695\n",
      "Epoch: 1... Training loss: 0.02993... Test loss: 0.01082\n",
      "Epoch: 1... Training loss: 0.0278... Test loss: 0.02424\n",
      "Epoch: 1... Training loss: 0.02675... Test loss: 0.01137\n",
      "Epoch: 1... Training loss: 0.02513... Test loss: 0.02592\n",
      "Epoch: 1... Training loss: 0.02443... Test loss: 0.0107\n",
      "Epoch: 1... Training loss: 0.02338... Test loss: 0.02395\n",
      "Epoch: 1... Training loss: 0.0224... Test loss: 0.01191\n",
      "Epoch: 1... Training loss: 0.02132... Test loss: 0.02538\n",
      "Epoch: 1... Training loss: 0.02059... Test loss: 0.01052\n",
      "Epoch: 1... Training loss: 0.01954... Test loss: 0.02503\n",
      "Epoch: 1... Training loss: 0.01895... Test loss: 0.01014\n",
      "Epoch: 1... Training loss: 0.01795... Test loss: 0.02094\n",
      "Epoch: 1... Training loss: 0.01691... Test loss: 0.01\n",
      "Epoch: 1... Training loss: 0.01645... Test loss: 0.01512\n",
      "Epoch: 1... Training loss: 0.01582... Test loss: 0.01962\n",
      "Epoch: 1... Training loss: 0.01532... Test loss: 0.01129\n",
      "Epoch: 1... Training loss: 0.01503... Test loss: 0.01863\n",
      "Epoch: 1... Training loss: 0.01451... Test loss: 0.01181\n",
      "Epoch: 1... Training loss: 0.01403... Test loss: 0.01846\n",
      "Epoch: 1... Training loss: 0.01357... Test loss: 0.01107\n",
      "Epoch: 1... Training loss: 0.01358... Test loss: 0.01192\n",
      "Epoch: 1... Training loss: 0.01266... Test loss: 0.0122\n",
      "Epoch: 1... Training loss: 0.01219... Test loss: 0.01037\n",
      "Epoch: 1... Training loss: 0.01196... Test loss: 0.01335\n",
      "Epoch: 1... Training loss: 0.01138... Test loss: 0.0085\n",
      "Epoch: 1... Training loss: 0.01124... Test loss: 0.01329\n",
      "Epoch: 1... Training loss: 0.01059... Test loss: 0.00681\n",
      "Epoch: 1... Training loss: 0.01033... Test loss: 0.0125\n",
      "Epoch: 1... Training loss: 0.01002... Test loss: 0.00732\n",
      "Epoch: 1... Training loss: 0.00977... Test loss: 0.01091\n",
      "Epoch: 1... Training loss: 0.00933... Test loss: 0.00735\n",
      "Epoch: 1... Training loss: 0.00909... Test loss: 0.00998\n",
      "Epoch: 1... Training loss: 0.00879... Test loss: 0.00751\n",
      "Epoch: 1... Training loss: 0.00851... Test loss: 0.0092\n",
      "Epoch: 1... Training loss: 0.00817... Test loss: 0.00684\n",
      "Epoch: 1... Training loss: 0.00794... Test loss: 0.00858\n",
      "Epoch: 1... Training loss: 0.00768... Test loss: 0.00656\n",
      "Epoch: 1... Training loss: 0.00741... Test loss: 0.0079\n",
      "Epoch: 1... Training loss: 0.00719... Test loss: 0.00677\n",
      "Epoch: 1... Training loss: 0.00713... Test loss: 0.00757\n",
      "Epoch: 1... Training loss: 0.00683... Test loss: 0.00715\n",
      "Epoch: 1... Training loss: 0.00666... Test loss: 0.00695\n",
      "Epoch: 1... Training loss: 0.00637... Test loss: 0.00583\n",
      "Epoch: 1... Training loss: 0.00623... Test loss: 0.00657\n",
      "Epoch: 1... Training loss: 0.00599... Test loss: 0.0048\n",
      "Epoch: 1... Training loss: 0.00577... Test loss: 0.00642\n",
      "Epoch: 1... Training loss: 0.00562... Test loss: 0.00463\n",
      "Epoch: 1... Training loss: 0.01131... Test loss: 0.03127\n",
      "Epoch: 1... Training loss: 0.00953... Test loss: 0.01096\n",
      "Epoch: 1... Training loss: 0.01069... Test loss: 0.01516\n",
      "Epoch: 1... Training loss: 0.00966... Test loss: 0.00978\n",
      "Epoch: 1... Training loss: 0.01079... Test loss: 0.0149\n",
      "Epoch: 1... Training loss: 0.00977... Test loss: 0.01171\n",
      "Epoch: 1... Training loss: 0.00887... Test loss: 0.00997\n",
      "Epoch: 1... Training loss: 0.00965... Test loss: 0.01153\n",
      "Epoch: 1... Training loss: 0.0081... Test loss: 0.00929\n",
      "Epoch: 1... Training loss: 0.00829... Test loss: 0.01101\n",
      "Epoch: 1... Training loss: 0.0076... Test loss: 0.00962\n",
      "Epoch: 1... Training loss: 0.00753... Test loss: 0.01114\n",
      "Epoch: 1... Training loss: 0.00696... Test loss: 0.00801\n",
      "Epoch: 1... Training loss: 0.00719... Test loss: 0.00888\n",
      "Epoch: 1... Training loss: 0.00738... Test loss: 0.01016\n",
      "Epoch: 1... Training loss: 0.00649... Test loss: 0.0106\n",
      "Epoch: 1... Training loss: 0.00619... Test loss: 0.00788\n",
      "Epoch: 1... Training loss: 0.00606... Test loss: 0.00943\n",
      "Epoch: 1... Training loss: 0.00592... Test loss: 0.0087\n",
      "Epoch: 1... Training loss: 0.00545... Test loss: 0.00774\n",
      "Epoch: 1... Training loss: 0.00582... Test loss: 0.00673\n",
      "Epoch: 1... Training loss: 0.00507... Test loss: 0.0071\n",
      "Epoch: 1... Training loss: 0.00518... Test loss: 0.00601\n",
      "Epoch: 1... Training loss: 0.00476... Test loss: 0.00793\n",
      "Epoch: 1... Training loss: 0.00496... Test loss: 0.00554\n",
      "Epoch: 1... Training loss: 0.0046... Test loss: 0.00714\n",
      "Epoch: 1... Training loss: 0.00432... Test loss: 0.00518\n",
      "Epoch: 1... Training loss: 0.00428... Test loss: 0.00578\n",
      "Epoch: 1... Training loss: 0.00394... Test loss: 0.00521\n",
      "Epoch: 1... Training loss: 0.00375... Test loss: 0.00622\n",
      "Epoch: 1... Training loss: 0.00376... Test loss: 0.00455\n",
      "Epoch: 1... Training loss: 0.00366... Test loss: 0.00535\n",
      "Epoch: 1... Training loss: 0.00351... Test loss: 0.00413\n",
      "Epoch: 1... Training loss: 0.00336... Test loss: 0.00416\n",
      "Epoch: 1... Training loss: 0.00337... Test loss: 0.00395\n",
      "Epoch: 1... Training loss: 0.00321... Test loss: 0.00374\n",
      "Epoch: 1... Training loss: 0.00304... Test loss: 0.00356\n",
      "Epoch: 1... Training loss: 0.0029... Test loss: 0.00373\n",
      "Epoch: 1... Training loss: 0.00294... Test loss: 0.00392\n",
      "Epoch: 1... Training loss: 0.00277... Test loss: 0.00401\n",
      "Epoch: 1... Training loss: 0.00278... Test loss: 0.00379\n",
      "Epoch: 1... Training loss: 0.00271... Test loss: 0.00363\n",
      "Epoch: 1... Training loss: 0.00259... Test loss: 0.00354\n",
      "Epoch: 1... Training loss: 0.00256... Test loss: 0.0033\n",
      "Epoch: 1... Training loss: 0.00238... Test loss: 0.00299\n",
      "Epoch: 1... Training loss: 0.00242... Test loss: 0.0031\n",
      "Epoch: 1... Training loss: 0.00224... Test loss: 0.00283\n",
      "Epoch: 1... Training loss: 0.0021... Test loss: 0.00287\n",
      "Epoch: 1... Training loss: 0.00211... Test loss: 0.00274\n",
      "Epoch: 1... Training loss: 0.00204... Test loss: 0.00254\n",
      "Epoch: 1... Training loss: 0.00201... Test loss: 0.00226\n",
      "Epoch: 1... Training loss: 0.00201... Test loss: 0.00237\n",
      "Epoch: 1... Training loss: 0.00188... Test loss: 0.00226\n",
      "Epoch: 1... Training loss: 0.00185... Test loss: 0.00216\n",
      "Epoch: 1... Training loss: 0.00179... Test loss: 0.00207\n",
      "Epoch: 1... Training loss: 0.00173... Test loss: 0.00216\n",
      "Epoch: 1... Training loss: 0.00167... Test loss: 0.00198\n",
      "Epoch: 1... Training loss: 0.00161... Test loss: 0.0018\n",
      "Epoch: 1... Training loss: 0.00151... Test loss: 0.00192\n",
      "Epoch: 1... Training loss: 0.00147... Test loss: 0.00156\n",
      "Epoch: 1... Training loss: 0.00141... Test loss: 0.00208\n",
      "Epoch: 1... Training loss: 0.00139... Test loss: 0.00136\n",
      "Epoch: 1... Training loss: 0.00129... Test loss: 0.002\n",
      "Epoch: 1... Training loss: 0.00124... Test loss: 0.00107\n",
      "Epoch: 1... Training loss: 0.00123... Test loss: 0.00152\n",
      "Epoch: 1... Training loss: 0.00116... Test loss: 0.00107\n",
      "Epoch: 1... Training loss: 0.0011... Test loss: 0.00166\n",
      "Epoch: 1... Training loss: 0.00109... Test loss: 0.0009\n",
      "Epoch: 1... Training loss: 0.00102... Test loss: 0.0014\n",
      "Epoch: 1... Training loss: 0.00095... Test loss: 0.00079\n",
      "Epoch: 1... Training loss: 0.0009... Test loss: 0.00116\n",
      "Epoch: 1... Training loss: 0.00088... Test loss: 0.00081\n",
      "Epoch: 1... Training loss: 0.00082... Test loss: 0.00112\n",
      "Epoch: 1... Training loss: 0.0008... Test loss: 0.00089\n",
      "Epoch: 1... Training loss: 0.00078... Test loss: 0.00077\n",
      "Epoch: 1... Training loss: 0.00074... Test loss: 0.00084\n",
      "Epoch: 1... Training loss: 0.00069... Test loss: 0.00082\n",
      "Epoch: 1... Training loss: 0.00066... Test loss: 0.00063\n",
      "Epoch: 1... Training loss: 0.00066... Test loss: 0.00073\n",
      "Epoch: 1... Training loss: 0.00064... Test loss: 0.00073\n",
      "Epoch: 1... Training loss: 0.00061... Test loss: 0.0006\n",
      "Epoch: 1... Training loss: 0.00059... Test loss: 0.00073\n",
      "Epoch: 1... Training loss: 0.00051... Test loss: 0.00065\n",
      "Epoch: 1... Training loss: 0.00052... Test loss: 0.00063\n",
      "Epoch: 1... Training loss: 0.00047... Test loss: 0.00063\n",
      "Epoch: 1... Training loss: 0.0005... Test loss: 0.00046\n",
      "Epoch: 1... Training loss: 0.00043... Test loss: 0.00064\n",
      "Epoch: 1... Training loss: 0.00047... Test loss: 0.00037\n",
      "Epoch: 1... Training loss: 0.00041... Test loss: 0.00065\n",
      "Epoch: 1... Training loss: 0.00045... Test loss: 0.00035\n",
      "Epoch: 1... Training loss: 0.00036... Test loss: 0.00067\n",
      "Epoch: 1... Training loss: 0.00039... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.00035... Test loss: 0.00055\n",
      "Epoch: 1... Training loss: 0.00037... Test loss: 0.00031\n",
      "Epoch: 1... Training loss: 0.00034... Test loss: 0.00045\n",
      "Epoch: 1... Training loss: 0.00034... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00041\n",
      "Epoch: 1... Training loss: 0.00034... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00046\n",
      "Epoch: 1... Training loss: 0.00031... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00034\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00031\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00024\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00031\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 8e-05\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 8e-05\n",
      "Epoch: 1... Training loss: 8e-05... Test loss: 7e-05\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 7e-05... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 7e-05... Test loss: 8e-05\n",
      "239.9339798205183\n",
      "Epoch: 1... Training loss: 0.88462... Test loss: 0.21735\n",
      "Epoch: 1... Training loss: 0.3964... Test loss: 0.11192\n",
      "Epoch: 1... Training loss: 0.23302... Test loss: 0.06042\n",
      "Epoch: 1... Training loss: 0.15041... Test loss: 0.03646\n",
      "Epoch: 1... Training loss: 0.12433... Test loss: 0.03488\n",
      "Epoch: 1... Training loss: 0.10419... Test loss: 0.02553\n",
      "Epoch: 1... Training loss: 0.08426... Test loss: 0.02113\n",
      "Epoch: 1... Training loss: 0.07438... Test loss: 0.01647\n",
      "Epoch: 1... Training loss: 0.06632... Test loss: 0.01411\n",
      "Epoch: 1... Training loss: 0.05931... Test loss: 0.01224\n",
      "Epoch: 1... Training loss: 0.05051... Test loss: 0.01192\n",
      "Epoch: 1... Training loss: 0.04225... Test loss: 0.00855\n",
      "Epoch: 1... Training loss: 0.04113... Test loss: 0.01171\n",
      "Epoch: 1... Training loss: 0.03834... Test loss: 0.00655\n",
      "Epoch: 1... Training loss: 0.03379... Test loss: 0.00925\n",
      "Epoch: 1... Training loss: 0.03232... Test loss: 0.00488\n",
      "Epoch: 1... Training loss: 0.0299... Test loss: 0.01005\n",
      "Epoch: 1... Training loss: 0.02788... Test loss: 0.00405\n",
      "Epoch: 1... Training loss: 0.02518... Test loss: 0.00989\n",
      "Epoch: 1... Training loss: 0.02469... Test loss: 0.00421\n",
      "Epoch: 1... Training loss: 0.02452... Test loss: 0.00628\n",
      "Epoch: 1... Training loss: 0.02252... Test loss: 0.00692\n",
      "Epoch: 1... Training loss: 0.02188... Test loss: 0.00436\n",
      "Epoch: 1... Training loss: 0.02035... Test loss: 0.00865\n",
      "Epoch: 1... Training loss: 0.0196... Test loss: 0.00495\n",
      "Epoch: 1... Training loss: 0.01863... Test loss: 0.00711\n",
      "Epoch: 1... Training loss: 0.01749... Test loss: 0.00541\n",
      "Epoch: 1... Training loss: 0.01667... Test loss: 0.00627\n",
      "Epoch: 1... Training loss: 0.01605... Test loss: 0.00839\n",
      "Epoch: 1... Training loss: 0.01538... Test loss: 0.00473\n",
      "Epoch: 1... Training loss: 0.01477... Test loss: 0.01121\n",
      "Epoch: 1... Training loss: 0.01449... Test loss: 0.00419\n",
      "Epoch: 1... Training loss: 0.01382... Test loss: 0.01021\n",
      "Epoch: 1... Training loss: 0.01344... Test loss: 0.00516\n",
      "Epoch: 1... Training loss: 0.01295... Test loss: 0.00823\n",
      "Epoch: 1... Training loss: 0.01248... Test loss: 0.00722\n",
      "Epoch: 1... Training loss: 0.01189... Test loss: 0.00663\n",
      "Epoch: 1... Training loss: 0.01194... Test loss: 0.00948\n",
      "Epoch: 1... Training loss: 0.01124... Test loss: 0.0052\n",
      "Epoch: 1... Training loss: 0.0111... Test loss: 0.00901\n",
      "Epoch: 1... Training loss: 0.01069... Test loss: 0.00481\n",
      "Epoch: 1... Training loss: 0.01038... Test loss: 0.00846\n",
      "Epoch: 1... Training loss: 0.00991... Test loss: 0.00706\n",
      "Epoch: 1... Training loss: 0.00982... Test loss: 0.00773\n",
      "Epoch: 1... Training loss: 0.00945... Test loss: 0.00952\n",
      "Epoch: 1... Training loss: 0.00929... Test loss: 0.00799\n",
      "Epoch: 1... Training loss: 0.00895... Test loss: 0.00942\n",
      "Epoch: 1... Training loss: 0.00873... Test loss: 0.00754\n",
      "Epoch: 1... Training loss: 0.00835... Test loss: 0.00707\n",
      "Epoch: 1... Training loss: 0.00801... Test loss: 0.00905\n",
      "Epoch: 1... Training loss: 0.00788... Test loss: 0.00628\n",
      "Epoch: 1... Training loss: 0.00753... Test loss: 0.00734\n",
      "Epoch: 1... Training loss: 0.00746... Test loss: 0.00613\n",
      "Epoch: 1... Training loss: 0.0071... Test loss: 0.0066\n",
      "Epoch: 1... Training loss: 0.00697... Test loss: 0.00646\n",
      "Epoch: 1... Training loss: 0.00668... Test loss: 0.00677\n",
      "Epoch: 1... Training loss: 0.00649... Test loss: 0.00698\n",
      "Epoch: 1... Training loss: 0.00619... Test loss: 0.00608\n",
      "Epoch: 1... Training loss: 0.00599... Test loss: 0.00645\n",
      "Epoch: 1... Training loss: 0.00573... Test loss: 0.00616\n",
      "Epoch: 1... Training loss: 0.00559... Test loss: 0.00597\n",
      "Epoch: 1... Training loss: 0.0054... Test loss: 0.00637\n",
      "Epoch: 1... Training loss: 0.0054... Test loss: 0.00607\n",
      "Epoch: 1... Training loss: 0.00524... Test loss: 0.0062\n",
      "Epoch: 1... Training loss: 0.00967... Test loss: 0.00843\n",
      "Epoch: 1... Training loss: 0.01422... Test loss: 0.01216\n",
      "Epoch: 1... Training loss: 0.00861... Test loss: 0.01233\n",
      "Epoch: 1... Training loss: 0.00852... Test loss: 0.01535\n",
      "Epoch: 1... Training loss: 0.00835... Test loss: 0.01249\n",
      "Epoch: 1... Training loss: 0.00849... Test loss: 0.01068\n",
      "Epoch: 1... Training loss: 0.00829... Test loss: 0.01695\n",
      "Epoch: 1... Training loss: 0.00853... Test loss: 0.00888\n",
      "Epoch: 1... Training loss: 0.00732... Test loss: 0.01223\n",
      "Epoch: 1... Training loss: 0.00714... Test loss: 0.00959\n",
      "Epoch: 1... Training loss: 0.00677... Test loss: 0.01056\n",
      "Epoch: 1... Training loss: 0.00729... Test loss: 0.00948\n",
      "Epoch: 1... Training loss: 0.0062... Test loss: 0.00813\n",
      "Epoch: 1... Training loss: 0.00658... Test loss: 0.00947\n",
      "Epoch: 1... Training loss: 0.00625... Test loss: 0.00722\n",
      "Epoch: 1... Training loss: 0.00594... Test loss: 0.00944\n",
      "Epoch: 1... Training loss: 0.006... Test loss: 0.0066\n",
      "Epoch: 1... Training loss: 0.00546... Test loss: 0.00709\n",
      "Epoch: 1... Training loss: 0.00533... Test loss: 0.00589\n",
      "Epoch: 1... Training loss: 0.00498... Test loss: 0.00667\n",
      "Epoch: 1... Training loss: 0.00525... Test loss: 0.00663\n",
      "Epoch: 1... Training loss: 0.0052... Test loss: 0.00599\n",
      "Epoch: 1... Training loss: 0.00479... Test loss: 0.00619\n",
      "Epoch: 1... Training loss: 0.00455... Test loss: 0.00532\n",
      "Epoch: 1... Training loss: 0.00443... Test loss: 0.0052\n",
      "Epoch: 1... Training loss: 0.00402... Test loss: 0.00465\n",
      "Epoch: 1... Training loss: 0.00391... Test loss: 0.00448\n",
      "Epoch: 1... Training loss: 0.00399... Test loss: 0.00483\n",
      "Epoch: 1... Training loss: 0.00365... Test loss: 0.00463\n",
      "Epoch: 1... Training loss: 0.00354... Test loss: 0.00559\n",
      "Epoch: 1... Training loss: 0.00346... Test loss: 0.00423\n",
      "Epoch: 1... Training loss: 0.00344... Test loss: 0.00459\n",
      "Epoch: 1... Training loss: 0.00341... Test loss: 0.00383\n",
      "Epoch: 1... Training loss: 0.00325... Test loss: 0.00404\n",
      "Epoch: 1... Training loss: 0.00327... Test loss: 0.00382\n",
      "Epoch: 1... Training loss: 0.00314... Test loss: 0.00421\n",
      "Epoch: 1... Training loss: 0.00314... Test loss: 0.0037\n",
      "Epoch: 1... Training loss: 0.00286... Test loss: 0.0037\n",
      "Epoch: 1... Training loss: 0.00294... Test loss: 0.00315\n",
      "Epoch: 1... Training loss: 0.00285... Test loss: 0.00278\n",
      "Epoch: 1... Training loss: 0.00267... Test loss: 0.00338\n",
      "Epoch: 1... Training loss: 0.00264... Test loss: 0.00327\n",
      "Epoch: 1... Training loss: 0.00249... Test loss: 0.00296\n",
      "Epoch: 1... Training loss: 0.00259... Test loss: 0.00292\n",
      "Epoch: 1... Training loss: 0.00239... Test loss: 0.00379\n",
      "Epoch: 1... Training loss: 0.00239... Test loss: 0.00282\n",
      "Epoch: 1... Training loss: 0.00233... Test loss: 0.0029\n",
      "Epoch: 1... Training loss: 0.00218... Test loss: 0.00263\n",
      "Epoch: 1... Training loss: 0.00221... Test loss: 0.00275\n",
      "Epoch: 1... Training loss: 0.00205... Test loss: 0.0025\n",
      "Epoch: 1... Training loss: 0.00202... Test loss: 0.00235\n",
      "Epoch: 1... Training loss: 0.00189... Test loss: 0.0025\n",
      "Epoch: 1... Training loss: 0.0019... Test loss: 0.00238\n",
      "Epoch: 1... Training loss: 0.00186... Test loss: 0.00198\n",
      "Epoch: 1... Training loss: 0.00185... Test loss: 0.00249\n",
      "Epoch: 1... Training loss: 0.0018... Test loss: 0.00205\n",
      "Epoch: 1... Training loss: 0.00173... Test loss: 0.0017\n",
      "Epoch: 1... Training loss: 0.00166... Test loss: 0.00206\n",
      "Epoch: 1... Training loss: 0.00169... Test loss: 0.00165\n",
      "Epoch: 1... Training loss: 0.00149... Test loss: 0.00209\n",
      "Epoch: 1... Training loss: 0.00156... Test loss: 0.00139\n",
      "Epoch: 1... Training loss: 0.00139... Test loss: 0.00185\n",
      "Epoch: 1... Training loss: 0.00145... Test loss: 0.00124\n",
      "Epoch: 1... Training loss: 0.00127... Test loss: 0.0019\n",
      "Epoch: 1... Training loss: 0.00128... Test loss: 0.00111\n",
      "Epoch: 1... Training loss: 0.0012... Test loss: 0.00158\n",
      "Epoch: 1... Training loss: 0.00127... Test loss: 0.00111\n",
      "Epoch: 1... Training loss: 0.00116... Test loss: 0.00145\n",
      "Epoch: 1... Training loss: 0.00116... Test loss: 0.00113\n",
      "Epoch: 1... Training loss: 0.00104... Test loss: 0.00116\n",
      "Epoch: 1... Training loss: 0.001... Test loss: 0.00115\n",
      "Epoch: 1... Training loss: 0.00091... Test loss: 0.0013\n",
      "Epoch: 1... Training loss: 0.00098... Test loss: 0.001\n",
      "Epoch: 1... Training loss: 0.0009... Test loss: 0.0009\n",
      "Epoch: 1... Training loss: 0.00083... Test loss: 0.00084\n",
      "Epoch: 1... Training loss: 0.00088... Test loss: 0.0007\n",
      "Epoch: 1... Training loss: 0.00081... Test loss: 0.00088\n",
      "Epoch: 1... Training loss: 0.00076... Test loss: 0.00085\n",
      "Epoch: 1... Training loss: 0.00074... Test loss: 0.0007\n",
      "Epoch: 1... Training loss: 0.00073... Test loss: 0.00092\n",
      "Epoch: 1... Training loss: 0.00064... Test loss: 0.00064\n",
      "Epoch: 1... Training loss: 0.00065... Test loss: 0.00069\n",
      "Epoch: 1... Training loss: 0.00063... Test loss: 0.00072\n",
      "Epoch: 1... Training loss: 0.00059... Test loss: 0.00076\n",
      "Epoch: 1... Training loss: 0.00054... Test loss: 0.00066\n",
      "Epoch: 1... Training loss: 0.00058... Test loss: 0.00058\n",
      "Epoch: 1... Training loss: 0.00054... Test loss: 0.00065\n",
      "Epoch: 1... Training loss: 0.00053... Test loss: 0.00052\n",
      "Epoch: 1... Training loss: 0.00047... Test loss: 0.00052\n",
      "Epoch: 1... Training loss: 0.00049... Test loss: 0.00055\n",
      "Epoch: 1... Training loss: 0.00046... Test loss: 0.00054\n",
      "Epoch: 1... Training loss: 0.0005... Test loss: 0.00041\n",
      "Epoch: 1... Training loss: 0.00042... Test loss: 0.00054\n",
      "Epoch: 1... Training loss: 0.00042... Test loss: 0.00034\n",
      "Epoch: 1... Training loss: 0.00042... Test loss: 0.00047\n",
      "Epoch: 1... Training loss: 0.00041... Test loss: 0.00037\n",
      "Epoch: 1... Training loss: 0.0004... Test loss: 0.00057\n",
      "Epoch: 1... Training loss: 0.00043... Test loss: 0.00036\n",
      "Epoch: 1... Training loss: 0.00037... Test loss: 0.00044\n",
      "Epoch: 1... Training loss: 0.00036... Test loss: 0.00035\n",
      "Epoch: 1... Training loss: 0.00046... Test loss: 0.00037\n",
      "Epoch: 1... Training loss: 0.00034... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.00035... Test loss: 0.00039\n",
      "Epoch: 1... Training loss: 0.00041... Test loss: 0.00033\n",
      "Epoch: 1... Training loss: 0.00032... Test loss: 0.00032\n",
      "Epoch: 1... Training loss: 0.00037... Test loss: 0.00031\n",
      "Epoch: 1... Training loss: 0.00031... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.00029... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.00026... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.00029... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00028\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00012\n",
      "225.34775545506272\n",
      "Epoch: 1... Training loss: 0.89552... Test loss: 0.31376\n",
      "Epoch: 1... Training loss: 0.47813... Test loss: 0.16165\n",
      "Epoch: 1... Training loss: 0.27901... Test loss: 0.09478\n",
      "Epoch: 1... Training loss: 0.16473... Test loss: 0.05827\n",
      "Epoch: 1... Training loss: 0.1292... Test loss: 0.04727\n",
      "Epoch: 1... Training loss: 0.09697... Test loss: 0.03251\n",
      "Epoch: 1... Training loss: 0.08008... Test loss: 0.02531\n",
      "Epoch: 1... Training loss: 0.06549... Test loss: 0.02011\n",
      "Epoch: 1... Training loss: 0.05814... Test loss: 0.0142\n",
      "Epoch: 1... Training loss: 0.04663... Test loss: 0.01304\n",
      "Epoch: 1... Training loss: 0.04338... Test loss: 0.00875\n",
      "Epoch: 1... Training loss: 0.04209... Test loss: 0.00977\n",
      "Epoch: 1... Training loss: 0.03739... Test loss: 0.00715\n",
      "Epoch: 1... Training loss: 0.03474... Test loss: 0.00708\n",
      "Epoch: 1... Training loss: 0.03255... Test loss: 0.00605\n",
      "Epoch: 1... Training loss: 0.03098... Test loss: 0.00521\n",
      "Epoch: 1... Training loss: 0.02926... Test loss: 0.00721\n",
      "Epoch: 1... Training loss: 0.02745... Test loss: 0.00502\n",
      "Epoch: 1... Training loss: 0.02587... Test loss: 0.01372\n",
      "Epoch: 1... Training loss: 0.02477... Test loss: 0.00393\n",
      "Epoch: 1... Training loss: 0.02469... Test loss: 0.01052\n",
      "Epoch: 1... Training loss: 0.02291... Test loss: 0.00362\n",
      "Epoch: 1... Training loss: 0.02113... Test loss: 0.0123\n",
      "Epoch: 1... Training loss: 0.02032... Test loss: 0.00399\n",
      "Epoch: 1... Training loss: 0.01945... Test loss: 0.01264\n",
      "Epoch: 1... Training loss: 0.01842... Test loss: 0.00449\n",
      "Epoch: 1... Training loss: 0.01769... Test loss: 0.01257\n",
      "Epoch: 1... Training loss: 0.01735... Test loss: 0.0052\n",
      "Epoch: 1... Training loss: 0.0165... Test loss: 0.01389\n",
      "Epoch: 1... Training loss: 0.01616... Test loss: 0.00738\n",
      "Epoch: 1... Training loss: 0.0154... Test loss: 0.00899\n",
      "Epoch: 1... Training loss: 0.0153... Test loss: 0.01146\n",
      "Epoch: 1... Training loss: 0.01463... Test loss: 0.00688\n",
      "Epoch: 1... Training loss: 0.01421... Test loss: 0.01316\n",
      "Epoch: 1... Training loss: 0.01373... Test loss: 0.00622\n",
      "Epoch: 1... Training loss: 0.01326... Test loss: 0.01214\n",
      "Epoch: 1... Training loss: 0.01287... Test loss: 0.00771\n",
      "Epoch: 1... Training loss: 0.01232... Test loss: 0.01101\n",
      "Epoch: 1... Training loss: 0.01196... Test loss: 0.0086\n",
      "Epoch: 1... Training loss: 0.01166... Test loss: 0.01093\n",
      "Epoch: 1... Training loss: 0.01107... Test loss: 0.01046\n",
      "Epoch: 1... Training loss: 0.01062... Test loss: 0.00884\n",
      "Epoch: 1... Training loss: 0.01016... Test loss: 0.01115\n",
      "Epoch: 1... Training loss: 0.01024... Test loss: 0.00772\n",
      "Epoch: 1... Training loss: 0.00952... Test loss: 0.01045\n",
      "Epoch: 1... Training loss: 0.00936... Test loss: 0.00566\n",
      "Epoch: 1... Training loss: 0.00915... Test loss: 0.00944\n",
      "Epoch: 1... Training loss: 0.009... Test loss: 0.00652\n",
      "Epoch: 1... Training loss: 0.00863... Test loss: 0.00762\n",
      "Epoch: 1... Training loss: 0.0083... Test loss: 0.00694\n",
      "Epoch: 1... Training loss: 0.00805... Test loss: 0.00677\n",
      "Epoch: 1... Training loss: 0.00793... Test loss: 0.00809\n",
      "Epoch: 1... Training loss: 0.00752... Test loss: 0.00572\n",
      "Epoch: 1... Training loss: 0.00736... Test loss: 0.00719\n",
      "Epoch: 1... Training loss: 0.00711... Test loss: 0.00517\n",
      "Epoch: 1... Training loss: 0.00699... Test loss: 0.00672\n",
      "Epoch: 1... Training loss: 0.00679... Test loss: 0.00491\n",
      "Epoch: 1... Training loss: 0.00667... Test loss: 0.0065\n",
      "Epoch: 1... Training loss: 0.00641... Test loss: 0.00484\n",
      "Epoch: 1... Training loss: 0.00617... Test loss: 0.00631\n",
      "Epoch: 1... Training loss: 0.00597... Test loss: 0.00542\n",
      "Epoch: 1... Training loss: 0.00585... Test loss: 0.00572\n",
      "Epoch: 1... Training loss: 0.00571... Test loss: 0.00592\n",
      "Epoch: 1... Training loss: 0.00547... Test loss: 0.00464\n",
      "Epoch: 1... Training loss: 0.01592... Test loss: 0.01889\n",
      "Epoch: 1... Training loss: 0.01127... Test loss: 0.02078\n",
      "Epoch: 1... Training loss: 0.00994... Test loss: 0.01765\n",
      "Epoch: 1... Training loss: 0.00878... Test loss: 0.01516\n",
      "Epoch: 1... Training loss: 0.00817... Test loss: 0.01336\n",
      "Epoch: 1... Training loss: 0.00909... Test loss: 0.01492\n",
      "Epoch: 1... Training loss: 0.00826... Test loss: 0.01208\n",
      "Epoch: 1... Training loss: 0.00799... Test loss: 0.01061\n",
      "Epoch: 1... Training loss: 0.00811... Test loss: 0.01199\n",
      "Epoch: 1... Training loss: 0.00856... Test loss: 0.00992\n",
      "Epoch: 1... Training loss: 0.00763... Test loss: 0.01273\n",
      "Epoch: 1... Training loss: 0.00732... Test loss: 0.01208\n",
      "Epoch: 1... Training loss: 0.00704... Test loss: 0.00986\n",
      "Epoch: 1... Training loss: 0.00652... Test loss: 0.01175\n",
      "Epoch: 1... Training loss: 0.00579... Test loss: 0.00897\n",
      "Epoch: 1... Training loss: 0.00572... Test loss: 0.0072\n",
      "Epoch: 1... Training loss: 0.00574... Test loss: 0.00933\n",
      "Epoch: 1... Training loss: 0.00555... Test loss: 0.00799\n",
      "Epoch: 1... Training loss: 0.00584... Test loss: 0.00662\n",
      "Epoch: 1... Training loss: 0.0052... Test loss: 0.00804\n",
      "Epoch: 1... Training loss: 0.00514... Test loss: 0.00565\n",
      "Epoch: 1... Training loss: 0.00495... Test loss: 0.00797\n",
      "Epoch: 1... Training loss: 0.00498... Test loss: 0.00651\n",
      "Epoch: 1... Training loss: 0.00465... Test loss: 0.00694\n",
      "Epoch: 1... Training loss: 0.00448... Test loss: 0.00556\n",
      "Epoch: 1... Training loss: 0.00408... Test loss: 0.00667\n",
      "Epoch: 1... Training loss: 0.00401... Test loss: 0.0059\n",
      "Epoch: 1... Training loss: 0.00401... Test loss: 0.0049\n",
      "Epoch: 1... Training loss: 0.00373... Test loss: 0.00469\n",
      "Epoch: 1... Training loss: 0.00371... Test loss: 0.00484\n",
      "Epoch: 1... Training loss: 0.00353... Test loss: 0.00384\n",
      "Epoch: 1... Training loss: 0.00343... Test loss: 0.00399\n",
      "Epoch: 1... Training loss: 0.00325... Test loss: 0.00458\n",
      "Epoch: 1... Training loss: 0.00315... Test loss: 0.00415\n",
      "Epoch: 1... Training loss: 0.00307... Test loss: 0.00371\n",
      "Epoch: 1... Training loss: 0.00309... Test loss: 0.00299\n",
      "Epoch: 1... Training loss: 0.003... Test loss: 0.00338\n",
      "Epoch: 1... Training loss: 0.00283... Test loss: 0.00328\n",
      "Epoch: 1... Training loss: 0.00279... Test loss: 0.00254\n",
      "Epoch: 1... Training loss: 0.00283... Test loss: 0.00435\n",
      "Epoch: 1... Training loss: 0.00277... Test loss: 0.00397\n",
      "Epoch: 1... Training loss: 0.00256... Test loss: 0.00261\n",
      "Epoch: 1... Training loss: 0.00245... Test loss: 0.00313\n",
      "Epoch: 1... Training loss: 0.0024... Test loss: 0.0026\n",
      "Epoch: 1... Training loss: 0.00237... Test loss: 0.00325\n",
      "Epoch: 1... Training loss: 0.00229... Test loss: 0.00276\n",
      "Epoch: 1... Training loss: 0.00218... Test loss: 0.00254\n",
      "Epoch: 1... Training loss: 0.00211... Test loss: 0.00252\n",
      "Epoch: 1... Training loss: 0.00205... Test loss: 0.00239\n",
      "Epoch: 1... Training loss: 0.00192... Test loss: 0.00229\n",
      "Epoch: 1... Training loss: 0.0019... Test loss: 0.00245\n",
      "Epoch: 1... Training loss: 0.00175... Test loss: 0.00238\n",
      "Epoch: 1... Training loss: 0.0018... Test loss: 0.00212\n",
      "Epoch: 1... Training loss: 0.00162... Test loss: 0.00237\n",
      "Epoch: 1... Training loss: 0.00162... Test loss: 0.0019\n",
      "Epoch: 1... Training loss: 0.00154... Test loss: 0.00247\n",
      "Epoch: 1... Training loss: 0.00142... Test loss: 0.00168\n",
      "Epoch: 1... Training loss: 0.00139... Test loss: 0.00238\n",
      "Epoch: 1... Training loss: 0.00132... Test loss: 0.00176\n",
      "Epoch: 1... Training loss: 0.00128... Test loss: 0.00223\n",
      "Epoch: 1... Training loss: 0.00119... Test loss: 0.0011\n",
      "Epoch: 1... Training loss: 0.00122... Test loss: 0.00201\n",
      "Epoch: 1... Training loss: 0.00109... Test loss: 0.00109\n",
      "Epoch: 1... Training loss: 0.00106... Test loss: 0.00177\n",
      "Epoch: 1... Training loss: 0.00098... Test loss: 0.00088\n",
      "Epoch: 1... Training loss: 0.00099... Test loss: 0.00138\n",
      "Epoch: 1... Training loss: 0.00092... Test loss: 0.00086\n",
      "Epoch: 1... Training loss: 0.00092... Test loss: 0.0011\n",
      "Epoch: 1... Training loss: 0.00085... Test loss: 0.0009\n",
      "Epoch: 1... Training loss: 0.00082... Test loss: 0.00105\n",
      "Epoch: 1... Training loss: 0.00075... Test loss: 0.00077\n",
      "Epoch: 1... Training loss: 0.00078... Test loss: 0.00111\n",
      "Epoch: 1... Training loss: 0.00073... Test loss: 0.00067\n",
      "Epoch: 1... Training loss: 0.00067... Test loss: 0.00078\n",
      "Epoch: 1... Training loss: 0.00059... Test loss: 0.00077\n",
      "Epoch: 1... Training loss: 0.0006... Test loss: 0.00076\n",
      "Epoch: 1... Training loss: 0.00053... Test loss: 0.00064\n",
      "Epoch: 1... Training loss: 0.00054... Test loss: 0.0007\n",
      "Epoch: 1... Training loss: 0.00054... Test loss: 0.00061\n",
      "Epoch: 1... Training loss: 0.00053... Test loss: 0.00064\n",
      "Epoch: 1... Training loss: 0.00055... Test loss: 0.0007\n",
      "Epoch: 1... Training loss: 0.00047... Test loss: 0.00047\n",
      "Epoch: 1... Training loss: 0.00044... Test loss: 0.00059\n",
      "Epoch: 1... Training loss: 0.00039... Test loss: 0.00041\n",
      "Epoch: 1... Training loss: 0.00037... Test loss: 0.00065\n",
      "Epoch: 1... Training loss: 0.00036... Test loss: 0.00043\n",
      "Epoch: 1... Training loss: 0.00038... Test loss: 0.0004\n",
      "Epoch: 1... Training loss: 0.00037... Test loss: 0.00034\n",
      "Epoch: 1... Training loss: 0.00033... Test loss: 0.00024\n",
      "Epoch: 1... Training loss: 0.00032... Test loss: 0.00031\n",
      "Epoch: 1... Training loss: 0.00032... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00036\n",
      "Epoch: 1... Training loss: 0.00029... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.0003\n",
      "Epoch: 1... Training loss: 0.00029... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00031\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.0003\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00024\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 8e-05\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 8e-05... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.0001\n",
      "225.99900645203888\n",
      "Epoch: 1... Training loss: 0.95379... Test loss: 0.243\n",
      "Epoch: 1... Training loss: 0.4178... Test loss: 0.14339\n",
      "Epoch: 1... Training loss: 0.25473... Test loss: 0.10237\n",
      "Epoch: 1... Training loss: 0.17902... Test loss: 0.07367\n",
      "Epoch: 1... Training loss: 0.13748... Test loss: 0.04926\n",
      "Epoch: 1... Training loss: 0.11555... Test loss: 0.04322\n",
      "Epoch: 1... Training loss: 0.1009... Test loss: 0.03462\n",
      "Epoch: 1... Training loss: 0.09064... Test loss: 0.03222\n",
      "Epoch: 1... Training loss: 0.07848... Test loss: 0.02366\n",
      "Epoch: 1... Training loss: 0.0685... Test loss: 0.02597\n",
      "Epoch: 1... Training loss: 0.06249... Test loss: 0.01529\n",
      "Epoch: 1... Training loss: 0.0555... Test loss: 0.01968\n",
      "Epoch: 1... Training loss: 0.04929... Test loss: 0.00978\n",
      "Epoch: 1... Training loss: 0.04559... Test loss: 0.01646\n",
      "Epoch: 1... Training loss: 0.04106... Test loss: 0.0087\n",
      "Epoch: 1... Training loss: 0.03852... Test loss: 0.01553\n",
      "Epoch: 1... Training loss: 0.03556... Test loss: 0.00728\n",
      "Epoch: 1... Training loss: 0.03195... Test loss: 0.014\n",
      "Epoch: 1... Training loss: 0.02989... Test loss: 0.0075\n",
      "Epoch: 1... Training loss: 0.02787... Test loss: 0.0146\n",
      "Epoch: 1... Training loss: 0.02619... Test loss: 0.00735\n",
      "Epoch: 1... Training loss: 0.02413... Test loss: 0.01415\n",
      "Epoch: 1... Training loss: 0.02296... Test loss: 0.00762\n",
      "Epoch: 1... Training loss: 0.02123... Test loss: 0.01557\n",
      "Epoch: 1... Training loss: 0.02059... Test loss: 0.00755\n",
      "Epoch: 1... Training loss: 0.01907... Test loss: 0.01407\n",
      "Epoch: 1... Training loss: 0.01842... Test loss: 0.00872\n",
      "Epoch: 1... Training loss: 0.01782... Test loss: 0.00967\n",
      "Epoch: 1... Training loss: 0.01718... Test loss: 0.01086\n",
      "Epoch: 1... Training loss: 0.01583... Test loss: 0.00717\n",
      "Epoch: 1... Training loss: 0.01506... Test loss: 0.01218\n",
      "Epoch: 1... Training loss: 0.01452... Test loss: 0.00743\n",
      "Epoch: 1... Training loss: 0.0133... Test loss: 0.01102\n",
      "Epoch: 1... Training loss: 0.01327... Test loss: 0.00693\n",
      "Epoch: 1... Training loss: 0.0127... Test loss: 0.00968\n",
      "Epoch: 1... Training loss: 0.01244... Test loss: 0.00599\n",
      "Epoch: 1... Training loss: 0.01206... Test loss: 0.008\n",
      "Epoch: 1... Training loss: 0.01181... Test loss: 0.00776\n",
      "Epoch: 1... Training loss: 0.0114... Test loss: 0.00695\n",
      "Epoch: 1... Training loss: 0.01121... Test loss: 0.00759\n",
      "Epoch: 1... Training loss: 0.01047... Test loss: 0.00574\n",
      "Epoch: 1... Training loss: 0.01033... Test loss: 0.00701\n",
      "Epoch: 1... Training loss: 0.00998... Test loss: 0.00519\n",
      "Epoch: 1... Training loss: 0.00964... Test loss: 0.00759\n",
      "Epoch: 1... Training loss: 0.00936... Test loss: 0.00476\n",
      "Epoch: 1... Training loss: 0.0091... Test loss: 0.00717\n",
      "Epoch: 1... Training loss: 0.00884... Test loss: 0.0047\n",
      "Epoch: 1... Training loss: 0.00852... Test loss: 0.00742\n",
      "Epoch: 1... Training loss: 0.0082... Test loss: 0.00681\n",
      "Epoch: 1... Training loss: 0.00781... Test loss: 0.00661\n",
      "Epoch: 1... Training loss: 0.00757... Test loss: 0.00789\n",
      "Epoch: 1... Training loss: 0.00736... Test loss: 0.00611\n",
      "Epoch: 1... Training loss: 0.0072... Test loss: 0.00751\n",
      "Epoch: 1... Training loss: 0.00704... Test loss: 0.00522\n",
      "Epoch: 1... Training loss: 0.00687... Test loss: 0.00663\n",
      "Epoch: 1... Training loss: 0.00657... Test loss: 0.00515\n",
      "Epoch: 1... Training loss: 0.00636... Test loss: 0.00594\n",
      "Epoch: 1... Training loss: 0.00616... Test loss: 0.00558\n",
      "Epoch: 1... Training loss: 0.00598... Test loss: 0.00564\n",
      "Epoch: 1... Training loss: 0.00576... Test loss: 0.00566\n",
      "Epoch: 1... Training loss: 0.00558... Test loss: 0.00544\n",
      "Epoch: 1... Training loss: 0.00544... Test loss: 0.00582\n",
      "Epoch: 1... Training loss: 0.00529... Test loss: 0.0052\n",
      "Epoch: 1... Training loss: 0.00514... Test loss: 0.00557\n",
      "Epoch: 1... Training loss: 0.00925... Test loss: 0.00902\n",
      "Epoch: 1... Training loss: 0.00947... Test loss: 0.01299\n",
      "Epoch: 1... Training loss: 0.00879... Test loss: 0.01092\n",
      "Epoch: 1... Training loss: 0.0084... Test loss: 0.01112\n",
      "Epoch: 1... Training loss: 0.00782... Test loss: 0.01078\n",
      "Epoch: 1... Training loss: 0.01019... Test loss: 0.01228\n",
      "Epoch: 1... Training loss: 0.00767... Test loss: 0.01358\n",
      "Epoch: 1... Training loss: 0.00726... Test loss: 0.00869\n",
      "Epoch: 1... Training loss: 0.00725... Test loss: 0.01226\n",
      "Epoch: 1... Training loss: 0.00816... Test loss: 0.00938\n",
      "Epoch: 1... Training loss: 0.00698... Test loss: 0.00907\n",
      "Epoch: 1... Training loss: 0.00678... Test loss: 0.01029\n",
      "Epoch: 1... Training loss: 0.00654... Test loss: 0.01021\n",
      "Epoch: 1... Training loss: 0.00622... Test loss: 0.00985\n",
      "Epoch: 1... Training loss: 0.00672... Test loss: 0.00717\n",
      "Epoch: 1... Training loss: 0.00595... Test loss: 0.01027\n",
      "Epoch: 1... Training loss: 0.0055... Test loss: 0.00744\n",
      "Epoch: 1... Training loss: 0.00549... Test loss: 0.00795\n",
      "Epoch: 1... Training loss: 0.00482... Test loss: 0.00571\n",
      "Epoch: 1... Training loss: 0.0049... Test loss: 0.00767\n",
      "Epoch: 1... Training loss: 0.0047... Test loss: 0.00567\n",
      "Epoch: 1... Training loss: 0.00445... Test loss: 0.00719\n",
      "Epoch: 1... Training loss: 0.00461... Test loss: 0.00621\n",
      "Epoch: 1... Training loss: 0.00429... Test loss: 0.00486\n",
      "Epoch: 1... Training loss: 0.004... Test loss: 0.00467\n",
      "Epoch: 1... Training loss: 0.00396... Test loss: 0.00552\n",
      "Epoch: 1... Training loss: 0.00376... Test loss: 0.0043\n",
      "Epoch: 1... Training loss: 0.00378... Test loss: 0.00437\n",
      "Epoch: 1... Training loss: 0.00358... Test loss: 0.00495\n",
      "Epoch: 1... Training loss: 0.00338... Test loss: 0.00416\n",
      "Epoch: 1... Training loss: 0.00322... Test loss: 0.00477\n",
      "Epoch: 1... Training loss: 0.00307... Test loss: 0.0043\n",
      "Epoch: 1... Training loss: 0.00312... Test loss: 0.00403\n",
      "Epoch: 1... Training loss: 0.00302... Test loss: 0.00433\n",
      "Epoch: 1... Training loss: 0.00293... Test loss: 0.00338\n",
      "Epoch: 1... Training loss: 0.00276... Test loss: 0.00355\n",
      "Epoch: 1... Training loss: 0.00278... Test loss: 0.00299\n",
      "Epoch: 1... Training loss: 0.00269... Test loss: 0.00355\n",
      "Epoch: 1... Training loss: 0.0025... Test loss: 0.00309\n",
      "Epoch: 1... Training loss: 0.00255... Test loss: 0.00276\n",
      "Epoch: 1... Training loss: 0.00236... Test loss: 0.00277\n",
      "Epoch: 1... Training loss: 0.00224... Test loss: 0.00279\n",
      "Epoch: 1... Training loss: 0.00235... Test loss: 0.00224\n",
      "Epoch: 1... Training loss: 0.00224... Test loss: 0.00236\n",
      "Epoch: 1... Training loss: 0.00215... Test loss: 0.00233\n",
      "Epoch: 1... Training loss: 0.00211... Test loss: 0.00264\n",
      "Epoch: 1... Training loss: 0.00199... Test loss: 0.00242\n",
      "Epoch: 1... Training loss: 0.00196... Test loss: 0.00269\n",
      "Epoch: 1... Training loss: 0.00189... Test loss: 0.00234\n",
      "Epoch: 1... Training loss: 0.00179... Test loss: 0.00238\n",
      "Epoch: 1... Training loss: 0.00173... Test loss: 0.00196\n",
      "Epoch: 1... Training loss: 0.00174... Test loss: 0.00266\n",
      "Epoch: 1... Training loss: 0.00154... Test loss: 0.0016\n",
      "Epoch: 1... Training loss: 0.00158... Test loss: 0.00191\n",
      "Epoch: 1... Training loss: 0.00149... Test loss: 0.0016\n",
      "Epoch: 1... Training loss: 0.00145... Test loss: 0.00182\n",
      "Epoch: 1... Training loss: 0.00139... Test loss: 0.00145\n",
      "Epoch: 1... Training loss: 0.00143... Test loss: 0.00171\n",
      "Epoch: 1... Training loss: 0.00142... Test loss: 0.00159\n",
      "Epoch: 1... Training loss: 0.0013... Test loss: 0.00131\n",
      "Epoch: 1... Training loss: 0.0012... Test loss: 0.00168\n",
      "Epoch: 1... Training loss: 0.0012... Test loss: 0.00132\n",
      "Epoch: 1... Training loss: 0.00114... Test loss: 0.00152\n",
      "Epoch: 1... Training loss: 0.00106... Test loss: 0.00137\n",
      "Epoch: 1... Training loss: 0.00106... Test loss: 0.00114\n",
      "Epoch: 1... Training loss: 0.00103... Test loss: 0.0012\n",
      "Epoch: 1... Training loss: 0.00098... Test loss: 0.00106\n",
      "Epoch: 1... Training loss: 0.00098... Test loss: 0.00104\n",
      "Epoch: 1... Training loss: 0.00104... Test loss: 0.00119\n",
      "Epoch: 1... Training loss: 0.00092... Test loss: 0.00091\n",
      "Epoch: 1... Training loss: 0.00084... Test loss: 0.00101\n",
      "Epoch: 1... Training loss: 0.00081... Test loss: 0.00068\n",
      "Epoch: 1... Training loss: 0.00076... Test loss: 0.00099\n",
      "Epoch: 1... Training loss: 0.00072... Test loss: 0.00071\n",
      "Epoch: 1... Training loss: 0.0007... Test loss: 0.00084\n",
      "Epoch: 1... Training loss: 0.00065... Test loss: 0.00079\n",
      "Epoch: 1... Training loss: 0.0007... Test loss: 0.00075\n",
      "Epoch: 1... Training loss: 0.00068... Test loss: 0.00072\n",
      "Epoch: 1... Training loss: 0.00059... Test loss: 0.00063\n",
      "Epoch: 1... Training loss: 0.00057... Test loss: 0.00063\n",
      "Epoch: 1... Training loss: 0.00059... Test loss: 0.0006\n",
      "Epoch: 1... Training loss: 0.00058... Test loss: 0.00055\n",
      "Epoch: 1... Training loss: 0.00057... Test loss: 0.00043\n",
      "Epoch: 1... Training loss: 0.00052... Test loss: 0.00057\n",
      "Epoch: 1... Training loss: 0.00051... Test loss: 0.00041\n",
      "Epoch: 1... Training loss: 0.00049... Test loss: 0.00042\n",
      "Epoch: 1... Training loss: 0.00048... Test loss: 0.00046\n",
      "Epoch: 1... Training loss: 0.00051... Test loss: 0.00055\n",
      "Epoch: 1... Training loss: 0.0005... Test loss: 0.00044\n",
      "Epoch: 1... Training loss: 0.00042... Test loss: 0.00045\n",
      "Epoch: 1... Training loss: 0.00043... Test loss: 0.00035\n",
      "Epoch: 1... Training loss: 0.00044... Test loss: 0.00038\n",
      "Epoch: 1... Training loss: 0.00042... Test loss: 0.0004\n",
      "Epoch: 1... Training loss: 0.0004... Test loss: 0.00037\n",
      "Epoch: 1... Training loss: 0.00042... Test loss: 0.00033\n",
      "Epoch: 1... Training loss: 0.00041... Test loss: 0.00031\n",
      "Epoch: 1... Training loss: 0.00039... Test loss: 0.00033\n",
      "Epoch: 1... Training loss: 0.00039... Test loss: 0.00033\n",
      "Epoch: 1... Training loss: 0.00037... Test loss: 0.00033\n",
      "Epoch: 1... Training loss: 0.00035... Test loss: 0.00028\n",
      "Epoch: 1... Training loss: 0.00033... Test loss: 0.00037\n",
      "Epoch: 1... Training loss: 0.00038... Test loss: 0.00039\n",
      "Epoch: 1... Training loss: 0.00036... Test loss: 0.00028\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.00034\n",
      "Epoch: 1... Training loss: 0.00031... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00029... Test loss: 0.00024\n",
      "Epoch: 1... Training loss: 0.00029... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00033... Test loss: 0.00028\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00028\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.0001\n",
      "258.66901647503255\n",
      "Epoch: 1... Training loss: 0.85728... Test loss: 0.18537\n",
      "Epoch: 1... Training loss: 0.42353... Test loss: 0.09873\n",
      "Epoch: 1... Training loss: 0.26776... Test loss: 0.06315\n",
      "Epoch: 1... Training loss: 0.17825... Test loss: 0.0413\n",
      "Epoch: 1... Training loss: 0.13139... Test loss: 0.03631\n",
      "Epoch: 1... Training loss: 0.10053... Test loss: 0.02888\n",
      "Epoch: 1... Training loss: 0.07768... Test loss: 0.02009\n",
      "Epoch: 1... Training loss: 0.06919... Test loss: 0.01799\n",
      "Epoch: 1... Training loss: 0.06281... Test loss: 0.01356\n",
      "Epoch: 1... Training loss: 0.05279... Test loss: 0.01558\n",
      "Epoch: 1... Training loss: 0.05099... Test loss: 0.00862\n",
      "Epoch: 1... Training loss: 0.04349... Test loss: 0.01338\n",
      "Epoch: 1... Training loss: 0.04025... Test loss: 0.0057\n",
      "Epoch: 1... Training loss: 0.03584... Test loss: 0.01059\n",
      "Epoch: 1... Training loss: 0.03529... Test loss: 0.00486\n",
      "Epoch: 1... Training loss: 0.0321... Test loss: 0.01055\n",
      "Epoch: 1... Training loss: 0.03071... Test loss: 0.00388\n",
      "Epoch: 1... Training loss: 0.02755... Test loss: 0.0116\n",
      "Epoch: 1... Training loss: 0.02706... Test loss: 0.00801\n",
      "Epoch: 1... Training loss: 0.02388... Test loss: 0.011\n",
      "Epoch: 1... Training loss: 0.02345... Test loss: 0.00666\n",
      "Epoch: 1... Training loss: 0.02172... Test loss: 0.01818\n",
      "Epoch: 1... Training loss: 0.02119... Test loss: 0.00538\n",
      "Epoch: 1... Training loss: 0.01996... Test loss: 0.01546\n",
      "Epoch: 1... Training loss: 0.01917... Test loss: 0.00591\n",
      "Epoch: 1... Training loss: 0.01844... Test loss: 0.01665\n",
      "Epoch: 1... Training loss: 0.01747... Test loss: 0.00605\n",
      "Epoch: 1... Training loss: 0.01582... Test loss: 0.01555\n",
      "Epoch: 1... Training loss: 0.01531... Test loss: 0.00683\n",
      "Epoch: 1... Training loss: 0.01428... Test loss: 0.01232\n",
      "Epoch: 1... Training loss: 0.01407... Test loss: 0.00773\n",
      "Epoch: 1... Training loss: 0.01282... Test loss: 0.01404\n",
      "Epoch: 1... Training loss: 0.01283... Test loss: 0.00636\n",
      "Epoch: 1... Training loss: 0.01215... Test loss: 0.01144\n",
      "Epoch: 1... Training loss: 0.01194... Test loss: 0.00536\n",
      "Epoch: 1... Training loss: 0.01141... Test loss: 0.01129\n",
      "Epoch: 1... Training loss: 0.01104... Test loss: 0.00476\n",
      "Epoch: 1... Training loss: 0.01069... Test loss: 0.01017\n",
      "Epoch: 1... Training loss: 0.01032... Test loss: 0.00478\n",
      "Epoch: 1... Training loss: 0.00999... Test loss: 0.0093\n",
      "Epoch: 1... Training loss: 0.00983... Test loss: 0.00503\n",
      "Epoch: 1... Training loss: 0.0094... Test loss: 0.0085\n",
      "Epoch: 1... Training loss: 0.00912... Test loss: 0.0061\n",
      "Epoch: 1... Training loss: 0.00892... Test loss: 0.00881\n",
      "Epoch: 1... Training loss: 0.00877... Test loss: 0.00597\n",
      "Epoch: 1... Training loss: 0.00854... Test loss: 0.0081\n",
      "Epoch: 1... Training loss: 0.00813... Test loss: 0.00641\n",
      "Epoch: 1... Training loss: 0.00792... Test loss: 0.0075\n",
      "Epoch: 1... Training loss: 0.0076... Test loss: 0.0066\n",
      "Epoch: 1... Training loss: 0.00725... Test loss: 0.00652\n",
      "Epoch: 1... Training loss: 0.00701... Test loss: 0.0077\n",
      "Epoch: 1... Training loss: 0.00685... Test loss: 0.0059\n",
      "Epoch: 1... Training loss: 0.00666... Test loss: 0.0078\n",
      "Epoch: 1... Training loss: 0.00649... Test loss: 0.00535\n",
      "Epoch: 1... Training loss: 0.0063... Test loss: 0.00718\n",
      "Epoch: 1... Training loss: 0.0062... Test loss: 0.00539\n",
      "Epoch: 1... Training loss: 0.00602... Test loss: 0.00632\n",
      "Epoch: 1... Training loss: 0.0058... Test loss: 0.00519\n",
      "Epoch: 1... Training loss: 0.00576... Test loss: 0.00519\n",
      "Epoch: 1... Training loss: 0.0055... Test loss: 0.00525\n",
      "Epoch: 1... Training loss: 0.00542... Test loss: 0.00436\n",
      "Epoch: 1... Training loss: 0.00523... Test loss: 0.00535\n",
      "Epoch: 1... Training loss: 0.00507... Test loss: 0.00412\n",
      "Epoch: 1... Training loss: 0.00496... Test loss: 0.00511\n",
      "Epoch: 1... Training loss: 0.01192... Test loss: 0.0203\n",
      "Epoch: 1... Training loss: 0.00972... Test loss: 0.01325\n",
      "Epoch: 1... Training loss: 0.00896... Test loss: 0.01131\n",
      "Epoch: 1... Training loss: 0.00886... Test loss: 0.0141\n",
      "Epoch: 1... Training loss: 0.00939... Test loss: 0.0141\n",
      "Epoch: 1... Training loss: 0.00737... Test loss: 0.01406\n",
      "Epoch: 1... Training loss: 0.00687... Test loss: 0.01328\n",
      "Epoch: 1... Training loss: 0.00718... Test loss: 0.01493\n",
      "Epoch: 1... Training loss: 0.00733... Test loss: 0.01322\n",
      "Epoch: 1... Training loss: 0.00716... Test loss: 0.00837\n",
      "Epoch: 1... Training loss: 0.00725... Test loss: 0.01004\n",
      "Epoch: 1... Training loss: 0.00636... Test loss: 0.00868\n",
      "Epoch: 1... Training loss: 0.00563... Test loss: 0.00717\n",
      "Epoch: 1... Training loss: 0.00679... Test loss: 0.00817\n",
      "Epoch: 1... Training loss: 0.00574... Test loss: 0.0092\n",
      "Epoch: 1... Training loss: 0.00564... Test loss: 0.00775\n",
      "Epoch: 1... Training loss: 0.00556... Test loss: 0.00817\n",
      "Epoch: 1... Training loss: 0.0055... Test loss: 0.00736\n",
      "Epoch: 1... Training loss: 0.0049... Test loss: 0.00733\n",
      "Epoch: 1... Training loss: 0.00473... Test loss: 0.00662\n",
      "Epoch: 1... Training loss: 0.00483... Test loss: 0.00612\n",
      "Epoch: 1... Training loss: 0.00442... Test loss: 0.00506\n",
      "Epoch: 1... Training loss: 0.0043... Test loss: 0.00673\n",
      "Epoch: 1... Training loss: 0.00386... Test loss: 0.00593\n",
      "Epoch: 1... Training loss: 0.00391... Test loss: 0.00525\n",
      "Epoch: 1... Training loss: 0.00375... Test loss: 0.00513\n",
      "Epoch: 1... Training loss: 0.00355... Test loss: 0.00441\n",
      "Epoch: 1... Training loss: 0.00347... Test loss: 0.00404\n",
      "Epoch: 1... Training loss: 0.00336... Test loss: 0.00412\n",
      "Epoch: 1... Training loss: 0.00314... Test loss: 0.00377\n",
      "Epoch: 1... Training loss: 0.00316... Test loss: 0.00383\n",
      "Epoch: 1... Training loss: 0.00322... Test loss: 0.00464\n",
      "Epoch: 1... Training loss: 0.00296... Test loss: 0.00298\n",
      "Epoch: 1... Training loss: 0.00291... Test loss: 0.00305\n",
      "Epoch: 1... Training loss: 0.00273... Test loss: 0.00397\n",
      "Epoch: 1... Training loss: 0.00272... Test loss: 0.00308\n",
      "Epoch: 1... Training loss: 0.00264... Test loss: 0.00397\n",
      "Epoch: 1... Training loss: 0.00256... Test loss: 0.00328\n",
      "Epoch: 1... Training loss: 0.0025... Test loss: 0.00377\n",
      "Epoch: 1... Training loss: 0.00249... Test loss: 0.00312\n",
      "Epoch: 1... Training loss: 0.00238... Test loss: 0.00254\n",
      "Epoch: 1... Training loss: 0.00232... Test loss: 0.00281\n",
      "Epoch: 1... Training loss: 0.00222... Test loss: 0.00232\n",
      "Epoch: 1... Training loss: 0.00219... Test loss: 0.00252\n",
      "Epoch: 1... Training loss: 0.00214... Test loss: 0.00261\n",
      "Epoch: 1... Training loss: 0.00202... Test loss: 0.00202\n",
      "Epoch: 1... Training loss: 0.00187... Test loss: 0.0023\n",
      "Epoch: 1... Training loss: 0.00189... Test loss: 0.00173\n",
      "Epoch: 1... Training loss: 0.00193... Test loss: 0.00217\n",
      "Epoch: 1... Training loss: 0.00182... Test loss: 0.00156\n",
      "Epoch: 1... Training loss: 0.00175... Test loss: 0.00211\n",
      "Epoch: 1... Training loss: 0.00174... Test loss: 0.00165\n",
      "Epoch: 1... Training loss: 0.00153... Test loss: 0.00195\n",
      "Epoch: 1... Training loss: 0.00157... Test loss: 0.00167\n",
      "Epoch: 1... Training loss: 0.00151... Test loss: 0.00157\n",
      "Epoch: 1... Training loss: 0.00141... Test loss: 0.00186\n",
      "Epoch: 1... Training loss: 0.00141... Test loss: 0.00161\n",
      "Epoch: 1... Training loss: 0.00136... Test loss: 0.00173\n",
      "Epoch: 1... Training loss: 0.00139... Test loss: 0.00161\n",
      "Epoch: 1... Training loss: 0.00145... Test loss: 0.0016\n",
      "Epoch: 1... Training loss: 0.00119... Test loss: 0.00121\n",
      "Epoch: 1... Training loss: 0.00121... Test loss: 0.00166\n",
      "Epoch: 1... Training loss: 0.00117... Test loss: 0.00102\n",
      "Epoch: 1... Training loss: 0.00118... Test loss: 0.00144\n",
      "Epoch: 1... Training loss: 0.00108... Test loss: 0.00103\n",
      "Epoch: 1... Training loss: 0.00104... Test loss: 0.00135\n",
      "Epoch: 1... Training loss: 0.00098... Test loss: 0.00097\n",
      "Epoch: 1... Training loss: 0.00095... Test loss: 0.00113\n",
      "Epoch: 1... Training loss: 0.00093... Test loss: 0.00095\n",
      "Epoch: 1... Training loss: 0.00087... Test loss: 0.00096\n",
      "Epoch: 1... Training loss: 0.00087... Test loss: 0.00077\n",
      "Epoch: 1... Training loss: 0.00081... Test loss: 0.00091\n",
      "Epoch: 1... Training loss: 0.00075... Test loss: 0.00079\n",
      "Epoch: 1... Training loss: 0.00082... Test loss: 0.00097\n",
      "Epoch: 1... Training loss: 0.00073... Test loss: 0.00077\n",
      "Epoch: 1... Training loss: 0.00067... Test loss: 0.00082\n",
      "Epoch: 1... Training loss: 0.00066... Test loss: 0.00072\n",
      "Epoch: 1... Training loss: 0.00063... Test loss: 0.0006\n",
      "Epoch: 1... Training loss: 0.0006... Test loss: 0.0008\n",
      "Epoch: 1... Training loss: 0.00054... Test loss: 0.00054\n",
      "Epoch: 1... Training loss: 0.00054... Test loss: 0.00067\n",
      "Epoch: 1... Training loss: 0.00052... Test loss: 0.0005\n",
      "Epoch: 1... Training loss: 0.00044... Test loss: 0.00066\n",
      "Epoch: 1... Training loss: 0.00049... Test loss: 0.00041\n",
      "Epoch: 1... Training loss: 0.00046... Test loss: 0.00053\n",
      "Epoch: 1... Training loss: 0.00044... Test loss: 0.0004\n",
      "Epoch: 1... Training loss: 0.0004... Test loss: 0.00053\n",
      "Epoch: 1... Training loss: 0.00036... Test loss: 0.00039\n",
      "Epoch: 1... Training loss: 0.00035... Test loss: 0.0005\n",
      "Epoch: 1... Training loss: 0.00035... Test loss: 0.00031\n",
      "Epoch: 1... Training loss: 0.00031... Test loss: 0.00038\n",
      "Epoch: 1... Training loss: 0.00031... Test loss: 0.0003\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00035\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00031\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00028\n",
      "Epoch: 1... Training loss: 0.00026... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00028\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00028\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 8e-05... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 8e-05... Test loss: 8e-05\n",
      "Epoch: 1... Training loss: 7e-05... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 8e-05\n",
      "Epoch: 1... Training loss: 7e-05... Test loss: 7e-05\n",
      "Epoch: 1... Training loss: 8e-05... Test loss: 9e-05\n",
      "214.09287219657563\n",
      "Epoch: 1... Training loss: 0.90657... Test loss: 0.25459\n",
      "Epoch: 1... Training loss: 0.44363... Test loss: 0.1261\n",
      "Epoch: 1... Training loss: 0.26492... Test loss: 0.09836\n",
      "Epoch: 1... Training loss: 0.18681... Test loss: 0.06258\n",
      "Epoch: 1... Training loss: 0.12963... Test loss: 0.03957\n",
      "Epoch: 1... Training loss: 0.09671... Test loss: 0.02639\n",
      "Epoch: 1... Training loss: 0.08441... Test loss: 0.01957\n",
      "Epoch: 1... Training loss: 0.07493... Test loss: 0.01766\n",
      "Epoch: 1... Training loss: 0.06531... Test loss: 0.01508\n",
      "Epoch: 1... Training loss: 0.05778... Test loss: 0.01381\n",
      "Epoch: 1... Training loss: 0.05065... Test loss: 0.01178\n",
      "Epoch: 1... Training loss: 0.04553... Test loss: 0.01113\n",
      "Epoch: 1... Training loss: 0.04164... Test loss: 0.01248\n",
      "Epoch: 1... Training loss: 0.03851... Test loss: 0.00698\n",
      "Epoch: 1... Training loss: 0.0358... Test loss: 0.01384\n",
      "Epoch: 1... Training loss: 0.0329... Test loss: 0.00654\n",
      "Epoch: 1... Training loss: 0.03041... Test loss: 0.01487\n",
      "Epoch: 1... Training loss: 0.02849... Test loss: 0.00859\n",
      "Epoch: 1... Training loss: 0.02657... Test loss: 0.01677\n",
      "Epoch: 1... Training loss: 0.02457... Test loss: 0.01202\n",
      "Epoch: 1... Training loss: 0.02374... Test loss: 0.01421\n",
      "Epoch: 1... Training loss: 0.02279... Test loss: 0.01041\n",
      "Epoch: 1... Training loss: 0.02177... Test loss: 0.01804\n",
      "Epoch: 1... Training loss: 0.02045... Test loss: 0.00984\n",
      "Epoch: 1... Training loss: 0.01951... Test loss: 0.01717\n",
      "Epoch: 1... Training loss: 0.01868... Test loss: 0.01139\n",
      "Epoch: 1... Training loss: 0.01765... Test loss: 0.0174\n",
      "Epoch: 1... Training loss: 0.01691... Test loss: 0.01417\n",
      "Epoch: 1... Training loss: 0.01665... Test loss: 0.01635\n",
      "Epoch: 1... Training loss: 0.016... Test loss: 0.01836\n",
      "Epoch: 1... Training loss: 0.01561... Test loss: 0.01028\n",
      "Epoch: 1... Training loss: 0.01459... Test loss: 0.01793\n",
      "Epoch: 1... Training loss: 0.01419... Test loss: 0.01009\n",
      "Epoch: 1... Training loss: 0.01356... Test loss: 0.01439\n",
      "Epoch: 1... Training loss: 0.01321... Test loss: 0.00883\n",
      "Epoch: 1... Training loss: 0.01263... Test loss: 0.01344\n",
      "Epoch: 1... Training loss: 0.0125... Test loss: 0.0106\n",
      "Epoch: 1... Training loss: 0.01193... Test loss: 0.01149\n",
      "Epoch: 1... Training loss: 0.01146... Test loss: 0.01006\n",
      "Epoch: 1... Training loss: 0.01133... Test loss: 0.00952\n",
      "Epoch: 1... Training loss: 0.01096... Test loss: 0.01194\n",
      "Epoch: 1... Training loss: 0.01072... Test loss: 0.00972\n",
      "Epoch: 1... Training loss: 0.01012... Test loss: 0.0099\n",
      "Epoch: 1... Training loss: 0.00997... Test loss: 0.00867\n",
      "Epoch: 1... Training loss: 0.00952... Test loss: 0.01056\n",
      "Epoch: 1... Training loss: 0.00943... Test loss: 0.00831\n",
      "Epoch: 1... Training loss: 0.00911... Test loss: 0.00877\n",
      "Epoch: 1... Training loss: 0.00888... Test loss: 0.00779\n",
      "Epoch: 1... Training loss: 0.00864... Test loss: 0.00845\n",
      "Epoch: 1... Training loss: 0.00847... Test loss: 0.00738\n",
      "Epoch: 1... Training loss: 0.00823... Test loss: 0.00998\n",
      "Epoch: 1... Training loss: 0.00807... Test loss: 0.00767\n",
      "Epoch: 1... Training loss: 0.00773... Test loss: 0.00988\n",
      "Epoch: 1... Training loss: 0.00741... Test loss: 0.00708\n",
      "Epoch: 1... Training loss: 0.00719... Test loss: 0.00957\n",
      "Epoch: 1... Training loss: 0.00695... Test loss: 0.00688\n",
      "Epoch: 1... Training loss: 0.00679... Test loss: 0.00874\n",
      "Epoch: 1... Training loss: 0.00655... Test loss: 0.00697\n",
      "Epoch: 1... Training loss: 0.00641... Test loss: 0.00754\n",
      "Epoch: 1... Training loss: 0.00616... Test loss: 0.00698\n",
      "Epoch: 1... Training loss: 0.00598... Test loss: 0.00662\n",
      "Epoch: 1... Training loss: 0.00576... Test loss: 0.00688\n",
      "Epoch: 1... Training loss: 0.00557... Test loss: 0.00621\n",
      "Epoch: 1... Training loss: 0.00538... Test loss: 0.00646\n",
      "Epoch: 1... Training loss: 0.01176... Test loss: 0.01627\n",
      "Epoch: 1... Training loss: 0.01134... Test loss: 0.01424\n",
      "Epoch: 1... Training loss: 0.01073... Test loss: 0.01113\n",
      "Epoch: 1... Training loss: 0.00827... Test loss: 0.01837\n",
      "Epoch: 1... Training loss: 0.00922... Test loss: 0.01397\n",
      "Epoch: 1... Training loss: 0.00878... Test loss: 0.01351\n",
      "Epoch: 1... Training loss: 0.00785... Test loss: 0.01016\n",
      "Epoch: 1... Training loss: 0.00827... Test loss: 0.01151\n",
      "Epoch: 1... Training loss: 0.00837... Test loss: 0.0102\n",
      "Epoch: 1... Training loss: 0.00751... Test loss: 0.00936\n",
      "Epoch: 1... Training loss: 0.00741... Test loss: 0.01034\n",
      "Epoch: 1... Training loss: 0.00757... Test loss: 0.00905\n",
      "Epoch: 1... Training loss: 0.00686... Test loss: 0.00941\n",
      "Epoch: 1... Training loss: 0.00701... Test loss: 0.00847\n",
      "Epoch: 1... Training loss: 0.00644... Test loss: 0.00933\n",
      "Epoch: 1... Training loss: 0.00638... Test loss: 0.00698\n",
      "Epoch: 1... Training loss: 0.00587... Test loss: 0.00974\n",
      "Epoch: 1... Training loss: 0.00608... Test loss: 0.00836\n",
      "Epoch: 1... Training loss: 0.00556... Test loss: 0.009\n",
      "Epoch: 1... Training loss: 0.00519... Test loss: 0.00799\n",
      "Epoch: 1... Training loss: 0.00505... Test loss: 0.0073\n",
      "Epoch: 1... Training loss: 0.00465... Test loss: 0.00659\n",
      "Epoch: 1... Training loss: 0.00476... Test loss: 0.00515\n",
      "Epoch: 1... Training loss: 0.00451... Test loss: 0.00537\n",
      "Epoch: 1... Training loss: 0.00443... Test loss: 0.00428\n",
      "Epoch: 1... Training loss: 0.00436... Test loss: 0.00472\n",
      "Epoch: 1... Training loss: 0.00413... Test loss: 0.00551\n",
      "Epoch: 1... Training loss: 0.00398... Test loss: 0.00428\n",
      "Epoch: 1... Training loss: 0.00383... Test loss: 0.00721\n",
      "Epoch: 1... Training loss: 0.00389... Test loss: 0.00485\n",
      "Epoch: 1... Training loss: 0.00357... Test loss: 0.00451\n",
      "Epoch: 1... Training loss: 0.00349... Test loss: 0.00342\n",
      "Epoch: 1... Training loss: 0.00325... Test loss: 0.00516\n",
      "Epoch: 1... Training loss: 0.00335... Test loss: 0.00344\n",
      "Epoch: 1... Training loss: 0.00313... Test loss: 0.00376\n",
      "Epoch: 1... Training loss: 0.00298... Test loss: 0.00263\n",
      "Epoch: 1... Training loss: 0.00299... Test loss: 0.00352\n",
      "Epoch: 1... Training loss: 0.0029... Test loss: 0.00304\n",
      "Epoch: 1... Training loss: 0.0028... Test loss: 0.0038\n",
      "Epoch: 1... Training loss: 0.00268... Test loss: 0.00276\n",
      "Epoch: 1... Training loss: 0.00269... Test loss: 0.00326\n",
      "Epoch: 1... Training loss: 0.00257... Test loss: 0.0032\n",
      "Epoch: 1... Training loss: 0.0026... Test loss: 0.00318\n",
      "Epoch: 1... Training loss: 0.00255... Test loss: 0.00313\n",
      "Epoch: 1... Training loss: 0.00254... Test loss: 0.00248\n",
      "Epoch: 1... Training loss: 0.00241... Test loss: 0.00305\n",
      "Epoch: 1... Training loss: 0.0023... Test loss: 0.00271\n",
      "Epoch: 1... Training loss: 0.00213... Test loss: 0.00276\n",
      "Epoch: 1... Training loss: 0.00207... Test loss: 0.00247\n",
      "Epoch: 1... Training loss: 0.00204... Test loss: 0.00231\n",
      "Epoch: 1... Training loss: 0.00195... Test loss: 0.00222\n",
      "Epoch: 1... Training loss: 0.00192... Test loss: 0.00223\n",
      "Epoch: 1... Training loss: 0.0019... Test loss: 0.00269\n",
      "Epoch: 1... Training loss: 0.00189... Test loss: 0.00244\n",
      "Epoch: 1... Training loss: 0.00177... Test loss: 0.00209\n",
      "Epoch: 1... Training loss: 0.00166... Test loss: 0.00195\n",
      "Epoch: 1... Training loss: 0.00163... Test loss: 0.00192\n",
      "Epoch: 1... Training loss: 0.00152... Test loss: 0.00183\n",
      "Epoch: 1... Training loss: 0.00145... Test loss: 0.00175\n",
      "Epoch: 1... Training loss: 0.00149... Test loss: 0.00185\n",
      "Epoch: 1... Training loss: 0.00141... Test loss: 0.00174\n",
      "Epoch: 1... Training loss: 0.00129... Test loss: 0.00169\n",
      "Epoch: 1... Training loss: 0.00131... Test loss: 0.00164\n",
      "Epoch: 1... Training loss: 0.00124... Test loss: 0.00152\n",
      "Epoch: 1... Training loss: 0.00116... Test loss: 0.00129\n",
      "Epoch: 1... Training loss: 0.00116... Test loss: 0.00125\n",
      "Epoch: 1... Training loss: 0.00108... Test loss: 0.001\n",
      "Epoch: 1... Training loss: 0.00103... Test loss: 0.00158\n",
      "Epoch: 1... Training loss: 0.001... Test loss: 0.00124\n",
      "Epoch: 1... Training loss: 0.00094... Test loss: 0.00138\n",
      "Epoch: 1... Training loss: 0.0009... Test loss: 0.00104\n",
      "Epoch: 1... Training loss: 0.00086... Test loss: 0.00181\n",
      "Epoch: 1... Training loss: 0.00089... Test loss: 0.00085\n",
      "Epoch: 1... Training loss: 0.0008... Test loss: 0.00127\n",
      "Epoch: 1... Training loss: 0.00084... Test loss: 0.00067\n",
      "Epoch: 1... Training loss: 0.00072... Test loss: 0.0009\n",
      "Epoch: 1... Training loss: 0.0007... Test loss: 0.00059\n",
      "Epoch: 1... Training loss: 0.00068... Test loss: 0.00074\n",
      "Epoch: 1... Training loss: 0.00068... Test loss: 0.0006\n",
      "Epoch: 1... Training loss: 0.00065... Test loss: 0.0006\n",
      "Epoch: 1... Training loss: 0.0006... Test loss: 0.00061\n",
      "Epoch: 1... Training loss: 0.00056... Test loss: 0.00072\n",
      "Epoch: 1... Training loss: 0.00061... Test loss: 0.00056\n",
      "Epoch: 1... Training loss: 0.00049... Test loss: 0.00085\n",
      "Epoch: 1... Training loss: 0.00051... Test loss: 0.00056\n",
      "Epoch: 1... Training loss: 0.00045... Test loss: 0.0007\n",
      "Epoch: 1... Training loss: 0.00044... Test loss: 0.00049\n",
      "Epoch: 1... Training loss: 0.00044... Test loss: 0.00057\n",
      "Epoch: 1... Training loss: 0.00042... Test loss: 0.00047\n",
      "Epoch: 1... Training loss: 0.00043... Test loss: 0.00055\n",
      "Epoch: 1... Training loss: 0.00038... Test loss: 0.00047\n",
      "Epoch: 1... Training loss: 0.0004... Test loss: 0.00042\n",
      "Epoch: 1... Training loss: 0.00037... Test loss: 0.00028\n",
      "Epoch: 1... Training loss: 0.00034... Test loss: 0.00038\n",
      "Epoch: 1... Training loss: 0.00033... Test loss: 0.00036\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00045\n",
      "Epoch: 1... Training loss: 0.00034... Test loss: 0.00043\n",
      "Epoch: 1... Training loss: 0.00029... Test loss: 0.00033\n",
      "Epoch: 1... Training loss: 0.00033... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.00041... Test loss: 0.00033\n",
      "Epoch: 1... Training loss: 0.00029... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.00042\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00035\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00026... Test loss: 0.00031\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00024\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 8e-05\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 8e-05\n",
      "192.03206066880375\n",
      "Epoch: 1... Training loss: 1.03682... Test loss: 0.39743\n",
      "Epoch: 1... Training loss: 0.50782... Test loss: 0.17437\n",
      "Epoch: 1... Training loss: 0.31909... Test loss: 0.11097\n",
      "Epoch: 1... Training loss: 0.22091... Test loss: 0.07813\n",
      "Epoch: 1... Training loss: 0.16143... Test loss: 0.06601\n",
      "Epoch: 1... Training loss: 0.13328... Test loss: 0.07299\n",
      "Epoch: 1... Training loss: 0.11526... Test loss: 0.066\n",
      "Epoch: 1... Training loss: 0.08731... Test loss: 0.03454\n",
      "Epoch: 1... Training loss: 0.07835... Test loss: 0.0451\n",
      "Epoch: 1... Training loss: 0.06594... Test loss: 0.01609\n",
      "Epoch: 1... Training loss: 0.05963... Test loss: 0.03028\n",
      "Epoch: 1... Training loss: 0.05139... Test loss: 0.01932\n",
      "Epoch: 1... Training loss: 0.04827... Test loss: 0.03568\n",
      "Epoch: 1... Training loss: 0.04121... Test loss: 0.01345\n",
      "Epoch: 1... Training loss: 0.04011... Test loss: 0.02828\n",
      "Epoch: 1... Training loss: 0.03539... Test loss: 0.02692\n",
      "Epoch: 1... Training loss: 0.03496... Test loss: 0.0142\n",
      "Epoch: 1... Training loss: 0.03009... Test loss: 0.03229\n",
      "Epoch: 1... Training loss: 0.02683... Test loss: 0.01601\n",
      "Epoch: 1... Training loss: 0.02568... Test loss: 0.02425\n",
      "Epoch: 1... Training loss: 0.02542... Test loss: 0.01564\n",
      "Epoch: 1... Training loss: 0.02345... Test loss: 0.01936\n",
      "Epoch: 1... Training loss: 0.0226... Test loss: 0.01218\n",
      "Epoch: 1... Training loss: 0.02153... Test loss: 0.0188\n",
      "Epoch: 1... Training loss: 0.02051... Test loss: 0.01074\n",
      "Epoch: 1... Training loss: 0.01979... Test loss: 0.01877\n",
      "Epoch: 1... Training loss: 0.01873... Test loss: 0.01239\n",
      "Epoch: 1... Training loss: 0.01797... Test loss: 0.02234\n",
      "Epoch: 1... Training loss: 0.0176... Test loss: 0.01015\n",
      "Epoch: 1... Training loss: 0.01679... Test loss: 0.01985\n",
      "Epoch: 1... Training loss: 0.01664... Test loss: 0.01041\n",
      "Epoch: 1... Training loss: 0.01545... Test loss: 0.01749\n",
      "Epoch: 1... Training loss: 0.01522... Test loss: 0.01044\n",
      "Epoch: 1... Training loss: 0.01458... Test loss: 0.01645\n",
      "Epoch: 1... Training loss: 0.01443... Test loss: 0.0101\n",
      "Epoch: 1... Training loss: 0.01377... Test loss: 0.01648\n",
      "Epoch: 1... Training loss: 0.01326... Test loss: 0.00851\n",
      "Epoch: 1... Training loss: 0.0129... Test loss: 0.01472\n",
      "Epoch: 1... Training loss: 0.01227... Test loss: 0.00908\n",
      "Epoch: 1... Training loss: 0.01188... Test loss: 0.01444\n",
      "Epoch: 1... Training loss: 0.01148... Test loss: 0.00961\n",
      "Epoch: 1... Training loss: 0.01111... Test loss: 0.01367\n",
      "Epoch: 1... Training loss: 0.01072... Test loss: 0.00923\n",
      "Epoch: 1... Training loss: 0.01056... Test loss: 0.01321\n",
      "Epoch: 1... Training loss: 0.01007... Test loss: 0.00795\n",
      "Epoch: 1... Training loss: 0.00995... Test loss: 0.01124\n",
      "Epoch: 1... Training loss: 0.00957... Test loss: 0.00923\n",
      "Epoch: 1... Training loss: 0.00921... Test loss: 0.00981\n",
      "Epoch: 1... Training loss: 0.00884... Test loss: 0.00943\n",
      "Epoch: 1... Training loss: 0.00856... Test loss: 0.00881\n",
      "Epoch: 1... Training loss: 0.00814... Test loss: 0.00934\n",
      "Epoch: 1... Training loss: 0.00798... Test loss: 0.00741\n",
      "Epoch: 1... Training loss: 0.00762... Test loss: 0.0087\n",
      "Epoch: 1... Training loss: 0.00748... Test loss: 0.00739\n",
      "Epoch: 1... Training loss: 0.00714... Test loss: 0.00915\n",
      "Epoch: 1... Training loss: 0.00697... Test loss: 0.00646\n",
      "Epoch: 1... Training loss: 0.00668... Test loss: 0.00813\n",
      "Epoch: 1... Training loss: 0.00653... Test loss: 0.00646\n",
      "Epoch: 1... Training loss: 0.00616... Test loss: 0.00776\n",
      "Epoch: 1... Training loss: 0.006... Test loss: 0.00552\n",
      "Epoch: 1... Training loss: 0.00585... Test loss: 0.00731\n",
      "Epoch: 1... Training loss: 0.00572... Test loss: 0.00554\n",
      "Epoch: 1... Training loss: 0.00548... Test loss: 0.00703\n",
      "Epoch: 1... Training loss: 0.00533... Test loss: 0.00566\n",
      "Epoch: 1... Training loss: 0.01306... Test loss: 0.03176\n",
      "Epoch: 1... Training loss: 0.00868... Test loss: 0.01396\n",
      "Epoch: 1... Training loss: 0.01049... Test loss: 0.01644\n",
      "Epoch: 1... Training loss: 0.009... Test loss: 0.01605\n",
      "Epoch: 1... Training loss: 0.00772... Test loss: 0.01275\n",
      "Epoch: 1... Training loss: 0.00854... Test loss: 0.00928\n",
      "Epoch: 1... Training loss: 0.00744... Test loss: 0.00993\n",
      "Epoch: 1... Training loss: 0.00799... Test loss: 0.01059\n",
      "Epoch: 1... Training loss: 0.00738... Test loss: 0.01548\n",
      "Epoch: 1... Training loss: 0.00734... Test loss: 0.00948\n",
      "Epoch: 1... Training loss: 0.00726... Test loss: 0.00826\n",
      "Epoch: 1... Training loss: 0.00733... Test loss: 0.01154\n",
      "Epoch: 1... Training loss: 0.00623... Test loss: 0.00652\n",
      "Epoch: 1... Training loss: 0.00665... Test loss: 0.01164\n",
      "Epoch: 1... Training loss: 0.00564... Test loss: 0.00829\n",
      "Epoch: 1... Training loss: 0.00564... Test loss: 0.00891\n",
      "Epoch: 1... Training loss: 0.00596... Test loss: 0.00698\n",
      "Epoch: 1... Training loss: 0.00564... Test loss: 0.00873\n",
      "Epoch: 1... Training loss: 0.00503... Test loss: 0.00699\n",
      "Epoch: 1... Training loss: 0.00494... Test loss: 0.00724\n",
      "Epoch: 1... Training loss: 0.00501... Test loss: 0.00585\n",
      "Epoch: 1... Training loss: 0.00471... Test loss: 0.00711\n",
      "Epoch: 1... Training loss: 0.00467... Test loss: 0.00558\n",
      "Epoch: 1... Training loss: 0.00443... Test loss: 0.0054\n",
      "Epoch: 1... Training loss: 0.00437... Test loss: 0.00569\n",
      "Epoch: 1... Training loss: 0.00411... Test loss: 0.00483\n",
      "Epoch: 1... Training loss: 0.00395... Test loss: 0.00543\n",
      "Epoch: 1... Training loss: 0.00381... Test loss: 0.00598\n",
      "Epoch: 1... Training loss: 0.00379... Test loss: 0.00498\n",
      "Epoch: 1... Training loss: 0.00347... Test loss: 0.00545\n",
      "Epoch: 1... Training loss: 0.00325... Test loss: 0.00489\n",
      "Epoch: 1... Training loss: 0.00327... Test loss: 0.00516\n",
      "Epoch: 1... Training loss: 0.00323... Test loss: 0.00427\n",
      "Epoch: 1... Training loss: 0.00306... Test loss: 0.00406\n",
      "Epoch: 1... Training loss: 0.00289... Test loss: 0.00338\n",
      "Epoch: 1... Training loss: 0.00286... Test loss: 0.00329\n",
      "Epoch: 1... Training loss: 0.00284... Test loss: 0.00314\n",
      "Epoch: 1... Training loss: 0.00282... Test loss: 0.0033\n",
      "Epoch: 1... Training loss: 0.00263... Test loss: 0.00334\n",
      "Epoch: 1... Training loss: 0.00267... Test loss: 0.00342\n",
      "Epoch: 1... Training loss: 0.00246... Test loss: 0.00342\n",
      "Epoch: 1... Training loss: 0.00233... Test loss: 0.00269\n",
      "Epoch: 1... Training loss: 0.00232... Test loss: 0.00299\n",
      "Epoch: 1... Training loss: 0.00222... Test loss: 0.00247\n",
      "Epoch: 1... Training loss: 0.0022... Test loss: 0.00225\n",
      "Epoch: 1... Training loss: 0.00217... Test loss: 0.00216\n",
      "Epoch: 1... Training loss: 0.0021... Test loss: 0.00248\n",
      "Epoch: 1... Training loss: 0.00211... Test loss: 0.00231\n",
      "Epoch: 1... Training loss: 0.00199... Test loss: 0.00248\n",
      "Epoch: 1... Training loss: 0.00202... Test loss: 0.00222\n",
      "Epoch: 1... Training loss: 0.00196... Test loss: 0.002\n",
      "Epoch: 1... Training loss: 0.00191... Test loss: 0.00162\n",
      "Epoch: 1... Training loss: 0.0018... Test loss: 0.0019\n",
      "Epoch: 1... Training loss: 0.00175... Test loss: 0.00186\n",
      "Epoch: 1... Training loss: 0.00174... Test loss: 0.00194\n",
      "Epoch: 1... Training loss: 0.00159... Test loss: 0.00189\n",
      "Epoch: 1... Training loss: 0.0016... Test loss: 0.00198\n",
      "Epoch: 1... Training loss: 0.00155... Test loss: 0.00141\n",
      "Epoch: 1... Training loss: 0.00152... Test loss: 0.00157\n",
      "Epoch: 1... Training loss: 0.00146... Test loss: 0.00166\n",
      "Epoch: 1... Training loss: 0.00144... Test loss: 0.00144\n",
      "Epoch: 1... Training loss: 0.00137... Test loss: 0.00155\n",
      "Epoch: 1... Training loss: 0.00127... Test loss: 0.00129\n",
      "Epoch: 1... Training loss: 0.00117... Test loss: 0.00164\n",
      "Epoch: 1... Training loss: 0.00115... Test loss: 0.0013\n",
      "Epoch: 1... Training loss: 0.00111... Test loss: 0.00126\n",
      "Epoch: 1... Training loss: 0.00111... Test loss: 0.00178\n",
      "Epoch: 1... Training loss: 0.00109... Test loss: 0.00131\n",
      "Epoch: 1... Training loss: 0.00105... Test loss: 0.00145\n",
      "Epoch: 1... Training loss: 0.00099... Test loss: 0.00116\n",
      "Epoch: 1... Training loss: 0.00095... Test loss: 0.00126\n",
      "Epoch: 1... Training loss: 0.00088... Test loss: 0.00097\n",
      "Epoch: 1... Training loss: 0.00086... Test loss: 0.00102\n",
      "Epoch: 1... Training loss: 0.00084... Test loss: 0.0009\n",
      "Epoch: 1... Training loss: 0.00079... Test loss: 0.00089\n",
      "Epoch: 1... Training loss: 0.00073... Test loss: 0.00089\n",
      "Epoch: 1... Training loss: 0.00075... Test loss: 0.00074\n",
      "Epoch: 1... Training loss: 0.00068... Test loss: 0.00076\n",
      "Epoch: 1... Training loss: 0.00061... Test loss: 0.0007\n",
      "Epoch: 1... Training loss: 0.0006... Test loss: 0.00072\n",
      "Epoch: 1... Training loss: 0.00061... Test loss: 0.00051\n",
      "Epoch: 1... Training loss: 0.00061... Test loss: 0.00076\n",
      "Epoch: 1... Training loss: 0.0006... Test loss: 0.00072\n",
      "Epoch: 1... Training loss: 0.00055... Test loss: 0.00043\n",
      "Epoch: 1... Training loss: 0.00055... Test loss: 0.00076\n",
      "Epoch: 1... Training loss: 0.00053... Test loss: 0.00042\n",
      "Epoch: 1... Training loss: 0.00047... Test loss: 0.00053\n",
      "Epoch: 1... Training loss: 0.00044... Test loss: 0.00048\n",
      "Epoch: 1... Training loss: 0.00039... Test loss: 0.00066\n",
      "Epoch: 1... Training loss: 0.00044... Test loss: 0.00035\n",
      "Epoch: 1... Training loss: 0.00039... Test loss: 0.00047\n",
      "Epoch: 1... Training loss: 0.0004... Test loss: 0.00038\n",
      "Epoch: 1... Training loss: 0.00036... Test loss: 0.00048\n",
      "Epoch: 1... Training loss: 0.00036... Test loss: 0.00024\n",
      "Epoch: 1... Training loss: 0.00035... Test loss: 0.0004\n",
      "Epoch: 1... Training loss: 0.00034... Test loss: 0.00033\n",
      "Epoch: 1... Training loss: 0.00039... Test loss: 0.00038\n",
      "Epoch: 1... Training loss: 0.00031... Test loss: 0.00034\n",
      "Epoch: 1... Training loss: 0.00034... Test loss: 0.00032\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00033... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.00031... Test loss: 0.00024\n",
      "Epoch: 1... Training loss: 0.00031... Test loss: 0.00031\n",
      "Epoch: 1... Training loss: 0.00029... Test loss: 0.00031\n",
      "Epoch: 1... Training loss: 0.00029... Test loss: 0.00031\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.0003\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.0003\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00024\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00028\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00024\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00014\n",
      "254.1685229887953\n",
      "Epoch: 1... Training loss: 1.14234... Test loss: 0.47649\n",
      "Epoch: 1... Training loss: 0.50146... Test loss: 0.16904\n",
      "Epoch: 1... Training loss: 0.28023... Test loss: 0.09243\n",
      "Epoch: 1... Training loss: 0.17689... Test loss: 0.05118\n",
      "Epoch: 1... Training loss: 0.1431... Test loss: 0.04254\n",
      "Epoch: 1... Training loss: 0.11774... Test loss: 0.03114\n",
      "Epoch: 1... Training loss: 0.09336... Test loss: 0.03662\n",
      "Epoch: 1... Training loss: 0.07808... Test loss: 0.04354\n",
      "Epoch: 1... Training loss: 0.07158... Test loss: 0.01501\n",
      "Epoch: 1... Training loss: 0.05966... Test loss: 0.01767\n",
      "Epoch: 1... Training loss: 0.0557... Test loss: 0.03211\n",
      "Epoch: 1... Training loss: 0.04764... Test loss: 0.03743\n",
      "Epoch: 1... Training loss: 0.04362... Test loss: 0.04576\n",
      "Epoch: 1... Training loss: 0.04149... Test loss: 0.01503\n",
      "Epoch: 1... Training loss: 0.03698... Test loss: 0.0384\n",
      "Epoch: 1... Training loss: 0.03489... Test loss: 0.02443\n",
      "Epoch: 1... Training loss: 0.03397... Test loss: 0.0097\n",
      "Epoch: 1... Training loss: 0.0294... Test loss: 0.01836\n",
      "Epoch: 1... Training loss: 0.02679... Test loss: 0.01529\n",
      "Epoch: 1... Training loss: 0.02582... Test loss: 0.01604\n",
      "Epoch: 1... Training loss: 0.02444... Test loss: 0.01097\n",
      "Epoch: 1... Training loss: 0.02275... Test loss: 0.01887\n",
      "Epoch: 1... Training loss: 0.0218... Test loss: 0.01213\n",
      "Epoch: 1... Training loss: 0.02045... Test loss: 0.01276\n",
      "Epoch: 1... Training loss: 0.01995... Test loss: 0.00806\n",
      "Epoch: 1... Training loss: 0.0189... Test loss: 0.01511\n",
      "Epoch: 1... Training loss: 0.01826... Test loss: 0.00607\n",
      "Epoch: 1... Training loss: 0.01705... Test loss: 0.01598\n",
      "Epoch: 1... Training loss: 0.01664... Test loss: 0.00608\n",
      "Epoch: 1... Training loss: 0.0154... Test loss: 0.01437\n",
      "Epoch: 1... Training loss: 0.01451... Test loss: 0.00617\n",
      "Epoch: 1... Training loss: 0.014... Test loss: 0.00938\n",
      "Epoch: 1... Training loss: 0.01397... Test loss: 0.00862\n",
      "Epoch: 1... Training loss: 0.01328... Test loss: 0.0041\n",
      "Epoch: 1... Training loss: 0.01307... Test loss: 0.0103\n",
      "Epoch: 1... Training loss: 0.01191... Test loss: 0.00474\n",
      "Epoch: 1... Training loss: 0.01175... Test loss: 0.0097\n",
      "Epoch: 1... Training loss: 0.01108... Test loss: 0.00607\n",
      "Epoch: 1... Training loss: 0.01086... Test loss: 0.00897\n",
      "Epoch: 1... Training loss: 0.01042... Test loss: 0.00682\n",
      "Epoch: 1... Training loss: 0.01034... Test loss: 0.00698\n",
      "Epoch: 1... Training loss: 0.00994... Test loss: 0.01134\n",
      "Epoch: 1... Training loss: 0.00984... Test loss: 0.00563\n",
      "Epoch: 1... Training loss: 0.00954... Test loss: 0.01011\n",
      "Epoch: 1... Training loss: 0.00929... Test loss: 0.00565\n",
      "Epoch: 1... Training loss: 0.00906... Test loss: 0.00891\n",
      "Epoch: 1... Training loss: 0.00872... Test loss: 0.00581\n",
      "Epoch: 1... Training loss: 0.00848... Test loss: 0.00792\n",
      "Epoch: 1... Training loss: 0.00822... Test loss: 0.00613\n",
      "Epoch: 1... Training loss: 0.00804... Test loss: 0.00783\n",
      "Epoch: 1... Training loss: 0.00762... Test loss: 0.00648\n",
      "Epoch: 1... Training loss: 0.00756... Test loss: 0.00617\n",
      "Epoch: 1... Training loss: 0.0072... Test loss: 0.00731\n",
      "Epoch: 1... Training loss: 0.00704... Test loss: 0.0056\n",
      "Epoch: 1... Training loss: 0.0068... Test loss: 0.00712\n",
      "Epoch: 1... Training loss: 0.00672... Test loss: 0.00549\n",
      "Epoch: 1... Training loss: 0.00648... Test loss: 0.0066\n",
      "Epoch: 1... Training loss: 0.00628... Test loss: 0.00566\n",
      "Epoch: 1... Training loss: 0.00611... Test loss: 0.00662\n",
      "Epoch: 1... Training loss: 0.00591... Test loss: 0.00493\n",
      "Epoch: 1... Training loss: 0.00577... Test loss: 0.00643\n",
      "Epoch: 1... Training loss: 0.00553... Test loss: 0.00452\n",
      "Epoch: 1... Training loss: 0.00545... Test loss: 0.00637\n",
      "Epoch: 1... Training loss: 0.0052... Test loss: 0.00473\n",
      "Epoch: 1... Training loss: 0.01078... Test loss: 0.00895\n",
      "Epoch: 1... Training loss: 0.00926... Test loss: 0.01155\n",
      "Epoch: 1... Training loss: 0.01056... Test loss: 0.00946\n",
      "Epoch: 1... Training loss: 0.01152... Test loss: 0.0142\n",
      "Epoch: 1... Training loss: 0.01108... Test loss: 0.01497\n",
      "Epoch: 1... Training loss: 0.008... Test loss: 0.01276\n",
      "Epoch: 1... Training loss: 0.00808... Test loss: 0.01143\n",
      "Epoch: 1... Training loss: 0.00861... Test loss: 0.01057\n",
      "Epoch: 1... Training loss: 0.00856... Test loss: 0.00929\n",
      "Epoch: 1... Training loss: 0.00788... Test loss: 0.00978\n",
      "Epoch: 1... Training loss: 0.0069... Test loss: 0.0097\n",
      "Epoch: 1... Training loss: 0.00703... Test loss: 0.01108\n",
      "Epoch: 1... Training loss: 0.0067... Test loss: 0.00879\n",
      "Epoch: 1... Training loss: 0.00621... Test loss: 0.0102\n",
      "Epoch: 1... Training loss: 0.00664... Test loss: 0.00974\n",
      "Epoch: 1... Training loss: 0.00604... Test loss: 0.00742\n",
      "Epoch: 1... Training loss: 0.00575... Test loss: 0.01101\n",
      "Epoch: 1... Training loss: 0.00581... Test loss: 0.00646\n",
      "Epoch: 1... Training loss: 0.00513... Test loss: 0.0071\n",
      "Epoch: 1... Training loss: 0.00494... Test loss: 0.00598\n",
      "Epoch: 1... Training loss: 0.00519... Test loss: 0.00673\n",
      "Epoch: 1... Training loss: 0.00469... Test loss: 0.00504\n",
      "Epoch: 1... Training loss: 0.00449... Test loss: 0.00648\n",
      "Epoch: 1... Training loss: 0.00435... Test loss: 0.00508\n",
      "Epoch: 1... Training loss: 0.00461... Test loss: 0.00559\n",
      "Epoch: 1... Training loss: 0.00446... Test loss: 0.0044\n",
      "Epoch: 1... Training loss: 0.00404... Test loss: 0.00442\n",
      "Epoch: 1... Training loss: 0.00422... Test loss: 0.00569\n",
      "Epoch: 1... Training loss: 0.00395... Test loss: 0.00408\n",
      "Epoch: 1... Training loss: 0.00375... Test loss: 0.00503\n",
      "Epoch: 1... Training loss: 0.00379... Test loss: 0.00423\n",
      "Epoch: 1... Training loss: 0.00361... Test loss: 0.00473\n",
      "Epoch: 1... Training loss: 0.00333... Test loss: 0.00363\n",
      "Epoch: 1... Training loss: 0.00321... Test loss: 0.00486\n",
      "Epoch: 1... Training loss: 0.00312... Test loss: 0.00375\n",
      "Epoch: 1... Training loss: 0.00293... Test loss: 0.00386\n",
      "Epoch: 1... Training loss: 0.00296... Test loss: 0.00386\n",
      "Epoch: 1... Training loss: 0.00297... Test loss: 0.00363\n",
      "Epoch: 1... Training loss: 0.00277... Test loss: 0.0043\n",
      "Epoch: 1... Training loss: 0.00266... Test loss: 0.00351\n",
      "Epoch: 1... Training loss: 0.00263... Test loss: 0.00344\n",
      "Epoch: 1... Training loss: 0.00257... Test loss: 0.00318\n",
      "Epoch: 1... Training loss: 0.00249... Test loss: 0.00297\n",
      "Epoch: 1... Training loss: 0.0024... Test loss: 0.003\n",
      "Epoch: 1... Training loss: 0.0024... Test loss: 0.00285\n",
      "Epoch: 1... Training loss: 0.00228... Test loss: 0.00276\n",
      "Epoch: 1... Training loss: 0.0022... Test loss: 0.00277\n",
      "Epoch: 1... Training loss: 0.00224... Test loss: 0.00255\n",
      "Epoch: 1... Training loss: 0.00212... Test loss: 0.00314\n",
      "Epoch: 1... Training loss: 0.00216... Test loss: 0.00309\n",
      "Epoch: 1... Training loss: 0.00199... Test loss: 0.00256\n",
      "Epoch: 1... Training loss: 0.00194... Test loss: 0.00232\n",
      "Epoch: 1... Training loss: 0.00182... Test loss: 0.0024\n",
      "Epoch: 1... Training loss: 0.0018... Test loss: 0.00193\n",
      "Epoch: 1... Training loss: 0.00174... Test loss: 0.00182\n",
      "Epoch: 1... Training loss: 0.00168... Test loss: 0.00173\n",
      "Epoch: 1... Training loss: 0.0017... Test loss: 0.00176\n",
      "Epoch: 1... Training loss: 0.00162... Test loss: 0.0015\n",
      "Epoch: 1... Training loss: 0.00146... Test loss: 0.00195\n",
      "Epoch: 1... Training loss: 0.00143... Test loss: 0.00146\n",
      "Epoch: 1... Training loss: 0.00142... Test loss: 0.00191\n",
      "Epoch: 1... Training loss: 0.00139... Test loss: 0.00144\n",
      "Epoch: 1... Training loss: 0.00126... Test loss: 0.00187\n",
      "Epoch: 1... Training loss: 0.00128... Test loss: 0.0013\n",
      "Epoch: 1... Training loss: 0.00134... Test loss: 0.00146\n",
      "Epoch: 1... Training loss: 0.00112... Test loss: 0.00152\n",
      "Epoch: 1... Training loss: 0.00119... Test loss: 0.00128\n",
      "Epoch: 1... Training loss: 0.00104... Test loss: 0.00141\n",
      "Epoch: 1... Training loss: 0.00104... Test loss: 0.001\n",
      "Epoch: 1... Training loss: 0.00093... Test loss: 0.00138\n",
      "Epoch: 1... Training loss: 0.00095... Test loss: 0.00087\n",
      "Epoch: 1... Training loss: 0.00091... Test loss: 0.00107\n",
      "Epoch: 1... Training loss: 0.00088... Test loss: 0.00097\n",
      "Epoch: 1... Training loss: 0.00084... Test loss: 0.00093\n",
      "Epoch: 1... Training loss: 0.00088... Test loss: 0.00087\n",
      "Epoch: 1... Training loss: 0.00076... Test loss: 0.00079\n",
      "Epoch: 1... Training loss: 0.00072... Test loss: 0.00087\n",
      "Epoch: 1... Training loss: 0.00077... Test loss: 0.00098\n",
      "Epoch: 1... Training loss: 0.00071... Test loss: 0.00076\n",
      "Epoch: 1... Training loss: 0.00063... Test loss: 0.00079\n",
      "Epoch: 1... Training loss: 0.00061... Test loss: 0.0008\n",
      "Epoch: 1... Training loss: 0.00057... Test loss: 0.00073\n",
      "Epoch: 1... Training loss: 0.00059... Test loss: 0.00073\n",
      "Epoch: 1... Training loss: 0.00056... Test loss: 0.0006\n",
      "Epoch: 1... Training loss: 0.00048... Test loss: 0.00048\n",
      "Epoch: 1... Training loss: 0.0005... Test loss: 0.00054\n",
      "Epoch: 1... Training loss: 0.00048... Test loss: 0.00049\n",
      "Epoch: 1... Training loss: 0.00045... Test loss: 0.00043\n",
      "Epoch: 1... Training loss: 0.00039... Test loss: 0.00059\n",
      "Epoch: 1... Training loss: 0.00045... Test loss: 0.00047\n",
      "Epoch: 1... Training loss: 0.00038... Test loss: 0.00051\n",
      "Epoch: 1... Training loss: 0.00037... Test loss: 0.00039\n",
      "Epoch: 1... Training loss: 0.00034... Test loss: 0.00039\n",
      "Epoch: 1... Training loss: 0.00039... Test loss: 0.0004\n",
      "Epoch: 1... Training loss: 0.00037... Test loss: 0.00047\n",
      "Epoch: 1... Training loss: 0.00033... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.00033... Test loss: 0.00035\n",
      "Epoch: 1... Training loss: 0.00034... Test loss: 0.00035\n",
      "Epoch: 1... Training loss: 0.00029... Test loss: 0.00037\n",
      "Epoch: 1... Training loss: 0.00032... Test loss: 0.00024\n",
      "Epoch: 1... Training loss: 0.00026... Test loss: 0.0003\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00035\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.0003\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00024\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 8e-05\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 8e-05... Test loss: 0.0001\n",
      "223.80243954912294\n",
      "Epoch: 1... Training loss: 0.83827... Test loss: 0.2338\n",
      "Epoch: 1... Training loss: 0.50878... Test loss: 0.1674\n",
      "Epoch: 1... Training loss: 0.33138... Test loss: 0.08655\n",
      "Epoch: 1... Training loss: 0.2227... Test loss: 0.05959\n",
      "Epoch: 1... Training loss: 0.17255... Test loss: 0.04721\n",
      "Epoch: 1... Training loss: 0.12675... Test loss: 0.0467\n",
      "Epoch: 1... Training loss: 0.11488... Test loss: 0.02647\n",
      "Epoch: 1... Training loss: 0.08383... Test loss: 0.02392\n",
      "Epoch: 1... Training loss: 0.06829... Test loss: 0.01995\n",
      "Epoch: 1... Training loss: 0.05709... Test loss: 0.01986\n",
      "Epoch: 1... Training loss: 0.04924... Test loss: 0.0196\n",
      "Epoch: 1... Training loss: 0.04526... Test loss: 0.02113\n",
      "Epoch: 1... Training loss: 0.04025... Test loss: 0.01414\n",
      "Epoch: 1... Training loss: 0.03878... Test loss: 0.01813\n",
      "Epoch: 1... Training loss: 0.03284... Test loss: 0.01113\n",
      "Epoch: 1... Training loss: 0.03448... Test loss: 0.01786\n",
      "Epoch: 1... Training loss: 0.02989... Test loss: 0.01246\n",
      "Epoch: 1... Training loss: 0.02765... Test loss: 0.01524\n",
      "Epoch: 1... Training loss: 0.02509... Test loss: 0.01256\n",
      "Epoch: 1... Training loss: 0.02452... Test loss: 0.01287\n",
      "Epoch: 1... Training loss: 0.02276... Test loss: 0.01105\n",
      "Epoch: 1... Training loss: 0.02222... Test loss: 0.01162\n",
      "Epoch: 1... Training loss: 0.02059... Test loss: 0.01374\n",
      "Epoch: 1... Training loss: 0.01922... Test loss: 0.00681\n",
      "Epoch: 1... Training loss: 0.01796... Test loss: 0.01496\n",
      "Epoch: 1... Training loss: 0.01742... Test loss: 0.00806\n",
      "Epoch: 1... Training loss: 0.01656... Test loss: 0.01484\n",
      "Epoch: 1... Training loss: 0.0159... Test loss: 0.01111\n",
      "Epoch: 1... Training loss: 0.01496... Test loss: 0.00693\n",
      "Epoch: 1... Training loss: 0.01476... Test loss: 0.01475\n",
      "Epoch: 1... Training loss: 0.01428... Test loss: 0.00561\n",
      "Epoch: 1... Training loss: 0.01395... Test loss: 0.01184\n",
      "Epoch: 1... Training loss: 0.01335... Test loss: 0.00809\n",
      "Epoch: 1... Training loss: 0.01297... Test loss: 0.01407\n",
      "Epoch: 1... Training loss: 0.01263... Test loss: 0.00486\n",
      "Epoch: 1... Training loss: 0.01237... Test loss: 0.01244\n",
      "Epoch: 1... Training loss: 0.01209... Test loss: 0.00637\n",
      "Epoch: 1... Training loss: 0.0116... Test loss: 0.01044\n",
      "Epoch: 1... Training loss: 0.0112... Test loss: 0.00728\n",
      "Epoch: 1... Training loss: 0.01092... Test loss: 0.00979\n",
      "Epoch: 1... Training loss: 0.01044... Test loss: 0.00661\n",
      "Epoch: 1... Training loss: 0.01022... Test loss: 0.00928\n",
      "Epoch: 1... Training loss: 0.00981... Test loss: 0.00655\n",
      "Epoch: 1... Training loss: 0.00966... Test loss: 0.00781\n",
      "Epoch: 1... Training loss: 0.0095... Test loss: 0.00836\n",
      "Epoch: 1... Training loss: 0.0093... Test loss: 0.00728\n",
      "Epoch: 1... Training loss: 0.00891... Test loss: 0.00703\n",
      "Epoch: 1... Training loss: 0.00869... Test loss: 0.00791\n",
      "Epoch: 1... Training loss: 0.00827... Test loss: 0.00594\n",
      "Epoch: 1... Training loss: 0.00799... Test loss: 0.0078\n",
      "Epoch: 1... Training loss: 0.00778... Test loss: 0.00813\n",
      "Epoch: 1... Training loss: 0.00757... Test loss: 0.00546\n",
      "Epoch: 1... Training loss: 0.00744... Test loss: 0.00849\n",
      "Epoch: 1... Training loss: 0.00717... Test loss: 0.0055\n",
      "Epoch: 1... Training loss: 0.00691... Test loss: 0.00747\n",
      "Epoch: 1... Training loss: 0.00671... Test loss: 0.00636\n",
      "Epoch: 1... Training loss: 0.00644... Test loss: 0.00745\n",
      "Epoch: 1... Training loss: 0.00643... Test loss: 0.00569\n",
      "Epoch: 1... Training loss: 0.00601... Test loss: 0.0072\n",
      "Epoch: 1... Training loss: 0.00598... Test loss: 0.00584\n",
      "Epoch: 1... Training loss: 0.00561... Test loss: 0.00607\n",
      "Epoch: 1... Training loss: 0.00551... Test loss: 0.0058\n",
      "Epoch: 1... Training loss: 0.00529... Test loss: 0.00598\n",
      "Epoch: 1... Training loss: 0.00522... Test loss: 0.00579\n",
      "Epoch: 1... Training loss: 0.01372... Test loss: 0.00865\n",
      "Epoch: 1... Training loss: 0.01016... Test loss: 0.01036\n",
      "Epoch: 1... Training loss: 0.01053... Test loss: 0.01152\n",
      "Epoch: 1... Training loss: 0.00854... Test loss: 0.01338\n",
      "Epoch: 1... Training loss: 0.00867... Test loss: 0.01135\n",
      "Epoch: 1... Training loss: 0.00826... Test loss: 0.01265\n",
      "Epoch: 1... Training loss: 0.00803... Test loss: 0.01387\n",
      "Epoch: 1... Training loss: 0.00738... Test loss: 0.01164\n",
      "Epoch: 1... Training loss: 0.00712... Test loss: 0.0134\n",
      "Epoch: 1... Training loss: 0.00832... Test loss: 0.0106\n",
      "Epoch: 1... Training loss: 0.00745... Test loss: 0.01414\n",
      "Epoch: 1... Training loss: 0.00698... Test loss: 0.00802\n",
      "Epoch: 1... Training loss: 0.00685... Test loss: 0.012\n",
      "Epoch: 1... Training loss: 0.00575... Test loss: 0.0085\n",
      "Epoch: 1... Training loss: 0.00557... Test loss: 0.00642\n",
      "Epoch: 1... Training loss: 0.00533... Test loss: 0.00765\n",
      "Epoch: 1... Training loss: 0.00553... Test loss: 0.00803\n",
      "Epoch: 1... Training loss: 0.00555... Test loss: 0.00657\n",
      "Epoch: 1... Training loss: 0.00515... Test loss: 0.00707\n",
      "Epoch: 1... Training loss: 0.00477... Test loss: 0.00713\n",
      "Epoch: 1... Training loss: 0.00479... Test loss: 0.00715\n",
      "Epoch: 1... Training loss: 0.00439... Test loss: 0.00545\n",
      "Epoch: 1... Training loss: 0.0042... Test loss: 0.00753\n",
      "Epoch: 1... Training loss: 0.00451... Test loss: 0.00572\n",
      "Epoch: 1... Training loss: 0.00395... Test loss: 0.0062\n",
      "Epoch: 1... Training loss: 0.0042... Test loss: 0.00491\n",
      "Epoch: 1... Training loss: 0.00376... Test loss: 0.00517\n",
      "Epoch: 1... Training loss: 0.00375... Test loss: 0.0043\n",
      "Epoch: 1... Training loss: 0.00372... Test loss: 0.00415\n",
      "Epoch: 1... Training loss: 0.00344... Test loss: 0.0049\n",
      "Epoch: 1... Training loss: 0.00333... Test loss: 0.00361\n",
      "Epoch: 1... Training loss: 0.00317... Test loss: 0.00375\n",
      "Epoch: 1... Training loss: 0.00298... Test loss: 0.00337\n",
      "Epoch: 1... Training loss: 0.00312... Test loss: 0.00332\n",
      "Epoch: 1... Training loss: 0.00289... Test loss: 0.00358\n",
      "Epoch: 1... Training loss: 0.0029... Test loss: 0.00316\n",
      "Epoch: 1... Training loss: 0.00273... Test loss: 0.00322\n",
      "Epoch: 1... Training loss: 0.00251... Test loss: 0.00353\n",
      "Epoch: 1... Training loss: 0.00259... Test loss: 0.00265\n",
      "Epoch: 1... Training loss: 0.00248... Test loss: 0.00346\n",
      "Epoch: 1... Training loss: 0.00245... Test loss: 0.00283\n",
      "Epoch: 1... Training loss: 0.0024... Test loss: 0.00267\n",
      "Epoch: 1... Training loss: 0.00228... Test loss: 0.00251\n",
      "Epoch: 1... Training loss: 0.00228... Test loss: 0.0028\n",
      "Epoch: 1... Training loss: 0.00217... Test loss: 0.00296\n",
      "Epoch: 1... Training loss: 0.00218... Test loss: 0.00274\n",
      "Epoch: 1... Training loss: 0.00207... Test loss: 0.00337\n",
      "Epoch: 1... Training loss: 0.00206... Test loss: 0.00258\n",
      "Epoch: 1... Training loss: 0.00197... Test loss: 0.00255\n",
      "Epoch: 1... Training loss: 0.00182... Test loss: 0.00209\n",
      "Epoch: 1... Training loss: 0.00183... Test loss: 0.00262\n",
      "Epoch: 1... Training loss: 0.0017... Test loss: 0.00196\n",
      "Epoch: 1... Training loss: 0.00166... Test loss: 0.00224\n",
      "Epoch: 1... Training loss: 0.00161... Test loss: 0.00147\n",
      "Epoch: 1... Training loss: 0.0016... Test loss: 0.002\n",
      "Epoch: 1... Training loss: 0.00159... Test loss: 0.0013\n",
      "Epoch: 1... Training loss: 0.0014... Test loss: 0.00172\n",
      "Epoch: 1... Training loss: 0.0015... Test loss: 0.00155\n",
      "Epoch: 1... Training loss: 0.00131... Test loss: 0.00143\n",
      "Epoch: 1... Training loss: 0.00131... Test loss: 0.00169\n",
      "Epoch: 1... Training loss: 0.00128... Test loss: 0.00138\n",
      "Epoch: 1... Training loss: 0.00125... Test loss: 0.00159\n",
      "Epoch: 1... Training loss: 0.00123... Test loss: 0.00132\n",
      "Epoch: 1... Training loss: 0.00112... Test loss: 0.00144\n",
      "Epoch: 1... Training loss: 0.00113... Test loss: 0.00127\n",
      "Epoch: 1... Training loss: 0.00106... Test loss: 0.00098\n",
      "Epoch: 1... Training loss: 0.00101... Test loss: 0.00127\n",
      "Epoch: 1... Training loss: 0.00091... Test loss: 0.00094\n",
      "Epoch: 1... Training loss: 0.00093... Test loss: 0.00128\n",
      "Epoch: 1... Training loss: 0.00089... Test loss: 0.0011\n",
      "Epoch: 1... Training loss: 0.00086... Test loss: 0.00111\n",
      "Epoch: 1... Training loss: 0.00077... Test loss: 0.0009\n",
      "Epoch: 1... Training loss: 0.00085... Test loss: 0.00106\n",
      "Epoch: 1... Training loss: 0.0007... Test loss: 0.00083\n",
      "Epoch: 1... Training loss: 0.00069... Test loss: 0.00085\n",
      "Epoch: 1... Training loss: 0.00061... Test loss: 0.00056\n",
      "Epoch: 1... Training loss: 0.00061... Test loss: 0.00077\n",
      "Epoch: 1... Training loss: 0.00059... Test loss: 0.00076\n",
      "Epoch: 1... Training loss: 0.00056... Test loss: 0.00053\n",
      "Epoch: 1... Training loss: 0.0005... Test loss: 0.00067\n",
      "Epoch: 1... Training loss: 0.00054... Test loss: 0.00067\n",
      "Epoch: 1... Training loss: 0.00044... Test loss: 0.00048\n",
      "Epoch: 1... Training loss: 0.00041... Test loss: 0.00059\n",
      "Epoch: 1... Training loss: 0.00042... Test loss: 0.00051\n",
      "Epoch: 1... Training loss: 0.00038... Test loss: 0.00045\n",
      "Epoch: 1... Training loss: 0.00036... Test loss: 0.00045\n",
      "Epoch: 1... Training loss: 0.00035... Test loss: 0.00047\n",
      "Epoch: 1... Training loss: 0.00035... Test loss: 0.00041\n",
      "Epoch: 1... Training loss: 0.00034... Test loss: 0.00051\n",
      "Epoch: 1... Training loss: 0.00031... Test loss: 0.00038\n",
      "Epoch: 1... Training loss: 0.00029... Test loss: 0.00033\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.0003\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00036\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00032\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 8e-05\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 7e-05\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 8e-05\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 6e-05\n",
      "Epoch: 1... Training loss: 8e-05... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 8e-05\n",
      "Epoch: 1... Training loss: 8e-05... Test loss: 0.00011\n",
      "237.47096147667617\n",
      "Epoch: 1... Training loss: 1.24731... Test loss: 0.53016\n",
      "Epoch: 1... Training loss: 0.48348... Test loss: 0.17589\n",
      "Epoch: 1... Training loss: 0.24287... Test loss: 0.08637\n",
      "Epoch: 1... Training loss: 0.16669... Test loss: 0.05351\n",
      "Epoch: 1... Training loss: 0.14142... Test loss: 0.04683\n",
      "Epoch: 1... Training loss: 0.11594... Test loss: 0.03716\n",
      "Epoch: 1... Training loss: 0.09338... Test loss: 0.02779\n",
      "Epoch: 1... Training loss: 0.07658... Test loss: 0.02155\n",
      "Epoch: 1... Training loss: 0.06791... Test loss: 0.02793\n",
      "Epoch: 1... Training loss: 0.05952... Test loss: 0.01986\n",
      "Epoch: 1... Training loss: 0.05562... Test loss: 0.01633\n",
      "Epoch: 1... Training loss: 0.05188... Test loss: 0.01587\n",
      "Epoch: 1... Training loss: 0.04453... Test loss: 0.01024\n",
      "Epoch: 1... Training loss: 0.04179... Test loss: 0.01604\n",
      "Epoch: 1... Training loss: 0.03828... Test loss: 0.00672\n",
      "Epoch: 1... Training loss: 0.03423... Test loss: 0.01641\n",
      "Epoch: 1... Training loss: 0.03089... Test loss: 0.00688\n",
      "Epoch: 1... Training loss: 0.02887... Test loss: 0.01485\n",
      "Epoch: 1... Training loss: 0.02728... Test loss: 0.00654\n",
      "Epoch: 1... Training loss: 0.02608... Test loss: 0.01821\n",
      "Epoch: 1... Training loss: 0.02521... Test loss: 0.00519\n",
      "Epoch: 1... Training loss: 0.02348... Test loss: 0.01376\n",
      "Epoch: 1... Training loss: 0.02165... Test loss: 0.00551\n",
      "Epoch: 1... Training loss: 0.02103... Test loss: 0.01145\n",
      "Epoch: 1... Training loss: 0.01936... Test loss: 0.01575\n",
      "Epoch: 1... Training loss: 0.01855... Test loss: 0.00555\n",
      "Epoch: 1... Training loss: 0.0175... Test loss: 0.01527\n",
      "Epoch: 1... Training loss: 0.01655... Test loss: 0.00629\n",
      "Epoch: 1... Training loss: 0.01642... Test loss: 0.01503\n",
      "Epoch: 1... Training loss: 0.01555... Test loss: 0.00473\n",
      "Epoch: 1... Training loss: 0.01525... Test loss: 0.01699\n",
      "Epoch: 1... Training loss: 0.01475... Test loss: 0.00471\n",
      "Epoch: 1... Training loss: 0.01465... Test loss: 0.00925\n",
      "Epoch: 1... Training loss: 0.01395... Test loss: 0.01134\n",
      "Epoch: 1... Training loss: 0.01339... Test loss: 0.00773\n",
      "Epoch: 1... Training loss: 0.01305... Test loss: 0.01033\n",
      "Epoch: 1... Training loss: 0.01238... Test loss: 0.00747\n",
      "Epoch: 1... Training loss: 0.01213... Test loss: 0.00811\n",
      "Epoch: 1... Training loss: 0.01186... Test loss: 0.00653\n",
      "Epoch: 1... Training loss: 0.01146... Test loss: 0.00922\n",
      "Epoch: 1... Training loss: 0.01115... Test loss: 0.00708\n",
      "Epoch: 1... Training loss: 0.0107... Test loss: 0.008\n",
      "Epoch: 1... Training loss: 0.01034... Test loss: 0.00692\n",
      "Epoch: 1... Training loss: 0.0101... Test loss: 0.0087\n",
      "Epoch: 1... Training loss: 0.00984... Test loss: 0.00683\n",
      "Epoch: 1... Training loss: 0.00961... Test loss: 0.0088\n",
      "Epoch: 1... Training loss: 0.00942... Test loss: 0.00771\n",
      "Epoch: 1... Training loss: 0.0089... Test loss: 0.0058\n",
      "Epoch: 1... Training loss: 0.00871... Test loss: 0.01063\n",
      "Epoch: 1... Training loss: 0.00841... Test loss: 0.00561\n",
      "Epoch: 1... Training loss: 0.0081... Test loss: 0.00953\n",
      "Epoch: 1... Training loss: 0.0079... Test loss: 0.00544\n",
      "Epoch: 1... Training loss: 0.00764... Test loss: 0.00841\n",
      "Epoch: 1... Training loss: 0.00746... Test loss: 0.00533\n",
      "Epoch: 1... Training loss: 0.00725... Test loss: 0.00727\n",
      "Epoch: 1... Training loss: 0.00697... Test loss: 0.00603\n",
      "Epoch: 1... Training loss: 0.00684... Test loss: 0.00651\n",
      "Epoch: 1... Training loss: 0.00676... Test loss: 0.00592\n",
      "Epoch: 1... Training loss: 0.00644... Test loss: 0.00608\n",
      "Epoch: 1... Training loss: 0.00638... Test loss: 0.00631\n",
      "Epoch: 1... Training loss: 0.00606... Test loss: 0.00518\n",
      "Epoch: 1... Training loss: 0.00589... Test loss: 0.00759\n",
      "Epoch: 1... Training loss: 0.00571... Test loss: 0.00523\n",
      "Epoch: 1... Training loss: 0.00543... Test loss: 0.00719\n",
      "Epoch: 1... Training loss: 0.01359... Test loss: 0.009\n",
      "Epoch: 1... Training loss: 0.0094... Test loss: 0.01569\n",
      "Epoch: 1... Training loss: 0.0101... Test loss: 0.01344\n",
      "Epoch: 1... Training loss: 0.0085... Test loss: 0.01253\n",
      "Epoch: 1... Training loss: 0.0092... Test loss: 0.01726\n",
      "Epoch: 1... Training loss: 0.0079... Test loss: 0.0091\n",
      "Epoch: 1... Training loss: 0.00771... Test loss: 0.01163\n",
      "Epoch: 1... Training loss: 0.00861... Test loss: 0.01058\n",
      "Epoch: 1... Training loss: 0.00749... Test loss: 0.01596\n",
      "Epoch: 1... Training loss: 0.00715... Test loss: 0.01106\n",
      "Epoch: 1... Training loss: 0.0079... Test loss: 0.01154\n",
      "Epoch: 1... Training loss: 0.00778... Test loss: 0.01045\n",
      "Epoch: 1... Training loss: 0.00664... Test loss: 0.00762\n",
      "Epoch: 1... Training loss: 0.0066... Test loss: 0.00829\n",
      "Epoch: 1... Training loss: 0.00618... Test loss: 0.00772\n",
      "Epoch: 1... Training loss: 0.00617... Test loss: 0.00746\n",
      "Epoch: 1... Training loss: 0.00627... Test loss: 0.00719\n",
      "Epoch: 1... Training loss: 0.00572... Test loss: 0.00821\n",
      "Epoch: 1... Training loss: 0.00521... Test loss: 0.00628\n",
      "Epoch: 1... Training loss: 0.00517... Test loss: 0.00626\n",
      "Epoch: 1... Training loss: 0.00493... Test loss: 0.00744\n",
      "Epoch: 1... Training loss: 0.00475... Test loss: 0.00613\n",
      "Epoch: 1... Training loss: 0.00467... Test loss: 0.0072\n",
      "Epoch: 1... Training loss: 0.00452... Test loss: 0.00642\n",
      "Epoch: 1... Training loss: 0.00449... Test loss: 0.00553\n",
      "Epoch: 1... Training loss: 0.00417... Test loss: 0.00637\n",
      "Epoch: 1... Training loss: 0.00413... Test loss: 0.00541\n",
      "Epoch: 1... Training loss: 0.00396... Test loss: 0.00496\n",
      "Epoch: 1... Training loss: 0.0038... Test loss: 0.00528\n",
      "Epoch: 1... Training loss: 0.00358... Test loss: 0.00455\n",
      "Epoch: 1... Training loss: 0.00355... Test loss: 0.00512\n",
      "Epoch: 1... Training loss: 0.0033... Test loss: 0.00415\n",
      "Epoch: 1... Training loss: 0.00323... Test loss: 0.00459\n",
      "Epoch: 1... Training loss: 0.0032... Test loss: 0.00363\n",
      "Epoch: 1... Training loss: 0.0031... Test loss: 0.00377\n",
      "Epoch: 1... Training loss: 0.00296... Test loss: 0.00356\n",
      "Epoch: 1... Training loss: 0.00282... Test loss: 0.00455\n",
      "Epoch: 1... Training loss: 0.00283... Test loss: 0.00411\n",
      "Epoch: 1... Training loss: 0.00278... Test loss: 0.00332\n",
      "Epoch: 1... Training loss: 0.00276... Test loss: 0.00406\n",
      "Epoch: 1... Training loss: 0.00245... Test loss: 0.00281\n",
      "Epoch: 1... Training loss: 0.00242... Test loss: 0.00341\n",
      "Epoch: 1... Training loss: 0.00225... Test loss: 0.00269\n",
      "Epoch: 1... Training loss: 0.00238... Test loss: 0.003\n",
      "Epoch: 1... Training loss: 0.00225... Test loss: 0.00264\n",
      "Epoch: 1... Training loss: 0.00207... Test loss: 0.00272\n",
      "Epoch: 1... Training loss: 0.00199... Test loss: 0.00244\n",
      "Epoch: 1... Training loss: 0.00196... Test loss: 0.00258\n",
      "Epoch: 1... Training loss: 0.00184... Test loss: 0.00233\n",
      "Epoch: 1... Training loss: 0.00178... Test loss: 0.00244\n",
      "Epoch: 1... Training loss: 0.00185... Test loss: 0.002\n",
      "Epoch: 1... Training loss: 0.00173... Test loss: 0.00227\n",
      "Epoch: 1... Training loss: 0.0018... Test loss: 0.00176\n",
      "Epoch: 1... Training loss: 0.00171... Test loss: 0.00181\n",
      "Epoch: 1... Training loss: 0.00163... Test loss: 0.00178\n",
      "Epoch: 1... Training loss: 0.0016... Test loss: 0.00178\n",
      "Epoch: 1... Training loss: 0.00149... Test loss: 0.0022\n",
      "Epoch: 1... Training loss: 0.00149... Test loss: 0.00158\n",
      "Epoch: 1... Training loss: 0.00145... Test loss: 0.00232\n",
      "Epoch: 1... Training loss: 0.00129... Test loss: 0.00158\n",
      "Epoch: 1... Training loss: 0.00135... Test loss: 0.00153\n",
      "Epoch: 1... Training loss: 0.0012... Test loss: 0.00133\n",
      "Epoch: 1... Training loss: 0.0012... Test loss: 0.0015\n",
      "Epoch: 1... Training loss: 0.00118... Test loss: 0.00116\n",
      "Epoch: 1... Training loss: 0.00105... Test loss: 0.00146\n",
      "Epoch: 1... Training loss: 0.001... Test loss: 0.00126\n",
      "Epoch: 1... Training loss: 0.00098... Test loss: 0.00119\n",
      "Epoch: 1... Training loss: 0.00089... Test loss: 0.00113\n",
      "Epoch: 1... Training loss: 0.00095... Test loss: 0.00106\n",
      "Epoch: 1... Training loss: 0.00084... Test loss: 0.00098\n",
      "Epoch: 1... Training loss: 0.0008... Test loss: 0.00103\n",
      "Epoch: 1... Training loss: 0.00078... Test loss: 0.00108\n",
      "Epoch: 1... Training loss: 0.00075... Test loss: 0.00085\n",
      "Epoch: 1... Training loss: 0.00072... Test loss: 0.00096\n",
      "Epoch: 1... Training loss: 0.00074... Test loss: 0.00072\n",
      "Epoch: 1... Training loss: 0.00064... Test loss: 0.00086\n",
      "Epoch: 1... Training loss: 0.00061... Test loss: 0.00055\n",
      "Epoch: 1... Training loss: 0.00058... Test loss: 0.00072\n",
      "Epoch: 1... Training loss: 0.00058... Test loss: 0.00061\n",
      "Epoch: 1... Training loss: 0.00051... Test loss: 0.00069\n",
      "Epoch: 1... Training loss: 0.00057... Test loss: 0.00049\n",
      "Epoch: 1... Training loss: 0.0005... Test loss: 0.00056\n",
      "Epoch: 1... Training loss: 0.00047... Test loss: 0.00052\n",
      "Epoch: 1... Training loss: 0.00048... Test loss: 0.00049\n",
      "Epoch: 1... Training loss: 0.00041... Test loss: 0.00056\n",
      "Epoch: 1... Training loss: 0.0004... Test loss: 0.0004\n",
      "Epoch: 1... Training loss: 0.0004... Test loss: 0.00049\n",
      "Epoch: 1... Training loss: 0.00037... Test loss: 0.00038\n",
      "Epoch: 1... Training loss: 0.00034... Test loss: 0.00043\n",
      "Epoch: 1... Training loss: 0.00036... Test loss: 0.00038\n",
      "Epoch: 1... Training loss: 0.00036... Test loss: 0.00037\n",
      "Epoch: 1... Training loss: 0.00031... Test loss: 0.00033\n",
      "Epoch: 1... Training loss: 0.00029... Test loss: 0.00032\n",
      "Epoch: 1... Training loss: 0.00031... Test loss: 0.00031\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00036\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.00033... Test loss: 0.00031\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00033\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00031... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.0003\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00028\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 8e-05\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 7e-05\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 7e-05\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 8e-05... Test loss: 9e-05\n",
      "233.2954215122736\n",
      "Epoch: 1... Training loss: 0.82322... Test loss: 0.17671\n",
      "Epoch: 1... Training loss: 0.43824... Test loss: 0.13965\n",
      "Epoch: 1... Training loss: 0.27793... Test loss: 0.07326\n",
      "Epoch: 1... Training loss: 0.19439... Test loss: 0.05003\n",
      "Epoch: 1... Training loss: 0.14743... Test loss: 0.03483\n",
      "Epoch: 1... Training loss: 0.10401... Test loss: 0.02497\n",
      "Epoch: 1... Training loss: 0.08947... Test loss: 0.02146\n",
      "Epoch: 1... Training loss: 0.07301... Test loss: 0.01594\n",
      "Epoch: 1... Training loss: 0.06503... Test loss: 0.01353\n",
      "Epoch: 1... Training loss: 0.05915... Test loss: 0.01358\n",
      "Epoch: 1... Training loss: 0.05137... Test loss: 0.0096\n",
      "Epoch: 1... Training loss: 0.04792... Test loss: 0.01579\n",
      "Epoch: 1... Training loss: 0.04345... Test loss: 0.00584\n",
      "Epoch: 1... Training loss: 0.03966... Test loss: 0.01048\n",
      "Epoch: 1... Training loss: 0.03772... Test loss: 0.00507\n",
      "Epoch: 1... Training loss: 0.03577... Test loss: 0.00856\n",
      "Epoch: 1... Training loss: 0.03256... Test loss: 0.00673\n",
      "Epoch: 1... Training loss: 0.02908... Test loss: 0.00483\n",
      "Epoch: 1... Training loss: 0.028... Test loss: 0.01146\n",
      "Epoch: 1... Training loss: 0.02643... Test loss: 0.00381\n",
      "Epoch: 1... Training loss: 0.02544... Test loss: 0.00788\n",
      "Epoch: 1... Training loss: 0.02342... Test loss: 0.00388\n",
      "Epoch: 1... Training loss: 0.02261... Test loss: 0.00751\n",
      "Epoch: 1... Training loss: 0.02083... Test loss: 0.00436\n",
      "Epoch: 1... Training loss: 0.02065... Test loss: 0.00683\n",
      "Epoch: 1... Training loss: 0.01901... Test loss: 0.00817\n",
      "Epoch: 1... Training loss: 0.0182... Test loss: 0.00684\n",
      "Epoch: 1... Training loss: 0.01792... Test loss: 0.00645\n",
      "Epoch: 1... Training loss: 0.01688... Test loss: 0.00762\n",
      "Epoch: 1... Training loss: 0.01589... Test loss: 0.00548\n",
      "Epoch: 1... Training loss: 0.01548... Test loss: 0.00723\n",
      "Epoch: 1... Training loss: 0.01494... Test loss: 0.00467\n",
      "Epoch: 1... Training loss: 0.01438... Test loss: 0.0079\n",
      "Epoch: 1... Training loss: 0.01363... Test loss: 0.00509\n",
      "Epoch: 1... Training loss: 0.01328... Test loss: 0.00812\n",
      "Epoch: 1... Training loss: 0.01278... Test loss: 0.0055\n",
      "Epoch: 1... Training loss: 0.0128... Test loss: 0.00726\n",
      "Epoch: 1... Training loss: 0.01213... Test loss: 0.00755\n",
      "Epoch: 1... Training loss: 0.01186... Test loss: 0.00637\n",
      "Epoch: 1... Training loss: 0.01149... Test loss: 0.00986\n",
      "Epoch: 1... Training loss: 0.01107... Test loss: 0.00473\n",
      "Epoch: 1... Training loss: 0.01073... Test loss: 0.00867\n",
      "Epoch: 1... Training loss: 0.01038... Test loss: 0.00484\n",
      "Epoch: 1... Training loss: 0.01024... Test loss: 0.00711\n",
      "Epoch: 1... Training loss: 0.0099... Test loss: 0.00614\n",
      "Epoch: 1... Training loss: 0.00949... Test loss: 0.00659\n",
      "Epoch: 1... Training loss: 0.00923... Test loss: 0.00668\n",
      "Epoch: 1... Training loss: 0.0087... Test loss: 0.00655\n",
      "Epoch: 1... Training loss: 0.00859... Test loss: 0.00628\n",
      "Epoch: 1... Training loss: 0.00825... Test loss: 0.0064\n",
      "Epoch: 1... Training loss: 0.00815... Test loss: 0.00588\n",
      "Epoch: 1... Training loss: 0.00768... Test loss: 0.00636\n",
      "Epoch: 1... Training loss: 0.00761... Test loss: 0.00532\n",
      "Epoch: 1... Training loss: 0.0073... Test loss: 0.00691\n",
      "Epoch: 1... Training loss: 0.00717... Test loss: 0.00411\n",
      "Epoch: 1... Training loss: 0.00696... Test loss: 0.00672\n",
      "Epoch: 1... Training loss: 0.00686... Test loss: 0.00445\n",
      "Epoch: 1... Training loss: 0.00656... Test loss: 0.00708\n",
      "Epoch: 1... Training loss: 0.0065... Test loss: 0.00549\n",
      "Epoch: 1... Training loss: 0.00638... Test loss: 0.00584\n",
      "Epoch: 1... Training loss: 0.00609... Test loss: 0.00535\n",
      "Epoch: 1... Training loss: 0.0059... Test loss: 0.00584\n",
      "Epoch: 1... Training loss: 0.00565... Test loss: 0.0054\n",
      "Epoch: 1... Training loss: 0.00564... Test loss: 0.00529\n",
      "Epoch: 1... Training loss: 0.01152... Test loss: 0.01386\n",
      "Epoch: 1... Training loss: 0.00941... Test loss: 0.01819\n",
      "Epoch: 1... Training loss: 0.01025... Test loss: 0.01103\n",
      "Epoch: 1... Training loss: 0.00906... Test loss: 0.0144\n",
      "Epoch: 1... Training loss: 0.00898... Test loss: 0.01146\n",
      "Epoch: 1... Training loss: 0.0089... Test loss: 0.01386\n",
      "Epoch: 1... Training loss: 0.00771... Test loss: 0.0149\n",
      "Epoch: 1... Training loss: 0.00765... Test loss: 0.00864\n",
      "Epoch: 1... Training loss: 0.00747... Test loss: 0.01203\n",
      "Epoch: 1... Training loss: 0.0073... Test loss: 0.00818\n",
      "Epoch: 1... Training loss: 0.00695... Test loss: 0.00625\n",
      "Epoch: 1... Training loss: 0.0074... Test loss: 0.01255\n",
      "Epoch: 1... Training loss: 0.00713... Test loss: 0.00622\n",
      "Epoch: 1... Training loss: 0.00678... Test loss: 0.01369\n",
      "Epoch: 1... Training loss: 0.00648... Test loss: 0.00664\n",
      "Epoch: 1... Training loss: 0.00615... Test loss: 0.01077\n",
      "Epoch: 1... Training loss: 0.00611... Test loss: 0.00648\n",
      "Epoch: 1... Training loss: 0.00602... Test loss: 0.01025\n",
      "Epoch: 1... Training loss: 0.00565... Test loss: 0.00692\n",
      "Epoch: 1... Training loss: 0.00579... Test loss: 0.00683\n",
      "Epoch: 1... Training loss: 0.00562... Test loss: 0.0061\n",
      "Epoch: 1... Training loss: 0.0048... Test loss: 0.0072\n",
      "Epoch: 1... Training loss: 0.00499... Test loss: 0.00466\n",
      "Epoch: 1... Training loss: 0.00476... Test loss: 0.00713\n",
      "Epoch: 1... Training loss: 0.00449... Test loss: 0.00498\n",
      "Epoch: 1... Training loss: 0.00436... Test loss: 0.00629\n",
      "Epoch: 1... Training loss: 0.00436... Test loss: 0.00696\n",
      "Epoch: 1... Training loss: 0.00395... Test loss: 0.00519\n",
      "Epoch: 1... Training loss: 0.00388... Test loss: 0.00627\n",
      "Epoch: 1... Training loss: 0.00369... Test loss: 0.00508\n",
      "Epoch: 1... Training loss: 0.00361... Test loss: 0.00472\n",
      "Epoch: 1... Training loss: 0.0034... Test loss: 0.00432\n",
      "Epoch: 1... Training loss: 0.00339... Test loss: 0.00401\n",
      "Epoch: 1... Training loss: 0.00325... Test loss: 0.00418\n",
      "Epoch: 1... Training loss: 0.0031... Test loss: 0.00377\n",
      "Epoch: 1... Training loss: 0.00303... Test loss: 0.00374\n",
      "Epoch: 1... Training loss: 0.00287... Test loss: 0.00391\n",
      "Epoch: 1... Training loss: 0.0027... Test loss: 0.00355\n",
      "Epoch: 1... Training loss: 0.0027... Test loss: 0.00402\n",
      "Epoch: 1... Training loss: 0.00262... Test loss: 0.00336\n",
      "Epoch: 1... Training loss: 0.00253... Test loss: 0.00323\n",
      "Epoch: 1... Training loss: 0.0025... Test loss: 0.00297\n",
      "Epoch: 1... Training loss: 0.00245... Test loss: 0.00287\n",
      "Epoch: 1... Training loss: 0.00237... Test loss: 0.00282\n",
      "Epoch: 1... Training loss: 0.00235... Test loss: 0.00291\n",
      "Epoch: 1... Training loss: 0.00228... Test loss: 0.00271\n",
      "Epoch: 1... Training loss: 0.00222... Test loss: 0.00263\n",
      "Epoch: 1... Training loss: 0.00204... Test loss: 0.00276\n",
      "Epoch: 1... Training loss: 0.00199... Test loss: 0.0024\n",
      "Epoch: 1... Training loss: 0.00197... Test loss: 0.00232\n",
      "Epoch: 1... Training loss: 0.00185... Test loss: 0.00211\n",
      "Epoch: 1... Training loss: 0.00182... Test loss: 0.00211\n",
      "Epoch: 1... Training loss: 0.00177... Test loss: 0.00188\n",
      "Epoch: 1... Training loss: 0.00167... Test loss: 0.00209\n",
      "Epoch: 1... Training loss: 0.00174... Test loss: 0.0017\n",
      "Epoch: 1... Training loss: 0.00161... Test loss: 0.00271\n",
      "Epoch: 1... Training loss: 0.00161... Test loss: 0.00142\n",
      "Epoch: 1... Training loss: 0.00146... Test loss: 0.00191\n",
      "Epoch: 1... Training loss: 0.00149... Test loss: 0.00143\n",
      "Epoch: 1... Training loss: 0.0015... Test loss: 0.00155\n",
      "Epoch: 1... Training loss: 0.00136... Test loss: 0.00141\n",
      "Epoch: 1... Training loss: 0.00123... Test loss: 0.00144\n",
      "Epoch: 1... Training loss: 0.00124... Test loss: 0.00132\n",
      "Epoch: 1... Training loss: 0.00113... Test loss: 0.00149\n",
      "Epoch: 1... Training loss: 0.00112... Test loss: 0.00115\n",
      "Epoch: 1... Training loss: 0.0011... Test loss: 0.00136\n",
      "Epoch: 1... Training loss: 0.00101... Test loss: 0.00129\n",
      "Epoch: 1... Training loss: 0.001... Test loss: 0.0013\n",
      "Epoch: 1... Training loss: 0.00094... Test loss: 0.00131\n",
      "Epoch: 1... Training loss: 0.0009... Test loss: 0.00095\n",
      "Epoch: 1... Training loss: 0.00084... Test loss: 0.00123\n",
      "Epoch: 1... Training loss: 0.00082... Test loss: 0.00092\n",
      "Epoch: 1... Training loss: 0.00073... Test loss: 0.00102\n",
      "Epoch: 1... Training loss: 0.00073... Test loss: 0.0009\n",
      "Epoch: 1... Training loss: 0.00067... Test loss: 0.00085\n",
      "Epoch: 1... Training loss: 0.00066... Test loss: 0.00093\n",
      "Epoch: 1... Training loss: 0.00062... Test loss: 0.00074\n",
      "Epoch: 1... Training loss: 0.00062... Test loss: 0.00075\n",
      "Epoch: 1... Training loss: 0.00057... Test loss: 0.00074\n",
      "Epoch: 1... Training loss: 0.0006... Test loss: 0.00073\n",
      "Epoch: 1... Training loss: 0.00051... Test loss: 0.00063\n",
      "Epoch: 1... Training loss: 0.0005... Test loss: 0.0005\n",
      "Epoch: 1... Training loss: 0.00045... Test loss: 0.00063\n",
      "Epoch: 1... Training loss: 0.00049... Test loss: 0.00038\n",
      "Epoch: 1... Training loss: 0.00044... Test loss: 0.00048\n",
      "Epoch: 1... Training loss: 0.00041... Test loss: 0.00038\n",
      "Epoch: 1... Training loss: 0.00044... Test loss: 0.0005\n",
      "Epoch: 1... Training loss: 0.00038... Test loss: 0.00036\n",
      "Epoch: 1... Training loss: 0.00044... Test loss: 0.00036\n",
      "Epoch: 1... Training loss: 0.00033... Test loss: 0.00032\n",
      "Epoch: 1... Training loss: 0.00035... Test loss: 0.00044\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.0003\n",
      "Epoch: 1... Training loss: 0.00029... Test loss: 0.00034\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.00024\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00035\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00028\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00024\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 8e-05... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 8e-05... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 8e-05... Test loss: 8e-05\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 8e-05\n",
      "Epoch: 1... Training loss: 8e-05... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 7e-05... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 7e-05... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 8e-05... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 7e-05... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 7e-05... Test loss: 9e-05\n",
      "216.09706863417523\n",
      "Epoch: 1... Training loss: 0.83789... Test loss: 0.15981\n",
      "Epoch: 1... Training loss: 0.44552... Test loss: 0.14382\n",
      "Epoch: 1... Training loss: 0.28916... Test loss: 0.08041\n",
      "Epoch: 1... Training loss: 0.19366... Test loss: 0.04989\n",
      "Epoch: 1... Training loss: 0.14173... Test loss: 0.03776\n",
      "Epoch: 1... Training loss: 0.10484... Test loss: 0.02804\n",
      "Epoch: 1... Training loss: 0.09175... Test loss: 0.02465\n",
      "Epoch: 1... Training loss: 0.08028... Test loss: 0.01893\n",
      "Epoch: 1... Training loss: 0.0686... Test loss: 0.01432\n",
      "Epoch: 1... Training loss: 0.06381... Test loss: 0.01258\n",
      "Epoch: 1... Training loss: 0.05667... Test loss: 0.01416\n",
      "Epoch: 1... Training loss: 0.05241... Test loss: 0.0085\n",
      "Epoch: 1... Training loss: 0.04513... Test loss: 0.01342\n",
      "Epoch: 1... Training loss: 0.04076... Test loss: 0.00638\n",
      "Epoch: 1... Training loss: 0.03887... Test loss: 0.01108\n",
      "Epoch: 1... Training loss: 0.03432... Test loss: 0.00547\n",
      "Epoch: 1... Training loss: 0.03336... Test loss: 0.01015\n",
      "Epoch: 1... Training loss: 0.03089... Test loss: 0.00696\n",
      "Epoch: 1... Training loss: 0.02962... Test loss: 0.01205\n",
      "Epoch: 1... Training loss: 0.02763... Test loss: 0.00626\n",
      "Epoch: 1... Training loss: 0.0265... Test loss: 0.00863\n",
      "Epoch: 1... Training loss: 0.02512... Test loss: 0.01009\n",
      "Epoch: 1... Training loss: 0.02407... Test loss: 0.00845\n",
      "Epoch: 1... Training loss: 0.02241... Test loss: 0.00992\n",
      "Epoch: 1... Training loss: 0.02178... Test loss: 0.01448\n",
      "Epoch: 1... Training loss: 0.02048... Test loss: 0.00712\n",
      "Epoch: 1... Training loss: 0.01974... Test loss: 0.01254\n",
      "Epoch: 1... Training loss: 0.01852... Test loss: 0.00793\n",
      "Epoch: 1... Training loss: 0.01755... Test loss: 0.00898\n",
      "Epoch: 1... Training loss: 0.01719... Test loss: 0.01097\n",
      "Epoch: 1... Training loss: 0.01608... Test loss: 0.00692\n",
      "Epoch: 1... Training loss: 0.01555... Test loss: 0.01236\n",
      "Epoch: 1... Training loss: 0.01482... Test loss: 0.00594\n",
      "Epoch: 1... Training loss: 0.01458... Test loss: 0.01193\n",
      "Epoch: 1... Training loss: 0.01379... Test loss: 0.0079\n",
      "Epoch: 1... Training loss: 0.01339... Test loss: 0.01141\n",
      "Epoch: 1... Training loss: 0.01297... Test loss: 0.01023\n",
      "Epoch: 1... Training loss: 0.01271... Test loss: 0.00993\n",
      "Epoch: 1... Training loss: 0.01236... Test loss: 0.01117\n",
      "Epoch: 1... Training loss: 0.01184... Test loss: 0.0085\n",
      "Epoch: 1... Training loss: 0.01149... Test loss: 0.0116\n",
      "Epoch: 1... Training loss: 0.01106... Test loss: 0.00771\n",
      "Epoch: 1... Training loss: 0.01077... Test loss: 0.01062\n",
      "Epoch: 1... Training loss: 0.0104... Test loss: 0.00803\n",
      "Epoch: 1... Training loss: 0.01003... Test loss: 0.00914\n",
      "Epoch: 1... Training loss: 0.00968... Test loss: 0.00822\n",
      "Epoch: 1... Training loss: 0.0093... Test loss: 0.00995\n",
      "Epoch: 1... Training loss: 0.0091... Test loss: 0.00864\n",
      "Epoch: 1... Training loss: 0.00888... Test loss: 0.0089\n",
      "Epoch: 1... Training loss: 0.00866... Test loss: 0.00778\n",
      "Epoch: 1... Training loss: 0.00849... Test loss: 0.00878\n",
      "Epoch: 1... Training loss: 0.00818... Test loss: 0.00738\n",
      "Epoch: 1... Training loss: 0.00786... Test loss: 0.00855\n",
      "Epoch: 1... Training loss: 0.00758... Test loss: 0.0065\n",
      "Epoch: 1... Training loss: 0.00734... Test loss: 0.00791\n",
      "Epoch: 1... Training loss: 0.00715... Test loss: 0.00665\n",
      "Epoch: 1... Training loss: 0.00687... Test loss: 0.00737\n",
      "Epoch: 1... Training loss: 0.00674... Test loss: 0.00614\n",
      "Epoch: 1... Training loss: 0.0065... Test loss: 0.00695\n",
      "Epoch: 1... Training loss: 0.00637... Test loss: 0.00561\n",
      "Epoch: 1... Training loss: 0.0061... Test loss: 0.00646\n",
      "Epoch: 1... Training loss: 0.00598... Test loss: 0.00581\n",
      "Epoch: 1... Training loss: 0.00572... Test loss: 0.00571\n",
      "Epoch: 1... Training loss: 0.00555... Test loss: 0.00534\n",
      "Epoch: 1... Training loss: 0.01043... Test loss: 0.01087\n",
      "Epoch: 1... Training loss: 0.01007... Test loss: 0.01151\n",
      "Epoch: 1... Training loss: 0.00975... Test loss: 0.01355\n",
      "Epoch: 1... Training loss: 0.00905... Test loss: 0.01343\n",
      "Epoch: 1... Training loss: 0.00844... Test loss: 0.01389\n",
      "Epoch: 1... Training loss: 0.00928... Test loss: 0.0118\n",
      "Epoch: 1... Training loss: 0.00846... Test loss: 0.01517\n",
      "Epoch: 1... Training loss: 0.00816... Test loss: 0.0122\n",
      "Epoch: 1... Training loss: 0.00811... Test loss: 0.01053\n",
      "Epoch: 1... Training loss: 0.00851... Test loss: 0.01237\n",
      "Epoch: 1... Training loss: 0.00736... Test loss: 0.00888\n",
      "Epoch: 1... Training loss: 0.00731... Test loss: 0.01038\n",
      "Epoch: 1... Training loss: 0.0066... Test loss: 0.00732\n",
      "Epoch: 1... Training loss: 0.00623... Test loss: 0.01059\n",
      "Epoch: 1... Training loss: 0.00627... Test loss: 0.00683\n",
      "Epoch: 1... Training loss: 0.00614... Test loss: 0.00964\n",
      "Epoch: 1... Training loss: 0.00622... Test loss: 0.00732\n",
      "Epoch: 1... Training loss: 0.00616... Test loss: 0.00755\n",
      "Epoch: 1... Training loss: 0.00534... Test loss: 0.00883\n",
      "Epoch: 1... Training loss: 0.00515... Test loss: 0.00631\n",
      "Epoch: 1... Training loss: 0.00512... Test loss: 0.00946\n",
      "Epoch: 1... Training loss: 0.00484... Test loss: 0.00538\n",
      "Epoch: 1... Training loss: 0.00481... Test loss: 0.00829\n",
      "Epoch: 1... Training loss: 0.00463... Test loss: 0.00592\n",
      "Epoch: 1... Training loss: 0.00458... Test loss: 0.00499\n",
      "Epoch: 1... Training loss: 0.00436... Test loss: 0.00496\n",
      "Epoch: 1... Training loss: 0.00404... Test loss: 0.00556\n",
      "Epoch: 1... Training loss: 0.00417... Test loss: 0.00544\n",
      "Epoch: 1... Training loss: 0.00401... Test loss: 0.00427\n",
      "Epoch: 1... Training loss: 0.00363... Test loss: 0.00491\n",
      "Epoch: 1... Training loss: 0.0036... Test loss: 0.00402\n",
      "Epoch: 1... Training loss: 0.00354... Test loss: 0.00453\n",
      "Epoch: 1... Training loss: 0.00326... Test loss: 0.00321\n",
      "Epoch: 1... Training loss: 0.00322... Test loss: 0.00391\n",
      "Epoch: 1... Training loss: 0.00312... Test loss: 0.00359\n",
      "Epoch: 1... Training loss: 0.00292... Test loss: 0.00387\n",
      "Epoch: 1... Training loss: 0.00295... Test loss: 0.00304\n",
      "Epoch: 1... Training loss: 0.0027... Test loss: 0.00476\n",
      "Epoch: 1... Training loss: 0.00282... Test loss: 0.00309\n",
      "Epoch: 1... Training loss: 0.00267... Test loss: 0.00294\n",
      "Epoch: 1... Training loss: 0.00258... Test loss: 0.00269\n",
      "Epoch: 1... Training loss: 0.00257... Test loss: 0.00303\n",
      "Epoch: 1... Training loss: 0.00247... Test loss: 0.0027\n",
      "Epoch: 1... Training loss: 0.00238... Test loss: 0.00245\n",
      "Epoch: 1... Training loss: 0.00229... Test loss: 0.0033\n",
      "Epoch: 1... Training loss: 0.00217... Test loss: 0.00223\n",
      "Epoch: 1... Training loss: 0.00215... Test loss: 0.00285\n",
      "Epoch: 1... Training loss: 0.00207... Test loss: 0.00221\n",
      "Epoch: 1... Training loss: 0.00198... Test loss: 0.00255\n",
      "Epoch: 1... Training loss: 0.00189... Test loss: 0.00193\n",
      "Epoch: 1... Training loss: 0.00182... Test loss: 0.0022\n",
      "Epoch: 1... Training loss: 0.0018... Test loss: 0.00178\n",
      "Epoch: 1... Training loss: 0.00169... Test loss: 0.0017\n",
      "Epoch: 1... Training loss: 0.00168... Test loss: 0.00196\n",
      "Epoch: 1... Training loss: 0.00162... Test loss: 0.00149\n",
      "Epoch: 1... Training loss: 0.00162... Test loss: 0.00168\n",
      "Epoch: 1... Training loss: 0.00145... Test loss: 0.00166\n",
      "Epoch: 1... Training loss: 0.00141... Test loss: 0.00172\n",
      "Epoch: 1... Training loss: 0.00134... Test loss: 0.00158\n",
      "Epoch: 1... Training loss: 0.00129... Test loss: 0.00142\n",
      "Epoch: 1... Training loss: 0.00125... Test loss: 0.00126\n",
      "Epoch: 1... Training loss: 0.0012... Test loss: 0.00141\n",
      "Epoch: 1... Training loss: 0.00116... Test loss: 0.00128\n",
      "Epoch: 1... Training loss: 0.00115... Test loss: 0.00143\n",
      "Epoch: 1... Training loss: 0.00109... Test loss: 0.00121\n",
      "Epoch: 1... Training loss: 0.00104... Test loss: 0.00148\n",
      "Epoch: 1... Training loss: 0.00102... Test loss: 0.00102\n",
      "Epoch: 1... Training loss: 0.00096... Test loss: 0.00136\n",
      "Epoch: 1... Training loss: 0.00097... Test loss: 0.00088\n",
      "Epoch: 1... Training loss: 0.00083... Test loss: 0.00123\n",
      "Epoch: 1... Training loss: 0.00083... Test loss: 0.00086\n",
      "Epoch: 1... Training loss: 0.00075... Test loss: 0.00091\n",
      "Epoch: 1... Training loss: 0.00074... Test loss: 0.00078\n",
      "Epoch: 1... Training loss: 0.00067... Test loss: 0.00085\n",
      "Epoch: 1... Training loss: 0.00067... Test loss: 0.00075\n",
      "Epoch: 1... Training loss: 0.00064... Test loss: 0.00078\n",
      "Epoch: 1... Training loss: 0.0006... Test loss: 0.00054\n",
      "Epoch: 1... Training loss: 0.00061... Test loss: 0.00081\n",
      "Epoch: 1... Training loss: 0.00057... Test loss: 0.00057\n",
      "Epoch: 1... Training loss: 0.00051... Test loss: 0.00066\n",
      "Epoch: 1... Training loss: 0.00052... Test loss: 0.00057\n",
      "Epoch: 1... Training loss: 0.00051... Test loss: 0.00051\n",
      "Epoch: 1... Training loss: 0.00046... Test loss: 0.00049\n",
      "Epoch: 1... Training loss: 0.00047... Test loss: 0.00053\n",
      "Epoch: 1... Training loss: 0.00043... Test loss: 0.00055\n",
      "Epoch: 1... Training loss: 0.00041... Test loss: 0.00043\n",
      "Epoch: 1... Training loss: 0.00037... Test loss: 0.00051\n",
      "Epoch: 1... Training loss: 0.00038... Test loss: 0.00042\n",
      "Epoch: 1... Training loss: 0.00039... Test loss: 0.00039\n",
      "Epoch: 1... Training loss: 0.00035... Test loss: 0.00039\n",
      "Epoch: 1... Training loss: 0.00036... Test loss: 0.00036\n",
      "Epoch: 1... Training loss: 0.00034... Test loss: 0.00031\n",
      "Epoch: 1... Training loss: 0.00032... Test loss: 0.00031\n",
      "Epoch: 1... Training loss: 0.00033... Test loss: 0.00033\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00028\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00024\n",
      "Epoch: 1... Training loss: 0.00026... Test loss: 0.00032\n",
      "Epoch: 1... Training loss: 0.00026... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 0.0001\n",
      "216.3991501093842\n",
      "Epoch: 1... Training loss: 0.93222... Test loss: 0.32917\n",
      "Epoch: 1... Training loss: 0.44583... Test loss: 0.13398\n",
      "Epoch: 1... Training loss: 0.24367... Test loss: 0.09001\n",
      "Epoch: 1... Training loss: 0.1681... Test loss: 0.05664\n",
      "Epoch: 1... Training loss: 0.1149... Test loss: 0.03558\n",
      "Epoch: 1... Training loss: 0.09065... Test loss: 0.03099\n",
      "Epoch: 1... Training loss: 0.07206... Test loss: 0.02931\n",
      "Epoch: 1... Training loss: 0.06492... Test loss: 0.01721\n",
      "Epoch: 1... Training loss: 0.05679... Test loss: 0.02251\n",
      "Epoch: 1... Training loss: 0.05328... Test loss: 0.01723\n",
      "Epoch: 1... Training loss: 0.04695... Test loss: 0.02457\n",
      "Epoch: 1... Training loss: 0.04545... Test loss: 0.01334\n",
      "Epoch: 1... Training loss: 0.03968... Test loss: 0.01869\n",
      "Epoch: 1... Training loss: 0.03801... Test loss: 0.00922\n",
      "Epoch: 1... Training loss: 0.03649... Test loss: 0.01492\n",
      "Epoch: 1... Training loss: 0.03329... Test loss: 0.00758\n",
      "Epoch: 1... Training loss: 0.03174... Test loss: 0.02096\n",
      "Epoch: 1... Training loss: 0.02949... Test loss: 0.00666\n",
      "Epoch: 1... Training loss: 0.02691... Test loss: 0.01714\n",
      "Epoch: 1... Training loss: 0.02524... Test loss: 0.00608\n",
      "Epoch: 1... Training loss: 0.0243... Test loss: 0.0168\n",
      "Epoch: 1... Training loss: 0.0231... Test loss: 0.01444\n",
      "Epoch: 1... Training loss: 0.02222... Test loss: 0.00652\n",
      "Epoch: 1... Training loss: 0.02182... Test loss: 0.01236\n",
      "Epoch: 1... Training loss: 0.01995... Test loss: 0.00731\n",
      "Epoch: 1... Training loss: 0.01969... Test loss: 0.01534\n",
      "Epoch: 1... Training loss: 0.01844... Test loss: 0.00608\n",
      "Epoch: 1... Training loss: 0.01806... Test loss: 0.01436\n",
      "Epoch: 1... Training loss: 0.01687... Test loss: 0.00521\n",
      "Epoch: 1... Training loss: 0.01657... Test loss: 0.01375\n",
      "Epoch: 1... Training loss: 0.01579... Test loss: 0.00591\n",
      "Epoch: 1... Training loss: 0.01554... Test loss: 0.01394\n",
      "Epoch: 1... Training loss: 0.01514... Test loss: 0.00587\n",
      "Epoch: 1... Training loss: 0.01449... Test loss: 0.01187\n",
      "Epoch: 1... Training loss: 0.01422... Test loss: 0.0078\n",
      "Epoch: 1... Training loss: 0.01359... Test loss: 0.01049\n",
      "Epoch: 1... Training loss: 0.01328... Test loss: 0.00795\n",
      "Epoch: 1... Training loss: 0.01267... Test loss: 0.01134\n",
      "Epoch: 1... Training loss: 0.01244... Test loss: 0.0061\n",
      "Epoch: 1... Training loss: 0.01203... Test loss: 0.01344\n",
      "Epoch: 1... Training loss: 0.01206... Test loss: 0.00632\n",
      "Epoch: 1... Training loss: 0.01149... Test loss: 0.01323\n",
      "Epoch: 1... Training loss: 0.01136... Test loss: 0.00679\n",
      "Epoch: 1... Training loss: 0.01096... Test loss: 0.01222\n",
      "Epoch: 1... Training loss: 0.01075... Test loss: 0.00744\n",
      "Epoch: 1... Training loss: 0.01042... Test loss: 0.0114\n",
      "Epoch: 1... Training loss: 0.01002... Test loss: 0.00737\n",
      "Epoch: 1... Training loss: 0.00977... Test loss: 0.01093\n",
      "Epoch: 1... Training loss: 0.0095... Test loss: 0.0063\n",
      "Epoch: 1... Training loss: 0.00928... Test loss: 0.0105\n",
      "Epoch: 1... Training loss: 0.00891... Test loss: 0.00607\n",
      "Epoch: 1... Training loss: 0.00876... Test loss: 0.00926\n",
      "Epoch: 1... Training loss: 0.0084... Test loss: 0.00634\n",
      "Epoch: 1... Training loss: 0.00811... Test loss: 0.008\n",
      "Epoch: 1... Training loss: 0.00783... Test loss: 0.0071\n",
      "Epoch: 1... Training loss: 0.00759... Test loss: 0.00771\n",
      "Epoch: 1... Training loss: 0.00727... Test loss: 0.00597\n",
      "Epoch: 1... Training loss: 0.00703... Test loss: 0.0069\n",
      "Epoch: 1... Training loss: 0.00671... Test loss: 0.00672\n",
      "Epoch: 1... Training loss: 0.00653... Test loss: 0.00563\n",
      "Epoch: 1... Training loss: 0.00633... Test loss: 0.00661\n",
      "Epoch: 1... Training loss: 0.00602... Test loss: 0.00622\n",
      "Epoch: 1... Training loss: 0.00595... Test loss: 0.00634\n",
      "Epoch: 1... Training loss: 0.00575... Test loss: 0.00701\n",
      "Epoch: 1... Training loss: 0.01551... Test loss: 0.01645\n",
      "Epoch: 1... Training loss: 0.01054... Test loss: 0.01588\n",
      "Epoch: 1... Training loss: 0.01282... Test loss: 0.01841\n",
      "Epoch: 1... Training loss: 0.00986... Test loss: 0.01299\n",
      "Epoch: 1... Training loss: 0.00973... Test loss: 0.01332\n",
      "Epoch: 1... Training loss: 0.0088... Test loss: 0.01523\n",
      "Epoch: 1... Training loss: 0.00903... Test loss: 0.01372\n",
      "Epoch: 1... Training loss: 0.00893... Test loss: 0.01281\n",
      "Epoch: 1... Training loss: 0.00865... Test loss: 0.01237\n",
      "Epoch: 1... Training loss: 0.00783... Test loss: 0.0091\n",
      "Epoch: 1... Training loss: 0.00851... Test loss: 0.01058\n",
      "Epoch: 1... Training loss: 0.00792... Test loss: 0.01084\n",
      "Epoch: 1... Training loss: 0.00699... Test loss: 0.01004\n",
      "Epoch: 1... Training loss: 0.00651... Test loss: 0.01067\n",
      "Epoch: 1... Training loss: 0.00678... Test loss: 0.00908\n",
      "Epoch: 1... Training loss: 0.00627... Test loss: 0.00866\n",
      "Epoch: 1... Training loss: 0.00617... Test loss: 0.00938\n",
      "Epoch: 1... Training loss: 0.00586... Test loss: 0.00778\n",
      "Epoch: 1... Training loss: 0.0055... Test loss: 0.00878\n",
      "Epoch: 1... Training loss: 0.00537... Test loss: 0.00635\n",
      "Epoch: 1... Training loss: 0.00522... Test loss: 0.00751\n",
      "Epoch: 1... Training loss: 0.00488... Test loss: 0.00686\n",
      "Epoch: 1... Training loss: 0.00489... Test loss: 0.00656\n",
      "Epoch: 1... Training loss: 0.00478... Test loss: 0.00778\n",
      "Epoch: 1... Training loss: 0.00455... Test loss: 0.00639\n",
      "Epoch: 1... Training loss: 0.00415... Test loss: 0.00773\n",
      "Epoch: 1... Training loss: 0.00398... Test loss: 0.00589\n",
      "Epoch: 1... Training loss: 0.00414... Test loss: 0.00481\n",
      "Epoch: 1... Training loss: 0.00407... Test loss: 0.00582\n",
      "Epoch: 1... Training loss: 0.00376... Test loss: 0.00377\n",
      "Epoch: 1... Training loss: 0.00372... Test loss: 0.00528\n",
      "Epoch: 1... Training loss: 0.00347... Test loss: 0.00371\n",
      "Epoch: 1... Training loss: 0.00357... Test loss: 0.00521\n",
      "Epoch: 1... Training loss: 0.00332... Test loss: 0.00353\n",
      "Epoch: 1... Training loss: 0.00315... Test loss: 0.00457\n",
      "Epoch: 1... Training loss: 0.00296... Test loss: 0.00342\n",
      "Epoch: 1... Training loss: 0.00293... Test loss: 0.00501\n",
      "Epoch: 1... Training loss: 0.00284... Test loss: 0.00307\n",
      "Epoch: 1... Training loss: 0.00282... Test loss: 0.00475\n",
      "Epoch: 1... Training loss: 0.00273... Test loss: 0.00263\n",
      "Epoch: 1... Training loss: 0.00264... Test loss: 0.00459\n",
      "Epoch: 1... Training loss: 0.00256... Test loss: 0.00318\n",
      "Epoch: 1... Training loss: 0.00245... Test loss: 0.00333\n",
      "Epoch: 1... Training loss: 0.0023... Test loss: 0.00309\n",
      "Epoch: 1... Training loss: 0.00229... Test loss: 0.00273\n",
      "Epoch: 1... Training loss: 0.00219... Test loss: 0.0028\n",
      "Epoch: 1... Training loss: 0.00215... Test loss: 0.00227\n",
      "Epoch: 1... Training loss: 0.00204... Test loss: 0.00281\n",
      "Epoch: 1... Training loss: 0.00198... Test loss: 0.00254\n",
      "Epoch: 1... Training loss: 0.00205... Test loss: 0.00258\n",
      "Epoch: 1... Training loss: 0.00192... Test loss: 0.00205\n",
      "Epoch: 1... Training loss: 0.00178... Test loss: 0.00231\n",
      "Epoch: 1... Training loss: 0.00168... Test loss: 0.00192\n",
      "Epoch: 1... Training loss: 0.00174... Test loss: 0.00175\n",
      "Epoch: 1... Training loss: 0.00153... Test loss: 0.00185\n",
      "Epoch: 1... Training loss: 0.00152... Test loss: 0.00156\n",
      "Epoch: 1... Training loss: 0.0015... Test loss: 0.00162\n",
      "Epoch: 1... Training loss: 0.0014... Test loss: 0.00138\n",
      "Epoch: 1... Training loss: 0.00133... Test loss: 0.00112\n",
      "Epoch: 1... Training loss: 0.00138... Test loss: 0.00143\n",
      "Epoch: 1... Training loss: 0.00122... Test loss: 0.00142\n",
      "Epoch: 1... Training loss: 0.00116... Test loss: 0.00168\n",
      "Epoch: 1... Training loss: 0.0011... Test loss: 0.00177\n",
      "Epoch: 1... Training loss: 0.00111... Test loss: 0.0013\n",
      "Epoch: 1... Training loss: 0.001... Test loss: 0.00157\n",
      "Epoch: 1... Training loss: 0.00101... Test loss: 0.00101\n",
      "Epoch: 1... Training loss: 0.00089... Test loss: 0.00133\n",
      "Epoch: 1... Training loss: 0.0009... Test loss: 0.00094\n",
      "Epoch: 1... Training loss: 0.00084... Test loss: 0.00118\n",
      "Epoch: 1... Training loss: 0.00079... Test loss: 0.00088\n",
      "Epoch: 1... Training loss: 0.00077... Test loss: 0.00088\n",
      "Epoch: 1... Training loss: 0.00074... Test loss: 0.00082\n",
      "Epoch: 1... Training loss: 0.00071... Test loss: 0.00068\n",
      "Epoch: 1... Training loss: 0.00067... Test loss: 0.00086\n",
      "Epoch: 1... Training loss: 0.00064... Test loss: 0.0006\n",
      "Epoch: 1... Training loss: 0.00062... Test loss: 0.00078\n",
      "Epoch: 1... Training loss: 0.00053... Test loss: 0.00051\n",
      "Epoch: 1... Training loss: 0.00051... Test loss: 0.00074\n",
      "Epoch: 1... Training loss: 0.00046... Test loss: 0.00041\n",
      "Epoch: 1... Training loss: 0.00046... Test loss: 0.00078\n",
      "Epoch: 1... Training loss: 0.0004... Test loss: 0.00045\n",
      "Epoch: 1... Training loss: 0.00042... Test loss: 0.00068\n",
      "Epoch: 1... Training loss: 0.00038... Test loss: 0.0005\n",
      "Epoch: 1... Training loss: 0.00037... Test loss: 0.00045\n",
      "Epoch: 1... Training loss: 0.00035... Test loss: 0.00038\n",
      "Epoch: 1... Training loss: 0.00031... Test loss: 0.00034\n",
      "Epoch: 1... Training loss: 0.00032... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.00032\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.00035\n",
      "Epoch: 1... Training loss: 0.00029... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00032\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00024\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 7e-05\n",
      "Epoch: 1... Training loss: 8e-05... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 7e-05\n",
      "Epoch: 1... Training loss: 8e-05... Test loss: 8e-05\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 8e-05\n",
      "Epoch: 1... Training loss: 8e-05... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 8e-05... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 8e-05... Test loss: 7e-05\n",
      "Epoch: 1... Training loss: 8e-05... Test loss: 8e-05\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 7e-05\n",
      "Epoch: 1... Training loss: 6e-05... Test loss: 9e-05\n",
      "227.06699235236738\n",
      "Epoch: 1... Training loss: 1.10212... Test loss: 0.42821\n",
      "Epoch: 1... Training loss: 0.52784... Test loss: 0.16227\n",
      "Epoch: 1... Training loss: 0.32514... Test loss: 0.10643\n",
      "Epoch: 1... Training loss: 0.2357... Test loss: 0.07742\n",
      "Epoch: 1... Training loss: 0.17341... Test loss: 0.06998\n",
      "Epoch: 1... Training loss: 0.14054... Test loss: 0.05733\n",
      "Epoch: 1... Training loss: 0.10912... Test loss: 0.0291\n",
      "Epoch: 1... Training loss: 0.08845... Test loss: 0.05157\n",
      "Epoch: 1... Training loss: 0.07883... Test loss: 0.0251\n",
      "Epoch: 1... Training loss: 0.06888... Test loss: 0.05337\n",
      "Epoch: 1... Training loss: 0.06053... Test loss: 0.02233\n",
      "Epoch: 1... Training loss: 0.05426... Test loss: 0.04391\n",
      "Epoch: 1... Training loss: 0.04844... Test loss: 0.05175\n",
      "Epoch: 1... Training loss: 0.0443... Test loss: 0.02266\n",
      "Epoch: 1... Training loss: 0.04097... Test loss: 0.04462\n",
      "Epoch: 1... Training loss: 0.03841... Test loss: 0.0203\n",
      "Epoch: 1... Training loss: 0.03595... Test loss: 0.03872\n",
      "Epoch: 1... Training loss: 0.03415... Test loss: 0.01877\n",
      "Epoch: 1... Training loss: 0.03066... Test loss: 0.03737\n",
      "Epoch: 1... Training loss: 0.02915... Test loss: 0.02268\n",
      "Epoch: 1... Training loss: 0.02716... Test loss: 0.03459\n",
      "Epoch: 1... Training loss: 0.02619... Test loss: 0.01852\n",
      "Epoch: 1... Training loss: 0.02439... Test loss: 0.03526\n",
      "Epoch: 1... Training loss: 0.02405... Test loss: 0.02167\n",
      "Epoch: 1... Training loss: 0.02139... Test loss: 0.02058\n",
      "Epoch: 1... Training loss: 0.02071... Test loss: 0.02593\n",
      "Epoch: 1... Training loss: 0.01987... Test loss: 0.02338\n",
      "Epoch: 1... Training loss: 0.01919... Test loss: 0.02047\n",
      "Epoch: 1... Training loss: 0.01823... Test loss: 0.01951\n",
      "Epoch: 1... Training loss: 0.01744... Test loss: 0.02351\n",
      "Epoch: 1... Training loss: 0.01649... Test loss: 0.01552\n",
      "Epoch: 1... Training loss: 0.01573... Test loss: 0.01648\n",
      "Epoch: 1... Training loss: 0.01544... Test loss: 0.01305\n",
      "Epoch: 1... Training loss: 0.0145... Test loss: 0.01218\n",
      "Epoch: 1... Training loss: 0.0136... Test loss: 0.01566\n",
      "Epoch: 1... Training loss: 0.01284... Test loss: 0.01131\n",
      "Epoch: 1... Training loss: 0.01241... Test loss: 0.01492\n",
      "Epoch: 1... Training loss: 0.01195... Test loss: 0.01065\n",
      "Epoch: 1... Training loss: 0.01197... Test loss: 0.01366\n",
      "Epoch: 1... Training loss: 0.01142... Test loss: 0.01179\n",
      "Epoch: 1... Training loss: 0.011... Test loss: 0.01079\n",
      "Epoch: 1... Training loss: 0.01068... Test loss: 0.01123\n",
      "Epoch: 1... Training loss: 0.01002... Test loss: 0.00916\n",
      "Epoch: 1... Training loss: 0.00986... Test loss: 0.01062\n",
      "Epoch: 1... Training loss: 0.00922... Test loss: 0.00714\n",
      "Epoch: 1... Training loss: 0.00913... Test loss: 0.01086\n",
      "Epoch: 1... Training loss: 0.00892... Test loss: 0.00699\n",
      "Epoch: 1... Training loss: 0.00863... Test loss: 0.01003\n",
      "Epoch: 1... Training loss: 0.00829... Test loss: 0.00953\n",
      "Epoch: 1... Training loss: 0.00806... Test loss: 0.00744\n",
      "Epoch: 1... Training loss: 0.00767... Test loss: 0.00994\n",
      "Epoch: 1... Training loss: 0.00754... Test loss: 0.00611\n",
      "Epoch: 1... Training loss: 0.00724... Test loss: 0.01013\n",
      "Epoch: 1... Training loss: 0.00706... Test loss: 0.0058\n",
      "Epoch: 1... Training loss: 0.00682... Test loss: 0.00787\n",
      "Epoch: 1... Training loss: 0.00676... Test loss: 0.00619\n",
      "Epoch: 1... Training loss: 0.00648... Test loss: 0.00805\n",
      "Epoch: 1... Training loss: 0.00637... Test loss: 0.00644\n",
      "Epoch: 1... Training loss: 0.00605... Test loss: 0.00683\n",
      "Epoch: 1... Training loss: 0.00597... Test loss: 0.00732\n",
      "Epoch: 1... Training loss: 0.00586... Test loss: 0.00522\n",
      "Epoch: 1... Training loss: 0.00567... Test loss: 0.00712\n",
      "Epoch: 1... Training loss: 0.00543... Test loss: 0.00509\n",
      "Epoch: 1... Training loss: 0.00538... Test loss: 0.006\n",
      "Epoch: 1... Training loss: 0.01566... Test loss: 0.02437\n",
      "Epoch: 1... Training loss: 0.00903... Test loss: 0.01777\n",
      "Epoch: 1... Training loss: 0.01029... Test loss: 0.01902\n",
      "Epoch: 1... Training loss: 0.01082... Test loss: 0.01708\n",
      "Epoch: 1... Training loss: 0.00808... Test loss: 0.01371\n",
      "Epoch: 1... Training loss: 0.01013... Test loss: 0.01525\n",
      "Epoch: 1... Training loss: 0.00814... Test loss: 0.01406\n",
      "Epoch: 1... Training loss: 0.00899... Test loss: 0.01244\n",
      "Epoch: 1... Training loss: 0.00774... Test loss: 0.01557\n",
      "Epoch: 1... Training loss: 0.0077... Test loss: 0.0104\n",
      "Epoch: 1... Training loss: 0.0078... Test loss: 0.01353\n",
      "Epoch: 1... Training loss: 0.0074... Test loss: 0.01048\n",
      "Epoch: 1... Training loss: 0.00734... Test loss: 0.00948\n",
      "Epoch: 1... Training loss: 0.00616... Test loss: 0.00986\n",
      "Epoch: 1... Training loss: 0.00574... Test loss: 0.00721\n",
      "Epoch: 1... Training loss: 0.006... Test loss: 0.0073\n",
      "Epoch: 1... Training loss: 0.0058... Test loss: 0.00959\n",
      "Epoch: 1... Training loss: 0.00585... Test loss: 0.00745\n",
      "Epoch: 1... Training loss: 0.00525... Test loss: 0.00984\n",
      "Epoch: 1... Training loss: 0.00549... Test loss: 0.00777\n",
      "Epoch: 1... Training loss: 0.00567... Test loss: 0.00729\n",
      "Epoch: 1... Training loss: 0.00475... Test loss: 0.00561\n",
      "Epoch: 1... Training loss: 0.00447... Test loss: 0.00548\n",
      "Epoch: 1... Training loss: 0.00487... Test loss: 0.0058\n",
      "Epoch: 1... Training loss: 0.00486... Test loss: 0.00572\n",
      "Epoch: 1... Training loss: 0.00424... Test loss: 0.00564\n",
      "Epoch: 1... Training loss: 0.00432... Test loss: 0.00447\n",
      "Epoch: 1... Training loss: 0.00415... Test loss: 0.00474\n",
      "Epoch: 1... Training loss: 0.00412... Test loss: 0.00394\n",
      "Epoch: 1... Training loss: 0.00365... Test loss: 0.00475\n",
      "Epoch: 1... Training loss: 0.00363... Test loss: 0.00392\n",
      "Epoch: 1... Training loss: 0.00333... Test loss: 0.00454\n",
      "Epoch: 1... Training loss: 0.00333... Test loss: 0.00417\n",
      "Epoch: 1... Training loss: 0.0032... Test loss: 0.00352\n",
      "Epoch: 1... Training loss: 0.00295... Test loss: 0.00381\n",
      "Epoch: 1... Training loss: 0.00293... Test loss: 0.00445\n",
      "Epoch: 1... Training loss: 0.00286... Test loss: 0.00356\n",
      "Epoch: 1... Training loss: 0.00278... Test loss: 0.0035\n",
      "Epoch: 1... Training loss: 0.00267... Test loss: 0.0034\n",
      "Epoch: 1... Training loss: 0.00261... Test loss: 0.00395\n",
      "Epoch: 1... Training loss: 0.00248... Test loss: 0.00268\n",
      "Epoch: 1... Training loss: 0.00246... Test loss: 0.00332\n",
      "Epoch: 1... Training loss: 0.00232... Test loss: 0.00228\n",
      "Epoch: 1... Training loss: 0.00226... Test loss: 0.00327\n",
      "Epoch: 1... Training loss: 0.00218... Test loss: 0.00239\n",
      "Epoch: 1... Training loss: 0.0022... Test loss: 0.00286\n",
      "Epoch: 1... Training loss: 0.00202... Test loss: 0.0023\n",
      "Epoch: 1... Training loss: 0.00202... Test loss: 0.00259\n",
      "Epoch: 1... Training loss: 0.00183... Test loss: 0.00225\n",
      "Epoch: 1... Training loss: 0.00183... Test loss: 0.00201\n",
      "Epoch: 1... Training loss: 0.00176... Test loss: 0.00216\n",
      "Epoch: 1... Training loss: 0.00164... Test loss: 0.00194\n",
      "Epoch: 1... Training loss: 0.0016... Test loss: 0.00176\n",
      "Epoch: 1... Training loss: 0.00161... Test loss: 0.00175\n",
      "Epoch: 1... Training loss: 0.00144... Test loss: 0.00183\n",
      "Epoch: 1... Training loss: 0.0015... Test loss: 0.00134\n",
      "Epoch: 1... Training loss: 0.00137... Test loss: 0.00166\n",
      "Epoch: 1... Training loss: 0.00132... Test loss: 0.00128\n",
      "Epoch: 1... Training loss: 0.00129... Test loss: 0.0017\n",
      "Epoch: 1... Training loss: 0.00125... Test loss: 0.00123\n",
      "Epoch: 1... Training loss: 0.00125... Test loss: 0.00153\n",
      "Epoch: 1... Training loss: 0.00121... Test loss: 0.00114\n",
      "Epoch: 1... Training loss: 0.00107... Test loss: 0.00176\n",
      "Epoch: 1... Training loss: 0.0011... Test loss: 0.00122\n",
      "Epoch: 1... Training loss: 0.00111... Test loss: 0.0013\n",
      "Epoch: 1... Training loss: 0.00096... Test loss: 0.00107\n",
      "Epoch: 1... Training loss: 0.00103... Test loss: 0.00122\n",
      "Epoch: 1... Training loss: 0.00093... Test loss: 0.00102\n",
      "Epoch: 1... Training loss: 0.00092... Test loss: 0.00125\n",
      "Epoch: 1... Training loss: 0.00085... Test loss: 0.00096\n",
      "Epoch: 1... Training loss: 0.00079... Test loss: 0.00105\n",
      "Epoch: 1... Training loss: 0.00079... Test loss: 0.0008\n",
      "Epoch: 1... Training loss: 0.00074... Test loss: 0.00076\n",
      "Epoch: 1... Training loss: 0.0007... Test loss: 0.00078\n",
      "Epoch: 1... Training loss: 0.00066... Test loss: 0.00082\n",
      "Epoch: 1... Training loss: 0.00063... Test loss: 0.00083\n",
      "Epoch: 1... Training loss: 0.00063... Test loss: 0.00079\n",
      "Epoch: 1... Training loss: 0.00056... Test loss: 0.00076\n",
      "Epoch: 1... Training loss: 0.00057... Test loss: 0.00081\n",
      "Epoch: 1... Training loss: 0.00059... Test loss: 0.00059\n",
      "Epoch: 1... Training loss: 0.00051... Test loss: 0.00066\n",
      "Epoch: 1... Training loss: 0.00048... Test loss: 0.0005\n",
      "Epoch: 1... Training loss: 0.00046... Test loss: 0.00052\n",
      "Epoch: 1... Training loss: 0.00048... Test loss: 0.00049\n",
      "Epoch: 1... Training loss: 0.00046... Test loss: 0.00042\n",
      "Epoch: 1... Training loss: 0.0004... Test loss: 0.00043\n",
      "Epoch: 1... Training loss: 0.00042... Test loss: 0.00046\n",
      "Epoch: 1... Training loss: 0.0004... Test loss: 0.00044\n",
      "Epoch: 1... Training loss: 0.00039... Test loss: 0.00033\n",
      "Epoch: 1... Training loss: 0.00035... Test loss: 0.00042\n",
      "Epoch: 1... Training loss: 0.00036... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00035... Test loss: 0.00038\n",
      "Epoch: 1... Training loss: 0.00029... Test loss: 0.00032\n",
      "Epoch: 1... Training loss: 0.00035... Test loss: 0.00038\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00028\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.0004\n",
      "Epoch: 1... Training loss: 0.00026... Test loss: 0.00028\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00033\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00028\n",
      "Epoch: 1... Training loss: 0.00026... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00028\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 8e-05\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 8e-05... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 9e-05\n",
      "234.23141750803916\n",
      "Epoch: 1... Training loss: 1.2745... Test loss: 0.59154\n",
      "Epoch: 1... Training loss: 0.54143... Test loss: 0.20636\n",
      "Epoch: 1... Training loss: 0.28768... Test loss: 0.12588\n",
      "Epoch: 1... Training loss: 0.18899... Test loss: 0.07621\n",
      "Epoch: 1... Training loss: 0.15984... Test loss: 0.04944\n",
      "Epoch: 1... Training loss: 0.11566... Test loss: 0.07132\n",
      "Epoch: 1... Training loss: 0.09454... Test loss: 0.04501\n",
      "Epoch: 1... Training loss: 0.07637... Test loss: 0.0478\n",
      "Epoch: 1... Training loss: 0.06902... Test loss: 0.04722\n",
      "Epoch: 1... Training loss: 0.05876... Test loss: 0.05477\n",
      "Epoch: 1... Training loss: 0.05316... Test loss: 0.0584\n",
      "Epoch: 1... Training loss: 0.04847... Test loss: 0.0377\n",
      "Epoch: 1... Training loss: 0.04447... Test loss: 0.08548\n",
      "Epoch: 1... Training loss: 0.04634... Test loss: 0.02704\n",
      "Epoch: 1... Training loss: 0.04105... Test loss: 0.05187\n",
      "Epoch: 1... Training loss: 0.03846... Test loss: 0.01581\n",
      "Epoch: 1... Training loss: 0.03568... Test loss: 0.04654\n",
      "Epoch: 1... Training loss: 0.03338... Test loss: 0.02852\n",
      "Epoch: 1... Training loss: 0.03148... Test loss: 0.0403\n",
      "Epoch: 1... Training loss: 0.02975... Test loss: 0.02629\n",
      "Epoch: 1... Training loss: 0.02713... Test loss: 0.05002\n",
      "Epoch: 1... Training loss: 0.02629... Test loss: 0.0168\n",
      "Epoch: 1... Training loss: 0.02494... Test loss: 0.03622\n",
      "Epoch: 1... Training loss: 0.02287... Test loss: 0.02195\n",
      "Epoch: 1... Training loss: 0.02098... Test loss: 0.03467\n",
      "Epoch: 1... Training loss: 0.02025... Test loss: 0.01278\n",
      "Epoch: 1... Training loss: 0.01855... Test loss: 0.03041\n",
      "Epoch: 1... Training loss: 0.01846... Test loss: 0.01062\n",
      "Epoch: 1... Training loss: 0.01739... Test loss: 0.02452\n",
      "Epoch: 1... Training loss: 0.01724... Test loss: 0.01006\n",
      "Epoch: 1... Training loss: 0.01611... Test loss: 0.02233\n",
      "Epoch: 1... Training loss: 0.0159... Test loss: 0.00902\n",
      "Epoch: 1... Training loss: 0.01529... Test loss: 0.01514\n",
      "Epoch: 1... Training loss: 0.0148... Test loss: 0.01659\n",
      "Epoch: 1... Training loss: 0.01399... Test loss: 0.01568\n",
      "Epoch: 1... Training loss: 0.0134... Test loss: 0.01304\n",
      "Epoch: 1... Training loss: 0.01313... Test loss: 0.01275\n",
      "Epoch: 1... Training loss: 0.01255... Test loss: 0.016\n",
      "Epoch: 1... Training loss: 0.01213... Test loss: 0.00775\n",
      "Epoch: 1... Training loss: 0.01181... Test loss: 0.01594\n",
      "Epoch: 1... Training loss: 0.01138... Test loss: 0.00615\n",
      "Epoch: 1... Training loss: 0.01117... Test loss: 0.01214\n",
      "Epoch: 1... Training loss: 0.01089... Test loss: 0.00804\n",
      "Epoch: 1... Training loss: 0.01031... Test loss: 0.01103\n",
      "Epoch: 1... Training loss: 0.01004... Test loss: 0.00827\n",
      "Epoch: 1... Training loss: 0.00962... Test loss: 0.01145\n",
      "Epoch: 1... Training loss: 0.00919... Test loss: 0.01081\n",
      "Epoch: 1... Training loss: 0.00889... Test loss: 0.00792\n",
      "Epoch: 1... Training loss: 0.0085... Test loss: 0.01108\n",
      "Epoch: 1... Training loss: 0.00821... Test loss: 0.00716\n",
      "Epoch: 1... Training loss: 0.00801... Test loss: 0.00918\n",
      "Epoch: 1... Training loss: 0.00765... Test loss: 0.0053\n",
      "Epoch: 1... Training loss: 0.00745... Test loss: 0.00869\n",
      "Epoch: 1... Training loss: 0.0072... Test loss: 0.00642\n",
      "Epoch: 1... Training loss: 0.00698... Test loss: 0.00868\n",
      "Epoch: 1... Training loss: 0.0067... Test loss: 0.00559\n",
      "Epoch: 1... Training loss: 0.00657... Test loss: 0.00779\n",
      "Epoch: 1... Training loss: 0.00626... Test loss: 0.00604\n",
      "Epoch: 1... Training loss: 0.00607... Test loss: 0.00761\n",
      "Epoch: 1... Training loss: 0.00579... Test loss: 0.00598\n",
      "Epoch: 1... Training loss: 0.00568... Test loss: 0.00694\n",
      "Epoch: 1... Training loss: 0.00552... Test loss: 0.00563\n",
      "Epoch: 1... Training loss: 0.0055... Test loss: 0.00656\n",
      "Epoch: 1... Training loss: 0.00531... Test loss: 0.0047\n",
      "Epoch: 1... Training loss: 0.0126... Test loss: 0.0121\n",
      "Epoch: 1... Training loss: 0.01033... Test loss: 0.01279\n",
      "Epoch: 1... Training loss: 0.01005... Test loss: 0.02058\n",
      "Epoch: 1... Training loss: 0.01202... Test loss: 0.01403\n",
      "Epoch: 1... Training loss: 0.00847... Test loss: 0.01282\n",
      "Epoch: 1... Training loss: 0.00986... Test loss: 0.01445\n",
      "Epoch: 1... Training loss: 0.00788... Test loss: 0.00962\n",
      "Epoch: 1... Training loss: 0.00913... Test loss: 0.0126\n",
      "Epoch: 1... Training loss: 0.00874... Test loss: 0.00849\n",
      "Epoch: 1... Training loss: 0.00741... Test loss: 0.01225\n",
      "Epoch: 1... Training loss: 0.00751... Test loss: 0.00876\n",
      "Epoch: 1... Training loss: 0.00759... Test loss: 0.00957\n",
      "Epoch: 1... Training loss: 0.00732... Test loss: 0.00819\n",
      "Epoch: 1... Training loss: 0.00738... Test loss: 0.00912\n",
      "Epoch: 1... Training loss: 0.00675... Test loss: 0.00943\n",
      "Epoch: 1... Training loss: 0.00652... Test loss: 0.00958\n",
      "Epoch: 1... Training loss: 0.00633... Test loss: 0.00793\n",
      "Epoch: 1... Training loss: 0.00573... Test loss: 0.00739\n",
      "Epoch: 1... Training loss: 0.00561... Test loss: 0.00793\n",
      "Epoch: 1... Training loss: 0.00534... Test loss: 0.00664\n",
      "Epoch: 1... Training loss: 0.00553... Test loss: 0.00644\n",
      "Epoch: 1... Training loss: 0.00505... Test loss: 0.00592\n",
      "Epoch: 1... Training loss: 0.00492... Test loss: 0.00669\n",
      "Epoch: 1... Training loss: 0.00481... Test loss: 0.00487\n",
      "Epoch: 1... Training loss: 0.00469... Test loss: 0.00641\n",
      "Epoch: 1... Training loss: 0.00431... Test loss: 0.00506\n",
      "Epoch: 1... Training loss: 0.00427... Test loss: 0.00506\n",
      "Epoch: 1... Training loss: 0.00407... Test loss: 0.0047\n",
      "Epoch: 1... Training loss: 0.00388... Test loss: 0.00524\n",
      "Epoch: 1... Training loss: 0.00378... Test loss: 0.00433\n",
      "Epoch: 1... Training loss: 0.00361... Test loss: 0.00466\n",
      "Epoch: 1... Training loss: 0.00361... Test loss: 0.00389\n",
      "Epoch: 1... Training loss: 0.00349... Test loss: 0.00455\n",
      "Epoch: 1... Training loss: 0.00356... Test loss: 0.00409\n",
      "Epoch: 1... Training loss: 0.0033... Test loss: 0.00356\n",
      "Epoch: 1... Training loss: 0.00313... Test loss: 0.00367\n",
      "Epoch: 1... Training loss: 0.00298... Test loss: 0.00385\n",
      "Epoch: 1... Training loss: 0.00314... Test loss: 0.00357\n",
      "Epoch: 1... Training loss: 0.00286... Test loss: 0.00363\n",
      "Epoch: 1... Training loss: 0.00276... Test loss: 0.0032\n",
      "Epoch: 1... Training loss: 0.00259... Test loss: 0.00298\n",
      "Epoch: 1... Training loss: 0.0026... Test loss: 0.00322\n",
      "Epoch: 1... Training loss: 0.00248... Test loss: 0.00285\n",
      "Epoch: 1... Training loss: 0.00246... Test loss: 0.00345\n",
      "Epoch: 1... Training loss: 0.00226... Test loss: 0.0027\n",
      "Epoch: 1... Training loss: 0.00231... Test loss: 0.00324\n",
      "Epoch: 1... Training loss: 0.00218... Test loss: 0.00256\n",
      "Epoch: 1... Training loss: 0.00205... Test loss: 0.00296\n",
      "Epoch: 1... Training loss: 0.00191... Test loss: 0.00246\n",
      "Epoch: 1... Training loss: 0.00191... Test loss: 0.00299\n",
      "Epoch: 1... Training loss: 0.00177... Test loss: 0.00235\n",
      "Epoch: 1... Training loss: 0.00172... Test loss: 0.00259\n",
      "Epoch: 1... Training loss: 0.0017... Test loss: 0.00195\n",
      "Epoch: 1... Training loss: 0.00165... Test loss: 0.00236\n",
      "Epoch: 1... Training loss: 0.00148... Test loss: 0.00187\n",
      "Epoch: 1... Training loss: 0.00145... Test loss: 0.00174\n",
      "Epoch: 1... Training loss: 0.00141... Test loss: 0.00183\n",
      "Epoch: 1... Training loss: 0.00133... Test loss: 0.00148\n",
      "Epoch: 1... Training loss: 0.00131... Test loss: 0.00138\n",
      "Epoch: 1... Training loss: 0.00128... Test loss: 0.00147\n",
      "Epoch: 1... Training loss: 0.00129... Test loss: 0.00106\n",
      "Epoch: 1... Training loss: 0.00118... Test loss: 0.00164\n",
      "Epoch: 1... Training loss: 0.00114... Test loss: 0.00102\n",
      "Epoch: 1... Training loss: 0.00108... Test loss: 0.00143\n",
      "Epoch: 1... Training loss: 0.00105... Test loss: 0.00103\n",
      "Epoch: 1... Training loss: 0.001... Test loss: 0.00108\n",
      "Epoch: 1... Training loss: 0.00096... Test loss: 0.00096\n",
      "Epoch: 1... Training loss: 0.00093... Test loss: 0.00122\n",
      "Epoch: 1... Training loss: 0.00088... Test loss: 0.00088\n",
      "Epoch: 1... Training loss: 0.00085... Test loss: 0.0009\n",
      "Epoch: 1... Training loss: 0.00083... Test loss: 0.00084\n",
      "Epoch: 1... Training loss: 0.00078... Test loss: 0.00103\n",
      "Epoch: 1... Training loss: 0.0008... Test loss: 0.00075\n",
      "Epoch: 1... Training loss: 0.00071... Test loss: 0.00094\n",
      "Epoch: 1... Training loss: 0.00073... Test loss: 0.00086\n",
      "Epoch: 1... Training loss: 0.00066... Test loss: 0.00064\n",
      "Epoch: 1... Training loss: 0.00065... Test loss: 0.0007\n",
      "Epoch: 1... Training loss: 0.0006... Test loss: 0.00067\n",
      "Epoch: 1... Training loss: 0.00058... Test loss: 0.00073\n",
      "Epoch: 1... Training loss: 0.00055... Test loss: 0.00058\n",
      "Epoch: 1... Training loss: 0.00049... Test loss: 0.00059\n",
      "Epoch: 1... Training loss: 0.00053... Test loss: 0.00045\n",
      "Epoch: 1... Training loss: 0.0005... Test loss: 0.00063\n",
      "Epoch: 1... Training loss: 0.0005... Test loss: 0.00046\n",
      "Epoch: 1... Training loss: 0.00048... Test loss: 0.00058\n",
      "Epoch: 1... Training loss: 0.00055... Test loss: 0.00041\n",
      "Epoch: 1... Training loss: 0.00044... Test loss: 0.00055\n",
      "Epoch: 1... Training loss: 0.0004... Test loss: 0.00047\n",
      "Epoch: 1... Training loss: 0.00042... Test loss: 0.00044\n",
      "Epoch: 1... Training loss: 0.00039... Test loss: 0.00038\n",
      "Epoch: 1... Training loss: 0.0004... Test loss: 0.00035\n",
      "Epoch: 1... Training loss: 0.00038... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.00038... Test loss: 0.00037\n",
      "Epoch: 1... Training loss: 0.00034... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00037... Test loss: 0.00034\n",
      "Epoch: 1... Training loss: 0.00034... Test loss: 0.0003\n",
      "Epoch: 1... Training loss: 0.00036... Test loss: 0.00031\n",
      "Epoch: 1... Training loss: 0.00034... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.00031... Test loss: 0.00034\n",
      "Epoch: 1... Training loss: 0.00032... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.00032... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00038\n",
      "Epoch: 1... Training loss: 0.00026... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00036\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00038\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 8e-05\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 7e-05\n",
      "199.83487549130223\n",
      "Epoch: 1... Training loss: 1.09987... Test loss: 0.52524\n",
      "Epoch: 1... Training loss: 0.46645... Test loss: 0.16935\n",
      "Epoch: 1... Training loss: 0.29744... Test loss: 0.08861\n",
      "Epoch: 1... Training loss: 0.21969... Test loss: 0.0805\n",
      "Epoch: 1... Training loss: 0.1534... Test loss: 0.08612\n",
      "Epoch: 1... Training loss: 0.11771... Test loss: 0.04619\n",
      "Epoch: 1... Training loss: 0.10181... Test loss: 0.06937\n",
      "Epoch: 1... Training loss: 0.08846... Test loss: 0.03219\n",
      "Epoch: 1... Training loss: 0.07489... Test loss: 0.05697\n",
      "Epoch: 1... Training loss: 0.0658... Test loss: 0.02422\n",
      "Epoch: 1... Training loss: 0.06076... Test loss: 0.04698\n",
      "Epoch: 1... Training loss: 0.05028... Test loss: 0.02793\n",
      "Epoch: 1... Training loss: 0.04616... Test loss: 0.04433\n",
      "Epoch: 1... Training loss: 0.04343... Test loss: 0.01656\n",
      "Epoch: 1... Training loss: 0.03984... Test loss: 0.03581\n",
      "Epoch: 1... Training loss: 0.03649... Test loss: 0.01343\n",
      "Epoch: 1... Training loss: 0.03523... Test loss: 0.03257\n",
      "Epoch: 1... Training loss: 0.03369... Test loss: 0.01533\n",
      "Epoch: 1... Training loss: 0.03075... Test loss: 0.03178\n",
      "Epoch: 1... Training loss: 0.02815... Test loss: 0.01373\n",
      "Epoch: 1... Training loss: 0.0266... Test loss: 0.02517\n",
      "Epoch: 1... Training loss: 0.0253... Test loss: 0.01574\n",
      "Epoch: 1... Training loss: 0.02381... Test loss: 0.02632\n",
      "Epoch: 1... Training loss: 0.02269... Test loss: 0.01261\n",
      "Epoch: 1... Training loss: 0.02181... Test loss: 0.02137\n",
      "Epoch: 1... Training loss: 0.0204... Test loss: 0.01163\n",
      "Epoch: 1... Training loss: 0.01854... Test loss: 0.02119\n",
      "Epoch: 1... Training loss: 0.01786... Test loss: 0.00992\n",
      "Epoch: 1... Training loss: 0.01697... Test loss: 0.01865\n",
      "Epoch: 1... Training loss: 0.01649... Test loss: 0.00893\n",
      "Epoch: 1... Training loss: 0.01572... Test loss: 0.0185\n",
      "Epoch: 1... Training loss: 0.01535... Test loss: 0.00854\n",
      "Epoch: 1... Training loss: 0.01473... Test loss: 0.01709\n",
      "Epoch: 1... Training loss: 0.01411... Test loss: 0.0079\n",
      "Epoch: 1... Training loss: 0.01337... Test loss: 0.01556\n",
      "Epoch: 1... Training loss: 0.01265... Test loss: 0.00732\n",
      "Epoch: 1... Training loss: 0.01263... Test loss: 0.0141\n",
      "Epoch: 1... Training loss: 0.01171... Test loss: 0.00874\n",
      "Epoch: 1... Training loss: 0.01162... Test loss: 0.01183\n",
      "Epoch: 1... Training loss: 0.01082... Test loss: 0.00773\n",
      "Epoch: 1... Training loss: 0.0109... Test loss: 0.00932\n",
      "Epoch: 1... Training loss: 0.01006... Test loss: 0.01072\n",
      "Epoch: 1... Training loss: 0.00972... Test loss: 0.009\n",
      "Epoch: 1... Training loss: 0.00928... Test loss: 0.00892\n",
      "Epoch: 1... Training loss: 0.00901... Test loss: 0.00684\n",
      "Epoch: 1... Training loss: 0.00879... Test loss: 0.00848\n",
      "Epoch: 1... Training loss: 0.00857... Test loss: 0.00645\n",
      "Epoch: 1... Training loss: 0.00828... Test loss: 0.00752\n",
      "Epoch: 1... Training loss: 0.00807... Test loss: 0.00655\n",
      "Epoch: 1... Training loss: 0.00768... Test loss: 0.00756\n",
      "Epoch: 1... Training loss: 0.00751... Test loss: 0.00546\n",
      "Epoch: 1... Training loss: 0.00737... Test loss: 0.00735\n",
      "Epoch: 1... Training loss: 0.00705... Test loss: 0.00598\n",
      "Epoch: 1... Training loss: 0.00681... Test loss: 0.00863\n",
      "Epoch: 1... Training loss: 0.00671... Test loss: 0.00594\n",
      "Epoch: 1... Training loss: 0.00647... Test loss: 0.00759\n",
      "Epoch: 1... Training loss: 0.00637... Test loss: 0.00516\n",
      "Epoch: 1... Training loss: 0.00615... Test loss: 0.00783\n",
      "Epoch: 1... Training loss: 0.00588... Test loss: 0.0049\n",
      "Epoch: 1... Training loss: 0.00569... Test loss: 0.00638\n",
      "Epoch: 1... Training loss: 0.00549... Test loss: 0.00448\n",
      "Epoch: 1... Training loss: 0.00541... Test loss: 0.00559\n",
      "Epoch: 1... Training loss: 0.00522... Test loss: 0.00518\n",
      "Epoch: 1... Training loss: 0.00511... Test loss: 0.0051\n",
      "Epoch: 1... Training loss: 0.01174... Test loss: 0.00769\n",
      "Epoch: 1... Training loss: 0.01246... Test loss: 0.0158\n",
      "Epoch: 1... Training loss: 0.00922... Test loss: 0.01391\n",
      "Epoch: 1... Training loss: 0.01095... Test loss: 0.0134\n",
      "Epoch: 1... Training loss: 0.0078... Test loss: 0.01908\n",
      "Epoch: 1... Training loss: 0.00968... Test loss: 0.01337\n",
      "Epoch: 1... Training loss: 0.00852... Test loss: 0.01615\n",
      "Epoch: 1... Training loss: 0.00723... Test loss: 0.01114\n",
      "Epoch: 1... Training loss: 0.00712... Test loss: 0.01161\n",
      "Epoch: 1... Training loss: 0.00721... Test loss: 0.00889\n",
      "Epoch: 1... Training loss: 0.00787... Test loss: 0.01014\n",
      "Epoch: 1... Training loss: 0.00631... Test loss: 0.01143\n",
      "Epoch: 1... Training loss: 0.00728... Test loss: 0.00972\n",
      "Epoch: 1... Training loss: 0.00591... Test loss: 0.01102\n",
      "Epoch: 1... Training loss: 0.00593... Test loss: 0.00678\n",
      "Epoch: 1... Training loss: 0.00564... Test loss: 0.00751\n",
      "Epoch: 1... Training loss: 0.00562... Test loss: 0.0065\n",
      "Epoch: 1... Training loss: 0.00542... Test loss: 0.00843\n",
      "Epoch: 1... Training loss: 0.00581... Test loss: 0.00623\n",
      "Epoch: 1... Training loss: 0.00544... Test loss: 0.0072\n",
      "Epoch: 1... Training loss: 0.00509... Test loss: 0.00683\n",
      "Epoch: 1... Training loss: 0.00485... Test loss: 0.006\n",
      "Epoch: 1... Training loss: 0.00441... Test loss: 0.00503\n",
      "Epoch: 1... Training loss: 0.00458... Test loss: 0.00699\n",
      "Epoch: 1... Training loss: 0.00455... Test loss: 0.00436\n",
      "Epoch: 1... Training loss: 0.00422... Test loss: 0.00854\n",
      "Epoch: 1... Training loss: 0.00412... Test loss: 0.00497\n",
      "Epoch: 1... Training loss: 0.00412... Test loss: 0.00543\n",
      "Epoch: 1... Training loss: 0.00386... Test loss: 0.0045\n",
      "Epoch: 1... Training loss: 0.00365... Test loss: 0.0043\n",
      "Epoch: 1... Training loss: 0.00344... Test loss: 0.00406\n",
      "Epoch: 1... Training loss: 0.00334... Test loss: 0.00351\n",
      "Epoch: 1... Training loss: 0.00323... Test loss: 0.00394\n",
      "Epoch: 1... Training loss: 0.00331... Test loss: 0.00337\n",
      "Epoch: 1... Training loss: 0.00311... Test loss: 0.00324\n",
      "Epoch: 1... Training loss: 0.00292... Test loss: 0.00363\n",
      "Epoch: 1... Training loss: 0.00289... Test loss: 0.00327\n",
      "Epoch: 1... Training loss: 0.00284... Test loss: 0.0028\n",
      "Epoch: 1... Training loss: 0.00284... Test loss: 0.00342\n",
      "Epoch: 1... Training loss: 0.00271... Test loss: 0.00275\n",
      "Epoch: 1... Training loss: 0.0027... Test loss: 0.00336\n",
      "Epoch: 1... Training loss: 0.00262... Test loss: 0.0023\n",
      "Epoch: 1... Training loss: 0.00245... Test loss: 0.00283\n",
      "Epoch: 1... Training loss: 0.00239... Test loss: 0.00214\n",
      "Epoch: 1... Training loss: 0.0023... Test loss: 0.00285\n",
      "Epoch: 1... Training loss: 0.00218... Test loss: 0.00319\n",
      "Epoch: 1... Training loss: 0.00221... Test loss: 0.003\n",
      "Epoch: 1... Training loss: 0.00217... Test loss: 0.00342\n",
      "Epoch: 1... Training loss: 0.00202... Test loss: 0.00209\n",
      "Epoch: 1... Training loss: 0.00196... Test loss: 0.00272\n",
      "Epoch: 1... Training loss: 0.00195... Test loss: 0.00195\n",
      "Epoch: 1... Training loss: 0.00192... Test loss: 0.00279\n",
      "Epoch: 1... Training loss: 0.00186... Test loss: 0.00199\n",
      "Epoch: 1... Training loss: 0.00171... Test loss: 0.00265\n",
      "Epoch: 1... Training loss: 0.0017... Test loss: 0.00195\n",
      "Epoch: 1... Training loss: 0.00155... Test loss: 0.00243\n",
      "Epoch: 1... Training loss: 0.00157... Test loss: 0.00147\n",
      "Epoch: 1... Training loss: 0.00145... Test loss: 0.00217\n",
      "Epoch: 1... Training loss: 0.00142... Test loss: 0.0017\n",
      "Epoch: 1... Training loss: 0.00131... Test loss: 0.00162\n",
      "Epoch: 1... Training loss: 0.00132... Test loss: 0.00134\n",
      "Epoch: 1... Training loss: 0.00127... Test loss: 0.00158\n",
      "Epoch: 1... Training loss: 0.0012... Test loss: 0.00103\n",
      "Epoch: 1... Training loss: 0.00119... Test loss: 0.00192\n",
      "Epoch: 1... Training loss: 0.00116... Test loss: 0.00124\n",
      "Epoch: 1... Training loss: 0.00125... Test loss: 0.00142\n",
      "Epoch: 1... Training loss: 0.00107... Test loss: 0.00134\n",
      "Epoch: 1... Training loss: 0.001... Test loss: 0.00121\n",
      "Epoch: 1... Training loss: 0.00099... Test loss: 0.00132\n",
      "Epoch: 1... Training loss: 0.00093... Test loss: 0.00117\n",
      "Epoch: 1... Training loss: 0.00094... Test loss: 0.00094\n",
      "Epoch: 1... Training loss: 0.00095... Test loss: 0.00123\n",
      "Epoch: 1... Training loss: 0.00089... Test loss: 0.00083\n",
      "Epoch: 1... Training loss: 0.00087... Test loss: 0.001\n",
      "Epoch: 1... Training loss: 0.00082... Test loss: 0.00082\n",
      "Epoch: 1... Training loss: 0.00081... Test loss: 0.00092\n",
      "Epoch: 1... Training loss: 0.00075... Test loss: 0.00075\n",
      "Epoch: 1... Training loss: 0.00074... Test loss: 0.00091\n",
      "Epoch: 1... Training loss: 0.00072... Test loss: 0.00077\n",
      "Epoch: 1... Training loss: 0.00071... Test loss: 0.00077\n",
      "Epoch: 1... Training loss: 0.0007... Test loss: 0.00099\n",
      "Epoch: 1... Training loss: 0.00067... Test loss: 0.00067\n",
      "Epoch: 1... Training loss: 0.00063... Test loss: 0.00087\n",
      "Epoch: 1... Training loss: 0.00057... Test loss: 0.00056\n",
      "Epoch: 1... Training loss: 0.00057... Test loss: 0.00079\n",
      "Epoch: 1... Training loss: 0.00052... Test loss: 0.00061\n",
      "Epoch: 1... Training loss: 0.00056... Test loss: 0.00053\n",
      "Epoch: 1... Training loss: 0.00057... Test loss: 0.00058\n",
      "Epoch: 1... Training loss: 0.00051... Test loss: 0.00055\n",
      "Epoch: 1... Training loss: 0.00047... Test loss: 0.00057\n",
      "Epoch: 1... Training loss: 0.00049... Test loss: 0.00051\n",
      "Epoch: 1... Training loss: 0.00043... Test loss: 0.00041\n",
      "Epoch: 1... Training loss: 0.00039... Test loss: 0.00046\n",
      "Epoch: 1... Training loss: 0.00043... Test loss: 0.00033\n",
      "Epoch: 1... Training loss: 0.00039... Test loss: 0.0003\n",
      "Epoch: 1... Training loss: 0.00038... Test loss: 0.00033\n",
      "Epoch: 1... Training loss: 0.00041... Test loss: 0.00031\n",
      "Epoch: 1... Training loss: 0.00039... Test loss: 0.00036\n",
      "Epoch: 1... Training loss: 0.00034... Test loss: 0.00031\n",
      "Epoch: 1... Training loss: 0.00034... Test loss: 0.00035\n",
      "Epoch: 1... Training loss: 0.00031... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00029... Test loss: 0.00035\n",
      "Epoch: 1... Training loss: 0.00026... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00033\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.0003\n",
      "Epoch: 1... Training loss: 0.00026... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00033\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.00026... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00011\n",
      "224.26308539684396\n",
      "Epoch: 1... Training loss: 1.13007... Test loss: 0.52329\n",
      "Epoch: 1... Training loss: 0.54319... Test loss: 0.21929\n",
      "Epoch: 1... Training loss: 0.29975... Test loss: 0.13102\n",
      "Epoch: 1... Training loss: 0.22578... Test loss: 0.0815\n",
      "Epoch: 1... Training loss: 0.16397... Test loss: 0.06382\n",
      "Epoch: 1... Training loss: 0.12091... Test loss: 0.0448\n",
      "Epoch: 1... Training loss: 0.10248... Test loss: 0.04498\n",
      "Epoch: 1... Training loss: 0.07718... Test loss: 0.02138\n",
      "Epoch: 1... Training loss: 0.06957... Test loss: 0.02251\n",
      "Epoch: 1... Training loss: 0.06155... Test loss: 0.02537\n",
      "Epoch: 1... Training loss: 0.06028... Test loss: 0.01602\n",
      "Epoch: 1... Training loss: 0.05135... Test loss: 0.02722\n",
      "Epoch: 1... Training loss: 0.05041... Test loss: 0.02003\n",
      "Epoch: 1... Training loss: 0.04438... Test loss: 0.0295\n",
      "Epoch: 1... Training loss: 0.04141... Test loss: 0.01539\n",
      "Epoch: 1... Training loss: 0.03888... Test loss: 0.02594\n",
      "Epoch: 1... Training loss: 0.03592... Test loss: 0.01734\n",
      "Epoch: 1... Training loss: 0.03391... Test loss: 0.0352\n",
      "Epoch: 1... Training loss: 0.03195... Test loss: 0.01463\n",
      "Epoch: 1... Training loss: 0.03018... Test loss: 0.0267\n",
      "Epoch: 1... Training loss: 0.02819... Test loss: 0.01584\n",
      "Epoch: 1... Training loss: 0.02598... Test loss: 0.03232\n",
      "Epoch: 1... Training loss: 0.02498... Test loss: 0.01728\n",
      "Epoch: 1... Training loss: 0.0239... Test loss: 0.02823\n",
      "Epoch: 1... Training loss: 0.0233... Test loss: 0.01669\n",
      "Epoch: 1... Training loss: 0.02198... Test loss: 0.02861\n",
      "Epoch: 1... Training loss: 0.02129... Test loss: 0.01748\n",
      "Epoch: 1... Training loss: 0.01983... Test loss: 0.03208\n",
      "Epoch: 1... Training loss: 0.01987... Test loss: 0.01784\n",
      "Epoch: 1... Training loss: 0.01796... Test loss: 0.03219\n",
      "Epoch: 1... Training loss: 0.01733... Test loss: 0.01755\n",
      "Epoch: 1... Training loss: 0.0166... Test loss: 0.02665\n",
      "Epoch: 1... Training loss: 0.01582... Test loss: 0.01829\n",
      "Epoch: 1... Training loss: 0.01534... Test loss: 0.0181\n",
      "Epoch: 1... Training loss: 0.01465... Test loss: 0.02305\n",
      "Epoch: 1... Training loss: 0.01432... Test loss: 0.01436\n",
      "Epoch: 1... Training loss: 0.01378... Test loss: 0.02099\n",
      "Epoch: 1... Training loss: 0.01331... Test loss: 0.01429\n",
      "Epoch: 1... Training loss: 0.01258... Test loss: 0.01673\n",
      "Epoch: 1... Training loss: 0.01237... Test loss: 0.0149\n",
      "Epoch: 1... Training loss: 0.01193... Test loss: 0.01418\n",
      "Epoch: 1... Training loss: 0.01144... Test loss: 0.01541\n",
      "Epoch: 1... Training loss: 0.01112... Test loss: 0.01218\n",
      "Epoch: 1... Training loss: 0.01087... Test loss: 0.01428\n",
      "Epoch: 1... Training loss: 0.01034... Test loss: 0.01135\n",
      "Epoch: 1... Training loss: 0.01018... Test loss: 0.013\n",
      "Epoch: 1... Training loss: 0.0097... Test loss: 0.01009\n",
      "Epoch: 1... Training loss: 0.00942... Test loss: 0.01213\n",
      "Epoch: 1... Training loss: 0.00893... Test loss: 0.00908\n",
      "Epoch: 1... Training loss: 0.00867... Test loss: 0.01056\n",
      "Epoch: 1... Training loss: 0.00856... Test loss: 0.0098\n",
      "Epoch: 1... Training loss: 0.00826... Test loss: 0.00916\n",
      "Epoch: 1... Training loss: 0.00812... Test loss: 0.00988\n",
      "Epoch: 1... Training loss: 0.00778... Test loss: 0.0095\n",
      "Epoch: 1... Training loss: 0.00752... Test loss: 0.009\n",
      "Epoch: 1... Training loss: 0.00731... Test loss: 0.00792\n",
      "Epoch: 1... Training loss: 0.00713... Test loss: 0.00794\n",
      "Epoch: 1... Training loss: 0.00685... Test loss: 0.00716\n",
      "Epoch: 1... Training loss: 0.00675... Test loss: 0.00672\n",
      "Epoch: 1... Training loss: 0.00652... Test loss: 0.0079\n",
      "Epoch: 1... Training loss: 0.00639... Test loss: 0.00583\n",
      "Epoch: 1... Training loss: 0.00626... Test loss: 0.00843\n",
      "Epoch: 1... Training loss: 0.006... Test loss: 0.00548\n",
      "Epoch: 1... Training loss: 0.00584... Test loss: 0.00774\n",
      "Epoch: 1... Training loss: 0.01566... Test loss: 0.01038\n",
      "Epoch: 1... Training loss: 0.01312... Test loss: 0.01943\n",
      "Epoch: 1... Training loss: 0.01379... Test loss: 0.0172\n",
      "Epoch: 1... Training loss: 0.0115... Test loss: 0.02047\n",
      "Epoch: 1... Training loss: 0.00965... Test loss: 0.01931\n",
      "Epoch: 1... Training loss: 0.00872... Test loss: 0.02463\n",
      "Epoch: 1... Training loss: 0.00783... Test loss: 0.01425\n",
      "Epoch: 1... Training loss: 0.00798... Test loss: 0.01665\n",
      "Epoch: 1... Training loss: 0.00807... Test loss: 0.01227\n",
      "Epoch: 1... Training loss: 0.00853... Test loss: 0.01397\n",
      "Epoch: 1... Training loss: 0.00773... Test loss: 0.01118\n",
      "Epoch: 1... Training loss: 0.00765... Test loss: 0.00914\n",
      "Epoch: 1... Training loss: 0.00805... Test loss: 0.01281\n",
      "Epoch: 1... Training loss: 0.00651... Test loss: 0.01001\n",
      "Epoch: 1... Training loss: 0.00668... Test loss: 0.01072\n",
      "Epoch: 1... Training loss: 0.00669... Test loss: 0.01026\n",
      "Epoch: 1... Training loss: 0.00625... Test loss: 0.01005\n",
      "Epoch: 1... Training loss: 0.00636... Test loss: 0.0067\n",
      "Epoch: 1... Training loss: 0.00603... Test loss: 0.01031\n",
      "Epoch: 1... Training loss: 0.00557... Test loss: 0.00689\n",
      "Epoch: 1... Training loss: 0.0054... Test loss: 0.00847\n",
      "Epoch: 1... Training loss: 0.00509... Test loss: 0.0064\n",
      "Epoch: 1... Training loss: 0.00495... Test loss: 0.00751\n",
      "Epoch: 1... Training loss: 0.00464... Test loss: 0.00665\n",
      "Epoch: 1... Training loss: 0.0046... Test loss: 0.00652\n",
      "Epoch: 1... Training loss: 0.00453... Test loss: 0.00789\n",
      "Epoch: 1... Training loss: 0.00412... Test loss: 0.00529\n",
      "Epoch: 1... Training loss: 0.00406... Test loss: 0.00603\n",
      "Epoch: 1... Training loss: 0.004... Test loss: 0.00514\n",
      "Epoch: 1... Training loss: 0.00374... Test loss: 0.00468\n",
      "Epoch: 1... Training loss: 0.00393... Test loss: 0.00402\n",
      "Epoch: 1... Training loss: 0.00343... Test loss: 0.00401\n",
      "Epoch: 1... Training loss: 0.00325... Test loss: 0.0045\n",
      "Epoch: 1... Training loss: 0.0032... Test loss: 0.00374\n",
      "Epoch: 1... Training loss: 0.00298... Test loss: 0.0044\n",
      "Epoch: 1... Training loss: 0.00306... Test loss: 0.00339\n",
      "Epoch: 1... Training loss: 0.00287... Test loss: 0.00357\n",
      "Epoch: 1... Training loss: 0.00278... Test loss: 0.00296\n",
      "Epoch: 1... Training loss: 0.00268... Test loss: 0.0044\n",
      "Epoch: 1... Training loss: 0.00264... Test loss: 0.00286\n",
      "Epoch: 1... Training loss: 0.00262... Test loss: 0.00364\n",
      "Epoch: 1... Training loss: 0.00259... Test loss: 0.00389\n",
      "Epoch: 1... Training loss: 0.00232... Test loss: 0.00353\n",
      "Epoch: 1... Training loss: 0.00238... Test loss: 0.00338\n",
      "Epoch: 1... Training loss: 0.00224... Test loss: 0.00321\n",
      "Epoch: 1... Training loss: 0.00219... Test loss: 0.00268\n",
      "Epoch: 1... Training loss: 0.00212... Test loss: 0.00256\n",
      "Epoch: 1... Training loss: 0.00195... Test loss: 0.00272\n",
      "Epoch: 1... Training loss: 0.00195... Test loss: 0.00211\n",
      "Epoch: 1... Training loss: 0.00184... Test loss: 0.00271\n",
      "Epoch: 1... Training loss: 0.00178... Test loss: 0.00212\n",
      "Epoch: 1... Training loss: 0.00187... Test loss: 0.00274\n",
      "Epoch: 1... Training loss: 0.00164... Test loss: 0.00195\n",
      "Epoch: 1... Training loss: 0.00169... Test loss: 0.00187\n",
      "Epoch: 1... Training loss: 0.00157... Test loss: 0.00194\n",
      "Epoch: 1... Training loss: 0.00161... Test loss: 0.00162\n",
      "Epoch: 1... Training loss: 0.00149... Test loss: 0.00174\n",
      "Epoch: 1... Training loss: 0.0015... Test loss: 0.00149\n",
      "Epoch: 1... Training loss: 0.00138... Test loss: 0.00189\n",
      "Epoch: 1... Training loss: 0.0014... Test loss: 0.00138\n",
      "Epoch: 1... Training loss: 0.00143... Test loss: 0.00154\n",
      "Epoch: 1... Training loss: 0.00126... Test loss: 0.00127\n",
      "Epoch: 1... Training loss: 0.00118... Test loss: 0.00156\n",
      "Epoch: 1... Training loss: 0.00127... Test loss: 0.00113\n",
      "Epoch: 1... Training loss: 0.0011... Test loss: 0.0013\n",
      "Epoch: 1... Training loss: 0.0011... Test loss: 0.00114\n",
      "Epoch: 1... Training loss: 0.00106... Test loss: 0.00124\n",
      "Epoch: 1... Training loss: 0.00109... Test loss: 0.00112\n",
      "Epoch: 1... Training loss: 0.00097... Test loss: 0.00179\n",
      "Epoch: 1... Training loss: 0.00094... Test loss: 0.0009\n",
      "Epoch: 1... Training loss: 0.00108... Test loss: 0.00136\n",
      "Epoch: 1... Training loss: 0.00082... Test loss: 0.00087\n",
      "Epoch: 1... Training loss: 0.0008... Test loss: 0.00112\n",
      "Epoch: 1... Training loss: 0.00081... Test loss: 0.00071\n",
      "Epoch: 1... Training loss: 0.00092... Test loss: 0.00096\n",
      "Epoch: 1... Training loss: 0.00078... Test loss: 0.0006\n",
      "Epoch: 1... Training loss: 0.0007... Test loss: 0.00084\n",
      "Epoch: 1... Training loss: 0.00066... Test loss: 0.00062\n",
      "Epoch: 1... Training loss: 0.00069... Test loss: 0.00091\n",
      "Epoch: 1... Training loss: 0.00065... Test loss: 0.00056\n",
      "Epoch: 1... Training loss: 0.00059... Test loss: 0.00076\n",
      "Epoch: 1... Training loss: 0.00056... Test loss: 0.00061\n",
      "Epoch: 1... Training loss: 0.00059... Test loss: 0.00056\n",
      "Epoch: 1... Training loss: 0.00051... Test loss: 0.00063\n",
      "Epoch: 1... Training loss: 0.00054... Test loss: 0.00057\n",
      "Epoch: 1... Training loss: 0.0005... Test loss: 0.00054\n",
      "Epoch: 1... Training loss: 0.00044... Test loss: 0.00036\n",
      "Epoch: 1... Training loss: 0.00044... Test loss: 0.0004\n",
      "Epoch: 1... Training loss: 0.00039... Test loss: 0.00047\n",
      "Epoch: 1... Training loss: 0.00042... Test loss: 0.00037\n",
      "Epoch: 1... Training loss: 0.00037... Test loss: 0.00046\n",
      "Epoch: 1... Training loss: 0.00039... Test loss: 0.00042\n",
      "Epoch: 1... Training loss: 0.00035... Test loss: 0.0003\n",
      "Epoch: 1... Training loss: 0.00034... Test loss: 0.00035\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00036\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00031\n",
      "Epoch: 1... Training loss: 0.00031... Test loss: 0.0003\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.0003\n",
      "Epoch: 1... Training loss: 0.00026... Test loss: 0.00028\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00028\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.00024\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.00029... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.00026... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00028\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00013\n",
      "258.8271529902704\n",
      "Epoch: 1... Training loss: 1.21004... Test loss: 0.55615\n",
      "Epoch: 1... Training loss: 0.51602... Test loss: 0.20717\n",
      "Epoch: 1... Training loss: 0.35064... Test loss: 0.11784\n",
      "Epoch: 1... Training loss: 0.23526... Test loss: 0.10925\n",
      "Epoch: 1... Training loss: 0.17627... Test loss: 0.0585\n",
      "Epoch: 1... Training loss: 0.1361... Test loss: 0.07817\n",
      "Epoch: 1... Training loss: 0.11294... Test loss: 0.03415\n",
      "Epoch: 1... Training loss: 0.0939... Test loss: 0.06339\n",
      "Epoch: 1... Training loss: 0.0872... Test loss: 0.03129\n",
      "Epoch: 1... Training loss: 0.06975... Test loss: 0.04423\n",
      "Epoch: 1... Training loss: 0.06377... Test loss: 0.05951\n",
      "Epoch: 1... Training loss: 0.0561... Test loss: 0.0333\n",
      "Epoch: 1... Training loss: 0.04939... Test loss: 0.04441\n",
      "Epoch: 1... Training loss: 0.04656... Test loss: 0.04034\n",
      "Epoch: 1... Training loss: 0.04168... Test loss: 0.02509\n",
      "Epoch: 1... Training loss: 0.03901... Test loss: 0.03718\n",
      "Epoch: 1... Training loss: 0.03606... Test loss: 0.0198\n",
      "Epoch: 1... Training loss: 0.03322... Test loss: 0.03418\n",
      "Epoch: 1... Training loss: 0.03072... Test loss: 0.0279\n",
      "Epoch: 1... Training loss: 0.02974... Test loss: 0.01492\n",
      "Epoch: 1... Training loss: 0.02709... Test loss: 0.0307\n",
      "Epoch: 1... Training loss: 0.02563... Test loss: 0.01971\n",
      "Epoch: 1... Training loss: 0.02377... Test loss: 0.02448\n",
      "Epoch: 1... Training loss: 0.02282... Test loss: 0.02046\n",
      "Epoch: 1... Training loss: 0.02186... Test loss: 0.01669\n",
      "Epoch: 1... Training loss: 0.02056... Test loss: 0.02447\n",
      "Epoch: 1... Training loss: 0.01947... Test loss: 0.01177\n",
      "Epoch: 1... Training loss: 0.01887... Test loss: 0.0216\n",
      "Epoch: 1... Training loss: 0.0178... Test loss: 0.01299\n",
      "Epoch: 1... Training loss: 0.01695... Test loss: 0.02652\n",
      "Epoch: 1... Training loss: 0.01648... Test loss: 0.0117\n",
      "Epoch: 1... Training loss: 0.01573... Test loss: 0.01735\n",
      "Epoch: 1... Training loss: 0.01537... Test loss: 0.01149\n",
      "Epoch: 1... Training loss: 0.01477... Test loss: 0.01426\n",
      "Epoch: 1... Training loss: 0.01465... Test loss: 0.0124\n",
      "Epoch: 1... Training loss: 0.01416... Test loss: 0.01258\n",
      "Epoch: 1... Training loss: 0.0137... Test loss: 0.01494\n",
      "Epoch: 1... Training loss: 0.01324... Test loss: 0.00912\n",
      "Epoch: 1... Training loss: 0.01254... Test loss: 0.01407\n",
      "Epoch: 1... Training loss: 0.01197... Test loss: 0.01057\n",
      "Epoch: 1... Training loss: 0.01145... Test loss: 0.0114\n",
      "Epoch: 1... Training loss: 0.01101... Test loss: 0.01282\n",
      "Epoch: 1... Training loss: 0.01068... Test loss: 0.00813\n",
      "Epoch: 1... Training loss: 0.01027... Test loss: 0.01254\n",
      "Epoch: 1... Training loss: 0.01... Test loss: 0.00813\n",
      "Epoch: 1... Training loss: 0.00972... Test loss: 0.01169\n",
      "Epoch: 1... Training loss: 0.00943... Test loss: 0.00753\n",
      "Epoch: 1... Training loss: 0.00898... Test loss: 0.01018\n",
      "Epoch: 1... Training loss: 0.00873... Test loss: 0.00731\n",
      "Epoch: 1... Training loss: 0.00856... Test loss: 0.00898\n",
      "Epoch: 1... Training loss: 0.00818... Test loss: 0.00826\n",
      "Epoch: 1... Training loss: 0.00803... Test loss: 0.00704\n",
      "Epoch: 1... Training loss: 0.00776... Test loss: 0.01053\n",
      "Epoch: 1... Training loss: 0.00762... Test loss: 0.00641\n",
      "Epoch: 1... Training loss: 0.00725... Test loss: 0.01021\n",
      "Epoch: 1... Training loss: 0.00698... Test loss: 0.00656\n",
      "Epoch: 1... Training loss: 0.00673... Test loss: 0.00941\n",
      "Epoch: 1... Training loss: 0.00647... Test loss: 0.00623\n",
      "Epoch: 1... Training loss: 0.00635... Test loss: 0.00783\n",
      "Epoch: 1... Training loss: 0.00618... Test loss: 0.00674\n",
      "Epoch: 1... Training loss: 0.00594... Test loss: 0.00606\n",
      "Epoch: 1... Training loss: 0.00577... Test loss: 0.00666\n",
      "Epoch: 1... Training loss: 0.00552... Test loss: 0.00573\n",
      "Epoch: 1... Training loss: 0.0054... Test loss: 0.00581\n",
      "Epoch: 1... Training loss: 0.0107... Test loss: 0.01581\n",
      "Epoch: 1... Training loss: 0.01017... Test loss: 0.01311\n",
      "Epoch: 1... Training loss: 0.01092... Test loss: 0.01084\n",
      "Epoch: 1... Training loss: 0.01036... Test loss: 0.01661\n",
      "Epoch: 1... Training loss: 0.00973... Test loss: 0.01647\n",
      "Epoch: 1... Training loss: 0.00928... Test loss: 0.01548\n",
      "Epoch: 1... Training loss: 0.00785... Test loss: 0.01712\n",
      "Epoch: 1... Training loss: 0.00829... Test loss: 0.01192\n",
      "Epoch: 1... Training loss: 0.0074... Test loss: 0.01401\n",
      "Epoch: 1... Training loss: 0.00763... Test loss: 0.0139\n",
      "Epoch: 1... Training loss: 0.00807... Test loss: 0.01221\n",
      "Epoch: 1... Training loss: 0.00733... Test loss: 0.00963\n",
      "Epoch: 1... Training loss: 0.00632... Test loss: 0.01305\n",
      "Epoch: 1... Training loss: 0.00606... Test loss: 0.0084\n",
      "Epoch: 1... Training loss: 0.0061... Test loss: 0.01292\n",
      "Epoch: 1... Training loss: 0.00596... Test loss: 0.00768\n",
      "Epoch: 1... Training loss: 0.00592... Test loss: 0.01069\n",
      "Epoch: 1... Training loss: 0.00566... Test loss: 0.00633\n",
      "Epoch: 1... Training loss: 0.00541... Test loss: 0.00902\n",
      "Epoch: 1... Training loss: 0.00533... Test loss: 0.00649\n",
      "Epoch: 1... Training loss: 0.00514... Test loss: 0.00752\n",
      "Epoch: 1... Training loss: 0.00485... Test loss: 0.00576\n",
      "Epoch: 1... Training loss: 0.00465... Test loss: 0.00553\n",
      "Epoch: 1... Training loss: 0.00446... Test loss: 0.00436\n",
      "Epoch: 1... Training loss: 0.00433... Test loss: 0.00623\n",
      "Epoch: 1... Training loss: 0.00466... Test loss: 0.00379\n",
      "Epoch: 1... Training loss: 0.00402... Test loss: 0.00528\n",
      "Epoch: 1... Training loss: 0.0043... Test loss: 0.00484\n",
      "Epoch: 1... Training loss: 0.00423... Test loss: 0.0047\n",
      "Epoch: 1... Training loss: 0.00363... Test loss: 0.00348\n",
      "Epoch: 1... Training loss: 0.00359... Test loss: 0.00535\n",
      "Epoch: 1... Training loss: 0.00377... Test loss: 0.00367\n",
      "Epoch: 1... Training loss: 0.00339... Test loss: 0.00447\n",
      "Epoch: 1... Training loss: 0.00327... Test loss: 0.00301\n",
      "Epoch: 1... Training loss: 0.00313... Test loss: 0.00401\n",
      "Epoch: 1... Training loss: 0.00301... Test loss: 0.00346\n",
      "Epoch: 1... Training loss: 0.0029... Test loss: 0.00383\n",
      "Epoch: 1... Training loss: 0.00279... Test loss: 0.00322\n",
      "Epoch: 1... Training loss: 0.00275... Test loss: 0.00312\n",
      "Epoch: 1... Training loss: 0.00256... Test loss: 0.00257\n",
      "Epoch: 1... Training loss: 0.00259... Test loss: 0.00334\n",
      "Epoch: 1... Training loss: 0.00239... Test loss: 0.00268\n",
      "Epoch: 1... Training loss: 0.0025... Test loss: 0.00312\n",
      "Epoch: 1... Training loss: 0.00222... Test loss: 0.00253\n",
      "Epoch: 1... Training loss: 0.00223... Test loss: 0.00273\n",
      "Epoch: 1... Training loss: 0.00209... Test loss: 0.00255\n",
      "Epoch: 1... Training loss: 0.00205... Test loss: 0.00267\n",
      "Epoch: 1... Training loss: 0.00204... Test loss: 0.0024\n",
      "Epoch: 1... Training loss: 0.00188... Test loss: 0.00215\n",
      "Epoch: 1... Training loss: 0.00192... Test loss: 0.00224\n",
      "Epoch: 1... Training loss: 0.00183... Test loss: 0.0019\n",
      "Epoch: 1... Training loss: 0.00173... Test loss: 0.00174\n",
      "Epoch: 1... Training loss: 0.00165... Test loss: 0.00199\n",
      "Epoch: 1... Training loss: 0.00153... Test loss: 0.00191\n",
      "Epoch: 1... Training loss: 0.00154... Test loss: 0.00187\n",
      "Epoch: 1... Training loss: 0.00142... Test loss: 0.00185\n",
      "Epoch: 1... Training loss: 0.00138... Test loss: 0.00169\n",
      "Epoch: 1... Training loss: 0.00131... Test loss: 0.00165\n",
      "Epoch: 1... Training loss: 0.00128... Test loss: 0.00132\n",
      "Epoch: 1... Training loss: 0.0012... Test loss: 0.00185\n",
      "Epoch: 1... Training loss: 0.00113... Test loss: 0.00119\n",
      "Epoch: 1... Training loss: 0.00113... Test loss: 0.00155\n",
      "Epoch: 1... Training loss: 0.00111... Test loss: 0.00099\n",
      "Epoch: 1... Training loss: 0.00099... Test loss: 0.00134\n",
      "Epoch: 1... Training loss: 0.00098... Test loss: 0.00112\n",
      "Epoch: 1... Training loss: 0.00102... Test loss: 0.00095\n",
      "Epoch: 1... Training loss: 0.00094... Test loss: 0.00097\n",
      "Epoch: 1... Training loss: 0.0009... Test loss: 0.00094\n",
      "Epoch: 1... Training loss: 0.00083... Test loss: 0.00114\n",
      "Epoch: 1... Training loss: 0.00085... Test loss: 0.00087\n",
      "Epoch: 1... Training loss: 0.00076... Test loss: 0.00069\n",
      "Epoch: 1... Training loss: 0.00075... Test loss: 0.00082\n",
      "Epoch: 1... Training loss: 0.00073... Test loss: 0.00062\n",
      "Epoch: 1... Training loss: 0.00065... Test loss: 0.00062\n",
      "Epoch: 1... Training loss: 0.00067... Test loss: 0.00072\n",
      "Epoch: 1... Training loss: 0.00062... Test loss: 0.00068\n",
      "Epoch: 1... Training loss: 0.00065... Test loss: 0.00055\n",
      "Epoch: 1... Training loss: 0.00058... Test loss: 0.00062\n",
      "Epoch: 1... Training loss: 0.00054... Test loss: 0.00049\n",
      "Epoch: 1... Training loss: 0.00053... Test loss: 0.00064\n",
      "Epoch: 1... Training loss: 0.00051... Test loss: 0.00049\n",
      "Epoch: 1... Training loss: 0.00048... Test loss: 0.00072\n",
      "Epoch: 1... Training loss: 0.00047... Test loss: 0.00043\n",
      "Epoch: 1... Training loss: 0.00047... Test loss: 0.00052\n",
      "Epoch: 1... Training loss: 0.00047... Test loss: 0.00044\n",
      "Epoch: 1... Training loss: 0.0005... Test loss: 0.00041\n",
      "Epoch: 1... Training loss: 0.00039... Test loss: 0.00042\n",
      "Epoch: 1... Training loss: 0.00036... Test loss: 0.00046\n",
      "Epoch: 1... Training loss: 0.00037... Test loss: 0.00033\n",
      "Epoch: 1... Training loss: 0.00034... Test loss: 0.00035\n",
      "Epoch: 1... Training loss: 0.00036... Test loss: 0.00035\n",
      "Epoch: 1... Training loss: 0.00037... Test loss: 0.00042\n",
      "Epoch: 1... Training loss: 0.00031... Test loss: 0.00036\n",
      "Epoch: 1... Training loss: 0.00033... Test loss: 0.00045\n",
      "Epoch: 1... Training loss: 0.00032... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00033... Test loss: 0.00034\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.0003\n",
      "Epoch: 1... Training loss: 0.00032... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00028\n",
      "Epoch: 1... Training loss: 0.00034... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00024\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00024\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.00011\n",
      "216.1761823022971\n",
      "Epoch: 1... Training loss: 0.83661... Test loss: 0.18597\n",
      "Epoch: 1... Training loss: 0.42552... Test loss: 0.1076\n",
      "Epoch: 1... Training loss: 0.24879... Test loss: 0.08233\n",
      "Epoch: 1... Training loss: 0.18418... Test loss: 0.05836\n",
      "Epoch: 1... Training loss: 0.14984... Test loss: 0.04747\n",
      "Epoch: 1... Training loss: 0.1166... Test loss: 0.03661\n",
      "Epoch: 1... Training loss: 0.08846... Test loss: 0.03222\n",
      "Epoch: 1... Training loss: 0.07713... Test loss: 0.02599\n",
      "Epoch: 1... Training loss: 0.06663... Test loss: 0.02185\n",
      "Epoch: 1... Training loss: 0.05911... Test loss: 0.01598\n",
      "Epoch: 1... Training loss: 0.04879... Test loss: 0.01082\n",
      "Epoch: 1... Training loss: 0.042... Test loss: 0.00974\n",
      "Epoch: 1... Training loss: 0.03833... Test loss: 0.00751\n",
      "Epoch: 1... Training loss: 0.0358... Test loss: 0.00837\n",
      "Epoch: 1... Training loss: 0.03247... Test loss: 0.00533\n",
      "Epoch: 1... Training loss: 0.03103... Test loss: 0.01032\n",
      "Epoch: 1... Training loss: 0.02895... Test loss: 0.00366\n",
      "Epoch: 1... Training loss: 0.02607... Test loss: 0.00969\n",
      "Epoch: 1... Training loss: 0.02547... Test loss: 0.00376\n",
      "Epoch: 1... Training loss: 0.02301... Test loss: 0.01014\n",
      "Epoch: 1... Training loss: 0.02337... Test loss: 0.00358\n",
      "Epoch: 1... Training loss: 0.02093... Test loss: 0.00794\n",
      "Epoch: 1... Training loss: 0.02061... Test loss: 0.00313\n",
      "Epoch: 1... Training loss: 0.01938... Test loss: 0.00863\n",
      "Epoch: 1... Training loss: 0.01878... Test loss: 0.00328\n",
      "Epoch: 1... Training loss: 0.01771... Test loss: 0.01016\n",
      "Epoch: 1... Training loss: 0.01735... Test loss: 0.00373\n",
      "Epoch: 1... Training loss: 0.01655... Test loss: 0.00885\n",
      "Epoch: 1... Training loss: 0.01625... Test loss: 0.00659\n",
      "Epoch: 1... Training loss: 0.01558... Test loss: 0.00324\n",
      "Epoch: 1... Training loss: 0.01523... Test loss: 0.00814\n",
      "Epoch: 1... Training loss: 0.01462... Test loss: 0.00401\n",
      "Epoch: 1... Training loss: 0.01425... Test loss: 0.00775\n",
      "Epoch: 1... Training loss: 0.01376... Test loss: 0.00604\n",
      "Epoch: 1... Training loss: 0.01318... Test loss: 0.00706\n",
      "Epoch: 1... Training loss: 0.01256... Test loss: 0.0102\n",
      "Epoch: 1... Training loss: 0.01211... Test loss: 0.0053\n",
      "Epoch: 1... Training loss: 0.01169... Test loss: 0.01144\n",
      "Epoch: 1... Training loss: 0.01132... Test loss: 0.00463\n",
      "Epoch: 1... Training loss: 0.01089... Test loss: 0.0094\n",
      "Epoch: 1... Training loss: 0.01058... Test loss: 0.0047\n",
      "Epoch: 1... Training loss: 0.01015... Test loss: 0.00813\n",
      "Epoch: 1... Training loss: 0.00974... Test loss: 0.00563\n",
      "Epoch: 1... Training loss: 0.0095... Test loss: 0.00816\n",
      "Epoch: 1... Training loss: 0.0092... Test loss: 0.00574\n",
      "Epoch: 1... Training loss: 0.009... Test loss: 0.00761\n",
      "Epoch: 1... Training loss: 0.00877... Test loss: 0.00701\n",
      "Epoch: 1... Training loss: 0.00852... Test loss: 0.00757\n",
      "Epoch: 1... Training loss: 0.00846... Test loss: 0.00675\n",
      "Epoch: 1... Training loss: 0.00814... Test loss: 0.00583\n",
      "Epoch: 1... Training loss: 0.00776... Test loss: 0.00745\n",
      "Epoch: 1... Training loss: 0.00767... Test loss: 0.0041\n",
      "Epoch: 1... Training loss: 0.00734... Test loss: 0.00749\n",
      "Epoch: 1... Training loss: 0.00713... Test loss: 0.0051\n",
      "Epoch: 1... Training loss: 0.00674... Test loss: 0.00684\n",
      "Epoch: 1... Training loss: 0.00658... Test loss: 0.00529\n",
      "Epoch: 1... Training loss: 0.00639... Test loss: 0.00531\n",
      "Epoch: 1... Training loss: 0.00611... Test loss: 0.00592\n",
      "Epoch: 1... Training loss: 0.00595... Test loss: 0.00534\n",
      "Epoch: 1... Training loss: 0.00588... Test loss: 0.00536\n",
      "Epoch: 1... Training loss: 0.00566... Test loss: 0.00544\n",
      "Epoch: 1... Training loss: 0.00545... Test loss: 0.00464\n",
      "Epoch: 1... Training loss: 0.0053... Test loss: 0.00592\n",
      "Epoch: 1... Training loss: 0.00518... Test loss: 0.00414\n",
      "Epoch: 1... Training loss: 0.01734... Test loss: 0.02363\n",
      "Epoch: 1... Training loss: 0.00954... Test loss: 0.00974\n",
      "Epoch: 1... Training loss: 0.0107... Test loss: 0.0143\n",
      "Epoch: 1... Training loss: 0.00766... Test loss: 0.00875\n",
      "Epoch: 1... Training loss: 0.00988... Test loss: 0.01152\n",
      "Epoch: 1... Training loss: 0.01012... Test loss: 0.0145\n",
      "Epoch: 1... Training loss: 0.00786... Test loss: 0.01045\n",
      "Epoch: 1... Training loss: 0.00846... Test loss: 0.01319\n",
      "Epoch: 1... Training loss: 0.0073... Test loss: 0.01403\n",
      "Epoch: 1... Training loss: 0.00747... Test loss: 0.0099\n",
      "Epoch: 1... Training loss: 0.00702... Test loss: 0.01299\n",
      "Epoch: 1... Training loss: 0.00738... Test loss: 0.00909\n",
      "Epoch: 1... Training loss: 0.00651... Test loss: 0.01078\n",
      "Epoch: 1... Training loss: 0.00604... Test loss: 0.00708\n",
      "Epoch: 1... Training loss: 0.00596... Test loss: 0.00807\n",
      "Epoch: 1... Training loss: 0.00537... Test loss: 0.00696\n",
      "Epoch: 1... Training loss: 0.0055... Test loss: 0.00681\n",
      "Epoch: 1... Training loss: 0.00574... Test loss: 0.0072\n",
      "Epoch: 1... Training loss: 0.00515... Test loss: 0.0047\n",
      "Epoch: 1... Training loss: 0.00488... Test loss: 0.00647\n",
      "Epoch: 1... Training loss: 0.00514... Test loss: 0.00577\n",
      "Epoch: 1... Training loss: 0.00471... Test loss: 0.00557\n",
      "Epoch: 1... Training loss: 0.00451... Test loss: 0.00591\n",
      "Epoch: 1... Training loss: 0.00435... Test loss: 0.00522\n",
      "Epoch: 1... Training loss: 0.00422... Test loss: 0.00459\n",
      "Epoch: 1... Training loss: 0.00419... Test loss: 0.00393\n",
      "Epoch: 1... Training loss: 0.00396... Test loss: 0.00509\n",
      "Epoch: 1... Training loss: 0.00378... Test loss: 0.00371\n",
      "Epoch: 1... Training loss: 0.00406... Test loss: 0.00559\n",
      "Epoch: 1... Training loss: 0.0035... Test loss: 0.00428\n",
      "Epoch: 1... Training loss: 0.00347... Test loss: 0.00466\n",
      "Epoch: 1... Training loss: 0.00337... Test loss: 0.00375\n",
      "Epoch: 1... Training loss: 0.00314... Test loss: 0.00524\n",
      "Epoch: 1... Training loss: 0.00303... Test loss: 0.00394\n",
      "Epoch: 1... Training loss: 0.003... Test loss: 0.00363\n",
      "Epoch: 1... Training loss: 0.00284... Test loss: 0.00342\n",
      "Epoch: 1... Training loss: 0.00272... Test loss: 0.00393\n",
      "Epoch: 1... Training loss: 0.00273... Test loss: 0.00295\n",
      "Epoch: 1... Training loss: 0.0027... Test loss: 0.00376\n",
      "Epoch: 1... Training loss: 0.00258... Test loss: 0.00252\n",
      "Epoch: 1... Training loss: 0.00253... Test loss: 0.00344\n",
      "Epoch: 1... Training loss: 0.00254... Test loss: 0.00279\n",
      "Epoch: 1... Training loss: 0.00235... Test loss: 0.0028\n",
      "Epoch: 1... Training loss: 0.0021... Test loss: 0.00286\n",
      "Epoch: 1... Training loss: 0.00217... Test loss: 0.00264\n",
      "Epoch: 1... Training loss: 0.00209... Test loss: 0.00248\n",
      "Epoch: 1... Training loss: 0.00199... Test loss: 0.00249\n",
      "Epoch: 1... Training loss: 0.00206... Test loss: 0.00287\n",
      "Epoch: 1... Training loss: 0.00194... Test loss: 0.00249\n",
      "Epoch: 1... Training loss: 0.0019... Test loss: 0.00249\n",
      "Epoch: 1... Training loss: 0.00183... Test loss: 0.00243\n",
      "Epoch: 1... Training loss: 0.00167... Test loss: 0.00188\n",
      "Epoch: 1... Training loss: 0.00166... Test loss: 0.00228\n",
      "Epoch: 1... Training loss: 0.00163... Test loss: 0.00162\n",
      "Epoch: 1... Training loss: 0.00169... Test loss: 0.00189\n",
      "Epoch: 1... Training loss: 0.00157... Test loss: 0.00152\n",
      "Epoch: 1... Training loss: 0.00143... Test loss: 0.00197\n",
      "Epoch: 1... Training loss: 0.00139... Test loss: 0.00154\n",
      "Epoch: 1... Training loss: 0.00136... Test loss: 0.00148\n",
      "Epoch: 1... Training loss: 0.00126... Test loss: 0.00162\n",
      "Epoch: 1... Training loss: 0.00127... Test loss: 0.00167\n",
      "Epoch: 1... Training loss: 0.00122... Test loss: 0.00162\n",
      "Epoch: 1... Training loss: 0.00113... Test loss: 0.0016\n",
      "Epoch: 1... Training loss: 0.00105... Test loss: 0.00153\n",
      "Epoch: 1... Training loss: 0.00105... Test loss: 0.00147\n",
      "Epoch: 1... Training loss: 0.00097... Test loss: 0.00145\n",
      "Epoch: 1... Training loss: 0.001... Test loss: 0.00118\n",
      "Epoch: 1... Training loss: 0.0009... Test loss: 0.001\n",
      "Epoch: 1... Training loss: 0.00087... Test loss: 0.00094\n",
      "Epoch: 1... Training loss: 0.00085... Test loss: 0.00097\n",
      "Epoch: 1... Training loss: 0.00074... Test loss: 0.00084\n",
      "Epoch: 1... Training loss: 0.00076... Test loss: 0.0008\n",
      "Epoch: 1... Training loss: 0.00071... Test loss: 0.00067\n",
      "Epoch: 1... Training loss: 0.00064... Test loss: 0.00084\n",
      "Epoch: 1... Training loss: 0.00063... Test loss: 0.00071\n",
      "Epoch: 1... Training loss: 0.0006... Test loss: 0.00072\n",
      "Epoch: 1... Training loss: 0.00054... Test loss: 0.00059\n",
      "Epoch: 1... Training loss: 0.00053... Test loss: 0.0007\n",
      "Epoch: 1... Training loss: 0.00049... Test loss: 0.00051\n",
      "Epoch: 1... Training loss: 0.0005... Test loss: 0.0005\n",
      "Epoch: 1... Training loss: 0.00046... Test loss: 0.00054\n",
      "Epoch: 1... Training loss: 0.00047... Test loss: 0.00052\n",
      "Epoch: 1... Training loss: 0.00044... Test loss: 0.00044\n",
      "Epoch: 1... Training loss: 0.00045... Test loss: 0.00056\n",
      "Epoch: 1... Training loss: 0.0004... Test loss: 0.00047\n",
      "Epoch: 1... Training loss: 0.00037... Test loss: 0.00047\n",
      "Epoch: 1... Training loss: 0.00035... Test loss: 0.00034\n",
      "Epoch: 1... Training loss: 0.00034... Test loss: 0.00043\n",
      "Epoch: 1... Training loss: 0.00031... Test loss: 0.00042\n",
      "Epoch: 1... Training loss: 0.00035... Test loss: 0.00035\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.0003\n",
      "Epoch: 1... Training loss: 0.00037... Test loss: 0.00038\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00042\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.0003\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00024\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 8e-05\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.0001\n",
      "222.47988878272008\n",
      "Epoch: 1... Training loss: 0.95174... Test loss: 0.28265\n",
      "Epoch: 1... Training loss: 0.46973... Test loss: 0.15505\n",
      "Epoch: 1... Training loss: 0.25897... Test loss: 0.08506\n",
      "Epoch: 1... Training loss: 0.18194... Test loss: 0.06162\n",
      "Epoch: 1... Training loss: 0.13943... Test loss: 0.04192\n",
      "Epoch: 1... Training loss: 0.10996... Test loss: 0.03384\n",
      "Epoch: 1... Training loss: 0.09926... Test loss: 0.02763\n",
      "Epoch: 1... Training loss: 0.08218... Test loss: 0.03331\n",
      "Epoch: 1... Training loss: 0.07513... Test loss: 0.01766\n",
      "Epoch: 1... Training loss: 0.06457... Test loss: 0.02426\n",
      "Epoch: 1... Training loss: 0.05627... Test loss: 0.01407\n",
      "Epoch: 1... Training loss: 0.0519... Test loss: 0.01992\n",
      "Epoch: 1... Training loss: 0.04978... Test loss: 0.01129\n",
      "Epoch: 1... Training loss: 0.0435... Test loss: 0.0182\n",
      "Epoch: 1... Training loss: 0.03933... Test loss: 0.01082\n",
      "Epoch: 1... Training loss: 0.03555... Test loss: 0.01527\n",
      "Epoch: 1... Training loss: 0.03256... Test loss: 0.00987\n",
      "Epoch: 1... Training loss: 0.03099... Test loss: 0.01395\n",
      "Epoch: 1... Training loss: 0.02794... Test loss: 0.01\n",
      "Epoch: 1... Training loss: 0.02547... Test loss: 0.01168\n",
      "Epoch: 1... Training loss: 0.02436... Test loss: 0.01509\n",
      "Epoch: 1... Training loss: 0.02311... Test loss: 0.01359\n",
      "Epoch: 1... Training loss: 0.02171... Test loss: 0.01387\n",
      "Epoch: 1... Training loss: 0.02109... Test loss: 0.02142\n",
      "Epoch: 1... Training loss: 0.0212... Test loss: 0.00879\n",
      "Epoch: 1... Training loss: 0.01838... Test loss: 0.0159\n",
      "Epoch: 1... Training loss: 0.01835... Test loss: 0.01261\n",
      "Epoch: 1... Training loss: 0.01755... Test loss: 0.00946\n",
      "Epoch: 1... Training loss: 0.01664... Test loss: 0.01414\n",
      "Epoch: 1... Training loss: 0.01604... Test loss: 0.00907\n",
      "Epoch: 1... Training loss: 0.01514... Test loss: 0.01776\n",
      "Epoch: 1... Training loss: 0.01505... Test loss: 0.00866\n",
      "Epoch: 1... Training loss: 0.01394... Test loss: 0.0144\n",
      "Epoch: 1... Training loss: 0.01376... Test loss: 0.00832\n",
      "Epoch: 1... Training loss: 0.01311... Test loss: 0.01195\n",
      "Epoch: 1... Training loss: 0.01268... Test loss: 0.00889\n",
      "Epoch: 1... Training loss: 0.01189... Test loss: 0.01125\n",
      "Epoch: 1... Training loss: 0.01167... Test loss: 0.0093\n",
      "Epoch: 1... Training loss: 0.0112... Test loss: 0.01057\n",
      "Epoch: 1... Training loss: 0.01078... Test loss: 0.00916\n",
      "Epoch: 1... Training loss: 0.01046... Test loss: 0.01063\n",
      "Epoch: 1... Training loss: 0.01032... Test loss: 0.00804\n",
      "Epoch: 1... Training loss: 0.01008... Test loss: 0.0107\n",
      "Epoch: 1... Training loss: 0.00995... Test loss: 0.00646\n",
      "Epoch: 1... Training loss: 0.00957... Test loss: 0.01166\n",
      "Epoch: 1... Training loss: 0.00935... Test loss: 0.00585\n",
      "Epoch: 1... Training loss: 0.00915... Test loss: 0.01086\n",
      "Epoch: 1... Training loss: 0.0088... Test loss: 0.00674\n",
      "Epoch: 1... Training loss: 0.00835... Test loss: 0.00952\n",
      "Epoch: 1... Training loss: 0.00801... Test loss: 0.00637\n",
      "Epoch: 1... Training loss: 0.0078... Test loss: 0.00886\n",
      "Epoch: 1... Training loss: 0.00761... Test loss: 0.00565\n",
      "Epoch: 1... Training loss: 0.00737... Test loss: 0.00914\n",
      "Epoch: 1... Training loss: 0.00724... Test loss: 0.00542\n",
      "Epoch: 1... Training loss: 0.007... Test loss: 0.00824\n",
      "Epoch: 1... Training loss: 0.00675... Test loss: 0.00596\n",
      "Epoch: 1... Training loss: 0.00649... Test loss: 0.00716\n",
      "Epoch: 1... Training loss: 0.00627... Test loss: 0.00682\n",
      "Epoch: 1... Training loss: 0.00605... Test loss: 0.00574\n",
      "Epoch: 1... Training loss: 0.00593... Test loss: 0.00851\n",
      "Epoch: 1... Training loss: 0.00568... Test loss: 0.00601\n",
      "Epoch: 1... Training loss: 0.00557... Test loss: 0.0082\n",
      "Epoch: 1... Training loss: 0.00535... Test loss: 0.00591\n",
      "Epoch: 1... Training loss: 0.00522... Test loss: 0.00688\n",
      "Epoch: 1... Training loss: 0.01323... Test loss: 0.01289\n",
      "Epoch: 1... Training loss: 0.01133... Test loss: 0.01611\n",
      "Epoch: 1... Training loss: 0.00861... Test loss: 0.01447\n",
      "Epoch: 1... Training loss: 0.00875... Test loss: 0.01361\n",
      "Epoch: 1... Training loss: 0.00907... Test loss: 0.01148\n",
      "Epoch: 1... Training loss: 0.00927... Test loss: 0.01071\n",
      "Epoch: 1... Training loss: 0.00909... Test loss: 0.01098\n",
      "Epoch: 1... Training loss: 0.00869... Test loss: 0.01244\n",
      "Epoch: 1... Training loss: 0.00839... Test loss: 0.01058\n",
      "Epoch: 1... Training loss: 0.00751... Test loss: 0.01095\n",
      "Epoch: 1... Training loss: 0.00765... Test loss: 0.01262\n",
      "Epoch: 1... Training loss: 0.00778... Test loss: 0.01072\n",
      "Epoch: 1... Training loss: 0.0068... Test loss: 0.01101\n",
      "Epoch: 1... Training loss: 0.00631... Test loss: 0.00869\n",
      "Epoch: 1... Training loss: 0.00649... Test loss: 0.01111\n",
      "Epoch: 1... Training loss: 0.00584... Test loss: 0.00795\n",
      "Epoch: 1... Training loss: 0.00617... Test loss: 0.00839\n",
      "Epoch: 1... Training loss: 0.00546... Test loss: 0.00653\n",
      "Epoch: 1... Training loss: 0.00555... Test loss: 0.00635\n",
      "Epoch: 1... Training loss: 0.005... Test loss: 0.00637\n",
      "Epoch: 1... Training loss: 0.00549... Test loss: 0.00641\n",
      "Epoch: 1... Training loss: 0.00496... Test loss: 0.00587\n",
      "Epoch: 1... Training loss: 0.00459... Test loss: 0.00571\n",
      "Epoch: 1... Training loss: 0.00498... Test loss: 0.00505\n",
      "Epoch: 1... Training loss: 0.00468... Test loss: 0.00646\n",
      "Epoch: 1... Training loss: 0.00451... Test loss: 0.00505\n",
      "Epoch: 1... Training loss: 0.00411... Test loss: 0.00605\n",
      "Epoch: 1... Training loss: 0.00394... Test loss: 0.00489\n",
      "Epoch: 1... Training loss: 0.00382... Test loss: 0.00483\n",
      "Epoch: 1... Training loss: 0.00369... Test loss: 0.0048\n",
      "Epoch: 1... Training loss: 0.00363... Test loss: 0.00493\n",
      "Epoch: 1... Training loss: 0.00377... Test loss: 0.00423\n",
      "Epoch: 1... Training loss: 0.00354... Test loss: 0.00488\n",
      "Epoch: 1... Training loss: 0.00327... Test loss: 0.00406\n",
      "Epoch: 1... Training loss: 0.00335... Test loss: 0.00472\n",
      "Epoch: 1... Training loss: 0.00309... Test loss: 0.00376\n",
      "Epoch: 1... Training loss: 0.00294... Test loss: 0.00388\n",
      "Epoch: 1... Training loss: 0.00299... Test loss: 0.00366\n",
      "Epoch: 1... Training loss: 0.0028... Test loss: 0.00337\n",
      "Epoch: 1... Training loss: 0.00271... Test loss: 0.0037\n",
      "Epoch: 1... Training loss: 0.00259... Test loss: 0.00287\n",
      "Epoch: 1... Training loss: 0.00263... Test loss: 0.00304\n",
      "Epoch: 1... Training loss: 0.00247... Test loss: 0.00293\n",
      "Epoch: 1... Training loss: 0.0024... Test loss: 0.00274\n",
      "Epoch: 1... Training loss: 0.00229... Test loss: 0.00307\n",
      "Epoch: 1... Training loss: 0.00229... Test loss: 0.00294\n",
      "Epoch: 1... Training loss: 0.00228... Test loss: 0.00237\n",
      "Epoch: 1... Training loss: 0.00224... Test loss: 0.00293\n",
      "Epoch: 1... Training loss: 0.00204... Test loss: 0.00215\n",
      "Epoch: 1... Training loss: 0.00202... Test loss: 0.00306\n",
      "Epoch: 1... Training loss: 0.00201... Test loss: 0.00202\n",
      "Epoch: 1... Training loss: 0.00201... Test loss: 0.00242\n",
      "Epoch: 1... Training loss: 0.00186... Test loss: 0.00187\n",
      "Epoch: 1... Training loss: 0.00182... Test loss: 0.00246\n",
      "Epoch: 1... Training loss: 0.00186... Test loss: 0.00196\n",
      "Epoch: 1... Training loss: 0.00167... Test loss: 0.00214\n",
      "Epoch: 1... Training loss: 0.00162... Test loss: 0.00161\n",
      "Epoch: 1... Training loss: 0.00155... Test loss: 0.00199\n",
      "Epoch: 1... Training loss: 0.00146... Test loss: 0.00138\n",
      "Epoch: 1... Training loss: 0.00142... Test loss: 0.00211\n",
      "Epoch: 1... Training loss: 0.00135... Test loss: 0.00154\n",
      "Epoch: 1... Training loss: 0.00135... Test loss: 0.002\n",
      "Epoch: 1... Training loss: 0.00132... Test loss: 0.00146\n",
      "Epoch: 1... Training loss: 0.00121... Test loss: 0.00202\n",
      "Epoch: 1... Training loss: 0.00121... Test loss: 0.0013\n",
      "Epoch: 1... Training loss: 0.00109... Test loss: 0.00183\n",
      "Epoch: 1... Training loss: 0.00114... Test loss: 0.0012\n",
      "Epoch: 1... Training loss: 0.00103... Test loss: 0.00142\n",
      "Epoch: 1... Training loss: 0.00101... Test loss: 0.00121\n",
      "Epoch: 1... Training loss: 0.00092... Test loss: 0.00113\n",
      "Epoch: 1... Training loss: 0.00085... Test loss: 0.00095\n",
      "Epoch: 1... Training loss: 0.00083... Test loss: 0.00112\n",
      "Epoch: 1... Training loss: 0.00083... Test loss: 0.00072\n",
      "Epoch: 1... Training loss: 0.00079... Test loss: 0.00102\n",
      "Epoch: 1... Training loss: 0.00072... Test loss: 0.00074\n",
      "Epoch: 1... Training loss: 0.00081... Test loss: 0.00109\n",
      "Epoch: 1... Training loss: 0.00072... Test loss: 0.00075\n",
      "Epoch: 1... Training loss: 0.00073... Test loss: 0.00075\n",
      "Epoch: 1... Training loss: 0.00067... Test loss: 0.00063\n",
      "Epoch: 1... Training loss: 0.00057... Test loss: 0.00091\n",
      "Epoch: 1... Training loss: 0.00059... Test loss: 0.00065\n",
      "Epoch: 1... Training loss: 0.00052... Test loss: 0.00077\n",
      "Epoch: 1... Training loss: 0.0005... Test loss: 0.00053\n",
      "Epoch: 1... Training loss: 0.00048... Test loss: 0.00071\n",
      "Epoch: 1... Training loss: 0.0005... Test loss: 0.00053\n",
      "Epoch: 1... Training loss: 0.00053... Test loss: 0.00051\n",
      "Epoch: 1... Training loss: 0.0005... Test loss: 0.00041\n",
      "Epoch: 1... Training loss: 0.00047... Test loss: 0.0006\n",
      "Epoch: 1... Training loss: 0.00045... Test loss: 0.00048\n",
      "Epoch: 1... Training loss: 0.0004... Test loss: 0.00054\n",
      "Epoch: 1... Training loss: 0.00037... Test loss: 0.00034\n",
      "Epoch: 1... Training loss: 0.00035... Test loss: 0.00056\n",
      "Epoch: 1... Training loss: 0.00036... Test loss: 0.00039\n",
      "Epoch: 1... Training loss: 0.00039... Test loss: 0.0004\n",
      "Epoch: 1... Training loss: 0.0004... Test loss: 0.00031\n",
      "Epoch: 1... Training loss: 0.00035... Test loss: 0.00037\n",
      "Epoch: 1... Training loss: 0.00033... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.0005\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.00024\n",
      "Epoch: 1... Training loss: 0.00037... Test loss: 0.00031\n",
      "Epoch: 1... Training loss: 0.00026... Test loss: 0.00041\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00028\n",
      "Epoch: 1... Training loss: 0.00031... Test loss: 0.00036\n",
      "Epoch: 1... Training loss: 0.00026... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00033\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.00026... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 7e-05\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 0.00011\n",
      "238.3853850341402\n",
      "Epoch: 1... Training loss: 0.99923... Test loss: 0.39879\n",
      "Epoch: 1... Training loss: 0.40966... Test loss: 0.12907\n",
      "Epoch: 1... Training loss: 0.24089... Test loss: 0.07576\n",
      "Epoch: 1... Training loss: 0.16589... Test loss: 0.0521\n",
      "Epoch: 1... Training loss: 0.11227... Test loss: 0.04634\n",
      "Epoch: 1... Training loss: 0.09843... Test loss: 0.0251\n",
      "Epoch: 1... Training loss: 0.08184... Test loss: 0.03611\n",
      "Epoch: 1... Training loss: 0.07107... Test loss: 0.02189\n",
      "Epoch: 1... Training loss: 0.05851... Test loss: 0.02028\n",
      "Epoch: 1... Training loss: 0.05457... Test loss: 0.01897\n",
      "Epoch: 1... Training loss: 0.04922... Test loss: 0.02107\n",
      "Epoch: 1... Training loss: 0.04643... Test loss: 0.01543\n",
      "Epoch: 1... Training loss: 0.04319... Test loss: 0.01662\n",
      "Epoch: 1... Training loss: 0.03813... Test loss: 0.02245\n",
      "Epoch: 1... Training loss: 0.03614... Test loss: 0.02144\n",
      "Epoch: 1... Training loss: 0.03254... Test loss: 0.02218\n",
      "Epoch: 1... Training loss: 0.03143... Test loss: 0.0257\n",
      "Epoch: 1... Training loss: 0.02967... Test loss: 0.00894\n",
      "Epoch: 1... Training loss: 0.02853... Test loss: 0.02206\n",
      "Epoch: 1... Training loss: 0.0276... Test loss: 0.00926\n",
      "Epoch: 1... Training loss: 0.02607... Test loss: 0.01297\n",
      "Epoch: 1... Training loss: 0.02356... Test loss: 0.01225\n",
      "Epoch: 1... Training loss: 0.02307... Test loss: 0.01633\n",
      "Epoch: 1... Training loss: 0.02124... Test loss: 0.00744\n",
      "Epoch: 1... Training loss: 0.02024... Test loss: 0.01922\n",
      "Epoch: 1... Training loss: 0.01957... Test loss: 0.00945\n",
      "Epoch: 1... Training loss: 0.01873... Test loss: 0.01211\n",
      "Epoch: 1... Training loss: 0.01755... Test loss: 0.01299\n",
      "Epoch: 1... Training loss: 0.01638... Test loss: 0.016\n",
      "Epoch: 1... Training loss: 0.01605... Test loss: 0.01008\n",
      "Epoch: 1... Training loss: 0.0155... Test loss: 0.00739\n",
      "Epoch: 1... Training loss: 0.01575... Test loss: 0.01255\n",
      "Epoch: 1... Training loss: 0.01415... Test loss: 0.00574\n",
      "Epoch: 1... Training loss: 0.01409... Test loss: 0.01129\n",
      "Epoch: 1... Training loss: 0.01331... Test loss: 0.00664\n",
      "Epoch: 1... Training loss: 0.01277... Test loss: 0.0111\n",
      "Epoch: 1... Training loss: 0.01223... Test loss: 0.00615\n",
      "Epoch: 1... Training loss: 0.01174... Test loss: 0.01031\n",
      "Epoch: 1... Training loss: 0.01115... Test loss: 0.00618\n",
      "Epoch: 1... Training loss: 0.01086... Test loss: 0.00873\n",
      "Epoch: 1... Training loss: 0.01039... Test loss: 0.00715\n",
      "Epoch: 1... Training loss: 0.00997... Test loss: 0.00852\n",
      "Epoch: 1... Training loss: 0.00972... Test loss: 0.00639\n",
      "Epoch: 1... Training loss: 0.00951... Test loss: 0.00838\n",
      "Epoch: 1... Training loss: 0.00909... Test loss: 0.00634\n",
      "Epoch: 1... Training loss: 0.00892... Test loss: 0.00808\n",
      "Epoch: 1... Training loss: 0.00861... Test loss: 0.00698\n",
      "Epoch: 1... Training loss: 0.00824... Test loss: 0.00881\n",
      "Epoch: 1... Training loss: 0.00804... Test loss: 0.00547\n",
      "Epoch: 1... Training loss: 0.00785... Test loss: 0.00767\n",
      "Epoch: 1... Training loss: 0.00776... Test loss: 0.00508\n",
      "Epoch: 1... Training loss: 0.00735... Test loss: 0.00728\n",
      "Epoch: 1... Training loss: 0.00718... Test loss: 0.00508\n",
      "Epoch: 1... Training loss: 0.00704... Test loss: 0.00645\n",
      "Epoch: 1... Training loss: 0.00683... Test loss: 0.00482\n",
      "Epoch: 1... Training loss: 0.00667... Test loss: 0.00622\n",
      "Epoch: 1... Training loss: 0.00646... Test loss: 0.00456\n",
      "Epoch: 1... Training loss: 0.0063... Test loss: 0.0071\n",
      "Epoch: 1... Training loss: 0.00619... Test loss: 0.00495\n",
      "Epoch: 1... Training loss: 0.00598... Test loss: 0.00716\n",
      "Epoch: 1... Training loss: 0.00575... Test loss: 0.0049\n",
      "Epoch: 1... Training loss: 0.00556... Test loss: 0.00697\n",
      "Epoch: 1... Training loss: 0.00534... Test loss: 0.00518\n",
      "Epoch: 1... Training loss: 0.00519... Test loss: 0.00581\n",
      "Epoch: 1... Training loss: 0.01348... Test loss: 0.01592\n",
      "Epoch: 1... Training loss: 0.00947... Test loss: 0.01996\n",
      "Epoch: 1... Training loss: 0.0134... Test loss: 0.01465\n",
      "Epoch: 1... Training loss: 0.00852... Test loss: 0.01864\n",
      "Epoch: 1... Training loss: 0.00866... Test loss: 0.01235\n",
      "Epoch: 1... Training loss: 0.00876... Test loss: 0.01693\n",
      "Epoch: 1... Training loss: 0.00819... Test loss: 0.01314\n",
      "Epoch: 1... Training loss: 0.00761... Test loss: 0.01478\n",
      "Epoch: 1... Training loss: 0.00759... Test loss: 0.01241\n",
      "Epoch: 1... Training loss: 0.00766... Test loss: 0.01088\n",
      "Epoch: 1... Training loss: 0.00755... Test loss: 0.01112\n",
      "Epoch: 1... Training loss: 0.00716... Test loss: 0.01086\n",
      "Epoch: 1... Training loss: 0.00654... Test loss: 0.00959\n",
      "Epoch: 1... Training loss: 0.0073... Test loss: 0.01035\n",
      "Epoch: 1... Training loss: 0.0062... Test loss: 0.00917\n",
      "Epoch: 1... Training loss: 0.00574... Test loss: 0.00894\n",
      "Epoch: 1... Training loss: 0.00574... Test loss: 0.00687\n",
      "Epoch: 1... Training loss: 0.00622... Test loss: 0.00686\n",
      "Epoch: 1... Training loss: 0.0054... Test loss: 0.00909\n",
      "Epoch: 1... Training loss: 0.00518... Test loss: 0.00613\n",
      "Epoch: 1... Training loss: 0.00514... Test loss: 0.00556\n",
      "Epoch: 1... Training loss: 0.00497... Test loss: 0.00652\n",
      "Epoch: 1... Training loss: 0.0049... Test loss: 0.00519\n",
      "Epoch: 1... Training loss: 0.00484... Test loss: 0.00682\n",
      "Epoch: 1... Training loss: 0.00438... Test loss: 0.00544\n",
      "Epoch: 1... Training loss: 0.00414... Test loss: 0.00599\n",
      "Epoch: 1... Training loss: 0.00411... Test loss: 0.00608\n",
      "Epoch: 1... Training loss: 0.00379... Test loss: 0.00577\n",
      "Epoch: 1... Training loss: 0.00374... Test loss: 0.00426\n",
      "Epoch: 1... Training loss: 0.00371... Test loss: 0.00416\n",
      "Epoch: 1... Training loss: 0.0035... Test loss: 0.00398\n",
      "Epoch: 1... Training loss: 0.00339... Test loss: 0.00468\n",
      "Epoch: 1... Training loss: 0.0033... Test loss: 0.00335\n",
      "Epoch: 1... Training loss: 0.00321... Test loss: 0.00455\n",
      "Epoch: 1... Training loss: 0.00305... Test loss: 0.00369\n",
      "Epoch: 1... Training loss: 0.00308... Test loss: 0.00387\n",
      "Epoch: 1... Training loss: 0.00294... Test loss: 0.00392\n",
      "Epoch: 1... Training loss: 0.00277... Test loss: 0.00316\n",
      "Epoch: 1... Training loss: 0.0027... Test loss: 0.00262\n",
      "Epoch: 1... Training loss: 0.00262... Test loss: 0.0037\n",
      "Epoch: 1... Training loss: 0.00258... Test loss: 0.00225\n",
      "Epoch: 1... Training loss: 0.00248... Test loss: 0.0035\n",
      "Epoch: 1... Training loss: 0.00235... Test loss: 0.00228\n",
      "Epoch: 1... Training loss: 0.00235... Test loss: 0.00332\n",
      "Epoch: 1... Training loss: 0.00228... Test loss: 0.0026\n",
      "Epoch: 1... Training loss: 0.00218... Test loss: 0.00232\n",
      "Epoch: 1... Training loss: 0.00211... Test loss: 0.0023\n",
      "Epoch: 1... Training loss: 0.00204... Test loss: 0.00233\n",
      "Epoch: 1... Training loss: 0.00197... Test loss: 0.00246\n",
      "Epoch: 1... Training loss: 0.00213... Test loss: 0.00336\n",
      "Epoch: 1... Training loss: 0.00185... Test loss: 0.00201\n",
      "Epoch: 1... Training loss: 0.00187... Test loss: 0.00281\n",
      "Epoch: 1... Training loss: 0.0017... Test loss: 0.00224\n",
      "Epoch: 1... Training loss: 0.00169... Test loss: 0.00191\n",
      "Epoch: 1... Training loss: 0.00172... Test loss: 0.00214\n",
      "Epoch: 1... Training loss: 0.00156... Test loss: 0.00187\n",
      "Epoch: 1... Training loss: 0.00148... Test loss: 0.00209\n",
      "Epoch: 1... Training loss: 0.00144... Test loss: 0.00168\n",
      "Epoch: 1... Training loss: 0.00141... Test loss: 0.00214\n",
      "Epoch: 1... Training loss: 0.00136... Test loss: 0.00157\n",
      "Epoch: 1... Training loss: 0.00129... Test loss: 0.00146\n",
      "Epoch: 1... Training loss: 0.00118... Test loss: 0.00151\n",
      "Epoch: 1... Training loss: 0.00117... Test loss: 0.0016\n",
      "Epoch: 1... Training loss: 0.00112... Test loss: 0.00121\n",
      "Epoch: 1... Training loss: 0.00116... Test loss: 0.0009\n",
      "Epoch: 1... Training loss: 0.00107... Test loss: 0.00154\n",
      "Epoch: 1... Training loss: 0.001... Test loss: 0.00093\n",
      "Epoch: 1... Training loss: 0.00093... Test loss: 0.00166\n",
      "Epoch: 1... Training loss: 0.00094... Test loss: 0.00087\n",
      "Epoch: 1... Training loss: 0.00084... Test loss: 0.00152\n",
      "Epoch: 1... Training loss: 0.00091... Test loss: 0.0009\n",
      "Epoch: 1... Training loss: 0.00081... Test loss: 0.00098\n",
      "Epoch: 1... Training loss: 0.00077... Test loss: 0.00061\n",
      "Epoch: 1... Training loss: 0.00075... Test loss: 0.00096\n",
      "Epoch: 1... Training loss: 0.00071... Test loss: 0.00062\n",
      "Epoch: 1... Training loss: 0.00071... Test loss: 0.00075\n",
      "Epoch: 1... Training loss: 0.00064... Test loss: 0.00059\n",
      "Epoch: 1... Training loss: 0.00064... Test loss: 0.00093\n",
      "Epoch: 1... Training loss: 0.00062... Test loss: 0.00058\n",
      "Epoch: 1... Training loss: 0.00062... Test loss: 0.00065\n",
      "Epoch: 1... Training loss: 0.00056... Test loss: 0.00062\n",
      "Epoch: 1... Training loss: 0.00054... Test loss: 0.00064\n",
      "Epoch: 1... Training loss: 0.00052... Test loss: 0.00045\n",
      "Epoch: 1... Training loss: 0.00052... Test loss: 0.00054\n",
      "Epoch: 1... Training loss: 0.0005... Test loss: 0.00065\n",
      "Epoch: 1... Training loss: 0.00046... Test loss: 0.00059\n",
      "Epoch: 1... Training loss: 0.0004... Test loss: 0.00057\n",
      "Epoch: 1... Training loss: 0.00046... Test loss: 0.00043\n",
      "Epoch: 1... Training loss: 0.0004... Test loss: 0.00044\n",
      "Epoch: 1... Training loss: 0.0004... Test loss: 0.0004\n",
      "Epoch: 1... Training loss: 0.00033... Test loss: 0.00046\n",
      "Epoch: 1... Training loss: 0.00037... Test loss: 0.00039\n",
      "Epoch: 1... Training loss: 0.00041... Test loss: 0.00044\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00042\n",
      "Epoch: 1... Training loss: 0.00029... Test loss: 0.00032\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00033\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00033\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00037\n",
      "Epoch: 1... Training loss: 0.00026... Test loss: 0.0004\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00024\n",
      "Epoch: 1... Training loss: 0.00026... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00028\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 8e-05\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 7e-05... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 8e-05... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 8e-05\n",
      "215.07826713682152\n",
      "Epoch: 1... Training loss: 1.12426... Test loss: 0.4652\n",
      "Epoch: 1... Training loss: 0.52343... Test loss: 0.21248\n",
      "Epoch: 1... Training loss: 0.3006... Test loss: 0.10791\n",
      "Epoch: 1... Training loss: 0.1882... Test loss: 0.06896\n",
      "Epoch: 1... Training loss: 0.15787... Test loss: 0.04211\n",
      "Epoch: 1... Training loss: 0.11145... Test loss: 0.05627\n",
      "Epoch: 1... Training loss: 0.08977... Test loss: 0.0367\n",
      "Epoch: 1... Training loss: 0.07451... Test loss: 0.04436\n",
      "Epoch: 1... Training loss: 0.06832... Test loss: 0.02103\n",
      "Epoch: 1... Training loss: 0.05591... Test loss: 0.04036\n",
      "Epoch: 1... Training loss: 0.05213... Test loss: 0.01881\n",
      "Epoch: 1... Training loss: 0.0471... Test loss: 0.0314\n",
      "Epoch: 1... Training loss: 0.04496... Test loss: 0.01678\n",
      "Epoch: 1... Training loss: 0.04013... Test loss: 0.0376\n",
      "Epoch: 1... Training loss: 0.04205... Test loss: 0.01882\n",
      "Epoch: 1... Training loss: 0.0348... Test loss: 0.02211\n",
      "Epoch: 1... Training loss: 0.03463... Test loss: 0.01748\n",
      "Epoch: 1... Training loss: 0.03096... Test loss: 0.01633\n",
      "Epoch: 1... Training loss: 0.02999... Test loss: 0.01897\n",
      "Epoch: 1... Training loss: 0.02793... Test loss: 0.00878\n",
      "Epoch: 1... Training loss: 0.02564... Test loss: 0.02061\n",
      "Epoch: 1... Training loss: 0.0245... Test loss: 0.01739\n",
      "Epoch: 1... Training loss: 0.02351... Test loss: 0.01099\n",
      "Epoch: 1... Training loss: 0.02263... Test loss: 0.01924\n",
      "Epoch: 1... Training loss: 0.02113... Test loss: 0.01654\n",
      "Epoch: 1... Training loss: 0.01967... Test loss: 0.01689\n",
      "Epoch: 1... Training loss: 0.01907... Test loss: 0.013\n",
      "Epoch: 1... Training loss: 0.01837... Test loss: 0.01447\n",
      "Epoch: 1... Training loss: 0.01739... Test loss: 0.01059\n",
      "Epoch: 1... Training loss: 0.01603... Test loss: 0.0114\n",
      "Epoch: 1... Training loss: 0.01572... Test loss: 0.00935\n",
      "Epoch: 1... Training loss: 0.01501... Test loss: 0.00968\n",
      "Epoch: 1... Training loss: 0.01449... Test loss: 0.00803\n",
      "Epoch: 1... Training loss: 0.01391... Test loss: 0.01203\n",
      "Epoch: 1... Training loss: 0.01316... Test loss: 0.01064\n",
      "Epoch: 1... Training loss: 0.0128... Test loss: 0.01086\n",
      "Epoch: 1... Training loss: 0.01246... Test loss: 0.0126\n",
      "Epoch: 1... Training loss: 0.01201... Test loss: 0.00547\n",
      "Epoch: 1... Training loss: 0.01164... Test loss: 0.01278\n",
      "Epoch: 1... Training loss: 0.01135... Test loss: 0.00659\n",
      "Epoch: 1... Training loss: 0.01087... Test loss: 0.01316\n",
      "Epoch: 1... Training loss: 0.01083... Test loss: 0.00639\n",
      "Epoch: 1... Training loss: 0.01039... Test loss: 0.01141\n",
      "Epoch: 1... Training loss: 0.01027... Test loss: 0.00644\n",
      "Epoch: 1... Training loss: 0.01... Test loss: 0.00819\n",
      "Epoch: 1... Training loss: 0.00963... Test loss: 0.00637\n",
      "Epoch: 1... Training loss: 0.00945... Test loss: 0.00789\n",
      "Epoch: 1... Training loss: 0.00915... Test loss: 0.00846\n",
      "Epoch: 1... Training loss: 0.00904... Test loss: 0.0073\n",
      "Epoch: 1... Training loss: 0.00869... Test loss: 0.00929\n",
      "Epoch: 1... Training loss: 0.0083... Test loss: 0.00615\n",
      "Epoch: 1... Training loss: 0.00814... Test loss: 0.00873\n",
      "Epoch: 1... Training loss: 0.00799... Test loss: 0.00585\n",
      "Epoch: 1... Training loss: 0.00771... Test loss: 0.00825\n",
      "Epoch: 1... Training loss: 0.00759... Test loss: 0.00602\n",
      "Epoch: 1... Training loss: 0.00727... Test loss: 0.00852\n",
      "Epoch: 1... Training loss: 0.00699... Test loss: 0.00615\n",
      "Epoch: 1... Training loss: 0.00672... Test loss: 0.00882\n",
      "Epoch: 1... Training loss: 0.00643... Test loss: 0.00611\n",
      "Epoch: 1... Training loss: 0.00618... Test loss: 0.00774\n",
      "Epoch: 1... Training loss: 0.00601... Test loss: 0.00511\n",
      "Epoch: 1... Training loss: 0.0058... Test loss: 0.00639\n",
      "Epoch: 1... Training loss: 0.00571... Test loss: 0.00511\n",
      "Epoch: 1... Training loss: 0.00549... Test loss: 0.00623\n",
      "Epoch: 1... Training loss: 0.00971... Test loss: 0.0155\n",
      "Epoch: 1... Training loss: 0.00994... Test loss: 0.02304\n",
      "Epoch: 1... Training loss: 0.01013... Test loss: 0.01208\n",
      "Epoch: 1... Training loss: 0.01178... Test loss: 0.01765\n",
      "Epoch: 1... Training loss: 0.00861... Test loss: 0.01518\n",
      "Epoch: 1... Training loss: 0.00925... Test loss: 0.01197\n",
      "Epoch: 1... Training loss: 0.00802... Test loss: 0.01481\n",
      "Epoch: 1... Training loss: 0.00859... Test loss: 0.01372\n",
      "Epoch: 1... Training loss: 0.00841... Test loss: 0.01431\n",
      "Epoch: 1... Training loss: 0.0076... Test loss: 0.0133\n",
      "Epoch: 1... Training loss: 0.0072... Test loss: 0.01009\n",
      "Epoch: 1... Training loss: 0.00787... Test loss: 0.01151\n",
      "Epoch: 1... Training loss: 0.00706... Test loss: 0.00955\n",
      "Epoch: 1... Training loss: 0.00663... Test loss: 0.01186\n",
      "Epoch: 1... Training loss: 0.00634... Test loss: 0.01116\n",
      "Epoch: 1... Training loss: 0.00628... Test loss: 0.00987\n",
      "Epoch: 1... Training loss: 0.0061... Test loss: 0.01558\n",
      "Epoch: 1... Training loss: 0.00605... Test loss: 0.0099\n",
      "Epoch: 1... Training loss: 0.0056... Test loss: 0.01333\n",
      "Epoch: 1... Training loss: 0.00515... Test loss: 0.00793\n",
      "Epoch: 1... Training loss: 0.00507... Test loss: 0.00841\n",
      "Epoch: 1... Training loss: 0.00476... Test loss: 0.00713\n",
      "Epoch: 1... Training loss: 0.00482... Test loss: 0.00806\n",
      "Epoch: 1... Training loss: 0.00456... Test loss: 0.00555\n",
      "Epoch: 1... Training loss: 0.00431... Test loss: 0.00767\n",
      "Epoch: 1... Training loss: 0.00427... Test loss: 0.00549\n",
      "Epoch: 1... Training loss: 0.00398... Test loss: 0.00488\n",
      "Epoch: 1... Training loss: 0.00386... Test loss: 0.00505\n",
      "Epoch: 1... Training loss: 0.00399... Test loss: 0.005\n",
      "Epoch: 1... Training loss: 0.00356... Test loss: 0.00446\n",
      "Epoch: 1... Training loss: 0.00351... Test loss: 0.00412\n",
      "Epoch: 1... Training loss: 0.00332... Test loss: 0.00371\n",
      "Epoch: 1... Training loss: 0.00314... Test loss: 0.00452\n",
      "Epoch: 1... Training loss: 0.00315... Test loss: 0.0031\n",
      "Epoch: 1... Training loss: 0.00298... Test loss: 0.00437\n",
      "Epoch: 1... Training loss: 0.00289... Test loss: 0.00309\n",
      "Epoch: 1... Training loss: 0.00285... Test loss: 0.00407\n",
      "Epoch: 1... Training loss: 0.00276... Test loss: 0.00264\n",
      "Epoch: 1... Training loss: 0.00266... Test loss: 0.00383\n",
      "Epoch: 1... Training loss: 0.00259... Test loss: 0.00232\n",
      "Epoch: 1... Training loss: 0.00257... Test loss: 0.00346\n",
      "Epoch: 1... Training loss: 0.00244... Test loss: 0.0021\n",
      "Epoch: 1... Training loss: 0.00239... Test loss: 0.00291\n",
      "Epoch: 1... Training loss: 0.0023... Test loss: 0.00263\n",
      "Epoch: 1... Training loss: 0.00217... Test loss: 0.00261\n",
      "Epoch: 1... Training loss: 0.00221... Test loss: 0.00213\n",
      "Epoch: 1... Training loss: 0.00209... Test loss: 0.00235\n",
      "Epoch: 1... Training loss: 0.00204... Test loss: 0.00191\n",
      "Epoch: 1... Training loss: 0.00206... Test loss: 0.00242\n",
      "Epoch: 1... Training loss: 0.00182... Test loss: 0.00164\n",
      "Epoch: 1... Training loss: 0.00188... Test loss: 0.00228\n",
      "Epoch: 1... Training loss: 0.00179... Test loss: 0.0022\n",
      "Epoch: 1... Training loss: 0.00169... Test loss: 0.00196\n",
      "Epoch: 1... Training loss: 0.00171... Test loss: 0.00185\n",
      "Epoch: 1... Training loss: 0.00156... Test loss: 0.0016\n",
      "Epoch: 1... Training loss: 0.00153... Test loss: 0.00156\n",
      "Epoch: 1... Training loss: 0.00151... Test loss: 0.00158\n",
      "Epoch: 1... Training loss: 0.00148... Test loss: 0.00166\n",
      "Epoch: 1... Training loss: 0.00139... Test loss: 0.00152\n",
      "Epoch: 1... Training loss: 0.00136... Test loss: 0.00181\n",
      "Epoch: 1... Training loss: 0.0014... Test loss: 0.00132\n",
      "Epoch: 1... Training loss: 0.00129... Test loss: 0.00153\n",
      "Epoch: 1... Training loss: 0.00123... Test loss: 0.00119\n",
      "Epoch: 1... Training loss: 0.00117... Test loss: 0.0014\n",
      "Epoch: 1... Training loss: 0.00111... Test loss: 0.00122\n",
      "Epoch: 1... Training loss: 0.00106... Test loss: 0.00139\n",
      "Epoch: 1... Training loss: 0.00104... Test loss: 0.00116\n",
      "Epoch: 1... Training loss: 0.00102... Test loss: 0.00117\n",
      "Epoch: 1... Training loss: 0.00092... Test loss: 0.00117\n",
      "Epoch: 1... Training loss: 0.00093... Test loss: 0.00109\n",
      "Epoch: 1... Training loss: 0.0009... Test loss: 0.00111\n",
      "Epoch: 1... Training loss: 0.00083... Test loss: 0.0008\n",
      "Epoch: 1... Training loss: 0.00083... Test loss: 0.00077\n",
      "Epoch: 1... Training loss: 0.00069... Test loss: 0.00095\n",
      "Epoch: 1... Training loss: 0.00074... Test loss: 0.00092\n",
      "Epoch: 1... Training loss: 0.00074... Test loss: 0.0007\n",
      "Epoch: 1... Training loss: 0.00069... Test loss: 0.00069\n",
      "Epoch: 1... Training loss: 0.00061... Test loss: 0.00082\n",
      "Epoch: 1... Training loss: 0.00056... Test loss: 0.00081\n",
      "Epoch: 1... Training loss: 0.00053... Test loss: 0.00064\n",
      "Epoch: 1... Training loss: 0.0005... Test loss: 0.00056\n",
      "Epoch: 1... Training loss: 0.0005... Test loss: 0.00044\n",
      "Epoch: 1... Training loss: 0.00049... Test loss: 0.00043\n",
      "Epoch: 1... Training loss: 0.00044... Test loss: 0.00049\n",
      "Epoch: 1... Training loss: 0.00041... Test loss: 0.00057\n",
      "Epoch: 1... Training loss: 0.00038... Test loss: 0.00055\n",
      "Epoch: 1... Training loss: 0.00046... Test loss: 0.00039\n",
      "Epoch: 1... Training loss: 0.00037... Test loss: 0.0004\n",
      "Epoch: 1... Training loss: 0.00033... Test loss: 0.00041\n",
      "Epoch: 1... Training loss: 0.00037... Test loss: 0.00041\n",
      "Epoch: 1... Training loss: 0.00033... Test loss: 0.00045\n",
      "Epoch: 1... Training loss: 0.00031... Test loss: 0.00036\n",
      "Epoch: 1... Training loss: 0.00029... Test loss: 0.0003\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00033\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00028\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.00026... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00042\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 8e-05\n",
      "241.67440224892925\n",
      "Epoch: 1... Training loss: 1.20644... Test loss: 0.50926\n",
      "Epoch: 1... Training loss: 0.47642... Test loss: 0.13643\n",
      "Epoch: 1... Training loss: 0.24099... Test loss: 0.07917\n",
      "Epoch: 1... Training loss: 0.16545... Test loss: 0.06715\n",
      "Epoch: 1... Training loss: 0.11453... Test loss: 0.05044\n",
      "Epoch: 1... Training loss: 0.10733... Test loss: 0.04531\n",
      "Epoch: 1... Training loss: 0.07733... Test loss: 0.05591\n",
      "Epoch: 1... Training loss: 0.07675... Test loss: 0.09089\n",
      "Epoch: 1... Training loss: 0.05822... Test loss: 0.04366\n",
      "Epoch: 1... Training loss: 0.05257... Test loss: 0.0617\n",
      "Epoch: 1... Training loss: 0.0486... Test loss: 0.02367\n",
      "Epoch: 1... Training loss: 0.04447... Test loss: 0.04834\n",
      "Epoch: 1... Training loss: 0.0419... Test loss: 0.01891\n",
      "Epoch: 1... Training loss: 0.03618... Test loss: 0.0352\n",
      "Epoch: 1... Training loss: 0.0324... Test loss: 0.02113\n",
      "Epoch: 1... Training loss: 0.03141... Test loss: 0.03648\n",
      "Epoch: 1... Training loss: 0.02952... Test loss: 0.02127\n",
      "Epoch: 1... Training loss: 0.02801... Test loss: 0.01019\n",
      "Epoch: 1... Training loss: 0.02544... Test loss: 0.02235\n",
      "Epoch: 1... Training loss: 0.02432... Test loss: 0.03495\n",
      "Epoch: 1... Training loss: 0.0235... Test loss: 0.01159\n",
      "Epoch: 1... Training loss: 0.02255... Test loss: 0.02081\n",
      "Epoch: 1... Training loss: 0.02098... Test loss: 0.01778\n",
      "Epoch: 1... Training loss: 0.02013... Test loss: 0.00957\n",
      "Epoch: 1... Training loss: 0.01941... Test loss: 0.02307\n",
      "Epoch: 1... Training loss: 0.01914... Test loss: 0.00851\n",
      "Epoch: 1... Training loss: 0.0178... Test loss: 0.02168\n",
      "Epoch: 1... Training loss: 0.01708... Test loss: 0.00773\n",
      "Epoch: 1... Training loss: 0.01677... Test loss: 0.01545\n",
      "Epoch: 1... Training loss: 0.01612... Test loss: 0.01197\n",
      "Epoch: 1... Training loss: 0.01566... Test loss: 0.01243\n",
      "Epoch: 1... Training loss: 0.01517... Test loss: 0.01439\n",
      "Epoch: 1... Training loss: 0.01445... Test loss: 0.007\n",
      "Epoch: 1... Training loss: 0.01364... Test loss: 0.01523\n",
      "Epoch: 1... Training loss: 0.01322... Test loss: 0.00653\n",
      "Epoch: 1... Training loss: 0.01294... Test loss: 0.01333\n",
      "Epoch: 1... Training loss: 0.01249... Test loss: 0.00906\n",
      "Epoch: 1... Training loss: 0.01193... Test loss: 0.01036\n",
      "Epoch: 1... Training loss: 0.01147... Test loss: 0.01089\n",
      "Epoch: 1... Training loss: 0.01108... Test loss: 0.00664\n",
      "Epoch: 1... Training loss: 0.01073... Test loss: 0.01051\n",
      "Epoch: 1... Training loss: 0.01038... Test loss: 0.00686\n",
      "Epoch: 1... Training loss: 0.01005... Test loss: 0.00901\n",
      "Epoch: 1... Training loss: 0.00978... Test loss: 0.0064\n",
      "Epoch: 1... Training loss: 0.00942... Test loss: 0.00867\n",
      "Epoch: 1... Training loss: 0.00928... Test loss: 0.00797\n",
      "Epoch: 1... Training loss: 0.0088... Test loss: 0.00804\n",
      "Epoch: 1... Training loss: 0.00869... Test loss: 0.00858\n",
      "Epoch: 1... Training loss: 0.00822... Test loss: 0.00779\n",
      "Epoch: 1... Training loss: 0.00809... Test loss: 0.0092\n",
      "Epoch: 1... Training loss: 0.0078... Test loss: 0.00619\n",
      "Epoch: 1... Training loss: 0.00764... Test loss: 0.00811\n",
      "Epoch: 1... Training loss: 0.00735... Test loss: 0.00705\n",
      "Epoch: 1... Training loss: 0.00724... Test loss: 0.00739\n",
      "Epoch: 1... Training loss: 0.00685... Test loss: 0.00708\n",
      "Epoch: 1... Training loss: 0.00665... Test loss: 0.0065\n",
      "Epoch: 1... Training loss: 0.00648... Test loss: 0.00644\n",
      "Epoch: 1... Training loss: 0.00638... Test loss: 0.00557\n",
      "Epoch: 1... Training loss: 0.00606... Test loss: 0.00644\n",
      "Epoch: 1... Training loss: 0.00593... Test loss: 0.00527\n",
      "Epoch: 1... Training loss: 0.00567... Test loss: 0.00637\n",
      "Epoch: 1... Training loss: 0.00545... Test loss: 0.00474\n",
      "Epoch: 1... Training loss: 0.0053... Test loss: 0.00671\n",
      "Epoch: 1... Training loss: 0.00506... Test loss: 0.0048\n",
      "Epoch: 1... Training loss: 0.01358... Test loss: 0.02887\n",
      "Epoch: 1... Training loss: 0.0092... Test loss: 0.01068\n",
      "Epoch: 1... Training loss: 0.01156... Test loss: 0.01045\n",
      "Epoch: 1... Training loss: 0.00841... Test loss: 0.0155\n",
      "Epoch: 1... Training loss: 0.00858... Test loss: 0.01373\n",
      "Epoch: 1... Training loss: 0.00762... Test loss: 0.0119\n",
      "Epoch: 1... Training loss: 0.00864... Test loss: 0.01474\n",
      "Epoch: 1... Training loss: 0.00777... Test loss: 0.01189\n",
      "Epoch: 1... Training loss: 0.00671... Test loss: 0.01258\n",
      "Epoch: 1... Training loss: 0.00677... Test loss: 0.0077\n",
      "Epoch: 1... Training loss: 0.00689... Test loss: 0.01276\n",
      "Epoch: 1... Training loss: 0.00674... Test loss: 0.00652\n",
      "Epoch: 1... Training loss: 0.00634... Test loss: 0.01085\n",
      "Epoch: 1... Training loss: 0.00599... Test loss: 0.00932\n",
      "Epoch: 1... Training loss: 0.00597... Test loss: 0.00828\n",
      "Epoch: 1... Training loss: 0.00545... Test loss: 0.00839\n",
      "Epoch: 1... Training loss: 0.00546... Test loss: 0.00772\n",
      "Epoch: 1... Training loss: 0.00542... Test loss: 0.00789\n",
      "Epoch: 1... Training loss: 0.00485... Test loss: 0.00905\n",
      "Epoch: 1... Training loss: 0.00522... Test loss: 0.00566\n",
      "Epoch: 1... Training loss: 0.00479... Test loss: 0.00882\n",
      "Epoch: 1... Training loss: 0.00454... Test loss: 0.00457\n",
      "Epoch: 1... Training loss: 0.00447... Test loss: 0.00454\n",
      "Epoch: 1... Training loss: 0.0041... Test loss: 0.00514\n",
      "Epoch: 1... Training loss: 0.0041... Test loss: 0.00394\n",
      "Epoch: 1... Training loss: 0.00374... Test loss: 0.0057\n",
      "Epoch: 1... Training loss: 0.00353... Test loss: 0.00396\n",
      "Epoch: 1... Training loss: 0.00362... Test loss: 0.00489\n",
      "Epoch: 1... Training loss: 0.00344... Test loss: 0.00367\n",
      "Epoch: 1... Training loss: 0.0032... Test loss: 0.00503\n",
      "Epoch: 1... Training loss: 0.00315... Test loss: 0.00339\n",
      "Epoch: 1... Training loss: 0.00292... Test loss: 0.00435\n",
      "Epoch: 1... Training loss: 0.00314... Test loss: 0.00327\n",
      "Epoch: 1... Training loss: 0.00288... Test loss: 0.00375\n",
      "Epoch: 1... Training loss: 0.0027... Test loss: 0.00322\n",
      "Epoch: 1... Training loss: 0.00266... Test loss: 0.00404\n",
      "Epoch: 1... Training loss: 0.00284... Test loss: 0.00297\n",
      "Epoch: 1... Training loss: 0.00241... Test loss: 0.00303\n",
      "Epoch: 1... Training loss: 0.00246... Test loss: 0.00288\n",
      "Epoch: 1... Training loss: 0.00241... Test loss: 0.00328\n",
      "Epoch: 1... Training loss: 0.00249... Test loss: 0.0029\n",
      "Epoch: 1... Training loss: 0.00224... Test loss: 0.00313\n",
      "Epoch: 1... Training loss: 0.00222... Test loss: 0.00267\n",
      "Epoch: 1... Training loss: 0.00209... Test loss: 0.0029\n",
      "Epoch: 1... Training loss: 0.00218... Test loss: 0.00247\n",
      "Epoch: 1... Training loss: 0.00201... Test loss: 0.00264\n",
      "Epoch: 1... Training loss: 0.00193... Test loss: 0.00227\n",
      "Epoch: 1... Training loss: 0.00192... Test loss: 0.00218\n",
      "Epoch: 1... Training loss: 0.00181... Test loss: 0.00203\n",
      "Epoch: 1... Training loss: 0.00171... Test loss: 0.00251\n",
      "Epoch: 1... Training loss: 0.00176... Test loss: 0.00177\n",
      "Epoch: 1... Training loss: 0.00158... Test loss: 0.00219\n",
      "Epoch: 1... Training loss: 0.00152... Test loss: 0.00161\n",
      "Epoch: 1... Training loss: 0.00143... Test loss: 0.00181\n",
      "Epoch: 1... Training loss: 0.00145... Test loss: 0.00149\n",
      "Epoch: 1... Training loss: 0.00141... Test loss: 0.00149\n",
      "Epoch: 1... Training loss: 0.00132... Test loss: 0.00162\n",
      "Epoch: 1... Training loss: 0.00128... Test loss: 0.00149\n",
      "Epoch: 1... Training loss: 0.00121... Test loss: 0.00118\n",
      "Epoch: 1... Training loss: 0.0012... Test loss: 0.00168\n",
      "Epoch: 1... Training loss: 0.00109... Test loss: 0.00113\n",
      "Epoch: 1... Training loss: 0.00103... Test loss: 0.00146\n",
      "Epoch: 1... Training loss: 0.00099... Test loss: 0.00126\n",
      "Epoch: 1... Training loss: 0.00095... Test loss: 0.00145\n",
      "Epoch: 1... Training loss: 0.0009... Test loss: 0.00139\n",
      "Epoch: 1... Training loss: 0.00087... Test loss: 0.00121\n",
      "Epoch: 1... Training loss: 0.0008... Test loss: 0.00103\n",
      "Epoch: 1... Training loss: 0.00075... Test loss: 0.00121\n",
      "Epoch: 1... Training loss: 0.00075... Test loss: 0.00063\n",
      "Epoch: 1... Training loss: 0.00071... Test loss: 0.00098\n",
      "Epoch: 1... Training loss: 0.00067... Test loss: 0.00075\n",
      "Epoch: 1... Training loss: 0.00062... Test loss: 0.00065\n",
      "Epoch: 1... Training loss: 0.0006... Test loss: 0.00077\n",
      "Epoch: 1... Training loss: 0.00054... Test loss: 0.00054\n",
      "Epoch: 1... Training loss: 0.00058... Test loss: 0.00069\n",
      "Epoch: 1... Training loss: 0.00054... Test loss: 0.00061\n",
      "Epoch: 1... Training loss: 0.00053... Test loss: 0.0005\n",
      "Epoch: 1... Training loss: 0.00053... Test loss: 0.00064\n",
      "Epoch: 1... Training loss: 0.00045... Test loss: 0.00046\n",
      "Epoch: 1... Training loss: 0.00048... Test loss: 0.00042\n",
      "Epoch: 1... Training loss: 0.00042... Test loss: 0.00057\n",
      "Epoch: 1... Training loss: 0.00043... Test loss: 0.00057\n",
      "Epoch: 1... Training loss: 0.00036... Test loss: 0.00047\n",
      "Epoch: 1... Training loss: 0.00035... Test loss: 0.00041\n",
      "Epoch: 1... Training loss: 0.00035... Test loss: 0.0004\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00037\n",
      "Epoch: 1... Training loss: 0.00029... Test loss: 0.00035\n",
      "Epoch: 1... Training loss: 0.00026... Test loss: 0.00033\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00032\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00024\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 8e-05... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 8e-05... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00011\n",
      "254.26048076263396\n",
      "Epoch: 1... Training loss: 0.85098... Test loss: 0.21929\n",
      "Epoch: 1... Training loss: 0.46427... Test loss: 0.13544\n",
      "Epoch: 1... Training loss: 0.3088... Test loss: 0.06296\n",
      "Epoch: 1... Training loss: 0.20742... Test loss: 0.03797\n",
      "Epoch: 1... Training loss: 0.13897... Test loss: 0.02859\n",
      "Epoch: 1... Training loss: 0.10593... Test loss: 0.02206\n",
      "Epoch: 1... Training loss: 0.08872... Test loss: 0.01895\n",
      "Epoch: 1... Training loss: 0.07454... Test loss: 0.01488\n",
      "Epoch: 1... Training loss: 0.06448... Test loss: 0.01144\n",
      "Epoch: 1... Training loss: 0.06036... Test loss: 0.01048\n",
      "Epoch: 1... Training loss: 0.05541... Test loss: 0.00898\n",
      "Epoch: 1... Training loss: 0.0505... Test loss: 0.0086\n",
      "Epoch: 1... Training loss: 0.0457... Test loss: 0.007\n",
      "Epoch: 1... Training loss: 0.04253... Test loss: 0.007\n",
      "Epoch: 1... Training loss: 0.0384... Test loss: 0.0068\n",
      "Epoch: 1... Training loss: 0.0353... Test loss: 0.00849\n",
      "Epoch: 1... Training loss: 0.03277... Test loss: 0.00672\n",
      "Epoch: 1... Training loss: 0.0319... Test loss: 0.01024\n",
      "Epoch: 1... Training loss: 0.02962... Test loss: 0.00439\n",
      "Epoch: 1... Training loss: 0.02713... Test loss: 0.01182\n",
      "Epoch: 1... Training loss: 0.02625... Test loss: 0.00237\n",
      "Epoch: 1... Training loss: 0.02522... Test loss: 0.00923\n",
      "Epoch: 1... Training loss: 0.02366... Test loss: 0.00285\n",
      "Epoch: 1... Training loss: 0.02325... Test loss: 0.01022\n",
      "Epoch: 1... Training loss: 0.02073... Test loss: 0.00344\n",
      "Epoch: 1... Training loss: 0.02024... Test loss: 0.00995\n",
      "Epoch: 1... Training loss: 0.01904... Test loss: 0.00381\n",
      "Epoch: 1... Training loss: 0.01866... Test loss: 0.01139\n",
      "Epoch: 1... Training loss: 0.01754... Test loss: 0.00345\n",
      "Epoch: 1... Training loss: 0.01714... Test loss: 0.00828\n",
      "Epoch: 1... Training loss: 0.0162... Test loss: 0.00489\n",
      "Epoch: 1... Training loss: 0.01585... Test loss: 0.00734\n",
      "Epoch: 1... Training loss: 0.01507... Test loss: 0.00713\n",
      "Epoch: 1... Training loss: 0.01462... Test loss: 0.00688\n",
      "Epoch: 1... Training loss: 0.01428... Test loss: 0.00963\n",
      "Epoch: 1... Training loss: 0.01379... Test loss: 0.00438\n",
      "Epoch: 1... Training loss: 0.01314... Test loss: 0.01064\n",
      "Epoch: 1... Training loss: 0.01266... Test loss: 0.0043\n",
      "Epoch: 1... Training loss: 0.01225... Test loss: 0.00926\n",
      "Epoch: 1... Training loss: 0.01187... Test loss: 0.0057\n",
      "Epoch: 1... Training loss: 0.01141... Test loss: 0.00941\n",
      "Epoch: 1... Training loss: 0.01129... Test loss: 0.00575\n",
      "Epoch: 1... Training loss: 0.01077... Test loss: 0.00945\n",
      "Epoch: 1... Training loss: 0.01037... Test loss: 0.00544\n",
      "Epoch: 1... Training loss: 0.01004... Test loss: 0.00887\n",
      "Epoch: 1... Training loss: 0.00969... Test loss: 0.00632\n",
      "Epoch: 1... Training loss: 0.00962... Test loss: 0.00817\n",
      "Epoch: 1... Training loss: 0.00884... Test loss: 0.00708\n",
      "Epoch: 1... Training loss: 0.00861... Test loss: 0.00933\n",
      "Epoch: 1... Training loss: 0.00822... Test loss: 0.00721\n",
      "Epoch: 1... Training loss: 0.00797... Test loss: 0.00778\n",
      "Epoch: 1... Training loss: 0.00773... Test loss: 0.00593\n",
      "Epoch: 1... Training loss: 0.00758... Test loss: 0.00874\n",
      "Epoch: 1... Training loss: 0.00734... Test loss: 0.00575\n",
      "Epoch: 1... Training loss: 0.0072... Test loss: 0.00713\n",
      "Epoch: 1... Training loss: 0.00688... Test loss: 0.00587\n",
      "Epoch: 1... Training loss: 0.0068... Test loss: 0.00715\n",
      "Epoch: 1... Training loss: 0.00664... Test loss: 0.00695\n",
      "Epoch: 1... Training loss: 0.00636... Test loss: 0.00753\n",
      "Epoch: 1... Training loss: 0.00617... Test loss: 0.00641\n",
      "Epoch: 1... Training loss: 0.00595... Test loss: 0.00775\n",
      "Epoch: 1... Training loss: 0.00579... Test loss: 0.00657\n",
      "Epoch: 1... Training loss: 0.00551... Test loss: 0.00768\n",
      "Epoch: 1... Training loss: 0.00542... Test loss: 0.00652\n",
      "Epoch: 1... Training loss: 0.00925... Test loss: 0.02104\n",
      "Epoch: 1... Training loss: 0.01304... Test loss: 0.01489\n",
      "Epoch: 1... Training loss: 0.00877... Test loss: 0.0152\n",
      "Epoch: 1... Training loss: 0.00991... Test loss: 0.00957\n",
      "Epoch: 1... Training loss: 0.0089... Test loss: 0.01792\n",
      "Epoch: 1... Training loss: 0.00909... Test loss: 0.0097\n",
      "Epoch: 1... Training loss: 0.00883... Test loss: 0.01496\n",
      "Epoch: 1... Training loss: 0.00883... Test loss: 0.01198\n",
      "Epoch: 1... Training loss: 0.00772... Test loss: 0.01247\n",
      "Epoch: 1... Training loss: 0.00907... Test loss: 0.01428\n",
      "Epoch: 1... Training loss: 0.00755... Test loss: 0.00973\n",
      "Epoch: 1... Training loss: 0.00733... Test loss: 0.01131\n",
      "Epoch: 1... Training loss: 0.00706... Test loss: 0.01003\n",
      "Epoch: 1... Training loss: 0.00616... Test loss: 0.00949\n",
      "Epoch: 1... Training loss: 0.00639... Test loss: 0.01192\n",
      "Epoch: 1... Training loss: 0.00588... Test loss: 0.00917\n",
      "Epoch: 1... Training loss: 0.00667... Test loss: 0.01034\n",
      "Epoch: 1... Training loss: 0.00557... Test loss: 0.00947\n",
      "Epoch: 1... Training loss: 0.00552... Test loss: 0.0063\n",
      "Epoch: 1... Training loss: 0.00515... Test loss: 0.00915\n",
      "Epoch: 1... Training loss: 0.00524... Test loss: 0.00475\n",
      "Epoch: 1... Training loss: 0.00507... Test loss: 0.00834\n",
      "Epoch: 1... Training loss: 0.00467... Test loss: 0.00582\n",
      "Epoch: 1... Training loss: 0.00451... Test loss: 0.00529\n",
      "Epoch: 1... Training loss: 0.00442... Test loss: 0.00558\n",
      "Epoch: 1... Training loss: 0.00419... Test loss: 0.00452\n",
      "Epoch: 1... Training loss: 0.00405... Test loss: 0.00498\n",
      "Epoch: 1... Training loss: 0.00392... Test loss: 0.00459\n",
      "Epoch: 1... Training loss: 0.00378... Test loss: 0.00438\n",
      "Epoch: 1... Training loss: 0.00375... Test loss: 0.00473\n",
      "Epoch: 1... Training loss: 0.00363... Test loss: 0.00365\n",
      "Epoch: 1... Training loss: 0.0034... Test loss: 0.00413\n",
      "Epoch: 1... Training loss: 0.00334... Test loss: 0.00388\n",
      "Epoch: 1... Training loss: 0.00314... Test loss: 0.0042\n",
      "Epoch: 1... Training loss: 0.00311... Test loss: 0.00387\n",
      "Epoch: 1... Training loss: 0.00311... Test loss: 0.00315\n",
      "Epoch: 1... Training loss: 0.00306... Test loss: 0.00385\n",
      "Epoch: 1... Training loss: 0.00282... Test loss: 0.00327\n",
      "Epoch: 1... Training loss: 0.00279... Test loss: 0.00337\n",
      "Epoch: 1... Training loss: 0.00272... Test loss: 0.00302\n",
      "Epoch: 1... Training loss: 0.00256... Test loss: 0.00338\n",
      "Epoch: 1... Training loss: 0.00258... Test loss: 0.00308\n",
      "Epoch: 1... Training loss: 0.00241... Test loss: 0.00297\n",
      "Epoch: 1... Training loss: 0.0024... Test loss: 0.00293\n",
      "Epoch: 1... Training loss: 0.0023... Test loss: 0.00272\n",
      "Epoch: 1... Training loss: 0.00225... Test loss: 0.00246\n",
      "Epoch: 1... Training loss: 0.00226... Test loss: 0.00267\n",
      "Epoch: 1... Training loss: 0.00208... Test loss: 0.00218\n",
      "Epoch: 1... Training loss: 0.00205... Test loss: 0.00256\n",
      "Epoch: 1... Training loss: 0.00191... Test loss: 0.00225\n",
      "Epoch: 1... Training loss: 0.00214... Test loss: 0.00252\n",
      "Epoch: 1... Training loss: 0.00177... Test loss: 0.00245\n",
      "Epoch: 1... Training loss: 0.00182... Test loss: 0.00228\n",
      "Epoch: 1... Training loss: 0.0017... Test loss: 0.00231\n",
      "Epoch: 1... Training loss: 0.00167... Test loss: 0.00203\n",
      "Epoch: 1... Training loss: 0.00158... Test loss: 0.00226\n",
      "Epoch: 1... Training loss: 0.00162... Test loss: 0.00192\n",
      "Epoch: 1... Training loss: 0.00147... Test loss: 0.00208\n",
      "Epoch: 1... Training loss: 0.00151... Test loss: 0.00156\n",
      "Epoch: 1... Training loss: 0.00135... Test loss: 0.00209\n",
      "Epoch: 1... Training loss: 0.00139... Test loss: 0.0015\n",
      "Epoch: 1... Training loss: 0.00131... Test loss: 0.00166\n",
      "Epoch: 1... Training loss: 0.00133... Test loss: 0.0013\n",
      "Epoch: 1... Training loss: 0.00118... Test loss: 0.00124\n",
      "Epoch: 1... Training loss: 0.00117... Test loss: 0.00116\n",
      "Epoch: 1... Training loss: 0.0012... Test loss: 0.001\n",
      "Epoch: 1... Training loss: 0.00104... Test loss: 0.001\n",
      "Epoch: 1... Training loss: 0.00103... Test loss: 0.00107\n",
      "Epoch: 1... Training loss: 0.00096... Test loss: 0.00109\n",
      "Epoch: 1... Training loss: 0.00095... Test loss: 0.00119\n",
      "Epoch: 1... Training loss: 0.00089... Test loss: 0.00089\n",
      "Epoch: 1... Training loss: 0.0009... Test loss: 0.00121\n",
      "Epoch: 1... Training loss: 0.00087... Test loss: 0.00085\n",
      "Epoch: 1... Training loss: 0.00082... Test loss: 0.00085\n",
      "Epoch: 1... Training loss: 0.00071... Test loss: 0.0008\n",
      "Epoch: 1... Training loss: 0.00074... Test loss: 0.00072\n",
      "Epoch: 1... Training loss: 0.00063... Test loss: 0.00077\n",
      "Epoch: 1... Training loss: 0.00058... Test loss: 0.00063\n",
      "Epoch: 1... Training loss: 0.00054... Test loss: 0.00074\n",
      "Epoch: 1... Training loss: 0.00057... Test loss: 0.00055\n",
      "Epoch: 1... Training loss: 0.00054... Test loss: 0.00063\n",
      "Epoch: 1... Training loss: 0.00051... Test loss: 0.00054\n",
      "Epoch: 1... Training loss: 0.00046... Test loss: 0.00057\n",
      "Epoch: 1... Training loss: 0.00048... Test loss: 0.00034\n",
      "Epoch: 1... Training loss: 0.00046... Test loss: 0.00059\n",
      "Epoch: 1... Training loss: 0.00046... Test loss: 0.00041\n",
      "Epoch: 1... Training loss: 0.00046... Test loss: 0.00055\n",
      "Epoch: 1... Training loss: 0.0004... Test loss: 0.00037\n",
      "Epoch: 1... Training loss: 0.00049... Test loss: 0.00049\n",
      "Epoch: 1... Training loss: 0.00038... Test loss: 0.00035\n",
      "Epoch: 1... Training loss: 0.00037... Test loss: 0.00038\n",
      "Epoch: 1... Training loss: 0.00035... Test loss: 0.00042\n",
      "Epoch: 1... Training loss: 0.00034... Test loss: 0.00028\n",
      "Epoch: 1... Training loss: 0.00034... Test loss: 0.00034\n",
      "Epoch: 1... Training loss: 0.00043... Test loss: 0.00037\n",
      "Epoch: 1... Training loss: 0.00033... Test loss: 0.00044\n",
      "Epoch: 1... Training loss: 0.00036... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00029... Test loss: 0.00034\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.0004\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00032\n",
      "Epoch: 1... Training loss: 0.00026... Test loss: 0.00032\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00032\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00024\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.0001\n",
      "234.52720852359198\n",
      "Epoch: 1... Training loss: 1.15199... Test loss: 0.45982\n",
      "Epoch: 1... Training loss: 0.5106... Test loss: 0.1784\n",
      "Epoch: 1... Training loss: 0.33424... Test loss: 0.11412\n",
      "Epoch: 1... Training loss: 0.22151... Test loss: 0.08127\n",
      "Epoch: 1... Training loss: 0.1495... Test loss: 0.06231\n",
      "Epoch: 1... Training loss: 0.12411... Test loss: 0.04672\n",
      "Epoch: 1... Training loss: 0.09027... Test loss: 0.06088\n",
      "Epoch: 1... Training loss: 0.07917... Test loss: 0.02226\n",
      "Epoch: 1... Training loss: 0.07158... Test loss: 0.05108\n",
      "Epoch: 1... Training loss: 0.0639... Test loss: 0.01612\n",
      "Epoch: 1... Training loss: 0.05741... Test loss: 0.04042\n",
      "Epoch: 1... Training loss: 0.05355... Test loss: 0.01521\n",
      "Epoch: 1... Training loss: 0.04673... Test loss: 0.03367\n",
      "Epoch: 1... Training loss: 0.04712... Test loss: 0.0185\n",
      "Epoch: 1... Training loss: 0.0408... Test loss: 0.01175\n",
      "Epoch: 1... Training loss: 0.03765... Test loss: 0.01999\n",
      "Epoch: 1... Training loss: 0.03639... Test loss: 0.02421\n",
      "Epoch: 1... Training loss: 0.0323... Test loss: 0.01227\n",
      "Epoch: 1... Training loss: 0.0296... Test loss: 0.01864\n",
      "Epoch: 1... Training loss: 0.0285... Test loss: 0.01795\n",
      "Epoch: 1... Training loss: 0.02671... Test loss: 0.01659\n",
      "Epoch: 1... Training loss: 0.02538... Test loss: 0.02468\n",
      "Epoch: 1... Training loss: 0.02386... Test loss: 0.01195\n",
      "Epoch: 1... Training loss: 0.02214... Test loss: 0.02687\n",
      "Epoch: 1... Training loss: 0.02125... Test loss: 0.01117\n",
      "Epoch: 1... Training loss: 0.02014... Test loss: 0.02427\n",
      "Epoch: 1... Training loss: 0.02147... Test loss: 0.0139\n",
      "Epoch: 1... Training loss: 0.01829... Test loss: 0.01078\n",
      "Epoch: 1... Training loss: 0.01731... Test loss: 0.01534\n",
      "Epoch: 1... Training loss: 0.01646... Test loss: 0.01205\n",
      "Epoch: 1... Training loss: 0.01542... Test loss: 0.0155\n",
      "Epoch: 1... Training loss: 0.01498... Test loss: 0.0117\n",
      "Epoch: 1... Training loss: 0.01461... Test loss: 0.01116\n",
      "Epoch: 1... Training loss: 0.01414... Test loss: 0.00946\n",
      "Epoch: 1... Training loss: 0.01341... Test loss: 0.01471\n",
      "Epoch: 1... Training loss: 0.01316... Test loss: 0.0072\n",
      "Epoch: 1... Training loss: 0.01255... Test loss: 0.01592\n",
      "Epoch: 1... Training loss: 0.01202... Test loss: 0.00731\n",
      "Epoch: 1... Training loss: 0.01159... Test loss: 0.01434\n",
      "Epoch: 1... Training loss: 0.011... Test loss: 0.00658\n",
      "Epoch: 1... Training loss: 0.01069... Test loss: 0.01307\n",
      "Epoch: 1... Training loss: 0.01045... Test loss: 0.00722\n",
      "Epoch: 1... Training loss: 0.01003... Test loss: 0.01047\n",
      "Epoch: 1... Training loss: 0.00971... Test loss: 0.00914\n",
      "Epoch: 1... Training loss: 0.00947... Test loss: 0.00728\n",
      "Epoch: 1... Training loss: 0.00923... Test loss: 0.00997\n",
      "Epoch: 1... Training loss: 0.00899... Test loss: 0.00618\n",
      "Epoch: 1... Training loss: 0.00857... Test loss: 0.00932\n",
      "Epoch: 1... Training loss: 0.00837... Test loss: 0.00708\n",
      "Epoch: 1... Training loss: 0.00807... Test loss: 0.01007\n",
      "Epoch: 1... Training loss: 0.00782... Test loss: 0.00649\n",
      "Epoch: 1... Training loss: 0.00761... Test loss: 0.00863\n",
      "Epoch: 1... Training loss: 0.00746... Test loss: 0.00553\n",
      "Epoch: 1... Training loss: 0.00726... Test loss: 0.00761\n",
      "Epoch: 1... Training loss: 0.00696... Test loss: 0.00534\n",
      "Epoch: 1... Training loss: 0.00669... Test loss: 0.00748\n",
      "Epoch: 1... Training loss: 0.0065... Test loss: 0.00541\n",
      "Epoch: 1... Training loss: 0.00632... Test loss: 0.00662\n",
      "Epoch: 1... Training loss: 0.00612... Test loss: 0.00591\n",
      "Epoch: 1... Training loss: 0.00603... Test loss: 0.00616\n",
      "Epoch: 1... Training loss: 0.00587... Test loss: 0.00605\n",
      "Epoch: 1... Training loss: 0.00572... Test loss: 0.00545\n",
      "Epoch: 1... Training loss: 0.0056... Test loss: 0.00566\n",
      "Epoch: 1... Training loss: 0.00542... Test loss: 0.00486\n",
      "Epoch: 1... Training loss: 0.01429... Test loss: 0.02144\n",
      "Epoch: 1... Training loss: 0.01078... Test loss: 0.0219\n",
      "Epoch: 1... Training loss: 0.01136... Test loss: 0.01278\n",
      "Epoch: 1... Training loss: 0.01117... Test loss: 0.01351\n",
      "Epoch: 1... Training loss: 0.00996... Test loss: 0.01465\n",
      "Epoch: 1... Training loss: 0.00943... Test loss: 0.0131\n",
      "Epoch: 1... Training loss: 0.00914... Test loss: 0.01426\n",
      "Epoch: 1... Training loss: 0.00802... Test loss: 0.01784\n",
      "Epoch: 1... Training loss: 0.00863... Test loss: 0.01056\n",
      "Epoch: 1... Training loss: 0.00811... Test loss: 0.01342\n",
      "Epoch: 1... Training loss: 0.0074... Test loss: 0.01108\n",
      "Epoch: 1... Training loss: 0.00759... Test loss: 0.01053\n",
      "Epoch: 1... Training loss: 0.00668... Test loss: 0.01214\n",
      "Epoch: 1... Training loss: 0.00653... Test loss: 0.00837\n",
      "Epoch: 1... Training loss: 0.00667... Test loss: 0.00957\n",
      "Epoch: 1... Training loss: 0.00656... Test loss: 0.00767\n",
      "Epoch: 1... Training loss: 0.00652... Test loss: 0.00833\n",
      "Epoch: 1... Training loss: 0.00576... Test loss: 0.00757\n",
      "Epoch: 1... Training loss: 0.00559... Test loss: 0.00763\n",
      "Epoch: 1... Training loss: 0.00559... Test loss: 0.00696\n",
      "Epoch: 1... Training loss: 0.00509... Test loss: 0.00661\n",
      "Epoch: 1... Training loss: 0.00514... Test loss: 0.00573\n",
      "Epoch: 1... Training loss: 0.00481... Test loss: 0.00644\n",
      "Epoch: 1... Training loss: 0.00486... Test loss: 0.00541\n",
      "Epoch: 1... Training loss: 0.00465... Test loss: 0.00585\n",
      "Epoch: 1... Training loss: 0.00445... Test loss: 0.00468\n",
      "Epoch: 1... Training loss: 0.00423... Test loss: 0.00601\n",
      "Epoch: 1... Training loss: 0.00413... Test loss: 0.00451\n",
      "Epoch: 1... Training loss: 0.00397... Test loss: 0.00461\n",
      "Epoch: 1... Training loss: 0.00367... Test loss: 0.00519\n",
      "Epoch: 1... Training loss: 0.00364... Test loss: 0.00491\n",
      "Epoch: 1... Training loss: 0.00354... Test loss: 0.00531\n",
      "Epoch: 1... Training loss: 0.00327... Test loss: 0.00462\n",
      "Epoch: 1... Training loss: 0.00326... Test loss: 0.00439\n",
      "Epoch: 1... Training loss: 0.00314... Test loss: 0.00339\n",
      "Epoch: 1... Training loss: 0.003... Test loss: 0.00359\n",
      "Epoch: 1... Training loss: 0.00306... Test loss: 0.00388\n",
      "Epoch: 1... Training loss: 0.00285... Test loss: 0.00347\n",
      "Epoch: 1... Training loss: 0.00282... Test loss: 0.0035\n",
      "Epoch: 1... Training loss: 0.00276... Test loss: 0.00347\n",
      "Epoch: 1... Training loss: 0.00274... Test loss: 0.00327\n",
      "Epoch: 1... Training loss: 0.00257... Test loss: 0.003\n",
      "Epoch: 1... Training loss: 0.00253... Test loss: 0.00318\n",
      "Epoch: 1... Training loss: 0.00238... Test loss: 0.00331\n",
      "Epoch: 1... Training loss: 0.00247... Test loss: 0.00326\n",
      "Epoch: 1... Training loss: 0.00225... Test loss: 0.00315\n",
      "Epoch: 1... Training loss: 0.00226... Test loss: 0.0027\n",
      "Epoch: 1... Training loss: 0.00207... Test loss: 0.00263\n",
      "Epoch: 1... Training loss: 0.00199... Test loss: 0.00242\n",
      "Epoch: 1... Training loss: 0.002... Test loss: 0.00253\n",
      "Epoch: 1... Training loss: 0.00188... Test loss: 0.00294\n",
      "Epoch: 1... Training loss: 0.00181... Test loss: 0.00222\n",
      "Epoch: 1... Training loss: 0.00174... Test loss: 0.00262\n",
      "Epoch: 1... Training loss: 0.00172... Test loss: 0.00224\n",
      "Epoch: 1... Training loss: 0.00167... Test loss: 0.00194\n",
      "Epoch: 1... Training loss: 0.0016... Test loss: 0.00208\n",
      "Epoch: 1... Training loss: 0.00153... Test loss: 0.00184\n",
      "Epoch: 1... Training loss: 0.00147... Test loss: 0.00152\n",
      "Epoch: 1... Training loss: 0.00147... Test loss: 0.00183\n",
      "Epoch: 1... Training loss: 0.00147... Test loss: 0.00183\n",
      "Epoch: 1... Training loss: 0.00137... Test loss: 0.00181\n",
      "Epoch: 1... Training loss: 0.0013... Test loss: 0.00179\n",
      "Epoch: 1... Training loss: 0.00129... Test loss: 0.00151\n",
      "Epoch: 1... Training loss: 0.00118... Test loss: 0.0018\n",
      "Epoch: 1... Training loss: 0.0012... Test loss: 0.00142\n",
      "Epoch: 1... Training loss: 0.00116... Test loss: 0.00147\n",
      "Epoch: 1... Training loss: 0.00117... Test loss: 0.00114\n",
      "Epoch: 1... Training loss: 0.00102... Test loss: 0.0016\n",
      "Epoch: 1... Training loss: 0.00108... Test loss: 0.00106\n",
      "Epoch: 1... Training loss: 0.00093... Test loss: 0.00148\n",
      "Epoch: 1... Training loss: 0.00093... Test loss: 0.00089\n",
      "Epoch: 1... Training loss: 0.00082... Test loss: 0.00109\n",
      "Epoch: 1... Training loss: 0.00082... Test loss: 0.00094\n",
      "Epoch: 1... Training loss: 0.00079... Test loss: 0.00079\n",
      "Epoch: 1... Training loss: 0.00077... Test loss: 0.0008\n",
      "Epoch: 1... Training loss: 0.00074... Test loss: 0.00074\n",
      "Epoch: 1... Training loss: 0.00077... Test loss: 0.00069\n",
      "Epoch: 1... Training loss: 0.00066... Test loss: 0.00073\n",
      "Epoch: 1... Training loss: 0.00066... Test loss: 0.00054\n",
      "Epoch: 1... Training loss: 0.00059... Test loss: 0.00075\n",
      "Epoch: 1... Training loss: 0.0006... Test loss: 0.00045\n",
      "Epoch: 1... Training loss: 0.00058... Test loss: 0.00058\n",
      "Epoch: 1... Training loss: 0.00055... Test loss: 0.00045\n",
      "Epoch: 1... Training loss: 0.00054... Test loss: 0.00066\n",
      "Epoch: 1... Training loss: 0.00056... Test loss: 0.00051\n",
      "Epoch: 1... Training loss: 0.00047... Test loss: 0.00059\n",
      "Epoch: 1... Training loss: 0.00044... Test loss: 0.00049\n",
      "Epoch: 1... Training loss: 0.00041... Test loss: 0.00057\n",
      "Epoch: 1... Training loss: 0.0004... Test loss: 0.00044\n",
      "Epoch: 1... Training loss: 0.00044... Test loss: 0.00051\n",
      "Epoch: 1... Training loss: 0.00034... Test loss: 0.00038\n",
      "Epoch: 1... Training loss: 0.00038... Test loss: 0.00057\n",
      "Epoch: 1... Training loss: 0.00039... Test loss: 0.00039\n",
      "Epoch: 1... Training loss: 0.00034... Test loss: 0.00041\n",
      "Epoch: 1... Training loss: 0.00033... Test loss: 0.00031\n",
      "Epoch: 1... Training loss: 0.00037... Test loss: 0.00032\n",
      "Epoch: 1... Training loss: 0.00031... Test loss: 0.00031\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00032\n",
      "Epoch: 1... Training loss: 0.00026... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00031\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00034\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00024\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 8e-05... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 8e-05... Test loss: 8e-05\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 7e-05... Test loss: 8e-05\n",
      "Epoch: 1... Training loss: 8e-05... Test loss: 8e-05\n",
      "Epoch: 1... Training loss: 8e-05... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 8e-05... Test loss: 8e-05\n",
      "Epoch: 1... Training loss: 8e-05... Test loss: 7e-05\n",
      "Epoch: 1... Training loss: 7e-05... Test loss: 7e-05\n",
      "Epoch: 1... Training loss: 8e-05... Test loss: 7e-05\n",
      "Epoch: 1... Training loss: 7e-05... Test loss: 7e-05\n",
      "229.2102989278501\n",
      "Epoch: 1... Training loss: 1.17623... Test loss: 0.52722\n",
      "Epoch: 1... Training loss: 0.54074... Test loss: 0.2086\n",
      "Epoch: 1... Training loss: 0.32085... Test loss: 0.11985\n",
      "Epoch: 1... Training loss: 0.22858... Test loss: 0.09037\n",
      "Epoch: 1... Training loss: 0.16291... Test loss: 0.07457\n",
      "Epoch: 1... Training loss: 0.13074... Test loss: 0.05493\n",
      "Epoch: 1... Training loss: 0.10656... Test loss: 0.08507\n",
      "Epoch: 1... Training loss: 0.09161... Test loss: 0.03125\n",
      "Epoch: 1... Training loss: 0.08164... Test loss: 0.06957\n",
      "Epoch: 1... Training loss: 0.07029... Test loss: 0.03023\n",
      "Epoch: 1... Training loss: 0.06173... Test loss: 0.05386\n",
      "Epoch: 1... Training loss: 0.05434... Test loss: 0.04883\n",
      "Epoch: 1... Training loss: 0.05024... Test loss: 0.06245\n",
      "Epoch: 1... Training loss: 0.04733... Test loss: 0.02583\n",
      "Epoch: 1... Training loss: 0.04281... Test loss: 0.06079\n",
      "Epoch: 1... Training loss: 0.03915... Test loss: 0.0309\n",
      "Epoch: 1... Training loss: 0.03647... Test loss: 0.04983\n",
      "Epoch: 1... Training loss: 0.03378... Test loss: 0.02764\n",
      "Epoch: 1... Training loss: 0.03103... Test loss: 0.0216\n",
      "Epoch: 1... Training loss: 0.02979... Test loss: 0.04734\n",
      "Epoch: 1... Training loss: 0.02796... Test loss: 0.01468\n",
      "Epoch: 1... Training loss: 0.02652... Test loss: 0.0416\n",
      "Epoch: 1... Training loss: 0.02491... Test loss: 0.01558\n",
      "Epoch: 1... Training loss: 0.02379... Test loss: 0.03508\n",
      "Epoch: 1... Training loss: 0.02197... Test loss: 0.02022\n",
      "Epoch: 1... Training loss: 0.02068... Test loss: 0.02423\n",
      "Epoch: 1... Training loss: 0.01965... Test loss: 0.03122\n",
      "Epoch: 1... Training loss: 0.01856... Test loss: 0.01382\n",
      "Epoch: 1... Training loss: 0.01761... Test loss: 0.03353\n",
      "Epoch: 1... Training loss: 0.01713... Test loss: 0.01396\n",
      "Epoch: 1... Training loss: 0.01641... Test loss: 0.03052\n",
      "Epoch: 1... Training loss: 0.01606... Test loss: 0.01184\n",
      "Epoch: 1... Training loss: 0.01534... Test loss: 0.02478\n",
      "Epoch: 1... Training loss: 0.01463... Test loss: 0.01287\n",
      "Epoch: 1... Training loss: 0.01388... Test loss: 0.02588\n",
      "Epoch: 1... Training loss: 0.0136... Test loss: 0.01367\n",
      "Epoch: 1... Training loss: 0.01292... Test loss: 0.02397\n",
      "Epoch: 1... Training loss: 0.01264... Test loss: 0.01096\n",
      "Epoch: 1... Training loss: 0.01224... Test loss: 0.02074\n",
      "Epoch: 1... Training loss: 0.01218... Test loss: 0.01368\n",
      "Epoch: 1... Training loss: 0.01129... Test loss: 0.01273\n",
      "Epoch: 1... Training loss: 0.01109... Test loss: 0.01443\n",
      "Epoch: 1... Training loss: 0.01063... Test loss: 0.01235\n",
      "Epoch: 1... Training loss: 0.01035... Test loss: 0.01435\n",
      "Epoch: 1... Training loss: 0.00994... Test loss: 0.00863\n",
      "Epoch: 1... Training loss: 0.00952... Test loss: 0.0142\n",
      "Epoch: 1... Training loss: 0.00925... Test loss: 0.00824\n",
      "Epoch: 1... Training loss: 0.00911... Test loss: 0.0123\n",
      "Epoch: 1... Training loss: 0.00872... Test loss: 0.0079\n",
      "Epoch: 1... Training loss: 0.0085... Test loss: 0.01117\n",
      "Epoch: 1... Training loss: 0.00808... Test loss: 0.00844\n",
      "Epoch: 1... Training loss: 0.00797... Test loss: 0.01004\n",
      "Epoch: 1... Training loss: 0.00769... Test loss: 0.00872\n",
      "Epoch: 1... Training loss: 0.00748... Test loss: 0.00944\n",
      "Epoch: 1... Training loss: 0.00711... Test loss: 0.00745\n",
      "Epoch: 1... Training loss: 0.00691... Test loss: 0.00875\n",
      "Epoch: 1... Training loss: 0.00672... Test loss: 0.00653\n",
      "Epoch: 1... Training loss: 0.00642... Test loss: 0.00776\n",
      "Epoch: 1... Training loss: 0.00633... Test loss: 0.00634\n",
      "Epoch: 1... Training loss: 0.00605... Test loss: 0.0073\n",
      "Epoch: 1... Training loss: 0.00587... Test loss: 0.00625\n",
      "Epoch: 1... Training loss: 0.00561... Test loss: 0.00716\n",
      "Epoch: 1... Training loss: 0.00552... Test loss: 0.00562\n",
      "Epoch: 1... Training loss: 0.00527... Test loss: 0.00636\n",
      "Epoch: 1... Training loss: 0.00767... Test loss: 0.01254\n",
      "Epoch: 1... Training loss: 0.00995... Test loss: 0.01623\n",
      "Epoch: 1... Training loss: 0.00858... Test loss: 0.01233\n",
      "Epoch: 1... Training loss: 0.01019... Test loss: 0.0171\n",
      "Epoch: 1... Training loss: 0.00879... Test loss: 0.01181\n",
      "Epoch: 1... Training loss: 0.00958... Test loss: 0.01759\n",
      "Epoch: 1... Training loss: 0.00753... Test loss: 0.01354\n",
      "Epoch: 1... Training loss: 0.00834... Test loss: 0.01586\n",
      "Epoch: 1... Training loss: 0.00728... Test loss: 0.01234\n",
      "Epoch: 1... Training loss: 0.00676... Test loss: 0.01252\n",
      "Epoch: 1... Training loss: 0.00663... Test loss: 0.00834\n",
      "Epoch: 1... Training loss: 0.00688... Test loss: 0.01658\n",
      "Epoch: 1... Training loss: 0.00633... Test loss: 0.00769\n",
      "Epoch: 1... Training loss: 0.00594... Test loss: 0.01044\n",
      "Epoch: 1... Training loss: 0.00634... Test loss: 0.00656\n",
      "Epoch: 1... Training loss: 0.00561... Test loss: 0.00901\n",
      "Epoch: 1... Training loss: 0.00552... Test loss: 0.00678\n",
      "Epoch: 1... Training loss: 0.00537... Test loss: 0.00832\n",
      "Epoch: 1... Training loss: 0.00566... Test loss: 0.00594\n",
      "Epoch: 1... Training loss: 0.00485... Test loss: 0.00685\n",
      "Epoch: 1... Training loss: 0.00507... Test loss: 0.00571\n",
      "Epoch: 1... Training loss: 0.00455... Test loss: 0.00681\n",
      "Epoch: 1... Training loss: 0.00426... Test loss: 0.00577\n",
      "Epoch: 1... Training loss: 0.00427... Test loss: 0.00512\n",
      "Epoch: 1... Training loss: 0.00423... Test loss: 0.00563\n",
      "Epoch: 1... Training loss: 0.00433... Test loss: 0.00568\n",
      "Epoch: 1... Training loss: 0.00373... Test loss: 0.0051\n",
      "Epoch: 1... Training loss: 0.00394... Test loss: 0.00349\n",
      "Epoch: 1... Training loss: 0.0036... Test loss: 0.00523\n",
      "Epoch: 1... Training loss: 0.00333... Test loss: 0.00328\n",
      "Epoch: 1... Training loss: 0.00327... Test loss: 0.005\n",
      "Epoch: 1... Training loss: 0.00327... Test loss: 0.00333\n",
      "Epoch: 1... Training loss: 0.00305... Test loss: 0.00515\n",
      "Epoch: 1... Training loss: 0.00311... Test loss: 0.00327\n",
      "Epoch: 1... Training loss: 0.00283... Test loss: 0.00333\n",
      "Epoch: 1... Training loss: 0.00269... Test loss: 0.00261\n",
      "Epoch: 1... Training loss: 0.00262... Test loss: 0.00336\n",
      "Epoch: 1... Training loss: 0.00269... Test loss: 0.00294\n",
      "Epoch: 1... Training loss: 0.00253... Test loss: 0.00307\n",
      "Epoch: 1... Training loss: 0.00247... Test loss: 0.0027\n",
      "Epoch: 1... Training loss: 0.00237... Test loss: 0.00307\n",
      "Epoch: 1... Training loss: 0.00224... Test loss: 0.00378\n",
      "Epoch: 1... Training loss: 0.00219... Test loss: 0.00292\n",
      "Epoch: 1... Training loss: 0.00202... Test loss: 0.00314\n",
      "Epoch: 1... Training loss: 0.00198... Test loss: 0.00238\n",
      "Epoch: 1... Training loss: 0.0019... Test loss: 0.00252\n",
      "Epoch: 1... Training loss: 0.00185... Test loss: 0.00215\n",
      "Epoch: 1... Training loss: 0.00182... Test loss: 0.00248\n",
      "Epoch: 1... Training loss: 0.00182... Test loss: 0.00219\n",
      "Epoch: 1... Training loss: 0.00164... Test loss: 0.00221\n",
      "Epoch: 1... Training loss: 0.00162... Test loss: 0.00176\n",
      "Epoch: 1... Training loss: 0.00159... Test loss: 0.00204\n",
      "Epoch: 1... Training loss: 0.00158... Test loss: 0.0013\n",
      "Epoch: 1... Training loss: 0.00152... Test loss: 0.00225\n",
      "Epoch: 1... Training loss: 0.00149... Test loss: 0.00162\n",
      "Epoch: 1... Training loss: 0.00135... Test loss: 0.00171\n",
      "Epoch: 1... Training loss: 0.00134... Test loss: 0.00159\n",
      "Epoch: 1... Training loss: 0.00126... Test loss: 0.00158\n",
      "Epoch: 1... Training loss: 0.00119... Test loss: 0.00123\n",
      "Epoch: 1... Training loss: 0.00121... Test loss: 0.00122\n",
      "Epoch: 1... Training loss: 0.0011... Test loss: 0.00118\n",
      "Epoch: 1... Training loss: 0.0012... Test loss: 0.00101\n",
      "Epoch: 1... Training loss: 0.00103... Test loss: 0.00119\n",
      "Epoch: 1... Training loss: 0.00109... Test loss: 0.00124\n",
      "Epoch: 1... Training loss: 0.00103... Test loss: 0.00112\n",
      "Epoch: 1... Training loss: 0.00088... Test loss: 0.00104\n",
      "Epoch: 1... Training loss: 0.00084... Test loss: 0.00114\n",
      "Epoch: 1... Training loss: 0.00084... Test loss: 0.00113\n",
      "Epoch: 1... Training loss: 0.00079... Test loss: 0.00103\n",
      "Epoch: 1... Training loss: 0.0008... Test loss: 0.00096\n",
      "Epoch: 1... Training loss: 0.00074... Test loss: 0.0007\n",
      "Epoch: 1... Training loss: 0.00078... Test loss: 0.00085\n",
      "Epoch: 1... Training loss: 0.00067... Test loss: 0.0007\n",
      "Epoch: 1... Training loss: 0.00066... Test loss: 0.00073\n",
      "Epoch: 1... Training loss: 0.00065... Test loss: 0.00067\n",
      "Epoch: 1... Training loss: 0.0006... Test loss: 0.00074\n",
      "Epoch: 1... Training loss: 0.00057... Test loss: 0.00066\n",
      "Epoch: 1... Training loss: 0.00056... Test loss: 0.0007\n",
      "Epoch: 1... Training loss: 0.00052... Test loss: 0.00068\n",
      "Epoch: 1... Training loss: 0.00059... Test loss: 0.00052\n",
      "Epoch: 1... Training loss: 0.00045... Test loss: 0.00053\n",
      "Epoch: 1... Training loss: 0.00044... Test loss: 0.00048\n",
      "Epoch: 1... Training loss: 0.00044... Test loss: 0.00061\n",
      "Epoch: 1... Training loss: 0.00039... Test loss: 0.00049\n",
      "Epoch: 1... Training loss: 0.0004... Test loss: 0.00059\n",
      "Epoch: 1... Training loss: 0.00035... Test loss: 0.00041\n",
      "Epoch: 1... Training loss: 0.0004... Test loss: 0.00039\n",
      "Epoch: 1... Training loss: 0.00033... Test loss: 0.00039\n",
      "Epoch: 1... Training loss: 0.00031... Test loss: 0.0004\n",
      "Epoch: 1... Training loss: 0.00031... Test loss: 0.00032\n",
      "Epoch: 1... Training loss: 0.00033... Test loss: 0.00032\n",
      "Epoch: 1... Training loss: 0.00033... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.00029... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00029... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.0001\n",
      "266.2499368907884\n",
      "Epoch: 1... Training loss: 1.26166... Test loss: 0.51234\n",
      "Epoch: 1... Training loss: 0.5617... Test loss: 0.19786\n",
      "Epoch: 1... Training loss: 0.32697... Test loss: 0.10825\n",
      "Epoch: 1... Training loss: 0.24097... Test loss: 0.07698\n",
      "Epoch: 1... Training loss: 0.17131... Test loss: 0.06629\n",
      "Epoch: 1... Training loss: 0.12821... Test loss: 0.05431\n",
      "Epoch: 1... Training loss: 0.10347... Test loss: 0.04727\n",
      "Epoch: 1... Training loss: 0.0855... Test loss: 0.05174\n",
      "Epoch: 1... Training loss: 0.07622... Test loss: 0.03192\n",
      "Epoch: 1... Training loss: 0.06385... Test loss: 0.05446\n",
      "Epoch: 1... Training loss: 0.05893... Test loss: 0.01972\n",
      "Epoch: 1... Training loss: 0.05352... Test loss: 0.04438\n",
      "Epoch: 1... Training loss: 0.04707... Test loss: 0.01741\n",
      "Epoch: 1... Training loss: 0.04336... Test loss: 0.03275\n",
      "Epoch: 1... Training loss: 0.04087... Test loss: 0.01466\n",
      "Epoch: 1... Training loss: 0.03783... Test loss: 0.03847\n",
      "Epoch: 1... Training loss: 0.03465... Test loss: 0.01507\n",
      "Epoch: 1... Training loss: 0.03234... Test loss: 0.03123\n",
      "Epoch: 1... Training loss: 0.03047... Test loss: 0.01396\n",
      "Epoch: 1... Training loss: 0.02953... Test loss: 0.02704\n",
      "Epoch: 1... Training loss: 0.02758... Test loss: 0.0142\n",
      "Epoch: 1... Training loss: 0.02549... Test loss: 0.02388\n",
      "Epoch: 1... Training loss: 0.02373... Test loss: 0.0116\n",
      "Epoch: 1... Training loss: 0.02315... Test loss: 0.01896\n",
      "Epoch: 1... Training loss: 0.02167... Test loss: 0.0121\n",
      "Epoch: 1... Training loss: 0.02112... Test loss: 0.0155\n",
      "Epoch: 1... Training loss: 0.01982... Test loss: 0.01638\n",
      "Epoch: 1... Training loss: 0.01892... Test loss: 0.00877\n",
      "Epoch: 1... Training loss: 0.01775... Test loss: 0.01667\n",
      "Epoch: 1... Training loss: 0.01662... Test loss: 0.01003\n",
      "Epoch: 1... Training loss: 0.01606... Test loss: 0.01639\n",
      "Epoch: 1... Training loss: 0.01516... Test loss: 0.00856\n",
      "Epoch: 1... Training loss: 0.01512... Test loss: 0.01462\n",
      "Epoch: 1... Training loss: 0.01448... Test loss: 0.00908\n",
      "Epoch: 1... Training loss: 0.01394... Test loss: 0.01413\n",
      "Epoch: 1... Training loss: 0.01362... Test loss: 0.00953\n",
      "Epoch: 1... Training loss: 0.01312... Test loss: 0.01115\n",
      "Epoch: 1... Training loss: 0.01272... Test loss: 0.01227\n",
      "Epoch: 1... Training loss: 0.0123... Test loss: 0.01114\n",
      "Epoch: 1... Training loss: 0.01188... Test loss: 0.0121\n",
      "Epoch: 1... Training loss: 0.01134... Test loss: 0.00951\n",
      "Epoch: 1... Training loss: 0.01073... Test loss: 0.01218\n",
      "Epoch: 1... Training loss: 0.01039... Test loss: 0.00795\n",
      "Epoch: 1... Training loss: 0.01007... Test loss: 0.01065\n",
      "Epoch: 1... Training loss: 0.00981... Test loss: 0.00802\n",
      "Epoch: 1... Training loss: 0.00941... Test loss: 0.0095\n",
      "Epoch: 1... Training loss: 0.00916... Test loss: 0.00972\n",
      "Epoch: 1... Training loss: 0.00884... Test loss: 0.00747\n",
      "Epoch: 1... Training loss: 0.00861... Test loss: 0.00869\n",
      "Epoch: 1... Training loss: 0.00826... Test loss: 0.00702\n",
      "Epoch: 1... Training loss: 0.00812... Test loss: 0.00877\n",
      "Epoch: 1... Training loss: 0.00783... Test loss: 0.00622\n",
      "Epoch: 1... Training loss: 0.00755... Test loss: 0.00848\n",
      "Epoch: 1... Training loss: 0.00734... Test loss: 0.00564\n",
      "Epoch: 1... Training loss: 0.00707... Test loss: 0.00806\n",
      "Epoch: 1... Training loss: 0.00695... Test loss: 0.0058\n",
      "Epoch: 1... Training loss: 0.00669... Test loss: 0.00821\n",
      "Epoch: 1... Training loss: 0.00644... Test loss: 0.00561\n",
      "Epoch: 1... Training loss: 0.00631... Test loss: 0.00734\n",
      "Epoch: 1... Training loss: 0.00606... Test loss: 0.00591\n",
      "Epoch: 1... Training loss: 0.00581... Test loss: 0.00558\n",
      "Epoch: 1... Training loss: 0.00564... Test loss: 0.00714\n",
      "Epoch: 1... Training loss: 0.00545... Test loss: 0.00559\n",
      "Epoch: 1... Training loss: 0.00524... Test loss: 0.00758\n",
      "Epoch: 1... Training loss: 0.00866... Test loss: 0.01504\n",
      "Epoch: 1... Training loss: 0.01097... Test loss: 0.02257\n",
      "Epoch: 1... Training loss: 0.00856... Test loss: 0.01286\n",
      "Epoch: 1... Training loss: 0.00923... Test loss: 0.01557\n",
      "Epoch: 1... Training loss: 0.00885... Test loss: 0.01186\n",
      "Epoch: 1... Training loss: 0.0093... Test loss: 0.01511\n",
      "Epoch: 1... Training loss: 0.00878... Test loss: 0.00975\n",
      "Epoch: 1... Training loss: 0.00828... Test loss: 0.01113\n",
      "Epoch: 1... Training loss: 0.00858... Test loss: 0.01164\n",
      "Epoch: 1... Training loss: 0.00785... Test loss: 0.01128\n",
      "Epoch: 1... Training loss: 0.00763... Test loss: 0.00962\n",
      "Epoch: 1... Training loss: 0.00778... Test loss: 0.01161\n",
      "Epoch: 1... Training loss: 0.00697... Test loss: 0.00827\n",
      "Epoch: 1... Training loss: 0.00675... Test loss: 0.01162\n",
      "Epoch: 1... Training loss: 0.00668... Test loss: 0.00965\n",
      "Epoch: 1... Training loss: 0.00587... Test loss: 0.01028\n",
      "Epoch: 1... Training loss: 0.00618... Test loss: 0.00728\n",
      "Epoch: 1... Training loss: 0.00571... Test loss: 0.01017\n",
      "Epoch: 1... Training loss: 0.00556... Test loss: 0.00698\n",
      "Epoch: 1... Training loss: 0.00548... Test loss: 0.00896\n",
      "Epoch: 1... Training loss: 0.00518... Test loss: 0.00626\n",
      "Epoch: 1... Training loss: 0.00499... Test loss: 0.00596\n",
      "Epoch: 1... Training loss: 0.00504... Test loss: 0.00575\n",
      "Epoch: 1... Training loss: 0.00459... Test loss: 0.00481\n",
      "Epoch: 1... Training loss: 0.0043... Test loss: 0.00559\n",
      "Epoch: 1... Training loss: 0.0044... Test loss: 0.00422\n",
      "Epoch: 1... Training loss: 0.0043... Test loss: 0.0062\n",
      "Epoch: 1... Training loss: 0.00411... Test loss: 0.00435\n",
      "Epoch: 1... Training loss: 0.00385... Test loss: 0.00542\n",
      "Epoch: 1... Training loss: 0.00371... Test loss: 0.00414\n",
      "Epoch: 1... Training loss: 0.00368... Test loss: 0.00497\n",
      "Epoch: 1... Training loss: 0.00368... Test loss: 0.00321\n",
      "Epoch: 1... Training loss: 0.00336... Test loss: 0.0045\n",
      "Epoch: 1... Training loss: 0.00323... Test loss: 0.00343\n",
      "Epoch: 1... Training loss: 0.00314... Test loss: 0.00348\n",
      "Epoch: 1... Training loss: 0.00301... Test loss: 0.00338\n",
      "Epoch: 1... Training loss: 0.00283... Test loss: 0.00327\n",
      "Epoch: 1... Training loss: 0.00277... Test loss: 0.00324\n",
      "Epoch: 1... Training loss: 0.00274... Test loss: 0.00335\n",
      "Epoch: 1... Training loss: 0.0026... Test loss: 0.0031\n",
      "Epoch: 1... Training loss: 0.00275... Test loss: 0.00291\n",
      "Epoch: 1... Training loss: 0.00251... Test loss: 0.00314\n",
      "Epoch: 1... Training loss: 0.00248... Test loss: 0.00325\n",
      "Epoch: 1... Training loss: 0.00242... Test loss: 0.00232\n",
      "Epoch: 1... Training loss: 0.00222... Test loss: 0.00346\n",
      "Epoch: 1... Training loss: 0.00214... Test loss: 0.00268\n",
      "Epoch: 1... Training loss: 0.00206... Test loss: 0.00278\n",
      "Epoch: 1... Training loss: 0.002... Test loss: 0.00229\n",
      "Epoch: 1... Training loss: 0.00195... Test loss: 0.00278\n",
      "Epoch: 1... Training loss: 0.00192... Test loss: 0.00209\n",
      "Epoch: 1... Training loss: 0.00181... Test loss: 0.00238\n",
      "Epoch: 1... Training loss: 0.00184... Test loss: 0.00182\n",
      "Epoch: 1... Training loss: 0.0017... Test loss: 0.00244\n",
      "Epoch: 1... Training loss: 0.0017... Test loss: 0.00195\n",
      "Epoch: 1... Training loss: 0.00163... Test loss: 0.00205\n",
      "Epoch: 1... Training loss: 0.00153... Test loss: 0.0022\n",
      "Epoch: 1... Training loss: 0.00152... Test loss: 0.00154\n",
      "Epoch: 1... Training loss: 0.00147... Test loss: 0.00163\n",
      "Epoch: 1... Training loss: 0.00139... Test loss: 0.00161\n",
      "Epoch: 1... Training loss: 0.0014... Test loss: 0.00133\n",
      "Epoch: 1... Training loss: 0.00121... Test loss: 0.00168\n",
      "Epoch: 1... Training loss: 0.0013... Test loss: 0.00147\n",
      "Epoch: 1... Training loss: 0.00117... Test loss: 0.00136\n",
      "Epoch: 1... Training loss: 0.00115... Test loss: 0.00102\n",
      "Epoch: 1... Training loss: 0.00105... Test loss: 0.00141\n",
      "Epoch: 1... Training loss: 0.00105... Test loss: 0.00101\n",
      "Epoch: 1... Training loss: 0.001... Test loss: 0.00125\n",
      "Epoch: 1... Training loss: 0.00098... Test loss: 0.00085\n",
      "Epoch: 1... Training loss: 0.00092... Test loss: 0.00133\n",
      "Epoch: 1... Training loss: 0.00089... Test loss: 0.00097\n",
      "Epoch: 1... Training loss: 0.00086... Test loss: 0.00113\n",
      "Epoch: 1... Training loss: 0.00079... Test loss: 0.00071\n",
      "Epoch: 1... Training loss: 0.00076... Test loss: 0.00107\n",
      "Epoch: 1... Training loss: 0.00084... Test loss: 0.00071\n",
      "Epoch: 1... Training loss: 0.00069... Test loss: 0.00103\n",
      "Epoch: 1... Training loss: 0.00068... Test loss: 0.0006\n",
      "Epoch: 1... Training loss: 0.00067... Test loss: 0.00087\n",
      "Epoch: 1... Training loss: 0.00062... Test loss: 0.00047\n",
      "Epoch: 1... Training loss: 0.00059... Test loss: 0.00086\n",
      "Epoch: 1... Training loss: 0.0006... Test loss: 0.00053\n",
      "Epoch: 1... Training loss: 0.00052... Test loss: 0.00056\n",
      "Epoch: 1... Training loss: 0.00048... Test loss: 0.00061\n",
      "Epoch: 1... Training loss: 0.00051... Test loss: 0.00063\n",
      "Epoch: 1... Training loss: 0.0005... Test loss: 0.00046\n",
      "Epoch: 1... Training loss: 0.00045... Test loss: 0.00056\n",
      "Epoch: 1... Training loss: 0.00045... Test loss: 0.00047\n",
      "Epoch: 1... Training loss: 0.00049... Test loss: 0.00046\n",
      "Epoch: 1... Training loss: 0.00042... Test loss: 0.00044\n",
      "Epoch: 1... Training loss: 0.00045... Test loss: 0.00047\n",
      "Epoch: 1... Training loss: 0.00039... Test loss: 0.00038\n",
      "Epoch: 1... Training loss: 0.00038... Test loss: 0.00052\n",
      "Epoch: 1... Training loss: 0.00038... Test loss: 0.00028\n",
      "Epoch: 1... Training loss: 0.00034... Test loss: 0.00045\n",
      "Epoch: 1... Training loss: 0.00033... Test loss: 0.00028\n",
      "Epoch: 1... Training loss: 0.00035... Test loss: 0.00039\n",
      "Epoch: 1... Training loss: 0.00032... Test loss: 0.00028\n",
      "Epoch: 1... Training loss: 0.00033... Test loss: 0.00033\n",
      "Epoch: 1... Training loss: 0.00031... Test loss: 0.00024\n",
      "Epoch: 1... Training loss: 0.00031... Test loss: 0.00033\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.0003\n",
      "Epoch: 1... Training loss: 0.00026... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.00024\n",
      "Epoch: 1... Training loss: 0.00026... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 7e-05\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 8e-05\n",
      "216.17881953006145\n",
      "Epoch: 1... Training loss: 0.91132... Test loss: 0.29649\n",
      "Epoch: 1... Training loss: 0.41467... Test loss: 0.10823\n",
      "Epoch: 1... Training loss: 0.30508... Test loss: 0.08641\n",
      "Epoch: 1... Training loss: 0.19151... Test loss: 0.05387\n",
      "Epoch: 1... Training loss: 0.15672... Test loss: 0.0465\n",
      "Epoch: 1... Training loss: 0.12144... Test loss: 0.03706\n",
      "Epoch: 1... Training loss: 0.09578... Test loss: 0.02775\n",
      "Epoch: 1... Training loss: 0.07936... Test loss: 0.03719\n",
      "Epoch: 1... Training loss: 0.06823... Test loss: 0.0199\n",
      "Epoch: 1... Training loss: 0.06022... Test loss: 0.0323\n",
      "Epoch: 1... Training loss: 0.05816... Test loss: 0.01387\n",
      "Epoch: 1... Training loss: 0.05068... Test loss: 0.03079\n",
      "Epoch: 1... Training loss: 0.04612... Test loss: 0.01261\n",
      "Epoch: 1... Training loss: 0.04357... Test loss: 0.02973\n",
      "Epoch: 1... Training loss: 0.03909... Test loss: 0.0121\n",
      "Epoch: 1... Training loss: 0.03712... Test loss: 0.02511\n",
      "Epoch: 1... Training loss: 0.03522... Test loss: 0.01305\n",
      "Epoch: 1... Training loss: 0.03324... Test loss: 0.02639\n",
      "Epoch: 1... Training loss: 0.03172... Test loss: 0.01303\n",
      "Epoch: 1... Training loss: 0.0293... Test loss: 0.02446\n",
      "Epoch: 1... Training loss: 0.02783... Test loss: 0.02584\n",
      "Epoch: 1... Training loss: 0.02613... Test loss: 0.01395\n",
      "Epoch: 1... Training loss: 0.0241... Test loss: 0.02533\n",
      "Epoch: 1... Training loss: 0.02365... Test loss: 0.01417\n",
      "Epoch: 1... Training loss: 0.02214... Test loss: 0.02612\n",
      "Epoch: 1... Training loss: 0.02181... Test loss: 0.0126\n",
      "Epoch: 1... Training loss: 0.02073... Test loss: 0.02255\n",
      "Epoch: 1... Training loss: 0.01976... Test loss: 0.01598\n",
      "Epoch: 1... Training loss: 0.01908... Test loss: 0.00968\n",
      "Epoch: 1... Training loss: 0.01788... Test loss: 0.02051\n",
      "Epoch: 1... Training loss: 0.01681... Test loss: 0.01023\n",
      "Epoch: 1... Training loss: 0.01587... Test loss: 0.02048\n",
      "Epoch: 1... Training loss: 0.01542... Test loss: 0.01045\n",
      "Epoch: 1... Training loss: 0.01451... Test loss: 0.01917\n",
      "Epoch: 1... Training loss: 0.01425... Test loss: 0.01297\n",
      "Epoch: 1... Training loss: 0.01362... Test loss: 0.01537\n",
      "Epoch: 1... Training loss: 0.01336... Test loss: 0.01295\n",
      "Epoch: 1... Training loss: 0.0127... Test loss: 0.01495\n",
      "Epoch: 1... Training loss: 0.01253... Test loss: 0.00944\n",
      "Epoch: 1... Training loss: 0.0117... Test loss: 0.01468\n",
      "Epoch: 1... Training loss: 0.01113... Test loss: 0.0082\n",
      "Epoch: 1... Training loss: 0.01079... Test loss: 0.01085\n",
      "Epoch: 1... Training loss: 0.01043... Test loss: 0.00934\n",
      "Epoch: 1... Training loss: 0.00996... Test loss: 0.00938\n",
      "Epoch: 1... Training loss: 0.0096... Test loss: 0.00948\n",
      "Epoch: 1... Training loss: 0.00913... Test loss: 0.0091\n",
      "Epoch: 1... Training loss: 0.00893... Test loss: 0.00902\n",
      "Epoch: 1... Training loss: 0.00861... Test loss: 0.00922\n",
      "Epoch: 1... Training loss: 0.00826... Test loss: 0.00819\n",
      "Epoch: 1... Training loss: 0.00803... Test loss: 0.00788\n",
      "Epoch: 1... Training loss: 0.00785... Test loss: 0.0074\n",
      "Epoch: 1... Training loss: 0.00766... Test loss: 0.00648\n",
      "Epoch: 1... Training loss: 0.00745... Test loss: 0.00797\n",
      "Epoch: 1... Training loss: 0.00703... Test loss: 0.00687\n",
      "Epoch: 1... Training loss: 0.00674... Test loss: 0.00745\n",
      "Epoch: 1... Training loss: 0.00648... Test loss: 0.00758\n",
      "Epoch: 1... Training loss: 0.00618... Test loss: 0.00685\n",
      "Epoch: 1... Training loss: 0.00614... Test loss: 0.00645\n",
      "Epoch: 1... Training loss: 0.00584... Test loss: 0.00672\n",
      "Epoch: 1... Training loss: 0.00563... Test loss: 0.00607\n",
      "Epoch: 1... Training loss: 0.0054... Test loss: 0.00603\n",
      "Epoch: 1... Training loss: 0.0054... Test loss: 0.00576\n",
      "Epoch: 1... Training loss: 0.00512... Test loss: 0.00492\n",
      "Epoch: 1... Training loss: 0.00507... Test loss: 0.00531\n",
      "Epoch: 1... Training loss: 0.01061... Test loss: 0.01635\n",
      "Epoch: 1... Training loss: 0.01213... Test loss: 0.01661\n",
      "Epoch: 1... Training loss: 0.01062... Test loss: 0.01157\n",
      "Epoch: 1... Training loss: 0.01024... Test loss: 0.01709\n",
      "Epoch: 1... Training loss: 0.00728... Test loss: 0.01711\n",
      "Epoch: 1... Training loss: 0.00795... Test loss: 0.01321\n",
      "Epoch: 1... Training loss: 0.00891... Test loss: 0.01235\n",
      "Epoch: 1... Training loss: 0.00707... Test loss: 0.01582\n",
      "Epoch: 1... Training loss: 0.00702... Test loss: 0.01006\n",
      "Epoch: 1... Training loss: 0.00745... Test loss: 0.01149\n",
      "Epoch: 1... Training loss: 0.00652... Test loss: 0.01094\n",
      "Epoch: 1... Training loss: 0.00677... Test loss: 0.00877\n",
      "Epoch: 1... Training loss: 0.00682... Test loss: 0.01043\n",
      "Epoch: 1... Training loss: 0.00521... Test loss: 0.00934\n",
      "Epoch: 1... Training loss: 0.00558... Test loss: 0.00863\n",
      "Epoch: 1... Training loss: 0.00519... Test loss: 0.00964\n",
      "Epoch: 1... Training loss: 0.00544... Test loss: 0.00671\n",
      "Epoch: 1... Training loss: 0.00504... Test loss: 0.00795\n",
      "Epoch: 1... Training loss: 0.00482... Test loss: 0.00695\n",
      "Epoch: 1... Training loss: 0.00452... Test loss: 0.00598\n",
      "Epoch: 1... Training loss: 0.0046... Test loss: 0.00485\n",
      "Epoch: 1... Training loss: 0.00432... Test loss: 0.00627\n",
      "Epoch: 1... Training loss: 0.00399... Test loss: 0.00498\n",
      "Epoch: 1... Training loss: 0.00394... Test loss: 0.0054\n",
      "Epoch: 1... Training loss: 0.00371... Test loss: 0.00597\n",
      "Epoch: 1... Training loss: 0.00368... Test loss: 0.00453\n",
      "Epoch: 1... Training loss: 0.00337... Test loss: 0.00505\n",
      "Epoch: 1... Training loss: 0.00336... Test loss: 0.00383\n",
      "Epoch: 1... Training loss: 0.00338... Test loss: 0.00502\n",
      "Epoch: 1... Training loss: 0.00297... Test loss: 0.00382\n",
      "Epoch: 1... Training loss: 0.00293... Test loss: 0.00467\n",
      "Epoch: 1... Training loss: 0.00297... Test loss: 0.00346\n",
      "Epoch: 1... Training loss: 0.00294... Test loss: 0.0032\n",
      "Epoch: 1... Training loss: 0.0028... Test loss: 0.00352\n",
      "Epoch: 1... Training loss: 0.00266... Test loss: 0.00365\n",
      "Epoch: 1... Training loss: 0.00257... Test loss: 0.00418\n",
      "Epoch: 1... Training loss: 0.00255... Test loss: 0.00298\n",
      "Epoch: 1... Training loss: 0.00239... Test loss: 0.0035\n",
      "Epoch: 1... Training loss: 0.00231... Test loss: 0.00238\n",
      "Epoch: 1... Training loss: 0.00223... Test loss: 0.00301\n",
      "Epoch: 1... Training loss: 0.00224... Test loss: 0.00319\n",
      "Epoch: 1... Training loss: 0.00212... Test loss: 0.00227\n",
      "Epoch: 1... Training loss: 0.00221... Test loss: 0.00231\n",
      "Epoch: 1... Training loss: 0.00207... Test loss: 0.00243\n",
      "Epoch: 1... Training loss: 0.00189... Test loss: 0.00191\n",
      "Epoch: 1... Training loss: 0.0018... Test loss: 0.00223\n",
      "Epoch: 1... Training loss: 0.0018... Test loss: 0.00203\n",
      "Epoch: 1... Training loss: 0.00172... Test loss: 0.00204\n",
      "Epoch: 1... Training loss: 0.00162... Test loss: 0.00224\n",
      "Epoch: 1... Training loss: 0.00152... Test loss: 0.00187\n",
      "Epoch: 1... Training loss: 0.00145... Test loss: 0.00155\n",
      "Epoch: 1... Training loss: 0.0015... Test loss: 0.00178\n",
      "Epoch: 1... Training loss: 0.00132... Test loss: 0.00181\n",
      "Epoch: 1... Training loss: 0.00132... Test loss: 0.00152\n",
      "Epoch: 1... Training loss: 0.00124... Test loss: 0.00124\n",
      "Epoch: 1... Training loss: 0.00118... Test loss: 0.00126\n",
      "Epoch: 1... Training loss: 0.00115... Test loss: 0.00115\n",
      "Epoch: 1... Training loss: 0.00117... Test loss: 0.00132\n",
      "Epoch: 1... Training loss: 0.00104... Test loss: 0.00113\n",
      "Epoch: 1... Training loss: 0.00097... Test loss: 0.0013\n",
      "Epoch: 1... Training loss: 0.00098... Test loss: 0.00107\n",
      "Epoch: 1... Training loss: 0.00095... Test loss: 0.00099\n",
      "Epoch: 1... Training loss: 0.00086... Test loss: 0.00079\n",
      "Epoch: 1... Training loss: 0.00082... Test loss: 0.00091\n",
      "Epoch: 1... Training loss: 0.00081... Test loss: 0.00083\n",
      "Epoch: 1... Training loss: 0.00085... Test loss: 0.00073\n",
      "Epoch: 1... Training loss: 0.00082... Test loss: 0.00076\n",
      "Epoch: 1... Training loss: 0.00074... Test loss: 0.00081\n",
      "Epoch: 1... Training loss: 0.00072... Test loss: 0.00073\n",
      "Epoch: 1... Training loss: 0.00068... Test loss: 0.0009\n",
      "Epoch: 1... Training loss: 0.00073... Test loss: 0.00062\n",
      "Epoch: 1... Training loss: 0.00062... Test loss: 0.00086\n",
      "Epoch: 1... Training loss: 0.00072... Test loss: 0.0005\n",
      "Epoch: 1... Training loss: 0.00057... Test loss: 0.00082\n",
      "Epoch: 1... Training loss: 0.00059... Test loss: 0.00055\n",
      "Epoch: 1... Training loss: 0.00057... Test loss: 0.00064\n",
      "Epoch: 1... Training loss: 0.00057... Test loss: 0.00051\n",
      "Epoch: 1... Training loss: 0.00052... Test loss: 0.00055\n",
      "Epoch: 1... Training loss: 0.00054... Test loss: 0.00057\n",
      "Epoch: 1... Training loss: 0.00049... Test loss: 0.00052\n",
      "Epoch: 1... Training loss: 0.00053... Test loss: 0.00042\n",
      "Epoch: 1... Training loss: 0.00049... Test loss: 0.00052\n",
      "Epoch: 1... Training loss: 0.00045... Test loss: 0.00043\n",
      "Epoch: 1... Training loss: 0.00044... Test loss: 0.00053\n",
      "Epoch: 1... Training loss: 0.00042... Test loss: 0.00034\n",
      "Epoch: 1... Training loss: 0.00045... Test loss: 0.00044\n",
      "Epoch: 1... Training loss: 0.00036... Test loss: 0.00041\n",
      "Epoch: 1... Training loss: 0.00039... Test loss: 0.00038\n",
      "Epoch: 1... Training loss: 0.00035... Test loss: 0.00037\n",
      "Epoch: 1... Training loss: 0.00043... Test loss: 0.00034\n",
      "Epoch: 1... Training loss: 0.00036... Test loss: 0.00033\n",
      "Epoch: 1... Training loss: 0.00033... Test loss: 0.00033\n",
      "Epoch: 1... Training loss: 0.00032... Test loss: 0.00038\n",
      "Epoch: 1... Training loss: 0.00033... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.00032... Test loss: 0.00031\n",
      "Epoch: 1... Training loss: 0.00032... Test loss: 0.00031\n",
      "Epoch: 1... Training loss: 0.00031... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.00032... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.00032... Test loss: 0.00024\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00034... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.00029... Test loss: 0.00024\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00024\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00028\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00013\n",
      "234.5317595055094\n",
      "Epoch: 1... Training loss: 1.00233... Test loss: 0.34203\n",
      "Epoch: 1... Training loss: 0.47825... Test loss: 0.18291\n",
      "Epoch: 1... Training loss: 0.27175... Test loss: 0.10928\n",
      "Epoch: 1... Training loss: 0.17931... Test loss: 0.06906\n",
      "Epoch: 1... Training loss: 0.13345... Test loss: 0.04419\n",
      "Epoch: 1... Training loss: 0.10652... Test loss: 0.03552\n",
      "Epoch: 1... Training loss: 0.09037... Test loss: 0.02952\n",
      "Epoch: 1... Training loss: 0.07673... Test loss: 0.03002\n",
      "Epoch: 1... Training loss: 0.06932... Test loss: 0.01787\n",
      "Epoch: 1... Training loss: 0.05881... Test loss: 0.02595\n",
      "Epoch: 1... Training loss: 0.05731... Test loss: 0.01246\n",
      "Epoch: 1... Training loss: 0.04946... Test loss: 0.01765\n",
      "Epoch: 1... Training loss: 0.04553... Test loss: 0.01288\n",
      "Epoch: 1... Training loss: 0.04288... Test loss: 0.01797\n",
      "Epoch: 1... Training loss: 0.03921... Test loss: 0.00996\n",
      "Epoch: 1... Training loss: 0.03777... Test loss: 0.02297\n",
      "Epoch: 1... Training loss: 0.03484... Test loss: 0.0132\n",
      "Epoch: 1... Training loss: 0.03232... Test loss: 0.02119\n",
      "Epoch: 1... Training loss: 0.03058... Test loss: 0.01589\n",
      "Epoch: 1... Training loss: 0.02884... Test loss: 0.01082\n",
      "Epoch: 1... Training loss: 0.0273... Test loss: 0.02358\n",
      "Epoch: 1... Training loss: 0.02517... Test loss: 0.00841\n",
      "Epoch: 1... Training loss: 0.0235... Test loss: 0.0209\n",
      "Epoch: 1... Training loss: 0.02347... Test loss: 0.01365\n",
      "Epoch: 1... Training loss: 0.02151... Test loss: 0.01586\n",
      "Epoch: 1... Training loss: 0.02094... Test loss: 0.01271\n",
      "Epoch: 1... Training loss: 0.02015... Test loss: 0.00993\n",
      "Epoch: 1... Training loss: 0.01867... Test loss: 0.01768\n",
      "Epoch: 1... Training loss: 0.01839... Test loss: 0.01017\n",
      "Epoch: 1... Training loss: 0.01707... Test loss: 0.01993\n",
      "Epoch: 1... Training loss: 0.01608... Test loss: 0.0084\n",
      "Epoch: 1... Training loss: 0.01517... Test loss: 0.01708\n",
      "Epoch: 1... Training loss: 0.01437... Test loss: 0.00933\n",
      "Epoch: 1... Training loss: 0.0139... Test loss: 0.01568\n",
      "Epoch: 1... Training loss: 0.01378... Test loss: 0.00851\n",
      "Epoch: 1... Training loss: 0.01319... Test loss: 0.01546\n",
      "Epoch: 1... Training loss: 0.01279... Test loss: 0.00774\n",
      "Epoch: 1... Training loss: 0.01224... Test loss: 0.01565\n",
      "Epoch: 1... Training loss: 0.01215... Test loss: 0.00786\n",
      "Epoch: 1... Training loss: 0.01153... Test loss: 0.01314\n",
      "Epoch: 1... Training loss: 0.01118... Test loss: 0.00839\n",
      "Epoch: 1... Training loss: 0.01073... Test loss: 0.01135\n",
      "Epoch: 1... Training loss: 0.01019... Test loss: 0.00963\n",
      "Epoch: 1... Training loss: 0.00991... Test loss: 0.00976\n",
      "Epoch: 1... Training loss: 0.0095... Test loss: 0.00867\n",
      "Epoch: 1... Training loss: 0.00932... Test loss: 0.01053\n",
      "Epoch: 1... Training loss: 0.00913... Test loss: 0.00774\n",
      "Epoch: 1... Training loss: 0.00887... Test loss: 0.00903\n",
      "Epoch: 1... Training loss: 0.00839... Test loss: 0.00767\n",
      "Epoch: 1... Training loss: 0.0082... Test loss: 0.00758\n",
      "Epoch: 1... Training loss: 0.00811... Test loss: 0.00859\n",
      "Epoch: 1... Training loss: 0.0078... Test loss: 0.006\n",
      "Epoch: 1... Training loss: 0.00785... Test loss: 0.00701\n",
      "Epoch: 1... Training loss: 0.0074... Test loss: 0.00757\n",
      "Epoch: 1... Training loss: 0.0072... Test loss: 0.0071\n",
      "Epoch: 1... Training loss: 0.00683... Test loss: 0.00743\n",
      "Epoch: 1... Training loss: 0.00662... Test loss: 0.00682\n",
      "Epoch: 1... Training loss: 0.00641... Test loss: 0.00672\n",
      "Epoch: 1... Training loss: 0.00625... Test loss: 0.00599\n",
      "Epoch: 1... Training loss: 0.00601... Test loss: 0.00612\n",
      "Epoch: 1... Training loss: 0.00598... Test loss: 0.00562\n",
      "Epoch: 1... Training loss: 0.00568... Test loss: 0.00576\n",
      "Epoch: 1... Training loss: 0.00554... Test loss: 0.0058\n",
      "Epoch: 1... Training loss: 0.00538... Test loss: 0.00498\n",
      "Epoch: 1... Training loss: 0.01241... Test loss: 0.01325\n",
      "Epoch: 1... Training loss: 0.01234... Test loss: 0.01403\n",
      "Epoch: 1... Training loss: 0.01277... Test loss: 0.01654\n",
      "Epoch: 1... Training loss: 0.00903... Test loss: 0.01339\n",
      "Epoch: 1... Training loss: 0.00838... Test loss: 0.01639\n",
      "Epoch: 1... Training loss: 0.00875... Test loss: 0.01566\n",
      "Epoch: 1... Training loss: 0.00861... Test loss: 0.01333\n",
      "Epoch: 1... Training loss: 0.00868... Test loss: 0.01241\n",
      "Epoch: 1... Training loss: 0.00898... Test loss: 0.01033\n",
      "Epoch: 1... Training loss: 0.00912... Test loss: 0.01312\n",
      "Epoch: 1... Training loss: 0.00686... Test loss: 0.01205\n",
      "Epoch: 1... Training loss: 0.00824... Test loss: 0.00932\n",
      "Epoch: 1... Training loss: 0.00736... Test loss: 0.0151\n",
      "Epoch: 1... Training loss: 0.00644... Test loss: 0.0076\n",
      "Epoch: 1... Training loss: 0.00616... Test loss: 0.01553\n",
      "Epoch: 1... Training loss: 0.0062... Test loss: 0.00732\n",
      "Epoch: 1... Training loss: 0.0059... Test loss: 0.01081\n",
      "Epoch: 1... Training loss: 0.00612... Test loss: 0.00809\n",
      "Epoch: 1... Training loss: 0.00535... Test loss: 0.00789\n",
      "Epoch: 1... Training loss: 0.00497... Test loss: 0.00557\n",
      "Epoch: 1... Training loss: 0.00523... Test loss: 0.00754\n",
      "Epoch: 1... Training loss: 0.00475... Test loss: 0.00555\n",
      "Epoch: 1... Training loss: 0.00468... Test loss: 0.00691\n",
      "Epoch: 1... Training loss: 0.00485... Test loss: 0.00476\n",
      "Epoch: 1... Training loss: 0.00467... Test loss: 0.00519\n",
      "Epoch: 1... Training loss: 0.00427... Test loss: 0.00511\n",
      "Epoch: 1... Training loss: 0.00423... Test loss: 0.00552\n",
      "Epoch: 1... Training loss: 0.00415... Test loss: 0.00452\n",
      "Epoch: 1... Training loss: 0.00385... Test loss: 0.00595\n",
      "Epoch: 1... Training loss: 0.0038... Test loss: 0.0055\n",
      "Epoch: 1... Training loss: 0.00377... Test loss: 0.00459\n",
      "Epoch: 1... Training loss: 0.00357... Test loss: 0.00406\n",
      "Epoch: 1... Training loss: 0.00331... Test loss: 0.00482\n",
      "Epoch: 1... Training loss: 0.00332... Test loss: 0.00405\n",
      "Epoch: 1... Training loss: 0.00312... Test loss: 0.00335\n",
      "Epoch: 1... Training loss: 0.00307... Test loss: 0.00433\n",
      "Epoch: 1... Training loss: 0.00301... Test loss: 0.00324\n",
      "Epoch: 1... Training loss: 0.00287... Test loss: 0.00408\n",
      "Epoch: 1... Training loss: 0.003... Test loss: 0.0029\n",
      "Epoch: 1... Training loss: 0.00266... Test loss: 0.00333\n",
      "Epoch: 1... Training loss: 0.00269... Test loss: 0.00287\n",
      "Epoch: 1... Training loss: 0.00258... Test loss: 0.00307\n",
      "Epoch: 1... Training loss: 0.00259... Test loss: 0.0028\n",
      "Epoch: 1... Training loss: 0.00248... Test loss: 0.00301\n",
      "Epoch: 1... Training loss: 0.00227... Test loss: 0.00262\n",
      "Epoch: 1... Training loss: 0.00232... Test loss: 0.00279\n",
      "Epoch: 1... Training loss: 0.00209... Test loss: 0.00218\n",
      "Epoch: 1... Training loss: 0.00204... Test loss: 0.00255\n",
      "Epoch: 1... Training loss: 0.00196... Test loss: 0.00233\n",
      "Epoch: 1... Training loss: 0.00197... Test loss: 0.00211\n",
      "Epoch: 1... Training loss: 0.00194... Test loss: 0.002\n",
      "Epoch: 1... Training loss: 0.00178... Test loss: 0.00223\n",
      "Epoch: 1... Training loss: 0.00179... Test loss: 0.00216\n",
      "Epoch: 1... Training loss: 0.00177... Test loss: 0.00219\n",
      "Epoch: 1... Training loss: 0.00162... Test loss: 0.00189\n",
      "Epoch: 1... Training loss: 0.00149... Test loss: 0.00235\n",
      "Epoch: 1... Training loss: 0.00151... Test loss: 0.00184\n",
      "Epoch: 1... Training loss: 0.00139... Test loss: 0.00205\n",
      "Epoch: 1... Training loss: 0.00139... Test loss: 0.00159\n",
      "Epoch: 1... Training loss: 0.0013... Test loss: 0.00165\n",
      "Epoch: 1... Training loss: 0.00128... Test loss: 0.00132\n",
      "Epoch: 1... Training loss: 0.00116... Test loss: 0.00187\n",
      "Epoch: 1... Training loss: 0.00121... Test loss: 0.0012\n",
      "Epoch: 1... Training loss: 0.00105... Test loss: 0.00128\n",
      "Epoch: 1... Training loss: 0.00112... Test loss: 0.00121\n",
      "Epoch: 1... Training loss: 0.001... Test loss: 0.00114\n",
      "Epoch: 1... Training loss: 0.00106... Test loss: 0.00101\n",
      "Epoch: 1... Training loss: 0.00096... Test loss: 0.001\n",
      "Epoch: 1... Training loss: 0.00096... Test loss: 0.00092\n",
      "Epoch: 1... Training loss: 0.00091... Test loss: 0.00082\n",
      "Epoch: 1... Training loss: 0.00089... Test loss: 0.00094\n",
      "Epoch: 1... Training loss: 0.00078... Test loss: 0.00101\n",
      "Epoch: 1... Training loss: 0.00082... Test loss: 0.00103\n",
      "Epoch: 1... Training loss: 0.00076... Test loss: 0.0008\n",
      "Epoch: 1... Training loss: 0.00081... Test loss: 0.00094\n",
      "Epoch: 1... Training loss: 0.00081... Test loss: 0.0009\n",
      "Epoch: 1... Training loss: 0.0007... Test loss: 0.00068\n",
      "Epoch: 1... Training loss: 0.00066... Test loss: 0.00099\n",
      "Epoch: 1... Training loss: 0.00068... Test loss: 0.0007\n",
      "Epoch: 1... Training loss: 0.00063... Test loss: 0.00063\n",
      "Epoch: 1... Training loss: 0.00062... Test loss: 0.0006\n",
      "Epoch: 1... Training loss: 0.00059... Test loss: 0.00058\n",
      "Epoch: 1... Training loss: 0.00056... Test loss: 0.00052\n",
      "Epoch: 1... Training loss: 0.00056... Test loss: 0.00049\n",
      "Epoch: 1... Training loss: 0.00053... Test loss: 0.00047\n",
      "Epoch: 1... Training loss: 0.00054... Test loss: 0.00044\n",
      "Epoch: 1... Training loss: 0.00052... Test loss: 0.00066\n",
      "Epoch: 1... Training loss: 0.00048... Test loss: 0.00047\n",
      "Epoch: 1... Training loss: 0.00046... Test loss: 0.00051\n",
      "Epoch: 1... Training loss: 0.00046... Test loss: 0.00042\n",
      "Epoch: 1... Training loss: 0.00048... Test loss: 0.00044\n",
      "Epoch: 1... Training loss: 0.00043... Test loss: 0.00051\n",
      "Epoch: 1... Training loss: 0.00041... Test loss: 0.00042\n",
      "Epoch: 1... Training loss: 0.00052... Test loss: 0.00046\n",
      "Epoch: 1... Training loss: 0.00037... Test loss: 0.00031\n",
      "Epoch: 1... Training loss: 0.00038... Test loss: 0.00037\n",
      "Epoch: 1... Training loss: 0.00037... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.00037... Test loss: 0.00035\n",
      "Epoch: 1... Training loss: 0.00038... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.00032... Test loss: 0.00038\n",
      "Epoch: 1... Training loss: 0.00043... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.00031... Test loss: 0.00034\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00031\n",
      "Epoch: 1... Training loss: 0.00026... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00029... Test loss: 0.00034\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.00012\n",
      "278.4805237436667\n",
      "Epoch: 1... Training loss: 0.85804... Test loss: 0.15669\n",
      "Epoch: 1... Training loss: 0.49053... Test loss: 0.17122\n",
      "Epoch: 1... Training loss: 0.2709... Test loss: 0.08316\n",
      "Epoch: 1... Training loss: 0.18299... Test loss: 0.07334\n",
      "Epoch: 1... Training loss: 0.13759... Test loss: 0.05006\n",
      "Epoch: 1... Training loss: 0.1005... Test loss: 0.03285\n",
      "Epoch: 1... Training loss: 0.08342... Test loss: 0.02721\n",
      "Epoch: 1... Training loss: 0.06163... Test loss: 0.02052\n",
      "Epoch: 1... Training loss: 0.05874... Test loss: 0.01781\n",
      "Epoch: 1... Training loss: 0.05337... Test loss: 0.01464\n",
      "Epoch: 1... Training loss: 0.04526... Test loss: 0.01197\n",
      "Epoch: 1... Training loss: 0.04172... Test loss: 0.01053\n",
      "Epoch: 1... Training loss: 0.03614... Test loss: 0.00835\n",
      "Epoch: 1... Training loss: 0.0328... Test loss: 0.00764\n",
      "Epoch: 1... Training loss: 0.02992... Test loss: 0.00518\n",
      "Epoch: 1... Training loss: 0.02801... Test loss: 0.00941\n",
      "Epoch: 1... Training loss: 0.02646... Test loss: 0.00342\n",
      "Epoch: 1... Training loss: 0.02521... Test loss: 0.00649\n",
      "Epoch: 1... Training loss: 0.02266... Test loss: 0.00271\n",
      "Epoch: 1... Training loss: 0.02111... Test loss: 0.0062\n",
      "Epoch: 1... Training loss: 0.02026... Test loss: 0.00252\n",
      "Epoch: 1... Training loss: 0.01905... Test loss: 0.00742\n",
      "Epoch: 1... Training loss: 0.01828... Test loss: 0.00232\n",
      "Epoch: 1... Training loss: 0.01782... Test loss: 0.00747\n",
      "Epoch: 1... Training loss: 0.01682... Test loss: 0.00244\n",
      "Epoch: 1... Training loss: 0.01645... Test loss: 0.00619\n",
      "Epoch: 1... Training loss: 0.01592... Test loss: 0.00283\n",
      "Epoch: 1... Training loss: 0.01519... Test loss: 0.00638\n",
      "Epoch: 1... Training loss: 0.01469... Test loss: 0.0045\n",
      "Epoch: 1... Training loss: 0.01425... Test loss: 0.00485\n",
      "Epoch: 1... Training loss: 0.01372... Test loss: 0.00712\n",
      "Epoch: 1... Training loss: 0.01307... Test loss: 0.00503\n",
      "Epoch: 1... Training loss: 0.0127... Test loss: 0.00628\n",
      "Epoch: 1... Training loss: 0.0123... Test loss: 0.00477\n",
      "Epoch: 1... Training loss: 0.01215... Test loss: 0.00486\n",
      "Epoch: 1... Training loss: 0.01174... Test loss: 0.0071\n",
      "Epoch: 1... Training loss: 0.01116... Test loss: 0.00423\n",
      "Epoch: 1... Training loss: 0.01113... Test loss: 0.00758\n",
      "Epoch: 1... Training loss: 0.01054... Test loss: 0.00338\n",
      "Epoch: 1... Training loss: 0.01032... Test loss: 0.00637\n",
      "Epoch: 1... Training loss: 0.01... Test loss: 0.00437\n",
      "Epoch: 1... Training loss: 0.00976... Test loss: 0.00561\n",
      "Epoch: 1... Training loss: 0.00931... Test loss: 0.0047\n",
      "Epoch: 1... Training loss: 0.00914... Test loss: 0.00497\n",
      "Epoch: 1... Training loss: 0.0088... Test loss: 0.00569\n",
      "Epoch: 1... Training loss: 0.00857... Test loss: 0.00432\n",
      "Epoch: 1... Training loss: 0.00834... Test loss: 0.00551\n",
      "Epoch: 1... Training loss: 0.00825... Test loss: 0.00497\n",
      "Epoch: 1... Training loss: 0.00791... Test loss: 0.00571\n",
      "Epoch: 1... Training loss: 0.00775... Test loss: 0.00534\n",
      "Epoch: 1... Training loss: 0.00743... Test loss: 0.00567\n",
      "Epoch: 1... Training loss: 0.00734... Test loss: 0.00562\n",
      "Epoch: 1... Training loss: 0.00701... Test loss: 0.00496\n",
      "Epoch: 1... Training loss: 0.00684... Test loss: 0.00545\n",
      "Epoch: 1... Training loss: 0.00669... Test loss: 0.00548\n",
      "Epoch: 1... Training loss: 0.00647... Test loss: 0.00599\n",
      "Epoch: 1... Training loss: 0.00636... Test loss: 0.0056\n",
      "Epoch: 1... Training loss: 0.00607... Test loss: 0.00576\n",
      "Epoch: 1... Training loss: 0.00596... Test loss: 0.00506\n",
      "Epoch: 1... Training loss: 0.00575... Test loss: 0.0059\n",
      "Epoch: 1... Training loss: 0.00561... Test loss: 0.00517\n",
      "Epoch: 1... Training loss: 0.00543... Test loss: 0.00463\n",
      "Epoch: 1... Training loss: 0.00534... Test loss: 0.00454\n",
      "Epoch: 1... Training loss: 0.00518... Test loss: 0.00503\n",
      "Epoch: 1... Training loss: 0.00908... Test loss: 0.01115\n",
      "Epoch: 1... Training loss: 0.01001... Test loss: 0.01393\n",
      "Epoch: 1... Training loss: 0.00876... Test loss: 0.01055\n",
      "Epoch: 1... Training loss: 0.00797... Test loss: 0.00874\n",
      "Epoch: 1... Training loss: 0.00846... Test loss: 0.00872\n",
      "Epoch: 1... Training loss: 0.00693... Test loss: 0.01294\n",
      "Epoch: 1... Training loss: 0.00853... Test loss: 0.00685\n",
      "Epoch: 1... Training loss: 0.00802... Test loss: 0.01057\n",
      "Epoch: 1... Training loss: 0.00839... Test loss: 0.00919\n",
      "Epoch: 1... Training loss: 0.00735... Test loss: 0.01136\n",
      "Epoch: 1... Training loss: 0.00743... Test loss: 0.00698\n",
      "Epoch: 1... Training loss: 0.00784... Test loss: 0.00821\n",
      "Epoch: 1... Training loss: 0.00622... Test loss: 0.00771\n",
      "Epoch: 1... Training loss: 0.00682... Test loss: 0.00787\n",
      "Epoch: 1... Training loss: 0.00635... Test loss: 0.00904\n",
      "Epoch: 1... Training loss: 0.00646... Test loss: 0.00787\n",
      "Epoch: 1... Training loss: 0.0056... Test loss: 0.00639\n",
      "Epoch: 1... Training loss: 0.00585... Test loss: 0.00787\n",
      "Epoch: 1... Training loss: 0.00539... Test loss: 0.00676\n",
      "Epoch: 1... Training loss: 0.00515... Test loss: 0.00698\n",
      "Epoch: 1... Training loss: 0.00489... Test loss: 0.00594\n",
      "Epoch: 1... Training loss: 0.00483... Test loss: 0.00645\n",
      "Epoch: 1... Training loss: 0.00488... Test loss: 0.00578\n",
      "Epoch: 1... Training loss: 0.00434... Test loss: 0.00589\n",
      "Epoch: 1... Training loss: 0.00433... Test loss: 0.00581\n",
      "Epoch: 1... Training loss: 0.00429... Test loss: 0.00457\n",
      "Epoch: 1... Training loss: 0.00398... Test loss: 0.00622\n",
      "Epoch: 1... Training loss: 0.00403... Test loss: 0.00517\n",
      "Epoch: 1... Training loss: 0.00391... Test loss: 0.00406\n",
      "Epoch: 1... Training loss: 0.00375... Test loss: 0.00451\n",
      "Epoch: 1... Training loss: 0.00345... Test loss: 0.00376\n",
      "Epoch: 1... Training loss: 0.00357... Test loss: 0.00353\n",
      "Epoch: 1... Training loss: 0.00325... Test loss: 0.00414\n",
      "Epoch: 1... Training loss: 0.0032... Test loss: 0.00395\n",
      "Epoch: 1... Training loss: 0.00319... Test loss: 0.00365\n",
      "Epoch: 1... Training loss: 0.00298... Test loss: 0.00391\n",
      "Epoch: 1... Training loss: 0.00287... Test loss: 0.00298\n",
      "Epoch: 1... Training loss: 0.00287... Test loss: 0.00365\n",
      "Epoch: 1... Training loss: 0.00281... Test loss: 0.0029\n",
      "Epoch: 1... Training loss: 0.00265... Test loss: 0.00359\n",
      "Epoch: 1... Training loss: 0.00272... Test loss: 0.0028\n",
      "Epoch: 1... Training loss: 0.00254... Test loss: 0.00328\n",
      "Epoch: 1... Training loss: 0.00252... Test loss: 0.0024\n",
      "Epoch: 1... Training loss: 0.00241... Test loss: 0.00253\n",
      "Epoch: 1... Training loss: 0.00243... Test loss: 0.00254\n",
      "Epoch: 1... Training loss: 0.00229... Test loss: 0.00289\n",
      "Epoch: 1... Training loss: 0.00222... Test loss: 0.0025\n",
      "Epoch: 1... Training loss: 0.00222... Test loss: 0.00248\n",
      "Epoch: 1... Training loss: 0.00218... Test loss: 0.00295\n",
      "Epoch: 1... Training loss: 0.00213... Test loss: 0.00236\n",
      "Epoch: 1... Training loss: 0.00201... Test loss: 0.00252\n",
      "Epoch: 1... Training loss: 0.00193... Test loss: 0.00223\n",
      "Epoch: 1... Training loss: 0.00192... Test loss: 0.00172\n",
      "Epoch: 1... Training loss: 0.0018... Test loss: 0.00208\n",
      "Epoch: 1... Training loss: 0.0018... Test loss: 0.00141\n",
      "Epoch: 1... Training loss: 0.00171... Test loss: 0.00219\n",
      "Epoch: 1... Training loss: 0.00166... Test loss: 0.00126\n",
      "Epoch: 1... Training loss: 0.00167... Test loss: 0.00265\n",
      "Epoch: 1... Training loss: 0.00152... Test loss: 0.00143\n",
      "Epoch: 1... Training loss: 0.0015... Test loss: 0.0023\n",
      "Epoch: 1... Training loss: 0.00145... Test loss: 0.00152\n",
      "Epoch: 1... Training loss: 0.00138... Test loss: 0.00224\n",
      "Epoch: 1... Training loss: 0.0014... Test loss: 0.00139\n",
      "Epoch: 1... Training loss: 0.00127... Test loss: 0.00152\n",
      "Epoch: 1... Training loss: 0.00123... Test loss: 0.00116\n",
      "Epoch: 1... Training loss: 0.00117... Test loss: 0.00171\n",
      "Epoch: 1... Training loss: 0.00117... Test loss: 0.0012\n",
      "Epoch: 1... Training loss: 0.00124... Test loss: 0.00138\n",
      "Epoch: 1... Training loss: 0.00106... Test loss: 0.00114\n",
      "Epoch: 1... Training loss: 0.00108... Test loss: 0.00124\n",
      "Epoch: 1... Training loss: 0.00101... Test loss: 0.00125\n",
      "Epoch: 1... Training loss: 0.00092... Test loss: 0.00145\n",
      "Epoch: 1... Training loss: 0.00089... Test loss: 0.00106\n",
      "Epoch: 1... Training loss: 0.00082... Test loss: 0.00116\n",
      "Epoch: 1... Training loss: 0.00082... Test loss: 0.00101\n",
      "Epoch: 1... Training loss: 0.00076... Test loss: 0.001\n",
      "Epoch: 1... Training loss: 0.00078... Test loss: 0.00087\n",
      "Epoch: 1... Training loss: 0.00076... Test loss: 0.00111\n",
      "Epoch: 1... Training loss: 0.00067... Test loss: 0.00059\n",
      "Epoch: 1... Training loss: 0.00064... Test loss: 0.00116\n",
      "Epoch: 1... Training loss: 0.00068... Test loss: 0.0007\n",
      "Epoch: 1... Training loss: 0.00064... Test loss: 0.00096\n",
      "Epoch: 1... Training loss: 0.00063... Test loss: 0.00056\n",
      "Epoch: 1... Training loss: 0.00055... Test loss: 0.00084\n",
      "Epoch: 1... Training loss: 0.00053... Test loss: 0.0005\n",
      "Epoch: 1... Training loss: 0.00049... Test loss: 0.00069\n",
      "Epoch: 1... Training loss: 0.00051... Test loss: 0.00057\n",
      "Epoch: 1... Training loss: 0.00048... Test loss: 0.00064\n",
      "Epoch: 1... Training loss: 0.00047... Test loss: 0.00046\n",
      "Epoch: 1... Training loss: 0.00048... Test loss: 0.00056\n",
      "Epoch: 1... Training loss: 0.00046... Test loss: 0.00051\n",
      "Epoch: 1... Training loss: 0.00043... Test loss: 0.00054\n",
      "Epoch: 1... Training loss: 0.0004... Test loss: 0.00039\n",
      "Epoch: 1... Training loss: 0.00037... Test loss: 0.00038\n",
      "Epoch: 1... Training loss: 0.00035... Test loss: 0.00041\n",
      "Epoch: 1... Training loss: 0.00032... Test loss: 0.00036\n",
      "Epoch: 1... Training loss: 0.00034... Test loss: 0.00034\n",
      "Epoch: 1... Training loss: 0.00032... Test loss: 0.0003\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00037\n",
      "Epoch: 1... Training loss: 0.00029... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.00029... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00026... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.0003\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00024\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 8e-05... Test loss: 6e-05\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 8e-05\n",
      "Epoch: 1... Training loss: 8e-05... Test loss: 7e-05\n",
      "Epoch: 1... Training loss: 7e-05... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 7e-05... Test loss: 7e-05\n",
      "205.71899019938428\n",
      "Epoch: 1... Training loss: 1.13567... Test loss: 0.4621\n",
      "Epoch: 1... Training loss: 0.46982... Test loss: 0.15305\n",
      "Epoch: 1... Training loss: 0.26498... Test loss: 0.06512\n",
      "Epoch: 1... Training loss: 0.15953... Test loss: 0.0422\n",
      "Epoch: 1... Training loss: 0.12169... Test loss: 0.02477\n",
      "Epoch: 1... Training loss: 0.09466... Test loss: 0.0165\n",
      "Epoch: 1... Training loss: 0.07942... Test loss: 0.01252\n",
      "Epoch: 1... Training loss: 0.07152... Test loss: 0.01027\n",
      "Epoch: 1... Training loss: 0.06427... Test loss: 0.01008\n",
      "Epoch: 1... Training loss: 0.05655... Test loss: 0.00993\n",
      "Epoch: 1... Training loss: 0.04917... Test loss: 0.00574\n",
      "Epoch: 1... Training loss: 0.04659... Test loss: 0.01077\n",
      "Epoch: 1... Training loss: 0.04164... Test loss: 0.01285\n",
      "Epoch: 1... Training loss: 0.03928... Test loss: 0.01132\n",
      "Epoch: 1... Training loss: 0.03489... Test loss: 0.02006\n",
      "Epoch: 1... Training loss: 0.03313... Test loss: 0.00839\n",
      "Epoch: 1... Training loss: 0.03175... Test loss: 0.02632\n",
      "Epoch: 1... Training loss: 0.03035... Test loss: 0.00922\n",
      "Epoch: 1... Training loss: 0.02831... Test loss: 0.02757\n",
      "Epoch: 1... Training loss: 0.02727... Test loss: 0.00895\n",
      "Epoch: 1... Training loss: 0.0265... Test loss: 0.02162\n",
      "Epoch: 1... Training loss: 0.02401... Test loss: 0.01184\n",
      "Epoch: 1... Training loss: 0.02253... Test loss: 0.02471\n",
      "Epoch: 1... Training loss: 0.02185... Test loss: 0.0091\n",
      "Epoch: 1... Training loss: 0.02041... Test loss: 0.02086\n",
      "Epoch: 1... Training loss: 0.01996... Test loss: 0.01098\n",
      "Epoch: 1... Training loss: 0.01835... Test loss: 0.02067\n",
      "Epoch: 1... Training loss: 0.01779... Test loss: 0.01031\n",
      "Epoch: 1... Training loss: 0.01673... Test loss: 0.01923\n",
      "Epoch: 1... Training loss: 0.016... Test loss: 0.00897\n",
      "Epoch: 1... Training loss: 0.01527... Test loss: 0.01706\n",
      "Epoch: 1... Training loss: 0.01476... Test loss: 0.00997\n",
      "Epoch: 1... Training loss: 0.01426... Test loss: 0.01471\n",
      "Epoch: 1... Training loss: 0.01352... Test loss: 0.00996\n",
      "Epoch: 1... Training loss: 0.01293... Test loss: 0.01573\n",
      "Epoch: 1... Training loss: 0.01271... Test loss: 0.00839\n",
      "Epoch: 1... Training loss: 0.01224... Test loss: 0.01443\n",
      "Epoch: 1... Training loss: 0.01161... Test loss: 0.00738\n",
      "Epoch: 1... Training loss: 0.01129... Test loss: 0.01278\n",
      "Epoch: 1... Training loss: 0.01091... Test loss: 0.00768\n",
      "Epoch: 1... Training loss: 0.01069... Test loss: 0.00924\n",
      "Epoch: 1... Training loss: 0.01049... Test loss: 0.01016\n",
      "Epoch: 1... Training loss: 0.01008... Test loss: 0.00546\n",
      "Epoch: 1... Training loss: 0.00968... Test loss: 0.00971\n",
      "Epoch: 1... Training loss: 0.00942... Test loss: 0.00765\n",
      "Epoch: 1... Training loss: 0.00918... Test loss: 0.00813\n",
      "Epoch: 1... Training loss: 0.00898... Test loss: 0.00648\n",
      "Epoch: 1... Training loss: 0.00873... Test loss: 0.00695\n",
      "Epoch: 1... Training loss: 0.0086... Test loss: 0.00591\n",
      "Epoch: 1... Training loss: 0.00832... Test loss: 0.00689\n",
      "Epoch: 1... Training loss: 0.00822... Test loss: 0.00585\n",
      "Epoch: 1... Training loss: 0.00789... Test loss: 0.00652\n",
      "Epoch: 1... Training loss: 0.00783... Test loss: 0.00702\n",
      "Epoch: 1... Training loss: 0.00737... Test loss: 0.00585\n",
      "Epoch: 1... Training loss: 0.00725... Test loss: 0.00821\n",
      "Epoch: 1... Training loss: 0.00709... Test loss: 0.00474\n",
      "Epoch: 1... Training loss: 0.00698... Test loss: 0.00737\n",
      "Epoch: 1... Training loss: 0.00679... Test loss: 0.0047\n",
      "Epoch: 1... Training loss: 0.00671... Test loss: 0.00702\n",
      "Epoch: 1... Training loss: 0.00639... Test loss: 0.00521\n",
      "Epoch: 1... Training loss: 0.00615... Test loss: 0.00605\n",
      "Epoch: 1... Training loss: 0.00588... Test loss: 0.00472\n",
      "Epoch: 1... Training loss: 0.00573... Test loss: 0.00625\n",
      "Epoch: 1... Training loss: 0.00557... Test loss: 0.00403\n",
      "Epoch: 1... Training loss: 0.01815... Test loss: 0.03376\n",
      "Epoch: 1... Training loss: 0.01111... Test loss: 0.01287\n",
      "Epoch: 1... Training loss: 0.01108... Test loss: 0.0292\n",
      "Epoch: 1... Training loss: 0.00976... Test loss: 0.02149\n",
      "Epoch: 1... Training loss: 0.01036... Test loss: 0.01647\n",
      "Epoch: 1... Training loss: 0.00896... Test loss: 0.02402\n",
      "Epoch: 1... Training loss: 0.00855... Test loss: 0.01106\n",
      "Epoch: 1... Training loss: 0.00778... Test loss: 0.01697\n",
      "Epoch: 1... Training loss: 0.00745... Test loss: 0.01174\n",
      "Epoch: 1... Training loss: 0.00758... Test loss: 0.01151\n",
      "Epoch: 1... Training loss: 0.00779... Test loss: 0.01111\n",
      "Epoch: 1... Training loss: 0.00736... Test loss: 0.00767\n",
      "Epoch: 1... Training loss: 0.00714... Test loss: 0.01317\n",
      "Epoch: 1... Training loss: 0.00645... Test loss: 0.00846\n",
      "Epoch: 1... Training loss: 0.00682... Test loss: 0.00974\n",
      "Epoch: 1... Training loss: 0.00663... Test loss: 0.01061\n",
      "Epoch: 1... Training loss: 0.00605... Test loss: 0.00956\n",
      "Epoch: 1... Training loss: 0.00564... Test loss: 0.00918\n",
      "Epoch: 1... Training loss: 0.00559... Test loss: 0.00719\n",
      "Epoch: 1... Training loss: 0.00556... Test loss: 0.00623\n",
      "Epoch: 1... Training loss: 0.00559... Test loss: 0.01033\n",
      "Epoch: 1... Training loss: 0.00488... Test loss: 0.00617\n",
      "Epoch: 1... Training loss: 0.00479... Test loss: 0.00563\n",
      "Epoch: 1... Training loss: 0.00461... Test loss: 0.00695\n",
      "Epoch: 1... Training loss: 0.00445... Test loss: 0.00658\n",
      "Epoch: 1... Training loss: 0.00421... Test loss: 0.00506\n",
      "Epoch: 1... Training loss: 0.00399... Test loss: 0.00595\n",
      "Epoch: 1... Training loss: 0.00398... Test loss: 0.00432\n",
      "Epoch: 1... Training loss: 0.00374... Test loss: 0.00487\n",
      "Epoch: 1... Training loss: 0.0036... Test loss: 0.0044\n",
      "Epoch: 1... Training loss: 0.00349... Test loss: 0.00441\n",
      "Epoch: 1... Training loss: 0.00332... Test loss: 0.00398\n",
      "Epoch: 1... Training loss: 0.00327... Test loss: 0.00338\n",
      "Epoch: 1... Training loss: 0.00317... Test loss: 0.00501\n",
      "Epoch: 1... Training loss: 0.00296... Test loss: 0.00382\n",
      "Epoch: 1... Training loss: 0.00296... Test loss: 0.00366\n",
      "Epoch: 1... Training loss: 0.00293... Test loss: 0.00424\n",
      "Epoch: 1... Training loss: 0.00283... Test loss: 0.00399\n",
      "Epoch: 1... Training loss: 0.00264... Test loss: 0.0034\n",
      "Epoch: 1... Training loss: 0.00265... Test loss: 0.00298\n",
      "Epoch: 1... Training loss: 0.00265... Test loss: 0.0028\n",
      "Epoch: 1... Training loss: 0.00247... Test loss: 0.00309\n",
      "Epoch: 1... Training loss: 0.00249... Test loss: 0.00323\n",
      "Epoch: 1... Training loss: 0.00239... Test loss: 0.00332\n",
      "Epoch: 1... Training loss: 0.00223... Test loss: 0.0025\n",
      "Epoch: 1... Training loss: 0.00216... Test loss: 0.00295\n",
      "Epoch: 1... Training loss: 0.00211... Test loss: 0.00248\n",
      "Epoch: 1... Training loss: 0.00207... Test loss: 0.00216\n",
      "Epoch: 1... Training loss: 0.00201... Test loss: 0.00267\n",
      "Epoch: 1... Training loss: 0.00185... Test loss: 0.00227\n",
      "Epoch: 1... Training loss: 0.00187... Test loss: 0.00253\n",
      "Epoch: 1... Training loss: 0.00201... Test loss: 0.00264\n",
      "Epoch: 1... Training loss: 0.00167... Test loss: 0.00194\n",
      "Epoch: 1... Training loss: 0.00156... Test loss: 0.00215\n",
      "Epoch: 1... Training loss: 0.00155... Test loss: 0.00175\n",
      "Epoch: 1... Training loss: 0.0016... Test loss: 0.00224\n",
      "Epoch: 1... Training loss: 0.00148... Test loss: 0.0016\n",
      "Epoch: 1... Training loss: 0.00144... Test loss: 0.00155\n",
      "Epoch: 1... Training loss: 0.00133... Test loss: 0.00182\n",
      "Epoch: 1... Training loss: 0.00134... Test loss: 0.00168\n",
      "Epoch: 1... Training loss: 0.00123... Test loss: 0.00126\n",
      "Epoch: 1... Training loss: 0.00119... Test loss: 0.00147\n",
      "Epoch: 1... Training loss: 0.00116... Test loss: 0.00165\n",
      "Epoch: 1... Training loss: 0.00108... Test loss: 0.00144\n",
      "Epoch: 1... Training loss: 0.00102... Test loss: 0.00137\n",
      "Epoch: 1... Training loss: 0.00107... Test loss: 0.00132\n",
      "Epoch: 1... Training loss: 0.00096... Test loss: 0.00118\n",
      "Epoch: 1... Training loss: 0.0009... Test loss: 0.00139\n",
      "Epoch: 1... Training loss: 0.00085... Test loss: 0.00097\n",
      "Epoch: 1... Training loss: 0.00092... Test loss: 0.00129\n",
      "Epoch: 1... Training loss: 0.0008... Test loss: 0.00081\n",
      "Epoch: 1... Training loss: 0.00077... Test loss: 0.00117\n",
      "Epoch: 1... Training loss: 0.00079... Test loss: 0.00072\n",
      "Epoch: 1... Training loss: 0.00077... Test loss: 0.00113\n",
      "Epoch: 1... Training loss: 0.00071... Test loss: 0.00068\n",
      "Epoch: 1... Training loss: 0.00065... Test loss: 0.00085\n",
      "Epoch: 1... Training loss: 0.00061... Test loss: 0.00072\n",
      "Epoch: 1... Training loss: 0.00058... Test loss: 0.00074\n",
      "Epoch: 1... Training loss: 0.00059... Test loss: 0.00057\n",
      "Epoch: 1... Training loss: 0.00055... Test loss: 0.00062\n",
      "Epoch: 1... Training loss: 0.0006... Test loss: 0.00059\n",
      "Epoch: 1... Training loss: 0.00051... Test loss: 0.00055\n",
      "Epoch: 1... Training loss: 0.00048... Test loss: 0.00055\n",
      "Epoch: 1... Training loss: 0.00044... Test loss: 0.00069\n",
      "Epoch: 1... Training loss: 0.00043... Test loss: 0.00044\n",
      "Epoch: 1... Training loss: 0.00038... Test loss: 0.00061\n",
      "Epoch: 1... Training loss: 0.00041... Test loss: 0.00039\n",
      "Epoch: 1... Training loss: 0.00035... Test loss: 0.00041\n",
      "Epoch: 1... Training loss: 0.00036... Test loss: 0.00046\n",
      "Epoch: 1... Training loss: 0.00037... Test loss: 0.00039\n",
      "Epoch: 1... Training loss: 0.00035... Test loss: 0.00048\n",
      "Epoch: 1... Training loss: 0.00036... Test loss: 0.00033\n",
      "Epoch: 1... Training loss: 0.00034... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.0003\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00031\n",
      "Epoch: 1... Training loss: 0.00033... Test loss: 0.00024\n",
      "Epoch: 1... Training loss: 0.00033... Test loss: 0.00024\n",
      "Epoch: 1... Training loss: 0.00026... Test loss: 0.00028\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.0003\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.0003\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00011\n",
      "220.09006602305453\n",
      "Epoch: 1... Training loss: 0.99006... Test loss: 0.3179\n",
      "Epoch: 1... Training loss: 0.48085... Test loss: 0.17605\n",
      "Epoch: 1... Training loss: 0.27623... Test loss: 0.09098\n",
      "Epoch: 1... Training loss: 0.19787... Test loss: 0.07598\n",
      "Epoch: 1... Training loss: 0.14721... Test loss: 0.04991\n",
      "Epoch: 1... Training loss: 0.12002... Test loss: 0.04029\n",
      "Epoch: 1... Training loss: 0.09487... Test loss: 0.04143\n",
      "Epoch: 1... Training loss: 0.07522... Test loss: 0.02424\n",
      "Epoch: 1... Training loss: 0.0677... Test loss: 0.03247\n",
      "Epoch: 1... Training loss: 0.05623... Test loss: 0.01861\n",
      "Epoch: 1... Training loss: 0.04987... Test loss: 0.02498\n",
      "Epoch: 1... Training loss: 0.04527... Test loss: 0.01593\n",
      "Epoch: 1... Training loss: 0.04229... Test loss: 0.02517\n",
      "Epoch: 1... Training loss: 0.03609... Test loss: 0.01555\n",
      "Epoch: 1... Training loss: 0.03542... Test loss: 0.02189\n",
      "Epoch: 1... Training loss: 0.03313... Test loss: 0.01123\n",
      "Epoch: 1... Training loss: 0.03069... Test loss: 0.02281\n",
      "Epoch: 1... Training loss: 0.02794... Test loss: 0.01039\n",
      "Epoch: 1... Training loss: 0.02695... Test loss: 0.023\n",
      "Epoch: 1... Training loss: 0.02558... Test loss: 0.0121\n",
      "Epoch: 1... Training loss: 0.02468... Test loss: 0.02025\n",
      "Epoch: 1... Training loss: 0.02327... Test loss: 0.01194\n",
      "Epoch: 1... Training loss: 0.0227... Test loss: 0.01526\n",
      "Epoch: 1... Training loss: 0.02174... Test loss: 0.02518\n",
      "Epoch: 1... Training loss: 0.02037... Test loss: 0.01294\n",
      "Epoch: 1... Training loss: 0.01986... Test loss: 0.01989\n",
      "Epoch: 1... Training loss: 0.01898... Test loss: 0.01113\n",
      "Epoch: 1... Training loss: 0.01835... Test loss: 0.02156\n",
      "Epoch: 1... Training loss: 0.01769... Test loss: 0.00982\n",
      "Epoch: 1... Training loss: 0.01672... Test loss: 0.02015\n",
      "Epoch: 1... Training loss: 0.01643... Test loss: 0.01121\n",
      "Epoch: 1... Training loss: 0.01553... Test loss: 0.01837\n",
      "Epoch: 1... Training loss: 0.01526... Test loss: 0.00956\n",
      "Epoch: 1... Training loss: 0.01463... Test loss: 0.01566\n",
      "Epoch: 1... Training loss: 0.01448... Test loss: 0.00845\n",
      "Epoch: 1... Training loss: 0.01379... Test loss: 0.01693\n",
      "Epoch: 1... Training loss: 0.01314... Test loss: 0.00718\n",
      "Epoch: 1... Training loss: 0.01254... Test loss: 0.01629\n",
      "Epoch: 1... Training loss: 0.01204... Test loss: 0.01032\n",
      "Epoch: 1... Training loss: 0.01156... Test loss: 0.00991\n",
      "Epoch: 1... Training loss: 0.01111... Test loss: 0.01348\n",
      "Epoch: 1... Training loss: 0.01098... Test loss: 0.00705\n",
      "Epoch: 1... Training loss: 0.01052... Test loss: 0.01362\n",
      "Epoch: 1... Training loss: 0.01018... Test loss: 0.00724\n",
      "Epoch: 1... Training loss: 0.00973... Test loss: 0.01119\n",
      "Epoch: 1... Training loss: 0.0095... Test loss: 0.00779\n",
      "Epoch: 1... Training loss: 0.00911... Test loss: 0.00936\n",
      "Epoch: 1... Training loss: 0.00884... Test loss: 0.00697\n",
      "Epoch: 1... Training loss: 0.00866... Test loss: 0.00901\n",
      "Epoch: 1... Training loss: 0.00825... Test loss: 0.00644\n",
      "Epoch: 1... Training loss: 0.00792... Test loss: 0.00826\n",
      "Epoch: 1... Training loss: 0.00754... Test loss: 0.00675\n",
      "Epoch: 1... Training loss: 0.00736... Test loss: 0.0079\n",
      "Epoch: 1... Training loss: 0.00707... Test loss: 0.00706\n",
      "Epoch: 1... Training loss: 0.00694... Test loss: 0.00704\n",
      "Epoch: 1... Training loss: 0.0067... Test loss: 0.00606\n",
      "Epoch: 1... Training loss: 0.00649... Test loss: 0.00698\n",
      "Epoch: 1... Training loss: 0.00631... Test loss: 0.00633\n",
      "Epoch: 1... Training loss: 0.00605... Test loss: 0.00671\n",
      "Epoch: 1... Training loss: 0.00592... Test loss: 0.00698\n",
      "Epoch: 1... Training loss: 0.00582... Test loss: 0.0057\n",
      "Epoch: 1... Training loss: 0.0056... Test loss: 0.00708\n",
      "Epoch: 1... Training loss: 0.00547... Test loss: 0.00517\n",
      "Epoch: 1... Training loss: 0.0054... Test loss: 0.00642\n",
      "Epoch: 1... Training loss: 0.01715... Test loss: 0.01391\n",
      "Epoch: 1... Training loss: 0.00761... Test loss: 0.01715\n",
      "Epoch: 1... Training loss: 0.00884... Test loss: 0.01659\n",
      "Epoch: 1... Training loss: 0.00955... Test loss: 0.01432\n",
      "Epoch: 1... Training loss: 0.00842... Test loss: 0.0143\n",
      "Epoch: 1... Training loss: 0.0085... Test loss: 0.0134\n",
      "Epoch: 1... Training loss: 0.00786... Test loss: 0.01508\n",
      "Epoch: 1... Training loss: 0.00723... Test loss: 0.0104\n",
      "Epoch: 1... Training loss: 0.00736... Test loss: 0.01259\n",
      "Epoch: 1... Training loss: 0.00833... Test loss: 0.01201\n",
      "Epoch: 1... Training loss: 0.00735... Test loss: 0.01195\n",
      "Epoch: 1... Training loss: 0.00676... Test loss: 0.00944\n",
      "Epoch: 1... Training loss: 0.00741... Test loss: 0.01154\n",
      "Epoch: 1... Training loss: 0.00605... Test loss: 0.00922\n",
      "Epoch: 1... Training loss: 0.00622... Test loss: 0.00768\n",
      "Epoch: 1... Training loss: 0.00551... Test loss: 0.0101\n",
      "Epoch: 1... Training loss: 0.00566... Test loss: 0.00663\n",
      "Epoch: 1... Training loss: 0.00515... Test loss: 0.00764\n",
      "Epoch: 1... Training loss: 0.00536... Test loss: 0.00542\n",
      "Epoch: 1... Training loss: 0.0047... Test loss: 0.00857\n",
      "Epoch: 1... Training loss: 0.00537... Test loss: 0.0051\n",
      "Epoch: 1... Training loss: 0.00456... Test loss: 0.00755\n",
      "Epoch: 1... Training loss: 0.00486... Test loss: 0.00517\n",
      "Epoch: 1... Training loss: 0.00478... Test loss: 0.00711\n",
      "Epoch: 1... Training loss: 0.00455... Test loss: 0.00473\n",
      "Epoch: 1... Training loss: 0.00412... Test loss: 0.00626\n",
      "Epoch: 1... Training loss: 0.00392... Test loss: 0.00413\n",
      "Epoch: 1... Training loss: 0.00381... Test loss: 0.00546\n",
      "Epoch: 1... Training loss: 0.00373... Test loss: 0.00454\n",
      "Epoch: 1... Training loss: 0.00351... Test loss: 0.00529\n",
      "Epoch: 1... Training loss: 0.00366... Test loss: 0.00472\n",
      "Epoch: 1... Training loss: 0.00338... Test loss: 0.00516\n",
      "Epoch: 1... Training loss: 0.00334... Test loss: 0.00362\n",
      "Epoch: 1... Training loss: 0.00316... Test loss: 0.00476\n",
      "Epoch: 1... Training loss: 0.00305... Test loss: 0.00356\n",
      "Epoch: 1... Training loss: 0.0031... Test loss: 0.00441\n",
      "Epoch: 1... Training loss: 0.00286... Test loss: 0.00339\n",
      "Epoch: 1... Training loss: 0.0027... Test loss: 0.00423\n",
      "Epoch: 1... Training loss: 0.00271... Test loss: 0.00329\n",
      "Epoch: 1... Training loss: 0.00266... Test loss: 0.00378\n",
      "Epoch: 1... Training loss: 0.00238... Test loss: 0.00266\n",
      "Epoch: 1... Training loss: 0.00249... Test loss: 0.00366\n",
      "Epoch: 1... Training loss: 0.00233... Test loss: 0.00352\n",
      "Epoch: 1... Training loss: 0.00254... Test loss: 0.00335\n",
      "Epoch: 1... Training loss: 0.00221... Test loss: 0.00274\n",
      "Epoch: 1... Training loss: 0.00229... Test loss: 0.0026\n",
      "Epoch: 1... Training loss: 0.00212... Test loss: 0.0032\n",
      "Epoch: 1... Training loss: 0.002... Test loss: 0.0023\n",
      "Epoch: 1... Training loss: 0.00194... Test loss: 0.00281\n",
      "Epoch: 1... Training loss: 0.00185... Test loss: 0.00216\n",
      "Epoch: 1... Training loss: 0.00181... Test loss: 0.0025\n",
      "Epoch: 1... Training loss: 0.0018... Test loss: 0.00206\n",
      "Epoch: 1... Training loss: 0.00166... Test loss: 0.00249\n",
      "Epoch: 1... Training loss: 0.00163... Test loss: 0.00192\n",
      "Epoch: 1... Training loss: 0.00151... Test loss: 0.00224\n",
      "Epoch: 1... Training loss: 0.0015... Test loss: 0.00171\n",
      "Epoch: 1... Training loss: 0.00144... Test loss: 0.00175\n",
      "Epoch: 1... Training loss: 0.0013... Test loss: 0.00174\n",
      "Epoch: 1... Training loss: 0.00127... Test loss: 0.00155\n",
      "Epoch: 1... Training loss: 0.00122... Test loss: 0.00145\n",
      "Epoch: 1... Training loss: 0.00116... Test loss: 0.00145\n",
      "Epoch: 1... Training loss: 0.00111... Test loss: 0.00148\n",
      "Epoch: 1... Training loss: 0.00101... Test loss: 0.00125\n",
      "Epoch: 1... Training loss: 0.00106... Test loss: 0.00164\n",
      "Epoch: 1... Training loss: 0.00097... Test loss: 0.00101\n",
      "Epoch: 1... Training loss: 0.00099... Test loss: 0.0014\n",
      "Epoch: 1... Training loss: 0.00093... Test loss: 0.00116\n",
      "Epoch: 1... Training loss: 0.00086... Test loss: 0.00148\n",
      "Epoch: 1... Training loss: 0.0009... Test loss: 0.00106\n",
      "Epoch: 1... Training loss: 0.00082... Test loss: 0.0009\n",
      "Epoch: 1... Training loss: 0.00074... Test loss: 0.00085\n",
      "Epoch: 1... Training loss: 0.00068... Test loss: 0.00091\n",
      "Epoch: 1... Training loss: 0.00067... Test loss: 0.00086\n",
      "Epoch: 1... Training loss: 0.00063... Test loss: 0.00078\n",
      "Epoch: 1... Training loss: 0.00061... Test loss: 0.00095\n",
      "Epoch: 1... Training loss: 0.00063... Test loss: 0.00085\n",
      "Epoch: 1... Training loss: 0.00063... Test loss: 0.00071\n",
      "Epoch: 1... Training loss: 0.00056... Test loss: 0.00085\n",
      "Epoch: 1... Training loss: 0.00055... Test loss: 0.00069\n",
      "Epoch: 1... Training loss: 0.00052... Test loss: 0.00064\n",
      "Epoch: 1... Training loss: 0.00051... Test loss: 0.00046\n",
      "Epoch: 1... Training loss: 0.00048... Test loss: 0.00056\n",
      "Epoch: 1... Training loss: 0.00048... Test loss: 0.00048\n",
      "Epoch: 1... Training loss: 0.00046... Test loss: 0.00049\n",
      "Epoch: 1... Training loss: 0.00041... Test loss: 0.00048\n",
      "Epoch: 1... Training loss: 0.0004... Test loss: 0.00039\n",
      "Epoch: 1... Training loss: 0.00042... Test loss: 0.00042\n",
      "Epoch: 1... Training loss: 0.00038... Test loss: 0.00041\n",
      "Epoch: 1... Training loss: 0.0004... Test loss: 0.0004\n",
      "Epoch: 1... Training loss: 0.00038... Test loss: 0.00038\n",
      "Epoch: 1... Training loss: 0.00037... Test loss: 0.00034\n",
      "Epoch: 1... Training loss: 0.00039... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.00031... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.0003\n",
      "Epoch: 1... Training loss: 0.00026... Test loss: 0.0003\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00024\n",
      "Epoch: 1... Training loss: 0.00029... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 8e-05... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 7e-05... Test loss: 8e-05\n",
      "Epoch: 1... Training loss: 8e-05... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 7e-05... Test loss: 8e-05\n",
      "284.602962528239\n",
      "Epoch: 1... Training loss: 1.18455... Test loss: 0.50153\n",
      "Epoch: 1... Training loss: 0.51726... Test loss: 0.17799\n",
      "Epoch: 1... Training loss: 0.32949... Test loss: 0.11049\n",
      "Epoch: 1... Training loss: 0.21943... Test loss: 0.10553\n",
      "Epoch: 1... Training loss: 0.16419... Test loss: 0.06992\n",
      "Epoch: 1... Training loss: 0.12565... Test loss: 0.09014\n",
      "Epoch: 1... Training loss: 0.09484... Test loss: 0.07463\n",
      "Epoch: 1... Training loss: 0.08295... Test loss: 0.06125\n",
      "Epoch: 1... Training loss: 0.06852... Test loss: 0.08165\n",
      "Epoch: 1... Training loss: 0.05684... Test loss: 0.04\n",
      "Epoch: 1... Training loss: 0.05272... Test loss: 0.066\n",
      "Epoch: 1... Training loss: 0.04672... Test loss: 0.02714\n",
      "Epoch: 1... Training loss: 0.04153... Test loss: 0.05585\n",
      "Epoch: 1... Training loss: 0.03779... Test loss: 0.03104\n",
      "Epoch: 1... Training loss: 0.03616... Test loss: 0.02087\n",
      "Epoch: 1... Training loss: 0.03421... Test loss: 0.0331\n",
      "Epoch: 1... Training loss: 0.03044... Test loss: 0.0138\n",
      "Epoch: 1... Training loss: 0.02914... Test loss: 0.02834\n",
      "Epoch: 1... Training loss: 0.02643... Test loss: 0.01571\n",
      "Epoch: 1... Training loss: 0.02438... Test loss: 0.02721\n",
      "Epoch: 1... Training loss: 0.02256... Test loss: 0.01464\n",
      "Epoch: 1... Training loss: 0.02132... Test loss: 0.0234\n",
      "Epoch: 1... Training loss: 0.01999... Test loss: 0.0191\n",
      "Epoch: 1... Training loss: 0.02029... Test loss: 0.0125\n",
      "Epoch: 1... Training loss: 0.01869... Test loss: 0.02657\n",
      "Epoch: 1... Training loss: 0.01902... Test loss: 0.01144\n",
      "Epoch: 1... Training loss: 0.01717... Test loss: 0.02256\n",
      "Epoch: 1... Training loss: 0.01659... Test loss: 0.0114\n",
      "Epoch: 1... Training loss: 0.01595... Test loss: 0.01902\n",
      "Epoch: 1... Training loss: 0.01605... Test loss: 0.01088\n",
      "Epoch: 1... Training loss: 0.0147... Test loss: 0.01928\n",
      "Epoch: 1... Training loss: 0.01468... Test loss: 0.01131\n",
      "Epoch: 1... Training loss: 0.01376... Test loss: 0.01795\n",
      "Epoch: 1... Training loss: 0.01368... Test loss: 0.0115\n",
      "Epoch: 1... Training loss: 0.01272... Test loss: 0.01527\n",
      "Epoch: 1... Training loss: 0.01241... Test loss: 0.00987\n",
      "Epoch: 1... Training loss: 0.0119... Test loss: 0.01422\n",
      "Epoch: 1... Training loss: 0.01144... Test loss: 0.01023\n",
      "Epoch: 1... Training loss: 0.01112... Test loss: 0.01191\n",
      "Epoch: 1... Training loss: 0.0109... Test loss: 0.01177\n",
      "Epoch: 1... Training loss: 0.01047... Test loss: 0.01101\n",
      "Epoch: 1... Training loss: 0.01029... Test loss: 0.00998\n",
      "Epoch: 1... Training loss: 0.00976... Test loss: 0.01198\n",
      "Epoch: 1... Training loss: 0.00957... Test loss: 0.01052\n",
      "Epoch: 1... Training loss: 0.00909... Test loss: 0.01134\n",
      "Epoch: 1... Training loss: 0.00894... Test loss: 0.00945\n",
      "Epoch: 1... Training loss: 0.00853... Test loss: 0.0118\n",
      "Epoch: 1... Training loss: 0.0083... Test loss: 0.00779\n",
      "Epoch: 1... Training loss: 0.00797... Test loss: 0.01129\n",
      "Epoch: 1... Training loss: 0.00765... Test loss: 0.00773\n",
      "Epoch: 1... Training loss: 0.00743... Test loss: 0.00992\n",
      "Epoch: 1... Training loss: 0.00735... Test loss: 0.00672\n",
      "Epoch: 1... Training loss: 0.00714... Test loss: 0.0096\n",
      "Epoch: 1... Training loss: 0.00686... Test loss: 0.00639\n",
      "Epoch: 1... Training loss: 0.00661... Test loss: 0.00839\n",
      "Epoch: 1... Training loss: 0.00628... Test loss: 0.00595\n",
      "Epoch: 1... Training loss: 0.0061... Test loss: 0.00763\n",
      "Epoch: 1... Training loss: 0.00585... Test loss: 0.00543\n",
      "Epoch: 1... Training loss: 0.00585... Test loss: 0.00684\n",
      "Epoch: 1... Training loss: 0.00568... Test loss: 0.00562\n",
      "Epoch: 1... Training loss: 0.00554... Test loss: 0.00562\n",
      "Epoch: 1... Training loss: 0.00538... Test loss: 0.00598\n",
      "Epoch: 1... Training loss: 0.00527... Test loss: 0.00608\n",
      "Epoch: 1... Training loss: 0.00511... Test loss: 0.0055\n",
      "Epoch: 1... Training loss: 0.01344... Test loss: 0.02551\n",
      "Epoch: 1... Training loss: 0.01323... Test loss: 0.01148\n",
      "Epoch: 1... Training loss: 0.00895... Test loss: 0.02306\n",
      "Epoch: 1... Training loss: 0.00883... Test loss: 0.01332\n",
      "Epoch: 1... Training loss: 0.00798... Test loss: 0.01838\n",
      "Epoch: 1... Training loss: 0.00759... Test loss: 0.01444\n",
      "Epoch: 1... Training loss: 0.0082... Test loss: 0.01186\n",
      "Epoch: 1... Training loss: 0.0081... Test loss: 0.01082\n",
      "Epoch: 1... Training loss: 0.00811... Test loss: 0.00996\n",
      "Epoch: 1... Training loss: 0.00729... Test loss: 0.01175\n",
      "Epoch: 1... Training loss: 0.00728... Test loss: 0.0121\n",
      "Epoch: 1... Training loss: 0.00709... Test loss: 0.01022\n",
      "Epoch: 1... Training loss: 0.00688... Test loss: 0.01227\n",
      "Epoch: 1... Training loss: 0.00655... Test loss: 0.01185\n",
      "Epoch: 1... Training loss: 0.00608... Test loss: 0.00737\n",
      "Epoch: 1... Training loss: 0.0058... Test loss: 0.00807\n",
      "Epoch: 1... Training loss: 0.00569... Test loss: 0.00787\n",
      "Epoch: 1... Training loss: 0.00513... Test loss: 0.00718\n",
      "Epoch: 1... Training loss: 0.00539... Test loss: 0.00629\n",
      "Epoch: 1... Training loss: 0.00472... Test loss: 0.0064\n",
      "Epoch: 1... Training loss: 0.00496... Test loss: 0.00561\n",
      "Epoch: 1... Training loss: 0.00479... Test loss: 0.00644\n",
      "Epoch: 1... Training loss: 0.00444... Test loss: 0.00589\n",
      "Epoch: 1... Training loss: 0.00448... Test loss: 0.00537\n",
      "Epoch: 1... Training loss: 0.00407... Test loss: 0.00579\n",
      "Epoch: 1... Training loss: 0.00391... Test loss: 0.00506\n",
      "Epoch: 1... Training loss: 0.00375... Test loss: 0.00464\n",
      "Epoch: 1... Training loss: 0.00369... Test loss: 0.00421\n",
      "Epoch: 1... Training loss: 0.00355... Test loss: 0.00457\n",
      "Epoch: 1... Training loss: 0.00325... Test loss: 0.00392\n",
      "Epoch: 1... Training loss: 0.00325... Test loss: 0.00471\n",
      "Epoch: 1... Training loss: 0.00313... Test loss: 0.00392\n",
      "Epoch: 1... Training loss: 0.00299... Test loss: 0.00427\n",
      "Epoch: 1... Training loss: 0.00295... Test loss: 0.00323\n",
      "Epoch: 1... Training loss: 0.00281... Test loss: 0.0036\n",
      "Epoch: 1... Training loss: 0.00281... Test loss: 0.00307\n",
      "Epoch: 1... Training loss: 0.00264... Test loss: 0.00351\n",
      "Epoch: 1... Training loss: 0.00265... Test loss: 0.00299\n",
      "Epoch: 1... Training loss: 0.00248... Test loss: 0.00364\n",
      "Epoch: 1... Training loss: 0.00235... Test loss: 0.00295\n",
      "Epoch: 1... Training loss: 0.00228... Test loss: 0.00317\n",
      "Epoch: 1... Training loss: 0.00224... Test loss: 0.00247\n",
      "Epoch: 1... Training loss: 0.00212... Test loss: 0.00292\n",
      "Epoch: 1... Training loss: 0.00219... Test loss: 0.00247\n",
      "Epoch: 1... Training loss: 0.00217... Test loss: 0.00187\n",
      "Epoch: 1... Training loss: 0.0022... Test loss: 0.00217\n",
      "Epoch: 1... Training loss: 0.00204... Test loss: 0.00204\n",
      "Epoch: 1... Training loss: 0.00196... Test loss: 0.00209\n",
      "Epoch: 1... Training loss: 0.00202... Test loss: 0.00188\n",
      "Epoch: 1... Training loss: 0.00176... Test loss: 0.00249\n",
      "Epoch: 1... Training loss: 0.00168... Test loss: 0.0018\n",
      "Epoch: 1... Training loss: 0.00161... Test loss: 0.00231\n",
      "Epoch: 1... Training loss: 0.00169... Test loss: 0.00168\n",
      "Epoch: 1... Training loss: 0.00157... Test loss: 0.00178\n",
      "Epoch: 1... Training loss: 0.00148... Test loss: 0.00152\n",
      "Epoch: 1... Training loss: 0.00148... Test loss: 0.00177\n",
      "Epoch: 1... Training loss: 0.00141... Test loss: 0.0017\n",
      "Epoch: 1... Training loss: 0.00139... Test loss: 0.0015\n",
      "Epoch: 1... Training loss: 0.0013... Test loss: 0.00169\n",
      "Epoch: 1... Training loss: 0.00123... Test loss: 0.00115\n",
      "Epoch: 1... Training loss: 0.0012... Test loss: 0.00162\n",
      "Epoch: 1... Training loss: 0.00119... Test loss: 0.00133\n",
      "Epoch: 1... Training loss: 0.00108... Test loss: 0.00144\n",
      "Epoch: 1... Training loss: 0.00104... Test loss: 0.0013\n",
      "Epoch: 1... Training loss: 0.00106... Test loss: 0.00095\n",
      "Epoch: 1... Training loss: 0.00098... Test loss: 0.001\n",
      "Epoch: 1... Training loss: 0.00091... Test loss: 0.00112\n",
      "Epoch: 1... Training loss: 0.00095... Test loss: 0.00097\n",
      "Epoch: 1... Training loss: 0.00086... Test loss: 0.00089\n",
      "Epoch: 1... Training loss: 0.00084... Test loss: 0.00082\n",
      "Epoch: 1... Training loss: 0.00079... Test loss: 0.00096\n",
      "Epoch: 1... Training loss: 0.00073... Test loss: 0.00074\n",
      "Epoch: 1... Training loss: 0.00071... Test loss: 0.00082\n",
      "Epoch: 1... Training loss: 0.00069... Test loss: 0.00087\n",
      "Epoch: 1... Training loss: 0.00069... Test loss: 0.00071\n",
      "Epoch: 1... Training loss: 0.00058... Test loss: 0.00069\n",
      "Epoch: 1... Training loss: 0.00058... Test loss: 0.00074\n",
      "Epoch: 1... Training loss: 0.00059... Test loss: 0.00078\n",
      "Epoch: 1... Training loss: 0.00053... Test loss: 0.0007\n",
      "Epoch: 1... Training loss: 0.00054... Test loss: 0.00076\n",
      "Epoch: 1... Training loss: 0.00054... Test loss: 0.00061\n",
      "Epoch: 1... Training loss: 0.00051... Test loss: 0.00046\n",
      "Epoch: 1... Training loss: 0.00065... Test loss: 0.00055\n",
      "Epoch: 1... Training loss: 0.00048... Test loss: 0.0004\n",
      "Epoch: 1... Training loss: 0.00047... Test loss: 0.00054\n",
      "Epoch: 1... Training loss: 0.00045... Test loss: 0.00049\n",
      "Epoch: 1... Training loss: 0.00046... Test loss: 0.00043\n",
      "Epoch: 1... Training loss: 0.00039... Test loss: 0.00052\n",
      "Epoch: 1... Training loss: 0.00043... Test loss: 0.00039\n",
      "Epoch: 1... Training loss: 0.0004... Test loss: 0.00051\n",
      "Epoch: 1... Training loss: 0.0004... Test loss: 0.00033\n",
      "Epoch: 1... Training loss: 0.00047... Test loss: 0.00039\n",
      "Epoch: 1... Training loss: 0.00038... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.00038... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.00034... Test loss: 0.00039\n",
      "Epoch: 1... Training loss: 0.00035... Test loss: 0.00033\n",
      "Epoch: 1... Training loss: 0.00029... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.00029... Test loss: 0.00034\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00031\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.00037\n",
      "Epoch: 1... Training loss: 0.00029... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.00031... Test loss: 0.0003\n",
      "Epoch: 1... Training loss: 0.00029... Test loss: 0.00024\n",
      "Epoch: 1... Training loss: 0.00029... Test loss: 0.0003\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 8e-05\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 7e-05\n",
      "212.33401473634876\n",
      "Epoch: 1... Training loss: 0.91512... Test loss: 0.31435\n",
      "Epoch: 1... Training loss: 0.42705... Test loss: 0.11046\n",
      "Epoch: 1... Training loss: 0.31737... Test loss: 0.0766\n",
      "Epoch: 1... Training loss: 0.19649... Test loss: 0.06087\n",
      "Epoch: 1... Training loss: 0.14395... Test loss: 0.04602\n",
      "Epoch: 1... Training loss: 0.11695... Test loss: 0.03376\n",
      "Epoch: 1... Training loss: 0.08859... Test loss: 0.02561\n",
      "Epoch: 1... Training loss: 0.07437... Test loss: 0.02333\n",
      "Epoch: 1... Training loss: 0.06613... Test loss: 0.01635\n",
      "Epoch: 1... Training loss: 0.06007... Test loss: 0.02473\n",
      "Epoch: 1... Training loss: 0.05743... Test loss: 0.01621\n",
      "Epoch: 1... Training loss: 0.04974... Test loss: 0.02648\n",
      "Epoch: 1... Training loss: 0.04558... Test loss: 0.01063\n",
      "Epoch: 1... Training loss: 0.04137... Test loss: 0.02751\n",
      "Epoch: 1... Training loss: 0.03771... Test loss: 0.01018\n",
      "Epoch: 1... Training loss: 0.03456... Test loss: 0.02335\n",
      "Epoch: 1... Training loss: 0.03219... Test loss: 0.01176\n",
      "Epoch: 1... Training loss: 0.03082... Test loss: 0.02507\n",
      "Epoch: 1... Training loss: 0.02909... Test loss: 0.01673\n",
      "Epoch: 1... Training loss: 0.02701... Test loss: 0.0285\n",
      "Epoch: 1... Training loss: 0.02713... Test loss: 0.01337\n",
      "Epoch: 1... Training loss: 0.02388... Test loss: 0.02869\n",
      "Epoch: 1... Training loss: 0.02277... Test loss: 0.01092\n",
      "Epoch: 1... Training loss: 0.0211... Test loss: 0.02666\n",
      "Epoch: 1... Training loss: 0.01981... Test loss: 0.01539\n",
      "Epoch: 1... Training loss: 0.01897... Test loss: 0.01555\n",
      "Epoch: 1... Training loss: 0.01854... Test loss: 0.01949\n",
      "Epoch: 1... Training loss: 0.01745... Test loss: 0.01191\n",
      "Epoch: 1... Training loss: 0.01729... Test loss: 0.01995\n",
      "Epoch: 1... Training loss: 0.01637... Test loss: 0.00744\n",
      "Epoch: 1... Training loss: 0.01586... Test loss: 0.01817\n",
      "Epoch: 1... Training loss: 0.01457... Test loss: 0.01073\n",
      "Epoch: 1... Training loss: 0.01376... Test loss: 0.02181\n",
      "Epoch: 1... Training loss: 0.01353... Test loss: 0.00924\n",
      "Epoch: 1... Training loss: 0.0128... Test loss: 0.01327\n",
      "Epoch: 1... Training loss: 0.01245... Test loss: 0.00852\n",
      "Epoch: 1... Training loss: 0.0121... Test loss: 0.01351\n",
      "Epoch: 1... Training loss: 0.01162... Test loss: 0.00793\n",
      "Epoch: 1... Training loss: 0.01103... Test loss: 0.0124\n",
      "Epoch: 1... Training loss: 0.01078... Test loss: 0.00749\n",
      "Epoch: 1... Training loss: 0.01043... Test loss: 0.00987\n",
      "Epoch: 1... Training loss: 0.01017... Test loss: 0.00594\n",
      "Epoch: 1... Training loss: 0.00974... Test loss: 0.01101\n",
      "Epoch: 1... Training loss: 0.00926... Test loss: 0.00562\n",
      "Epoch: 1... Training loss: 0.00926... Test loss: 0.01074\n",
      "Epoch: 1... Training loss: 0.00883... Test loss: 0.00671\n",
      "Epoch: 1... Training loss: 0.00858... Test loss: 0.00931\n",
      "Epoch: 1... Training loss: 0.0083... Test loss: 0.00732\n",
      "Epoch: 1... Training loss: 0.00795... Test loss: 0.00694\n",
      "Epoch: 1... Training loss: 0.00783... Test loss: 0.00735\n",
      "Epoch: 1... Training loss: 0.00756... Test loss: 0.00495\n",
      "Epoch: 1... Training loss: 0.00717... Test loss: 0.00761\n",
      "Epoch: 1... Training loss: 0.007... Test loss: 0.00495\n",
      "Epoch: 1... Training loss: 0.00669... Test loss: 0.00723\n",
      "Epoch: 1... Training loss: 0.00647... Test loss: 0.00596\n",
      "Epoch: 1... Training loss: 0.00621... Test loss: 0.00671\n",
      "Epoch: 1... Training loss: 0.00606... Test loss: 0.00657\n",
      "Epoch: 1... Training loss: 0.00587... Test loss: 0.0054\n",
      "Epoch: 1... Training loss: 0.00569... Test loss: 0.00607\n",
      "Epoch: 1... Training loss: 0.00556... Test loss: 0.00522\n",
      "Epoch: 1... Training loss: 0.00536... Test loss: 0.00522\n",
      "Epoch: 1... Training loss: 0.00515... Test loss: 0.00557\n",
      "Epoch: 1... Training loss: 0.005... Test loss: 0.0048\n",
      "Epoch: 1... Training loss: 0.0049... Test loss: 0.00475\n",
      "Epoch: 1... Training loss: 0.01194... Test loss: 0.02171\n",
      "Epoch: 1... Training loss: 0.00767... Test loss: 0.01079\n",
      "Epoch: 1... Training loss: 0.01088... Test loss: 0.01624\n",
      "Epoch: 1... Training loss: 0.00857... Test loss: 0.0111\n",
      "Epoch: 1... Training loss: 0.00986... Test loss: 0.01153\n",
      "Epoch: 1... Training loss: 0.0085... Test loss: 0.01289\n",
      "Epoch: 1... Training loss: 0.0077... Test loss: 0.00924\n",
      "Epoch: 1... Training loss: 0.00846... Test loss: 0.01213\n",
      "Epoch: 1... Training loss: 0.00684... Test loss: 0.01238\n",
      "Epoch: 1... Training loss: 0.00696... Test loss: 0.00811\n",
      "Epoch: 1... Training loss: 0.00731... Test loss: 0.01215\n",
      "Epoch: 1... Training loss: 0.00626... Test loss: 0.00683\n",
      "Epoch: 1... Training loss: 0.00672... Test loss: 0.01019\n",
      "Epoch: 1... Training loss: 0.00569... Test loss: 0.00802\n",
      "Epoch: 1... Training loss: 0.00652... Test loss: 0.00743\n",
      "Epoch: 1... Training loss: 0.00589... Test loss: 0.0096\n",
      "Epoch: 1... Training loss: 0.00566... Test loss: 0.00549\n",
      "Epoch: 1... Training loss: 0.00522... Test loss: 0.00891\n",
      "Epoch: 1... Training loss: 0.00487... Test loss: 0.00593\n",
      "Epoch: 1... Training loss: 0.00505... Test loss: 0.00683\n",
      "Epoch: 1... Training loss: 0.00478... Test loss: 0.00585\n",
      "Epoch: 1... Training loss: 0.00431... Test loss: 0.00655\n",
      "Epoch: 1... Training loss: 0.00437... Test loss: 0.00533\n",
      "Epoch: 1... Training loss: 0.00439... Test loss: 0.00383\n",
      "Epoch: 1... Training loss: 0.00426... Test loss: 0.00509\n",
      "Epoch: 1... Training loss: 0.00386... Test loss: 0.00375\n",
      "Epoch: 1... Training loss: 0.00395... Test loss: 0.0045\n",
      "Epoch: 1... Training loss: 0.00371... Test loss: 0.00526\n",
      "Epoch: 1... Training loss: 0.00374... Test loss: 0.00402\n",
      "Epoch: 1... Training loss: 0.00346... Test loss: 0.00447\n",
      "Epoch: 1... Training loss: 0.00337... Test loss: 0.00389\n",
      "Epoch: 1... Training loss: 0.00331... Test loss: 0.00446\n",
      "Epoch: 1... Training loss: 0.00302... Test loss: 0.00387\n",
      "Epoch: 1... Training loss: 0.00299... Test loss: 0.0043\n",
      "Epoch: 1... Training loss: 0.00286... Test loss: 0.00345\n",
      "Epoch: 1... Training loss: 0.00285... Test loss: 0.00344\n",
      "Epoch: 1... Training loss: 0.00264... Test loss: 0.00341\n",
      "Epoch: 1... Training loss: 0.00267... Test loss: 0.00284\n",
      "Epoch: 1... Training loss: 0.0026... Test loss: 0.00292\n",
      "Epoch: 1... Training loss: 0.00245... Test loss: 0.00352\n",
      "Epoch: 1... Training loss: 0.00236... Test loss: 0.00252\n",
      "Epoch: 1... Training loss: 0.00233... Test loss: 0.00271\n",
      "Epoch: 1... Training loss: 0.00229... Test loss: 0.00239\n",
      "Epoch: 1... Training loss: 0.0021... Test loss: 0.00294\n",
      "Epoch: 1... Training loss: 0.00202... Test loss: 0.00214\n",
      "Epoch: 1... Training loss: 0.0021... Test loss: 0.00221\n",
      "Epoch: 1... Training loss: 0.00187... Test loss: 0.00195\n",
      "Epoch: 1... Training loss: 0.00176... Test loss: 0.00187\n",
      "Epoch: 1... Training loss: 0.0017... Test loss: 0.00203\n",
      "Epoch: 1... Training loss: 0.0018... Test loss: 0.00171\n",
      "Epoch: 1... Training loss: 0.00167... Test loss: 0.00224\n",
      "Epoch: 1... Training loss: 0.00159... Test loss: 0.0013\n",
      "Epoch: 1... Training loss: 0.00155... Test loss: 0.00189\n",
      "Epoch: 1... Training loss: 0.00143... Test loss: 0.0013\n",
      "Epoch: 1... Training loss: 0.00143... Test loss: 0.00199\n",
      "Epoch: 1... Training loss: 0.00136... Test loss: 0.00155\n",
      "Epoch: 1... Training loss: 0.00128... Test loss: 0.00195\n",
      "Epoch: 1... Training loss: 0.00127... Test loss: 0.00131\n",
      "Epoch: 1... Training loss: 0.00124... Test loss: 0.00183\n",
      "Epoch: 1... Training loss: 0.00119... Test loss: 0.00156\n",
      "Epoch: 1... Training loss: 0.00116... Test loss: 0.00185\n",
      "Epoch: 1... Training loss: 0.00107... Test loss: 0.00142\n",
      "Epoch: 1... Training loss: 0.00106... Test loss: 0.00147\n",
      "Epoch: 1... Training loss: 0.00106... Test loss: 0.00097\n",
      "Epoch: 1... Training loss: 0.00098... Test loss: 0.0015\n",
      "Epoch: 1... Training loss: 0.00098... Test loss: 0.00115\n",
      "Epoch: 1... Training loss: 0.00087... Test loss: 0.00128\n",
      "Epoch: 1... Training loss: 0.00087... Test loss: 0.00122\n",
      "Epoch: 1... Training loss: 0.00088... Test loss: 0.00097\n",
      "Epoch: 1... Training loss: 0.00083... Test loss: 0.00116\n",
      "Epoch: 1... Training loss: 0.00081... Test loss: 0.00091\n",
      "Epoch: 1... Training loss: 0.00073... Test loss: 0.00089\n",
      "Epoch: 1... Training loss: 0.0007... Test loss: 0.00079\n",
      "Epoch: 1... Training loss: 0.00071... Test loss: 0.00069\n",
      "Epoch: 1... Training loss: 0.00065... Test loss: 0.00063\n",
      "Epoch: 1... Training loss: 0.00066... Test loss: 0.00087\n",
      "Epoch: 1... Training loss: 0.0006... Test loss: 0.00056\n",
      "Epoch: 1... Training loss: 0.00059... Test loss: 0.00094\n",
      "Epoch: 1... Training loss: 0.00057... Test loss: 0.0006\n",
      "Epoch: 1... Training loss: 0.00055... Test loss: 0.00073\n",
      "Epoch: 1... Training loss: 0.00051... Test loss: 0.00076\n",
      "Epoch: 1... Training loss: 0.00048... Test loss: 0.00063\n",
      "Epoch: 1... Training loss: 0.00048... Test loss: 0.0005\n",
      "Epoch: 1... Training loss: 0.00045... Test loss: 0.00056\n",
      "Epoch: 1... Training loss: 0.00042... Test loss: 0.00047\n",
      "Epoch: 1... Training loss: 0.00039... Test loss: 0.00044\n",
      "Epoch: 1... Training loss: 0.00038... Test loss: 0.00032\n",
      "Epoch: 1... Training loss: 0.00041... Test loss: 0.00041\n",
      "Epoch: 1... Training loss: 0.00038... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.00038... Test loss: 0.00055\n",
      "Epoch: 1... Training loss: 0.00035... Test loss: 0.00041\n",
      "Epoch: 1... Training loss: 0.00037... Test loss: 0.00052\n",
      "Epoch: 1... Training loss: 0.00033... Test loss: 0.00039\n",
      "Epoch: 1... Training loss: 0.00032... Test loss: 0.00043\n",
      "Epoch: 1... Training loss: 0.00029... Test loss: 0.0003\n",
      "Epoch: 1... Training loss: 0.00029... Test loss: 0.00036\n",
      "Epoch: 1... Training loss: 0.00031... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00032\n",
      "Epoch: 1... Training loss: 0.00032... Test loss: 0.00028\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00039\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00024\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00024\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 8e-05\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 6e-05\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 8e-05... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 7e-05\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 8e-05... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 8e-05\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 6e-05\n",
      "240.66097624064423\n",
      "Epoch: 1... Training loss: 0.87304... Test loss: 0.24979\n",
      "Epoch: 1... Training loss: 0.46331... Test loss: 0.1602\n",
      "Epoch: 1... Training loss: 0.30065... Test loss: 0.09923\n",
      "Epoch: 1... Training loss: 0.19915... Test loss: 0.06687\n",
      "Epoch: 1... Training loss: 0.12818... Test loss: 0.0485\n",
      "Epoch: 1... Training loss: 0.11449... Test loss: 0.03567\n",
      "Epoch: 1... Training loss: 0.08926... Test loss: 0.03371\n",
      "Epoch: 1... Training loss: 0.08076... Test loss: 0.03119\n",
      "Epoch: 1... Training loss: 0.06493... Test loss: 0.01749\n",
      "Epoch: 1... Training loss: 0.05813... Test loss: 0.01607\n",
      "Epoch: 1... Training loss: 0.0499... Test loss: 0.01337\n",
      "Epoch: 1... Training loss: 0.04477... Test loss: 0.01502\n",
      "Epoch: 1... Training loss: 0.03999... Test loss: 0.01377\n",
      "Epoch: 1... Training loss: 0.0378... Test loss: 0.01972\n",
      "Epoch: 1... Training loss: 0.03401... Test loss: 0.00652\n",
      "Epoch: 1... Training loss: 0.0313... Test loss: 0.01629\n",
      "Epoch: 1... Training loss: 0.02822... Test loss: 0.00945\n",
      "Epoch: 1... Training loss: 0.02819... Test loss: 0.00791\n",
      "Epoch: 1... Training loss: 0.02542... Test loss: 0.01034\n",
      "Epoch: 1... Training loss: 0.02403... Test loss: 0.00648\n",
      "Epoch: 1... Training loss: 0.02272... Test loss: 0.01051\n",
      "Epoch: 1... Training loss: 0.02125... Test loss: 0.0081\n",
      "Epoch: 1... Training loss: 0.01983... Test loss: 0.00894\n",
      "Epoch: 1... Training loss: 0.01881... Test loss: 0.00927\n",
      "Epoch: 1... Training loss: 0.0176... Test loss: 0.00783\n",
      "Epoch: 1... Training loss: 0.01741... Test loss: 0.00543\n",
      "Epoch: 1... Training loss: 0.01648... Test loss: 0.01199\n",
      "Epoch: 1... Training loss: 0.01594... Test loss: 0.00525\n",
      "Epoch: 1... Training loss: 0.01502... Test loss: 0.00907\n",
      "Epoch: 1... Training loss: 0.01481... Test loss: 0.00432\n",
      "Epoch: 1... Training loss: 0.01383... Test loss: 0.01133\n",
      "Epoch: 1... Training loss: 0.01374... Test loss: 0.00636\n",
      "Epoch: 1... Training loss: 0.0129... Test loss: 0.00968\n",
      "Epoch: 1... Training loss: 0.01273... Test loss: 0.00633\n",
      "Epoch: 1... Training loss: 0.01224... Test loss: 0.00882\n",
      "Epoch: 1... Training loss: 0.01183... Test loss: 0.00975\n",
      "Epoch: 1... Training loss: 0.01124... Test loss: 0.00599\n",
      "Epoch: 1... Training loss: 0.01077... Test loss: 0.00965\n",
      "Epoch: 1... Training loss: 0.01048... Test loss: 0.00603\n",
      "Epoch: 1... Training loss: 0.00982... Test loss: 0.00843\n",
      "Epoch: 1... Training loss: 0.0098... Test loss: 0.00578\n",
      "Epoch: 1... Training loss: 0.00937... Test loss: 0.00756\n",
      "Epoch: 1... Training loss: 0.00928... Test loss: 0.0049\n",
      "Epoch: 1... Training loss: 0.00903... Test loss: 0.0069\n",
      "Epoch: 1... Training loss: 0.00882... Test loss: 0.00459\n",
      "Epoch: 1... Training loss: 0.00852... Test loss: 0.00715\n",
      "Epoch: 1... Training loss: 0.00835... Test loss: 0.00602\n",
      "Epoch: 1... Training loss: 0.00804... Test loss: 0.0059\n",
      "Epoch: 1... Training loss: 0.00768... Test loss: 0.00617\n",
      "Epoch: 1... Training loss: 0.00736... Test loss: 0.00464\n",
      "Epoch: 1... Training loss: 0.00719... Test loss: 0.00643\n",
      "Epoch: 1... Training loss: 0.00708... Test loss: 0.00529\n",
      "Epoch: 1... Training loss: 0.00677... Test loss: 0.00657\n",
      "Epoch: 1... Training loss: 0.00675... Test loss: 0.00538\n",
      "Epoch: 1... Training loss: 0.00649... Test loss: 0.00596\n",
      "Epoch: 1... Training loss: 0.00626... Test loss: 0.00543\n",
      "Epoch: 1... Training loss: 0.00604... Test loss: 0.00513\n",
      "Epoch: 1... Training loss: 0.00592... Test loss: 0.00575\n",
      "Epoch: 1... Training loss: 0.00578... Test loss: 0.00425\n",
      "Epoch: 1... Training loss: 0.00558... Test loss: 0.00557\n",
      "Epoch: 1... Training loss: 0.00548... Test loss: 0.00402\n",
      "Epoch: 1... Training loss: 0.00532... Test loss: 0.00537\n",
      "Epoch: 1... Training loss: 0.00526... Test loss: 0.00535\n",
      "Epoch: 1... Training loss: 0.00508... Test loss: 0.00467\n",
      "Epoch: 1... Training loss: 0.01084... Test loss: 0.0222\n",
      "Epoch: 1... Training loss: 0.01315... Test loss: 0.0124\n",
      "Epoch: 1... Training loss: 0.00873... Test loss: 0.01238\n",
      "Epoch: 1... Training loss: 0.01018... Test loss: 0.01128\n",
      "Epoch: 1... Training loss: 0.00869... Test loss: 0.01599\n",
      "Epoch: 1... Training loss: 0.00771... Test loss: 0.00931\n",
      "Epoch: 1... Training loss: 0.00858... Test loss: 0.00989\n",
      "Epoch: 1... Training loss: 0.00754... Test loss: 0.01297\n",
      "Epoch: 1... Training loss: 0.00793... Test loss: 0.01218\n",
      "Epoch: 1... Training loss: 0.00801... Test loss: 0.0107\n",
      "Epoch: 1... Training loss: 0.00705... Test loss: 0.00842\n",
      "Epoch: 1... Training loss: 0.00717... Test loss: 0.00752\n",
      "Epoch: 1... Training loss: 0.007... Test loss: 0.01161\n",
      "Epoch: 1... Training loss: 0.00609... Test loss: 0.00742\n",
      "Epoch: 1... Training loss: 0.00587... Test loss: 0.00796\n",
      "Epoch: 1... Training loss: 0.00563... Test loss: 0.00749\n",
      "Epoch: 1... Training loss: 0.00601... Test loss: 0.00762\n",
      "Epoch: 1... Training loss: 0.00549... Test loss: 0.006\n",
      "Epoch: 1... Training loss: 0.00516... Test loss: 0.00758\n",
      "Epoch: 1... Training loss: 0.00506... Test loss: 0.00642\n",
      "Epoch: 1... Training loss: 0.00495... Test loss: 0.00677\n",
      "Epoch: 1... Training loss: 0.005... Test loss: 0.0069\n",
      "Epoch: 1... Training loss: 0.00463... Test loss: 0.00531\n",
      "Epoch: 1... Training loss: 0.00439... Test loss: 0.00633\n",
      "Epoch: 1... Training loss: 0.0044... Test loss: 0.00458\n",
      "Epoch: 1... Training loss: 0.00422... Test loss: 0.00545\n",
      "Epoch: 1... Training loss: 0.00388... Test loss: 0.00501\n",
      "Epoch: 1... Training loss: 0.00376... Test loss: 0.00466\n",
      "Epoch: 1... Training loss: 0.0037... Test loss: 0.0045\n",
      "Epoch: 1... Training loss: 0.00357... Test loss: 0.0039\n",
      "Epoch: 1... Training loss: 0.00347... Test loss: 0.00344\n",
      "Epoch: 1... Training loss: 0.00339... Test loss: 0.00431\n",
      "Epoch: 1... Training loss: 0.00325... Test loss: 0.00326\n",
      "Epoch: 1... Training loss: 0.00305... Test loss: 0.00369\n",
      "Epoch: 1... Training loss: 0.00304... Test loss: 0.00351\n",
      "Epoch: 1... Training loss: 0.00296... Test loss: 0.00381\n",
      "Epoch: 1... Training loss: 0.00284... Test loss: 0.00364\n",
      "Epoch: 1... Training loss: 0.00263... Test loss: 0.003\n",
      "Epoch: 1... Training loss: 0.00256... Test loss: 0.00312\n",
      "Epoch: 1... Training loss: 0.0025... Test loss: 0.00333\n",
      "Epoch: 1... Training loss: 0.00244... Test loss: 0.00297\n",
      "Epoch: 1... Training loss: 0.00242... Test loss: 0.00273\n",
      "Epoch: 1... Training loss: 0.00233... Test loss: 0.00274\n",
      "Epoch: 1... Training loss: 0.00228... Test loss: 0.0025\n",
      "Epoch: 1... Training loss: 0.0022... Test loss: 0.00262\n",
      "Epoch: 1... Training loss: 0.00214... Test loss: 0.00241\n",
      "Epoch: 1... Training loss: 0.0021... Test loss: 0.00191\n",
      "Epoch: 1... Training loss: 0.00198... Test loss: 0.00248\n",
      "Epoch: 1... Training loss: 0.00206... Test loss: 0.00228\n",
      "Epoch: 1... Training loss: 0.00198... Test loss: 0.00229\n",
      "Epoch: 1... Training loss: 0.0019... Test loss: 0.00199\n",
      "Epoch: 1... Training loss: 0.00179... Test loss: 0.00246\n",
      "Epoch: 1... Training loss: 0.00184... Test loss: 0.00208\n",
      "Epoch: 1... Training loss: 0.00172... Test loss: 0.00222\n",
      "Epoch: 1... Training loss: 0.00179... Test loss: 0.00169\n",
      "Epoch: 1... Training loss: 0.00157... Test loss: 0.0023\n",
      "Epoch: 1... Training loss: 0.0016... Test loss: 0.00202\n",
      "Epoch: 1... Training loss: 0.00148... Test loss: 0.00203\n",
      "Epoch: 1... Training loss: 0.00153... Test loss: 0.00189\n",
      "Epoch: 1... Training loss: 0.00137... Test loss: 0.00193\n",
      "Epoch: 1... Training loss: 0.00143... Test loss: 0.00156\n",
      "Epoch: 1... Training loss: 0.00137... Test loss: 0.00142\n",
      "Epoch: 1... Training loss: 0.00128... Test loss: 0.00182\n",
      "Epoch: 1... Training loss: 0.00123... Test loss: 0.0012\n",
      "Epoch: 1... Training loss: 0.00121... Test loss: 0.00129\n",
      "Epoch: 1... Training loss: 0.00114... Test loss: 0.00113\n",
      "Epoch: 1... Training loss: 0.0011... Test loss: 0.00156\n",
      "Epoch: 1... Training loss: 0.00112... Test loss: 0.00134\n",
      "Epoch: 1... Training loss: 0.00105... Test loss: 0.00137\n",
      "Epoch: 1... Training loss: 0.00099... Test loss: 0.0011\n",
      "Epoch: 1... Training loss: 0.00088... Test loss: 0.00102\n",
      "Epoch: 1... Training loss: 0.00091... Test loss: 0.00094\n",
      "Epoch: 1... Training loss: 0.00085... Test loss: 0.00109\n",
      "Epoch: 1... Training loss: 0.00088... Test loss: 0.00081\n",
      "Epoch: 1... Training loss: 0.00077... Test loss: 0.0008\n",
      "Epoch: 1... Training loss: 0.00077... Test loss: 0.00069\n",
      "Epoch: 1... Training loss: 0.00072... Test loss: 0.00066\n",
      "Epoch: 1... Training loss: 0.00075... Test loss: 0.00068\n",
      "Epoch: 1... Training loss: 0.00064... Test loss: 0.00068\n",
      "Epoch: 1... Training loss: 0.00067... Test loss: 0.00074\n",
      "Epoch: 1... Training loss: 0.00062... Test loss: 0.00075\n",
      "Epoch: 1... Training loss: 0.00063... Test loss: 0.00082\n",
      "Epoch: 1... Training loss: 0.00053... Test loss: 0.00068\n",
      "Epoch: 1... Training loss: 0.00052... Test loss: 0.00071\n",
      "Epoch: 1... Training loss: 0.00054... Test loss: 0.00056\n",
      "Epoch: 1... Training loss: 0.0005... Test loss: 0.00059\n",
      "Epoch: 1... Training loss: 0.00055... Test loss: 0.0005\n",
      "Epoch: 1... Training loss: 0.00044... Test loss: 0.00053\n",
      "Epoch: 1... Training loss: 0.00047... Test loss: 0.00039\n",
      "Epoch: 1... Training loss: 0.00039... Test loss: 0.00046\n",
      "Epoch: 1... Training loss: 0.00043... Test loss: 0.0004\n",
      "Epoch: 1... Training loss: 0.00043... Test loss: 0.00034\n",
      "Epoch: 1... Training loss: 0.0004... Test loss: 0.00037\n",
      "Epoch: 1... Training loss: 0.00037... Test loss: 0.00041\n",
      "Epoch: 1... Training loss: 0.00038... Test loss: 0.00028\n",
      "Epoch: 1... Training loss: 0.00035... Test loss: 0.00037\n",
      "Epoch: 1... Training loss: 0.00035... Test loss: 0.00031\n",
      "Epoch: 1... Training loss: 0.00033... Test loss: 0.00036\n",
      "Epoch: 1... Training loss: 0.00032... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00033\n",
      "Epoch: 1... Training loss: 0.00032... Test loss: 0.00028\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.00033\n",
      "Epoch: 1... Training loss: 0.00029... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00026... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00028\n",
      "Epoch: 1... Training loss: 0.00029... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.0003\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00028\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.0001\n",
      "239.35785582859535\n",
      "Epoch: 1... Training loss: 1.11549... Test loss: 0.51551\n",
      "Epoch: 1... Training loss: 0.59667... Test loss: 0.21267\n",
      "Epoch: 1... Training loss: 0.34596... Test loss: 0.12136\n",
      "Epoch: 1... Training loss: 0.22503... Test loss: 0.09233\n",
      "Epoch: 1... Training loss: 0.15993... Test loss: 0.06972\n",
      "Epoch: 1... Training loss: 0.13077... Test loss: 0.04191\n",
      "Epoch: 1... Training loss: 0.10704... Test loss: 0.06866\n",
      "Epoch: 1... Training loss: 0.08748... Test loss: 0.03204\n",
      "Epoch: 1... Training loss: 0.07292... Test loss: 0.06086\n",
      "Epoch: 1... Training loss: 0.06851... Test loss: 0.02245\n",
      "Epoch: 1... Training loss: 0.0582... Test loss: 0.04834\n",
      "Epoch: 1... Training loss: 0.05132... Test loss: 0.02338\n",
      "Epoch: 1... Training loss: 0.04492... Test loss: 0.04894\n",
      "Epoch: 1... Training loss: 0.04195... Test loss: 0.02236\n",
      "Epoch: 1... Training loss: 0.03907... Test loss: 0.04445\n",
      "Epoch: 1... Training loss: 0.03807... Test loss: 0.01901\n",
      "Epoch: 1... Training loss: 0.03373... Test loss: 0.04719\n",
      "Epoch: 1... Training loss: 0.03249... Test loss: 0.02583\n",
      "Epoch: 1... Training loss: 0.02956... Test loss: 0.03558\n",
      "Epoch: 1... Training loss: 0.02777... Test loss: 0.03085\n",
      "Epoch: 1... Training loss: 0.02674... Test loss: 0.01892\n",
      "Epoch: 1... Training loss: 0.02448... Test loss: 0.03708\n",
      "Epoch: 1... Training loss: 0.02385... Test loss: 0.01966\n",
      "Epoch: 1... Training loss: 0.02239... Test loss: 0.04009\n",
      "Epoch: 1... Training loss: 0.0219... Test loss: 0.01902\n",
      "Epoch: 1... Training loss: 0.02097... Test loss: 0.02706\n",
      "Epoch: 1... Training loss: 0.02003... Test loss: 0.01676\n",
      "Epoch: 1... Training loss: 0.01828... Test loss: 0.02861\n",
      "Epoch: 1... Training loss: 0.01732... Test loss: 0.01655\n",
      "Epoch: 1... Training loss: 0.01664... Test loss: 0.02022\n",
      "Epoch: 1... Training loss: 0.01629... Test loss: 0.01488\n",
      "Epoch: 1... Training loss: 0.01567... Test loss: 0.01967\n",
      "Epoch: 1... Training loss: 0.01503... Test loss: 0.01734\n",
      "Epoch: 1... Training loss: 0.01454... Test loss: 0.01617\n",
      "Epoch: 1... Training loss: 0.01384... Test loss: 0.01765\n",
      "Epoch: 1... Training loss: 0.01327... Test loss: 0.0122\n",
      "Epoch: 1... Training loss: 0.01293... Test loss: 0.01733\n",
      "Epoch: 1... Training loss: 0.01257... Test loss: 0.0093\n",
      "Epoch: 1... Training loss: 0.01223... Test loss: 0.01586\n",
      "Epoch: 1... Training loss: 0.01176... Test loss: 0.00836\n",
      "Epoch: 1... Training loss: 0.01171... Test loss: 0.01328\n",
      "Epoch: 1... Training loss: 0.01123... Test loss: 0.0125\n",
      "Epoch: 1... Training loss: 0.01107... Test loss: 0.00848\n",
      "Epoch: 1... Training loss: 0.01049... Test loss: 0.01321\n",
      "Epoch: 1... Training loss: 0.01012... Test loss: 0.00813\n",
      "Epoch: 1... Training loss: 0.00969... Test loss: 0.01143\n",
      "Epoch: 1... Training loss: 0.00935... Test loss: 0.00824\n",
      "Epoch: 1... Training loss: 0.00896... Test loss: 0.00989\n",
      "Epoch: 1... Training loss: 0.00869... Test loss: 0.0082\n",
      "Epoch: 1... Training loss: 0.00837... Test loss: 0.00928\n",
      "Epoch: 1... Training loss: 0.00804... Test loss: 0.00761\n",
      "Epoch: 1... Training loss: 0.00762... Test loss: 0.00854\n",
      "Epoch: 1... Training loss: 0.0073... Test loss: 0.00752\n",
      "Epoch: 1... Training loss: 0.00724... Test loss: 0.00784\n",
      "Epoch: 1... Training loss: 0.00702... Test loss: 0.00661\n",
      "Epoch: 1... Training loss: 0.00688... Test loss: 0.00742\n",
      "Epoch: 1... Training loss: 0.00669... Test loss: 0.00626\n",
      "Epoch: 1... Training loss: 0.00646... Test loss: 0.00792\n",
      "Epoch: 1... Training loss: 0.00622... Test loss: 0.00677\n",
      "Epoch: 1... Training loss: 0.00608... Test loss: 0.00719\n",
      "Epoch: 1... Training loss: 0.00582... Test loss: 0.00692\n",
      "Epoch: 1... Training loss: 0.00568... Test loss: 0.00666\n",
      "Epoch: 1... Training loss: 0.00546... Test loss: 0.0068\n",
      "Epoch: 1... Training loss: 0.00533... Test loss: 0.0061\n",
      "Epoch: 1... Training loss: 0.01298... Test loss: 0.03242\n",
      "Epoch: 1... Training loss: 0.00779... Test loss: 0.01107\n",
      "Epoch: 1... Training loss: 0.0101... Test loss: 0.02009\n",
      "Epoch: 1... Training loss: 0.00906... Test loss: 0.01175\n",
      "Epoch: 1... Training loss: 0.00788... Test loss: 0.01114\n",
      "Epoch: 1... Training loss: 0.00948... Test loss: 0.01275\n",
      "Epoch: 1... Training loss: 0.00809... Test loss: 0.01172\n",
      "Epoch: 1... Training loss: 0.00871... Test loss: 0.01555\n",
      "Epoch: 1... Training loss: 0.00765... Test loss: 0.00926\n",
      "Epoch: 1... Training loss: 0.00742... Test loss: 0.01822\n",
      "Epoch: 1... Training loss: 0.00785... Test loss: 0.0095\n",
      "Epoch: 1... Training loss: 0.00656... Test loss: 0.01325\n",
      "Epoch: 1... Training loss: 0.00626... Test loss: 0.00721\n",
      "Epoch: 1... Training loss: 0.00653... Test loss: 0.0103\n",
      "Epoch: 1... Training loss: 0.00643... Test loss: 0.00851\n",
      "Epoch: 1... Training loss: 0.00577... Test loss: 0.01002\n",
      "Epoch: 1... Training loss: 0.00596... Test loss: 0.00792\n",
      "Epoch: 1... Training loss: 0.00555... Test loss: 0.00793\n",
      "Epoch: 1... Training loss: 0.00514... Test loss: 0.00784\n",
      "Epoch: 1... Training loss: 0.0052... Test loss: 0.00668\n",
      "Epoch: 1... Training loss: 0.00501... Test loss: 0.0059\n",
      "Epoch: 1... Training loss: 0.00484... Test loss: 0.00586\n",
      "Epoch: 1... Training loss: 0.00484... Test loss: 0.00546\n",
      "Epoch: 1... Training loss: 0.00474... Test loss: 0.00607\n",
      "Epoch: 1... Training loss: 0.00423... Test loss: 0.00549\n",
      "Epoch: 1... Training loss: 0.00433... Test loss: 0.00625\n",
      "Epoch: 1... Training loss: 0.00423... Test loss: 0.00472\n",
      "Epoch: 1... Training loss: 0.00397... Test loss: 0.00471\n",
      "Epoch: 1... Training loss: 0.00387... Test loss: 0.00562\n",
      "Epoch: 1... Training loss: 0.00379... Test loss: 0.00384\n",
      "Epoch: 1... Training loss: 0.00358... Test loss: 0.00428\n",
      "Epoch: 1... Training loss: 0.00361... Test loss: 0.00363\n",
      "Epoch: 1... Training loss: 0.00344... Test loss: 0.00454\n",
      "Epoch: 1... Training loss: 0.0034... Test loss: 0.00377\n",
      "Epoch: 1... Training loss: 0.00328... Test loss: 0.00428\n",
      "Epoch: 1... Training loss: 0.00318... Test loss: 0.00375\n",
      "Epoch: 1... Training loss: 0.0029... Test loss: 0.00321\n",
      "Epoch: 1... Training loss: 0.00279... Test loss: 0.00323\n",
      "Epoch: 1... Training loss: 0.00296... Test loss: 0.00328\n",
      "Epoch: 1... Training loss: 0.00276... Test loss: 0.0026\n",
      "Epoch: 1... Training loss: 0.0026... Test loss: 0.00399\n",
      "Epoch: 1... Training loss: 0.00265... Test loss: 0.00264\n",
      "Epoch: 1... Training loss: 0.00252... Test loss: 0.00354\n",
      "Epoch: 1... Training loss: 0.00236... Test loss: 0.00249\n",
      "Epoch: 1... Training loss: 0.00234... Test loss: 0.00311\n",
      "Epoch: 1... Training loss: 0.00233... Test loss: 0.00222\n",
      "Epoch: 1... Training loss: 0.00246... Test loss: 0.00278\n",
      "Epoch: 1... Training loss: 0.0021... Test loss: 0.00233\n",
      "Epoch: 1... Training loss: 0.00204... Test loss: 0.00262\n",
      "Epoch: 1... Training loss: 0.00212... Test loss: 0.00224\n",
      "Epoch: 1... Training loss: 0.00186... Test loss: 0.00219\n",
      "Epoch: 1... Training loss: 0.00175... Test loss: 0.00238\n",
      "Epoch: 1... Training loss: 0.00168... Test loss: 0.00196\n",
      "Epoch: 1... Training loss: 0.00164... Test loss: 0.00233\n",
      "Epoch: 1... Training loss: 0.0016... Test loss: 0.00178\n",
      "Epoch: 1... Training loss: 0.00162... Test loss: 0.00235\n",
      "Epoch: 1... Training loss: 0.00149... Test loss: 0.00148\n",
      "Epoch: 1... Training loss: 0.00145... Test loss: 0.00217\n",
      "Epoch: 1... Training loss: 0.00141... Test loss: 0.00166\n",
      "Epoch: 1... Training loss: 0.00139... Test loss: 0.00171\n",
      "Epoch: 1... Training loss: 0.00135... Test loss: 0.00174\n",
      "Epoch: 1... Training loss: 0.00138... Test loss: 0.00156\n",
      "Epoch: 1... Training loss: 0.00129... Test loss: 0.00153\n",
      "Epoch: 1... Training loss: 0.00125... Test loss: 0.00121\n",
      "Epoch: 1... Training loss: 0.00121... Test loss: 0.0013\n",
      "Epoch: 1... Training loss: 0.00119... Test loss: 0.0013\n",
      "Epoch: 1... Training loss: 0.00115... Test loss: 0.00108\n",
      "Epoch: 1... Training loss: 0.00104... Test loss: 0.00116\n",
      "Epoch: 1... Training loss: 0.00102... Test loss: 0.00103\n",
      "Epoch: 1... Training loss: 0.00103... Test loss: 0.00101\n",
      "Epoch: 1... Training loss: 0.00095... Test loss: 0.00104\n",
      "Epoch: 1... Training loss: 0.00101... Test loss: 0.00092\n",
      "Epoch: 1... Training loss: 0.00095... Test loss: 0.00086\n",
      "Epoch: 1... Training loss: 0.00087... Test loss: 0.00085\n",
      "Epoch: 1... Training loss: 0.00078... Test loss: 0.00075\n",
      "Epoch: 1... Training loss: 0.00078... Test loss: 0.00076\n",
      "Epoch: 1... Training loss: 0.00072... Test loss: 0.00079\n",
      "Epoch: 1... Training loss: 0.00069... Test loss: 0.0007\n",
      "Epoch: 1... Training loss: 0.0007... Test loss: 0.00067\n",
      "Epoch: 1... Training loss: 0.00072... Test loss: 0.00079\n",
      "Epoch: 1... Training loss: 0.00068... Test loss: 0.0008\n",
      "Epoch: 1... Training loss: 0.00064... Test loss: 0.00069\n",
      "Epoch: 1... Training loss: 0.0007... Test loss: 0.00067\n",
      "Epoch: 1... Training loss: 0.00062... Test loss: 0.00062\n",
      "Epoch: 1... Training loss: 0.0006... Test loss: 0.00082\n",
      "Epoch: 1... Training loss: 0.0006... Test loss: 0.0006\n",
      "Epoch: 1... Training loss: 0.00063... Test loss: 0.0006\n",
      "Epoch: 1... Training loss: 0.00054... Test loss: 0.00062\n",
      "Epoch: 1... Training loss: 0.00056... Test loss: 0.00053\n",
      "Epoch: 1... Training loss: 0.0005... Test loss: 0.00061\n",
      "Epoch: 1... Training loss: 0.0005... Test loss: 0.00047\n",
      "Epoch: 1... Training loss: 0.00051... Test loss: 0.00054\n",
      "Epoch: 1... Training loss: 0.00052... Test loss: 0.00052\n",
      "Epoch: 1... Training loss: 0.00046... Test loss: 0.00046\n",
      "Epoch: 1... Training loss: 0.00056... Test loss: 0.00058\n",
      "Epoch: 1... Training loss: 0.00047... Test loss: 0.00041\n",
      "Epoch: 1... Training loss: 0.00046... Test loss: 0.00052\n",
      "Epoch: 1... Training loss: 0.00041... Test loss: 0.00043\n",
      "Epoch: 1... Training loss: 0.0004... Test loss: 0.00041\n",
      "Epoch: 1... Training loss: 0.00042... Test loss: 0.00044\n",
      "Epoch: 1... Training loss: 0.0004... Test loss: 0.00038\n",
      "Epoch: 1... Training loss: 0.00044... Test loss: 0.00044\n",
      "Epoch: 1... Training loss: 0.00044... Test loss: 0.00033\n",
      "Epoch: 1... Training loss: 0.00039... Test loss: 0.00037\n",
      "Epoch: 1... Training loss: 0.00035... Test loss: 0.00031\n",
      "Epoch: 1... Training loss: 0.00037... Test loss: 0.00041\n",
      "Epoch: 1... Training loss: 0.00036... Test loss: 0.00037\n",
      "Epoch: 1... Training loss: 0.00034... Test loss: 0.00035\n",
      "Epoch: 1... Training loss: 0.00034... Test loss: 0.00032\n",
      "Epoch: 1... Training loss: 0.00034... Test loss: 0.00033\n",
      "Epoch: 1... Training loss: 0.00032... Test loss: 0.00034\n",
      "Epoch: 1... Training loss: 0.00032... Test loss: 0.0003\n",
      "Epoch: 1... Training loss: 0.00033... Test loss: 0.00032\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.0003\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.0003\n",
      "Epoch: 1... Training loss: 0.00026... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.00026... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00015\n",
      "264.048219479213\n",
      "Epoch: 1... Training loss: 1.24105... Test loss: 0.57015\n",
      "Epoch: 1... Training loss: 0.62448... Test loss: 0.26589\n",
      "Epoch: 1... Training loss: 0.35831... Test loss: 0.14048\n",
      "Epoch: 1... Training loss: 0.23776... Test loss: 0.09594\n",
      "Epoch: 1... Training loss: 0.17394... Test loss: 0.07665\n",
      "Epoch: 1... Training loss: 0.13543... Test loss: 0.05849\n",
      "Epoch: 1... Training loss: 0.09903... Test loss: 0.0651\n",
      "Epoch: 1... Training loss: 0.08181... Test loss: 0.04299\n",
      "Epoch: 1... Training loss: 0.0703... Test loss: 0.02685\n",
      "Epoch: 1... Training loss: 0.06656... Test loss: 0.05229\n",
      "Epoch: 1... Training loss: 0.05996... Test loss: 0.02159\n",
      "Epoch: 1... Training loss: 0.04952... Test loss: 0.04627\n",
      "Epoch: 1... Training loss: 0.04673... Test loss: 0.01817\n",
      "Epoch: 1... Training loss: 0.04326... Test loss: 0.03782\n",
      "Epoch: 1... Training loss: 0.04117... Test loss: 0.01624\n",
      "Epoch: 1... Training loss: 0.03641... Test loss: 0.02807\n",
      "Epoch: 1... Training loss: 0.03515... Test loss: 0.01527\n",
      "Epoch: 1... Training loss: 0.03071... Test loss: 0.02769\n",
      "Epoch: 1... Training loss: 0.0287... Test loss: 0.01447\n",
      "Epoch: 1... Training loss: 0.02819... Test loss: 0.02737\n",
      "Epoch: 1... Training loss: 0.02537... Test loss: 0.01548\n",
      "Epoch: 1... Training loss: 0.02475... Test loss: 0.03068\n",
      "Epoch: 1... Training loss: 0.02342... Test loss: 0.01673\n",
      "Epoch: 1... Training loss: 0.02253... Test loss: 0.03333\n",
      "Epoch: 1... Training loss: 0.02099... Test loss: 0.01578\n",
      "Epoch: 1... Training loss: 0.02029... Test loss: 0.02699\n",
      "Epoch: 1... Training loss: 0.01856... Test loss: 0.01185\n",
      "Epoch: 1... Training loss: 0.0178... Test loss: 0.0189\n",
      "Epoch: 1... Training loss: 0.01758... Test loss: 0.01065\n",
      "Epoch: 1... Training loss: 0.0161... Test loss: 0.01885\n",
      "Epoch: 1... Training loss: 0.01517... Test loss: 0.01115\n",
      "Epoch: 1... Training loss: 0.01479... Test loss: 0.01456\n",
      "Epoch: 1... Training loss: 0.01374... Test loss: 0.01486\n",
      "Epoch: 1... Training loss: 0.01313... Test loss: 0.01098\n",
      "Epoch: 1... Training loss: 0.01265... Test loss: 0.01162\n",
      "Epoch: 1... Training loss: 0.01218... Test loss: 0.01096\n",
      "Epoch: 1... Training loss: 0.01187... Test loss: 0.01428\n",
      "Epoch: 1... Training loss: 0.01158... Test loss: 0.00976\n",
      "Epoch: 1... Training loss: 0.01118... Test loss: 0.0147\n",
      "Epoch: 1... Training loss: 0.01092... Test loss: 0.00951\n",
      "Epoch: 1... Training loss: 0.01033... Test loss: 0.0131\n",
      "Epoch: 1... Training loss: 0.01017... Test loss: 0.00868\n",
      "Epoch: 1... Training loss: 0.00979... Test loss: 0.01251\n",
      "Epoch: 1... Training loss: 0.00953... Test loss: 0.00666\n",
      "Epoch: 1... Training loss: 0.00931... Test loss: 0.01185\n",
      "Epoch: 1... Training loss: 0.00899... Test loss: 0.00729\n",
      "Epoch: 1... Training loss: 0.0088... Test loss: 0.01055\n",
      "Epoch: 1... Training loss: 0.00852... Test loss: 0.00616\n",
      "Epoch: 1... Training loss: 0.00835... Test loss: 0.00977\n",
      "Epoch: 1... Training loss: 0.0082... Test loss: 0.00579\n",
      "Epoch: 1... Training loss: 0.00808... Test loss: 0.00846\n",
      "Epoch: 1... Training loss: 0.00776... Test loss: 0.00654\n",
      "Epoch: 1... Training loss: 0.00759... Test loss: 0.00785\n",
      "Epoch: 1... Training loss: 0.0073... Test loss: 0.00685\n",
      "Epoch: 1... Training loss: 0.00714... Test loss: 0.00749\n",
      "Epoch: 1... Training loss: 0.00686... Test loss: 0.00637\n",
      "Epoch: 1... Training loss: 0.00673... Test loss: 0.00646\n",
      "Epoch: 1... Training loss: 0.00658... Test loss: 0.00622\n",
      "Epoch: 1... Training loss: 0.00643... Test loss: 0.00583\n",
      "Epoch: 1... Training loss: 0.00626... Test loss: 0.00605\n",
      "Epoch: 1... Training loss: 0.00604... Test loss: 0.00541\n",
      "Epoch: 1... Training loss: 0.00593... Test loss: 0.00675\n",
      "Epoch: 1... Training loss: 0.00569... Test loss: 0.00562\n",
      "Epoch: 1... Training loss: 0.00551... Test loss: 0.00785\n",
      "Epoch: 1... Training loss: 0.01001... Test loss: 0.01041\n",
      "Epoch: 1... Training loss: 0.01044... Test loss: 0.01694\n",
      "Epoch: 1... Training loss: 0.01073... Test loss: 0.00971\n",
      "Epoch: 1... Training loss: 0.01036... Test loss: 0.01254\n",
      "Epoch: 1... Training loss: 0.00992... Test loss: 0.01043\n",
      "Epoch: 1... Training loss: 0.00895... Test loss: 0.01513\n",
      "Epoch: 1... Training loss: 0.0082... Test loss: 0.00919\n",
      "Epoch: 1... Training loss: 0.00897... Test loss: 0.01166\n",
      "Epoch: 1... Training loss: 0.00882... Test loss: 0.0094\n",
      "Epoch: 1... Training loss: 0.00763... Test loss: 0.01068\n",
      "Epoch: 1... Training loss: 0.00709... Test loss: 0.00835\n",
      "Epoch: 1... Training loss: 0.00766... Test loss: 0.0082\n",
      "Epoch: 1... Training loss: 0.00718... Test loss: 0.0079\n",
      "Epoch: 1... Training loss: 0.00651... Test loss: 0.00985\n",
      "Epoch: 1... Training loss: 0.0071... Test loss: 0.00705\n",
      "Epoch: 1... Training loss: 0.00641... Test loss: 0.01082\n",
      "Epoch: 1... Training loss: 0.00666... Test loss: 0.00804\n",
      "Epoch: 1... Training loss: 0.00605... Test loss: 0.0095\n",
      "Epoch: 1... Training loss: 0.00625... Test loss: 0.00799\n",
      "Epoch: 1... Training loss: 0.0058... Test loss: 0.00822\n",
      "Epoch: 1... Training loss: 0.00598... Test loss: 0.00765\n",
      "Epoch: 1... Training loss: 0.0049... Test loss: 0.00625\n",
      "Epoch: 1... Training loss: 0.00482... Test loss: 0.00636\n",
      "Epoch: 1... Training loss: 0.00491... Test loss: 0.0056\n",
      "Epoch: 1... Training loss: 0.00448... Test loss: 0.00629\n",
      "Epoch: 1... Training loss: 0.00456... Test loss: 0.00569\n",
      "Epoch: 1... Training loss: 0.00421... Test loss: 0.0052\n",
      "Epoch: 1... Training loss: 0.00406... Test loss: 0.00581\n",
      "Epoch: 1... Training loss: 0.00403... Test loss: 0.00444\n",
      "Epoch: 1... Training loss: 0.00385... Test loss: 0.00596\n",
      "Epoch: 1... Training loss: 0.00367... Test loss: 0.00375\n",
      "Epoch: 1... Training loss: 0.00356... Test loss: 0.00565\n",
      "Epoch: 1... Training loss: 0.00348... Test loss: 0.00361\n",
      "Epoch: 1... Training loss: 0.00348... Test loss: 0.00525\n",
      "Epoch: 1... Training loss: 0.00328... Test loss: 0.00351\n",
      "Epoch: 1... Training loss: 0.00301... Test loss: 0.00518\n",
      "Epoch: 1... Training loss: 0.00308... Test loss: 0.00376\n",
      "Epoch: 1... Training loss: 0.00292... Test loss: 0.00348\n",
      "Epoch: 1... Training loss: 0.00284... Test loss: 0.00327\n",
      "Epoch: 1... Training loss: 0.00276... Test loss: 0.00354\n",
      "Epoch: 1... Training loss: 0.0027... Test loss: 0.00293\n",
      "Epoch: 1... Training loss: 0.00269... Test loss: 0.00355\n",
      "Epoch: 1... Training loss: 0.00257... Test loss: 0.00262\n",
      "Epoch: 1... Training loss: 0.00271... Test loss: 0.00349\n",
      "Epoch: 1... Training loss: 0.00245... Test loss: 0.00269\n",
      "Epoch: 1... Training loss: 0.0025... Test loss: 0.00311\n",
      "Epoch: 1... Training loss: 0.00236... Test loss: 0.00265\n",
      "Epoch: 1... Training loss: 0.00233... Test loss: 0.00305\n",
      "Epoch: 1... Training loss: 0.00214... Test loss: 0.00248\n",
      "Epoch: 1... Training loss: 0.0021... Test loss: 0.00274\n",
      "Epoch: 1... Training loss: 0.00201... Test loss: 0.00208\n",
      "Epoch: 1... Training loss: 0.002... Test loss: 0.00218\n",
      "Epoch: 1... Training loss: 0.00189... Test loss: 0.00255\n",
      "Epoch: 1... Training loss: 0.0019... Test loss: 0.00158\n",
      "Epoch: 1... Training loss: 0.00177... Test loss: 0.00259\n",
      "Epoch: 1... Training loss: 0.00188... Test loss: 0.00162\n",
      "Epoch: 1... Training loss: 0.00161... Test loss: 0.00234\n",
      "Epoch: 1... Training loss: 0.00171... Test loss: 0.00175\n",
      "Epoch: 1... Training loss: 0.00152... Test loss: 0.00263\n",
      "Epoch: 1... Training loss: 0.00147... Test loss: 0.00145\n",
      "Epoch: 1... Training loss: 0.00137... Test loss: 0.00217\n",
      "Epoch: 1... Training loss: 0.00137... Test loss: 0.00132\n",
      "Epoch: 1... Training loss: 0.00134... Test loss: 0.00185\n",
      "Epoch: 1... Training loss: 0.00126... Test loss: 0.00133\n",
      "Epoch: 1... Training loss: 0.00125... Test loss: 0.00178\n",
      "Epoch: 1... Training loss: 0.00131... Test loss: 0.0013\n",
      "Epoch: 1... Training loss: 0.00116... Test loss: 0.00159\n",
      "Epoch: 1... Training loss: 0.00111... Test loss: 0.00112\n",
      "Epoch: 1... Training loss: 0.00108... Test loss: 0.00147\n",
      "Epoch: 1... Training loss: 0.00103... Test loss: 0.00109\n",
      "Epoch: 1... Training loss: 0.00101... Test loss: 0.00106\n",
      "Epoch: 1... Training loss: 0.00097... Test loss: 0.00125\n",
      "Epoch: 1... Training loss: 0.00093... Test loss: 0.00089\n",
      "Epoch: 1... Training loss: 0.00091... Test loss: 0.00104\n",
      "Epoch: 1... Training loss: 0.00085... Test loss: 0.00078\n",
      "Epoch: 1... Training loss: 0.00078... Test loss: 0.00096\n",
      "Epoch: 1... Training loss: 0.00074... Test loss: 0.00087\n",
      "Epoch: 1... Training loss: 0.0007... Test loss: 0.00082\n",
      "Epoch: 1... Training loss: 0.00066... Test loss: 0.00092\n",
      "Epoch: 1... Training loss: 0.00067... Test loss: 0.00066\n",
      "Epoch: 1... Training loss: 0.00059... Test loss: 0.00086\n",
      "Epoch: 1... Training loss: 0.00058... Test loss: 0.00061\n",
      "Epoch: 1... Training loss: 0.00052... Test loss: 0.00082\n",
      "Epoch: 1... Training loss: 0.00053... Test loss: 0.00061\n",
      "Epoch: 1... Training loss: 0.00047... Test loss: 0.0007\n",
      "Epoch: 1... Training loss: 0.00044... Test loss: 0.00054\n",
      "Epoch: 1... Training loss: 0.00041... Test loss: 0.00047\n",
      "Epoch: 1... Training loss: 0.00045... Test loss: 0.00048\n",
      "Epoch: 1... Training loss: 0.00039... Test loss: 0.00052\n",
      "Epoch: 1... Training loss: 0.00038... Test loss: 0.0005\n",
      "Epoch: 1... Training loss: 0.00033... Test loss: 0.0004\n",
      "Epoch: 1... Training loss: 0.00032... Test loss: 0.00036\n",
      "Epoch: 1... Training loss: 0.00029... Test loss: 0.00043\n",
      "Epoch: 1... Training loss: 0.00029... Test loss: 0.00028\n",
      "Epoch: 1... Training loss: 0.00026... Test loss: 0.00032\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00024\n",
      "Epoch: 1... Training loss: 0.00026... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00026... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00026... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00024\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00024\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 7e-05\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 8e-05\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 8e-05\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 8e-05... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 8e-05... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 8e-05\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 7e-05\n",
      "Epoch: 1... Training loss: 7e-05... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 8e-05... Test loss: 8e-05\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 7e-05\n",
      "Epoch: 1... Training loss: 8e-05... Test loss: 7e-05\n",
      "Epoch: 1... Training loss: 7e-05... Test loss: 7e-05\n",
      "247.3261394992005\n",
      "Epoch: 1... Training loss: 1.24483... Test loss: 0.53947\n",
      "Epoch: 1... Training loss: 0.49959... Test loss: 0.15984\n",
      "Epoch: 1... Training loss: 0.30886... Test loss: 0.08748\n",
      "Epoch: 1... Training loss: 0.21728... Test loss: 0.06432\n",
      "Epoch: 1... Training loss: 0.14602... Test loss: 0.04232\n",
      "Epoch: 1... Training loss: 0.09762... Test loss: 0.02706\n",
      "Epoch: 1... Training loss: 0.08268... Test loss: 0.02289\n",
      "Epoch: 1... Training loss: 0.07465... Test loss: 0.01578\n",
      "Epoch: 1... Training loss: 0.06524... Test loss: 0.02073\n",
      "Epoch: 1... Training loss: 0.05803... Test loss: 0.02715\n",
      "Epoch: 1... Training loss: 0.05405... Test loss: 0.01641\n",
      "Epoch: 1... Training loss: 0.04856... Test loss: 0.0299\n",
      "Epoch: 1... Training loss: 0.04346... Test loss: 0.02021\n",
      "Epoch: 1... Training loss: 0.04104... Test loss: 0.02697\n",
      "Epoch: 1... Training loss: 0.03845... Test loss: 0.01633\n",
      "Epoch: 1... Training loss: 0.03496... Test loss: 0.0457\n",
      "Epoch: 1... Training loss: 0.03332... Test loss: 0.01391\n",
      "Epoch: 1... Training loss: 0.02971... Test loss: 0.03133\n",
      "Epoch: 1... Training loss: 0.02863... Test loss: 0.01307\n",
      "Epoch: 1... Training loss: 0.02648... Test loss: 0.0315\n",
      "Epoch: 1... Training loss: 0.02553... Test loss: 0.0113\n",
      "Epoch: 1... Training loss: 0.02439... Test loss: 0.02719\n",
      "Epoch: 1... Training loss: 0.02247... Test loss: 0.01775\n",
      "Epoch: 1... Training loss: 0.02091... Test loss: 0.00822\n",
      "Epoch: 1... Training loss: 0.01995... Test loss: 0.01918\n",
      "Epoch: 1... Training loss: 0.01861... Test loss: 0.00943\n",
      "Epoch: 1... Training loss: 0.01816... Test loss: 0.0198\n",
      "Epoch: 1... Training loss: 0.01729... Test loss: 0.00786\n",
      "Epoch: 1... Training loss: 0.01683... Test loss: 0.02068\n",
      "Epoch: 1... Training loss: 0.01603... Test loss: 0.00824\n",
      "Epoch: 1... Training loss: 0.01579... Test loss: 0.01712\n",
      "Epoch: 1... Training loss: 0.01472... Test loss: 0.01226\n",
      "Epoch: 1... Training loss: 0.01445... Test loss: 0.0185\n",
      "Epoch: 1... Training loss: 0.01347... Test loss: 0.01075\n",
      "Epoch: 1... Training loss: 0.0132... Test loss: 0.01754\n",
      "Epoch: 1... Training loss: 0.01264... Test loss: 0.01004\n",
      "Epoch: 1... Training loss: 0.01224... Test loss: 0.01638\n",
      "Epoch: 1... Training loss: 0.01159... Test loss: 0.00803\n",
      "Epoch: 1... Training loss: 0.01127... Test loss: 0.01538\n",
      "Epoch: 1... Training loss: 0.01088... Test loss: 0.00711\n",
      "Epoch: 1... Training loss: 0.01102... Test loss: 0.0116\n",
      "Epoch: 1... Training loss: 0.0106... Test loss: 0.00653\n",
      "Epoch: 1... Training loss: 0.0103... Test loss: 0.01062\n",
      "Epoch: 1... Training loss: 0.00974... Test loss: 0.00659\n",
      "Epoch: 1... Training loss: 0.00936... Test loss: 0.01028\n",
      "Epoch: 1... Training loss: 0.0091... Test loss: 0.00612\n",
      "Epoch: 1... Training loss: 0.00872... Test loss: 0.00943\n",
      "Epoch: 1... Training loss: 0.00842... Test loss: 0.00635\n",
      "Epoch: 1... Training loss: 0.00821... Test loss: 0.00835\n",
      "Epoch: 1... Training loss: 0.00793... Test loss: 0.00563\n",
      "Epoch: 1... Training loss: 0.00778... Test loss: 0.007\n",
      "Epoch: 1... Training loss: 0.00757... Test loss: 0.00512\n",
      "Epoch: 1... Training loss: 0.00732... Test loss: 0.00658\n",
      "Epoch: 1... Training loss: 0.00701... Test loss: 0.00468\n",
      "Epoch: 1... Training loss: 0.00675... Test loss: 0.00788\n",
      "Epoch: 1... Training loss: 0.00687... Test loss: 0.00449\n",
      "Epoch: 1... Training loss: 0.00632... Test loss: 0.00734\n",
      "Epoch: 1... Training loss: 0.00636... Test loss: 0.00446\n",
      "Epoch: 1... Training loss: 0.00609... Test loss: 0.00607\n",
      "Epoch: 1... Training loss: 0.00605... Test loss: 0.00436\n",
      "Epoch: 1... Training loss: 0.00578... Test loss: 0.00546\n",
      "Epoch: 1... Training loss: 0.0058... Test loss: 0.00559\n",
      "Epoch: 1... Training loss: 0.0055... Test loss: 0.005\n",
      "Epoch: 1... Training loss: 0.00546... Test loss: 0.00524\n",
      "Epoch: 1... Training loss: 0.01283... Test loss: 0.03278\n",
      "Epoch: 1... Training loss: 0.01398... Test loss: 0.00936\n",
      "Epoch: 1... Training loss: 0.01016... Test loss: 0.01577\n",
      "Epoch: 1... Training loss: 0.01142... Test loss: 0.0138\n",
      "Epoch: 1... Training loss: 0.00994... Test loss: 0.01794\n",
      "Epoch: 1... Training loss: 0.01064... Test loss: 0.01421\n",
      "Epoch: 1... Training loss: 0.00863... Test loss: 0.01537\n",
      "Epoch: 1... Training loss: 0.00848... Test loss: 0.01566\n",
      "Epoch: 1... Training loss: 0.0073... Test loss: 0.01273\n",
      "Epoch: 1... Training loss: 0.00863... Test loss: 0.01072\n",
      "Epoch: 1... Training loss: 0.0076... Test loss: 0.01729\n",
      "Epoch: 1... Training loss: 0.00732... Test loss: 0.01236\n",
      "Epoch: 1... Training loss: 0.00729... Test loss: 0.01247\n",
      "Epoch: 1... Training loss: 0.00601... Test loss: 0.015\n",
      "Epoch: 1... Training loss: 0.00611... Test loss: 0.00771\n",
      "Epoch: 1... Training loss: 0.00616... Test loss: 0.01244\n",
      "Epoch: 1... Training loss: 0.00648... Test loss: 0.00778\n",
      "Epoch: 1... Training loss: 0.00544... Test loss: 0.00991\n",
      "Epoch: 1... Training loss: 0.00564... Test loss: 0.00642\n",
      "Epoch: 1... Training loss: 0.00488... Test loss: 0.00924\n",
      "Epoch: 1... Training loss: 0.00515... Test loss: 0.00745\n",
      "Epoch: 1... Training loss: 0.00498... Test loss: 0.0094\n",
      "Epoch: 1... Training loss: 0.0045... Test loss: 0.00612\n",
      "Epoch: 1... Training loss: 0.00456... Test loss: 0.00655\n",
      "Epoch: 1... Training loss: 0.00439... Test loss: 0.00429\n",
      "Epoch: 1... Training loss: 0.00434... Test loss: 0.00795\n",
      "Epoch: 1... Training loss: 0.00409... Test loss: 0.00521\n",
      "Epoch: 1... Training loss: 0.00376... Test loss: 0.00635\n",
      "Epoch: 1... Training loss: 0.00394... Test loss: 0.00407\n",
      "Epoch: 1... Training loss: 0.00346... Test loss: 0.00482\n",
      "Epoch: 1... Training loss: 0.00354... Test loss: 0.00383\n",
      "Epoch: 1... Training loss: 0.00339... Test loss: 0.00419\n",
      "Epoch: 1... Training loss: 0.00336... Test loss: 0.0036\n",
      "Epoch: 1... Training loss: 0.00322... Test loss: 0.00395\n",
      "Epoch: 1... Training loss: 0.00309... Test loss: 0.00413\n",
      "Epoch: 1... Training loss: 0.00305... Test loss: 0.00343\n",
      "Epoch: 1... Training loss: 0.00289... Test loss: 0.00402\n",
      "Epoch: 1... Training loss: 0.00274... Test loss: 0.00337\n",
      "Epoch: 1... Training loss: 0.00262... Test loss: 0.00335\n",
      "Epoch: 1... Training loss: 0.00256... Test loss: 0.00328\n",
      "Epoch: 1... Training loss: 0.00245... Test loss: 0.00292\n",
      "Epoch: 1... Training loss: 0.00236... Test loss: 0.0024\n",
      "Epoch: 1... Training loss: 0.00229... Test loss: 0.00366\n",
      "Epoch: 1... Training loss: 0.00234... Test loss: 0.00206\n",
      "Epoch: 1... Training loss: 0.00212... Test loss: 0.0028\n",
      "Epoch: 1... Training loss: 0.00209... Test loss: 0.0019\n",
      "Epoch: 1... Training loss: 0.00203... Test loss: 0.00295\n",
      "Epoch: 1... Training loss: 0.00189... Test loss: 0.00157\n",
      "Epoch: 1... Training loss: 0.00184... Test loss: 0.00247\n",
      "Epoch: 1... Training loss: 0.00179... Test loss: 0.00163\n",
      "Epoch: 1... Training loss: 0.0017... Test loss: 0.00242\n",
      "Epoch: 1... Training loss: 0.00162... Test loss: 0.00182\n",
      "Epoch: 1... Training loss: 0.00148... Test loss: 0.00202\n",
      "Epoch: 1... Training loss: 0.00146... Test loss: 0.00149\n",
      "Epoch: 1... Training loss: 0.00144... Test loss: 0.0021\n",
      "Epoch: 1... Training loss: 0.00138... Test loss: 0.0016\n",
      "Epoch: 1... Training loss: 0.00129... Test loss: 0.00168\n",
      "Epoch: 1... Training loss: 0.00125... Test loss: 0.00149\n",
      "Epoch: 1... Training loss: 0.00123... Test loss: 0.00161\n",
      "Epoch: 1... Training loss: 0.00114... Test loss: 0.00129\n",
      "Epoch: 1... Training loss: 0.00115... Test loss: 0.00144\n",
      "Epoch: 1... Training loss: 0.00105... Test loss: 0.00117\n",
      "Epoch: 1... Training loss: 0.001... Test loss: 0.00114\n",
      "Epoch: 1... Training loss: 0.00094... Test loss: 0.00156\n",
      "Epoch: 1... Training loss: 0.00094... Test loss: 0.00109\n",
      "Epoch: 1... Training loss: 0.00084... Test loss: 0.00147\n",
      "Epoch: 1... Training loss: 0.00083... Test loss: 0.00093\n",
      "Epoch: 1... Training loss: 0.00077... Test loss: 0.0018\n",
      "Epoch: 1... Training loss: 0.00073... Test loss: 0.0011\n",
      "Epoch: 1... Training loss: 0.00074... Test loss: 0.00107\n",
      "Epoch: 1... Training loss: 0.00065... Test loss: 0.00083\n",
      "Epoch: 1... Training loss: 0.00061... Test loss: 0.00083\n",
      "Epoch: 1... Training loss: 0.00063... Test loss: 0.00078\n",
      "Epoch: 1... Training loss: 0.00058... Test loss: 0.00075\n",
      "Epoch: 1... Training loss: 0.00056... Test loss: 0.00062\n",
      "Epoch: 1... Training loss: 0.00055... Test loss: 0.00059\n",
      "Epoch: 1... Training loss: 0.0005... Test loss: 0.00068\n",
      "Epoch: 1... Training loss: 0.00049... Test loss: 0.00051\n",
      "Epoch: 1... Training loss: 0.00045... Test loss: 0.00057\n",
      "Epoch: 1... Training loss: 0.00043... Test loss: 0.00056\n",
      "Epoch: 1... Training loss: 0.00042... Test loss: 0.00043\n",
      "Epoch: 1... Training loss: 0.0004... Test loss: 0.00035\n",
      "Epoch: 1... Training loss: 0.00036... Test loss: 0.00044\n",
      "Epoch: 1... Training loss: 0.00041... Test loss: 0.00042\n",
      "Epoch: 1... Training loss: 0.00034... Test loss: 0.00041\n",
      "Epoch: 1... Training loss: 0.00035... Test loss: 0.00037\n",
      "Epoch: 1... Training loss: 0.00033... Test loss: 0.00038\n",
      "Epoch: 1... Training loss: 0.00032... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00031... Test loss: 0.00032\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.00035\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00036\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00024\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 8e-05... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 8e-05\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 7e-05\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 8e-05... Test loss: 8e-05\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 7e-05\n",
      "Epoch: 1... Training loss: 8e-05... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 8e-05... Test loss: 7e-05\n",
      "Epoch: 1... Training loss: 8e-05... Test loss: 9e-05\n",
      "229.1492965646321\n",
      "Epoch: 1... Training loss: 1.13941... Test loss: 0.51167\n",
      "Epoch: 1... Training loss: 0.51837... Test loss: 0.21\n",
      "Epoch: 1... Training loss: 0.2668... Test loss: 0.13284\n",
      "Epoch: 1... Training loss: 0.18771... Test loss: 0.11135\n",
      "Epoch: 1... Training loss: 0.15875... Test loss: 0.08526\n",
      "Epoch: 1... Training loss: 0.11347... Test loss: 0.05869\n",
      "Epoch: 1... Training loss: 0.08477... Test loss: 0.0686\n",
      "Epoch: 1... Training loss: 0.07165... Test loss: 0.0384\n",
      "Epoch: 1... Training loss: 0.05747... Test loss: 0.05561\n",
      "Epoch: 1... Training loss: 0.05414... Test loss: 0.04499\n",
      "Epoch: 1... Training loss: 0.05234... Test loss: 0.01697\n",
      "Epoch: 1... Training loss: 0.04451... Test loss: 0.03873\n",
      "Epoch: 1... Training loss: 0.03992... Test loss: 0.02099\n",
      "Epoch: 1... Training loss: 0.03809... Test loss: 0.01919\n",
      "Epoch: 1... Training loss: 0.03502... Test loss: 0.01633\n",
      "Epoch: 1... Training loss: 0.03238... Test loss: 0.02872\n",
      "Epoch: 1... Training loss: 0.03108... Test loss: 0.00898\n",
      "Epoch: 1... Training loss: 0.02783... Test loss: 0.02251\n",
      "Epoch: 1... Training loss: 0.02743... Test loss: 0.01176\n",
      "Epoch: 1... Training loss: 0.0251... Test loss: 0.0197\n",
      "Epoch: 1... Training loss: 0.02496... Test loss: 0.00974\n",
      "Epoch: 1... Training loss: 0.02292... Test loss: 0.0248\n",
      "Epoch: 1... Training loss: 0.0225... Test loss: 0.0102\n",
      "Epoch: 1... Training loss: 0.02104... Test loss: 0.02311\n",
      "Epoch: 1... Training loss: 0.02039... Test loss: 0.02031\n",
      "Epoch: 1... Training loss: 0.01946... Test loss: 0.01122\n",
      "Epoch: 1... Training loss: 0.01877... Test loss: 0.01617\n",
      "Epoch: 1... Training loss: 0.01815... Test loss: 0.01154\n",
      "Epoch: 1... Training loss: 0.0174... Test loss: 0.01418\n",
      "Epoch: 1... Training loss: 0.01659... Test loss: 0.01122\n",
      "Epoch: 1... Training loss: 0.01627... Test loss: 0.01389\n",
      "Epoch: 1... Training loss: 0.01569... Test loss: 0.0103\n",
      "Epoch: 1... Training loss: 0.01492... Test loss: 0.01959\n",
      "Epoch: 1... Training loss: 0.0145... Test loss: 0.00906\n",
      "Epoch: 1... Training loss: 0.01403... Test loss: 0.01903\n",
      "Epoch: 1... Training loss: 0.01383... Test loss: 0.00802\n",
      "Epoch: 1... Training loss: 0.01327... Test loss: 0.01595\n",
      "Epoch: 1... Training loss: 0.01301... Test loss: 0.00813\n",
      "Epoch: 1... Training loss: 0.01237... Test loss: 0.01055\n",
      "Epoch: 1... Training loss: 0.01206... Test loss: 0.00973\n",
      "Epoch: 1... Training loss: 0.0115... Test loss: 0.00942\n",
      "Epoch: 1... Training loss: 0.01108... Test loss: 0.01179\n",
      "Epoch: 1... Training loss: 0.01078... Test loss: 0.00684\n",
      "Epoch: 1... Training loss: 0.01033... Test loss: 0.01302\n",
      "Epoch: 1... Training loss: 0.01004... Test loss: 0.00721\n",
      "Epoch: 1... Training loss: 0.00957... Test loss: 0.01189\n",
      "Epoch: 1... Training loss: 0.00931... Test loss: 0.0088\n",
      "Epoch: 1... Training loss: 0.00903... Test loss: 0.00844\n",
      "Epoch: 1... Training loss: 0.00864... Test loss: 0.0087\n",
      "Epoch: 1... Training loss: 0.00838... Test loss: 0.00555\n",
      "Epoch: 1... Training loss: 0.00821... Test loss: 0.00861\n",
      "Epoch: 1... Training loss: 0.00794... Test loss: 0.00534\n",
      "Epoch: 1... Training loss: 0.0077... Test loss: 0.00778\n",
      "Epoch: 1... Training loss: 0.00756... Test loss: 0.00597\n",
      "Epoch: 1... Training loss: 0.00729... Test loss: 0.00759\n",
      "Epoch: 1... Training loss: 0.0071... Test loss: 0.00549\n",
      "Epoch: 1... Training loss: 0.00683... Test loss: 0.00771\n",
      "Epoch: 1... Training loss: 0.00663... Test loss: 0.00507\n",
      "Epoch: 1... Training loss: 0.00645... Test loss: 0.00793\n",
      "Epoch: 1... Training loss: 0.00625... Test loss: 0.00503\n",
      "Epoch: 1... Training loss: 0.00597... Test loss: 0.00805\n",
      "Epoch: 1... Training loss: 0.0058... Test loss: 0.00558\n",
      "Epoch: 1... Training loss: 0.00556... Test loss: 0.00833\n",
      "Epoch: 1... Training loss: 0.00541... Test loss: 0.00596\n",
      "Epoch: 1... Training loss: 0.00782... Test loss: 0.0212\n",
      "Epoch: 1... Training loss: 0.01126... Test loss: 0.01063\n",
      "Epoch: 1... Training loss: 0.00925... Test loss: 0.01969\n",
      "Epoch: 1... Training loss: 0.00927... Test loss: 0.00987\n",
      "Epoch: 1... Training loss: 0.00894... Test loss: 0.01337\n",
      "Epoch: 1... Training loss: 0.00916... Test loss: 0.01131\n",
      "Epoch: 1... Training loss: 0.00829... Test loss: 0.01084\n",
      "Epoch: 1... Training loss: 0.009... Test loss: 0.0105\n",
      "Epoch: 1... Training loss: 0.00818... Test loss: 0.01046\n",
      "Epoch: 1... Training loss: 0.00789... Test loss: 0.01253\n",
      "Epoch: 1... Training loss: 0.0074... Test loss: 0.01126\n",
      "Epoch: 1... Training loss: 0.00733... Test loss: 0.01059\n",
      "Epoch: 1... Training loss: 0.00703... Test loss: 0.01199\n",
      "Epoch: 1... Training loss: 0.00633... Test loss: 0.00824\n",
      "Epoch: 1... Training loss: 0.0064... Test loss: 0.01127\n",
      "Epoch: 1... Training loss: 0.00579... Test loss: 0.0071\n",
      "Epoch: 1... Training loss: 0.00599... Test loss: 0.00915\n",
      "Epoch: 1... Training loss: 0.00582... Test loss: 0.00773\n",
      "Epoch: 1... Training loss: 0.0054... Test loss: 0.00609\n",
      "Epoch: 1... Training loss: 0.00539... Test loss: 0.00729\n",
      "Epoch: 1... Training loss: 0.00522... Test loss: 0.00584\n",
      "Epoch: 1... Training loss: 0.00471... Test loss: 0.00651\n",
      "Epoch: 1... Training loss: 0.00517... Test loss: 0.00493\n",
      "Epoch: 1... Training loss: 0.00459... Test loss: 0.00761\n",
      "Epoch: 1... Training loss: 0.00458... Test loss: 0.00483\n",
      "Epoch: 1... Training loss: 0.00399... Test loss: 0.00695\n",
      "Epoch: 1... Training loss: 0.00402... Test loss: 0.00437\n",
      "Epoch: 1... Training loss: 0.00408... Test loss: 0.00548\n",
      "Epoch: 1... Training loss: 0.00373... Test loss: 0.00449\n",
      "Epoch: 1... Training loss: 0.00361... Test loss: 0.00535\n",
      "Epoch: 1... Training loss: 0.00347... Test loss: 0.00374\n",
      "Epoch: 1... Training loss: 0.00333... Test loss: 0.0046\n",
      "Epoch: 1... Training loss: 0.00344... Test loss: 0.00392\n",
      "Epoch: 1... Training loss: 0.00317... Test loss: 0.00436\n",
      "Epoch: 1... Training loss: 0.00299... Test loss: 0.00356\n",
      "Epoch: 1... Training loss: 0.00302... Test loss: 0.00441\n",
      "Epoch: 1... Training loss: 0.0028... Test loss: 0.00334\n",
      "Epoch: 1... Training loss: 0.00271... Test loss: 0.00417\n",
      "Epoch: 1... Training loss: 0.00273... Test loss: 0.00318\n",
      "Epoch: 1... Training loss: 0.00264... Test loss: 0.00323\n",
      "Epoch: 1... Training loss: 0.00265... Test loss: 0.00298\n",
      "Epoch: 1... Training loss: 0.00254... Test loss: 0.00335\n",
      "Epoch: 1... Training loss: 0.0024... Test loss: 0.0033\n",
      "Epoch: 1... Training loss: 0.0024... Test loss: 0.00343\n",
      "Epoch: 1... Training loss: 0.0023... Test loss: 0.00324\n",
      "Epoch: 1... Training loss: 0.00218... Test loss: 0.00323\n",
      "Epoch: 1... Training loss: 0.00218... Test loss: 0.00272\n",
      "Epoch: 1... Training loss: 0.00209... Test loss: 0.00282\n",
      "Epoch: 1... Training loss: 0.00204... Test loss: 0.00251\n",
      "Epoch: 1... Training loss: 0.00197... Test loss: 0.00234\n",
      "Epoch: 1... Training loss: 0.00194... Test loss: 0.00214\n",
      "Epoch: 1... Training loss: 0.00198... Test loss: 0.00249\n",
      "Epoch: 1... Training loss: 0.0017... Test loss: 0.00213\n",
      "Epoch: 1... Training loss: 0.00168... Test loss: 0.00226\n",
      "Epoch: 1... Training loss: 0.00164... Test loss: 0.00154\n",
      "Epoch: 1... Training loss: 0.0016... Test loss: 0.00195\n",
      "Epoch: 1... Training loss: 0.00148... Test loss: 0.00151\n",
      "Epoch: 1... Training loss: 0.00146... Test loss: 0.00199\n",
      "Epoch: 1... Training loss: 0.00142... Test loss: 0.00154\n",
      "Epoch: 1... Training loss: 0.00135... Test loss: 0.00239\n",
      "Epoch: 1... Training loss: 0.00129... Test loss: 0.00129\n",
      "Epoch: 1... Training loss: 0.00117... Test loss: 0.00212\n",
      "Epoch: 1... Training loss: 0.00121... Test loss: 0.00112\n",
      "Epoch: 1... Training loss: 0.00107... Test loss: 0.0016\n",
      "Epoch: 1... Training loss: 0.00104... Test loss: 0.00124\n",
      "Epoch: 1... Training loss: 0.00099... Test loss: 0.00149\n",
      "Epoch: 1... Training loss: 0.00092... Test loss: 0.00126\n",
      "Epoch: 1... Training loss: 0.00087... Test loss: 0.00111\n",
      "Epoch: 1... Training loss: 0.00085... Test loss: 0.00098\n",
      "Epoch: 1... Training loss: 0.0008... Test loss: 0.00105\n",
      "Epoch: 1... Training loss: 0.00077... Test loss: 0.00084\n",
      "Epoch: 1... Training loss: 0.00069... Test loss: 0.001\n",
      "Epoch: 1... Training loss: 0.00075... Test loss: 0.0007\n",
      "Epoch: 1... Training loss: 0.00069... Test loss: 0.00089\n",
      "Epoch: 1... Training loss: 0.00067... Test loss: 0.00063\n",
      "Epoch: 1... Training loss: 0.00062... Test loss: 0.00077\n",
      "Epoch: 1... Training loss: 0.00064... Test loss: 0.0005\n",
      "Epoch: 1... Training loss: 0.00056... Test loss: 0.00086\n",
      "Epoch: 1... Training loss: 0.00056... Test loss: 0.0005\n",
      "Epoch: 1... Training loss: 0.00055... Test loss: 0.00062\n",
      "Epoch: 1... Training loss: 0.00051... Test loss: 0.00052\n",
      "Epoch: 1... Training loss: 0.0005... Test loss: 0.00064\n",
      "Epoch: 1... Training loss: 0.00048... Test loss: 0.00051\n",
      "Epoch: 1... Training loss: 0.00047... Test loss: 0.00052\n",
      "Epoch: 1... Training loss: 0.00045... Test loss: 0.00045\n",
      "Epoch: 1... Training loss: 0.00044... Test loss: 0.00048\n",
      "Epoch: 1... Training loss: 0.00038... Test loss: 0.00045\n",
      "Epoch: 1... Training loss: 0.00041... Test loss: 0.00038\n",
      "Epoch: 1... Training loss: 0.00037... Test loss: 0.00034\n",
      "Epoch: 1... Training loss: 0.00035... Test loss: 0.00033\n",
      "Epoch: 1... Training loss: 0.00033... Test loss: 0.00036\n",
      "Epoch: 1... Training loss: 0.0004... Test loss: 0.00032\n",
      "Epoch: 1... Training loss: 0.00032... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.0003\n",
      "Epoch: 1... Training loss: 0.00031... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.00031... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.00031... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00024\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.0003\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00024\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 8e-05... Test loss: 8e-05\n",
      "Epoch: 1... Training loss: 8e-05... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 7e-05\n",
      "209.87228789570509\n",
      "Epoch: 1... Training loss: 0.86677... Test loss: 0.26428\n",
      "Epoch: 1... Training loss: 0.45389... Test loss: 0.15097\n",
      "Epoch: 1... Training loss: 0.26199... Test loss: 0.09742\n",
      "Epoch: 1... Training loss: 0.18135... Test loss: 0.06043\n",
      "Epoch: 1... Training loss: 0.14365... Test loss: 0.04992\n",
      "Epoch: 1... Training loss: 0.11816... Test loss: 0.04308\n",
      "Epoch: 1... Training loss: 0.09227... Test loss: 0.04764\n",
      "Epoch: 1... Training loss: 0.0781... Test loss: 0.02312\n",
      "Epoch: 1... Training loss: 0.06325... Test loss: 0.02158\n",
      "Epoch: 1... Training loss: 0.05851... Test loss: 0.01753\n",
      "Epoch: 1... Training loss: 0.05293... Test loss: 0.02561\n",
      "Epoch: 1... Training loss: 0.05021... Test loss: 0.01244\n",
      "Epoch: 1... Training loss: 0.04588... Test loss: 0.02542\n",
      "Epoch: 1... Training loss: 0.04258... Test loss: 0.02014\n",
      "Epoch: 1... Training loss: 0.03839... Test loss: 0.02288\n",
      "Epoch: 1... Training loss: 0.03541... Test loss: 0.02921\n",
      "Epoch: 1... Training loss: 0.03433... Test loss: 0.01209\n",
      "Epoch: 1... Training loss: 0.03197... Test loss: 0.02304\n",
      "Epoch: 1... Training loss: 0.02866... Test loss: 0.01322\n",
      "Epoch: 1... Training loss: 0.02719... Test loss: 0.026\n",
      "Epoch: 1... Training loss: 0.02508... Test loss: 0.01129\n",
      "Epoch: 1... Training loss: 0.0243... Test loss: 0.02003\n",
      "Epoch: 1... Training loss: 0.0221... Test loss: 0.01863\n",
      "Epoch: 1... Training loss: 0.02067... Test loss: 0.02932\n",
      "Epoch: 1... Training loss: 0.02053... Test loss: 0.01378\n",
      "Epoch: 1... Training loss: 0.01898... Test loss: 0.02393\n",
      "Epoch: 1... Training loss: 0.01878... Test loss: 0.01276\n",
      "Epoch: 1... Training loss: 0.01759... Test loss: 0.0223\n",
      "Epoch: 1... Training loss: 0.01711... Test loss: 0.01341\n",
      "Epoch: 1... Training loss: 0.01637... Test loss: 0.01881\n",
      "Epoch: 1... Training loss: 0.01626... Test loss: 0.01191\n",
      "Epoch: 1... Training loss: 0.0151... Test loss: 0.02094\n",
      "Epoch: 1... Training loss: 0.01459... Test loss: 0.01144\n",
      "Epoch: 1... Training loss: 0.0141... Test loss: 0.01935\n",
      "Epoch: 1... Training loss: 0.01378... Test loss: 0.01231\n",
      "Epoch: 1... Training loss: 0.01329... Test loss: 0.01617\n",
      "Epoch: 1... Training loss: 0.01296... Test loss: 0.01332\n",
      "Epoch: 1... Training loss: 0.01225... Test loss: 0.01134\n",
      "Epoch: 1... Training loss: 0.01183... Test loss: 0.01354\n",
      "Epoch: 1... Training loss: 0.01138... Test loss: 0.011\n",
      "Epoch: 1... Training loss: 0.01115... Test loss: 0.01323\n",
      "Epoch: 1... Training loss: 0.01087... Test loss: 0.00923\n",
      "Epoch: 1... Training loss: 0.01048... Test loss: 0.01311\n",
      "Epoch: 1... Training loss: 0.01014... Test loss: 0.00838\n",
      "Epoch: 1... Training loss: 0.00999... Test loss: 0.01202\n",
      "Epoch: 1... Training loss: 0.00954... Test loss: 0.00728\n",
      "Epoch: 1... Training loss: 0.00944... Test loss: 0.01102\n",
      "Epoch: 1... Training loss: 0.00908... Test loss: 0.00729\n",
      "Epoch: 1... Training loss: 0.00887... Test loss: 0.01023\n",
      "Epoch: 1... Training loss: 0.0087... Test loss: 0.00831\n",
      "Epoch: 1... Training loss: 0.00854... Test loss: 0.0086\n",
      "Epoch: 1... Training loss: 0.00836... Test loss: 0.00982\n",
      "Epoch: 1... Training loss: 0.0081... Test loss: 0.00709\n",
      "Epoch: 1... Training loss: 0.00784... Test loss: 0.00838\n",
      "Epoch: 1... Training loss: 0.00758... Test loss: 0.00697\n",
      "Epoch: 1... Training loss: 0.00729... Test loss: 0.00778\n",
      "Epoch: 1... Training loss: 0.00711... Test loss: 0.00653\n",
      "Epoch: 1... Training loss: 0.00689... Test loss: 0.00695\n",
      "Epoch: 1... Training loss: 0.00672... Test loss: 0.00614\n",
      "Epoch: 1... Training loss: 0.00661... Test loss: 0.00697\n",
      "Epoch: 1... Training loss: 0.00637... Test loss: 0.00604\n",
      "Epoch: 1... Training loss: 0.00609... Test loss: 0.00676\n",
      "Epoch: 1... Training loss: 0.00596... Test loss: 0.00561\n",
      "Epoch: 1... Training loss: 0.00574... Test loss: 0.00672\n",
      "Epoch: 1... Training loss: 0.01102... Test loss: 0.00986\n",
      "Epoch: 1... Training loss: 0.01342... Test loss: 0.01757\n",
      "Epoch: 1... Training loss: 0.0123... Test loss: 0.02671\n",
      "Epoch: 1... Training loss: 0.00885... Test loss: 0.01996\n",
      "Epoch: 1... Training loss: 0.00996... Test loss: 0.01504\n",
      "Epoch: 1... Training loss: 0.00866... Test loss: 0.01454\n",
      "Epoch: 1... Training loss: 0.00828... Test loss: 0.01709\n",
      "Epoch: 1... Training loss: 0.00811... Test loss: 0.01118\n",
      "Epoch: 1... Training loss: 0.00879... Test loss: 0.01456\n",
      "Epoch: 1... Training loss: 0.00854... Test loss: 0.01161\n",
      "Epoch: 1... Training loss: 0.00777... Test loss: 0.00904\n",
      "Epoch: 1... Training loss: 0.00787... Test loss: 0.0101\n",
      "Epoch: 1... Training loss: 0.00732... Test loss: 0.01123\n",
      "Epoch: 1... Training loss: 0.00689... Test loss: 0.0084\n",
      "Epoch: 1... Training loss: 0.00654... Test loss: 0.01064\n",
      "Epoch: 1... Training loss: 0.00647... Test loss: 0.00985\n",
      "Epoch: 1... Training loss: 0.00663... Test loss: 0.0091\n",
      "Epoch: 1... Training loss: 0.00649... Test loss: 0.00879\n",
      "Epoch: 1... Training loss: 0.00598... Test loss: 0.00743\n",
      "Epoch: 1... Training loss: 0.00563... Test loss: 0.00692\n",
      "Epoch: 1... Training loss: 0.00536... Test loss: 0.00785\n",
      "Epoch: 1... Training loss: 0.00519... Test loss: 0.00699\n",
      "Epoch: 1... Training loss: 0.00498... Test loss: 0.00758\n",
      "Epoch: 1... Training loss: 0.00487... Test loss: 0.00662\n",
      "Epoch: 1... Training loss: 0.00488... Test loss: 0.00724\n",
      "Epoch: 1... Training loss: 0.00459... Test loss: 0.0065\n",
      "Epoch: 1... Training loss: 0.00444... Test loss: 0.00647\n",
      "Epoch: 1... Training loss: 0.00426... Test loss: 0.00544\n",
      "Epoch: 1... Training loss: 0.00416... Test loss: 0.00617\n",
      "Epoch: 1... Training loss: 0.004... Test loss: 0.00568\n",
      "Epoch: 1... Training loss: 0.00373... Test loss: 0.00541\n",
      "Epoch: 1... Training loss: 0.00359... Test loss: 0.00443\n",
      "Epoch: 1... Training loss: 0.0035... Test loss: 0.00475\n",
      "Epoch: 1... Training loss: 0.00339... Test loss: 0.00366\n",
      "Epoch: 1... Training loss: 0.00323... Test loss: 0.00409\n",
      "Epoch: 1... Training loss: 0.00314... Test loss: 0.00349\n",
      "Epoch: 1... Training loss: 0.00312... Test loss: 0.00405\n",
      "Epoch: 1... Training loss: 0.00289... Test loss: 0.00342\n",
      "Epoch: 1... Training loss: 0.00286... Test loss: 0.00335\n",
      "Epoch: 1... Training loss: 0.00279... Test loss: 0.0036\n",
      "Epoch: 1... Training loss: 0.00274... Test loss: 0.00324\n",
      "Epoch: 1... Training loss: 0.00256... Test loss: 0.00396\n",
      "Epoch: 1... Training loss: 0.00252... Test loss: 0.00278\n",
      "Epoch: 1... Training loss: 0.00234... Test loss: 0.00349\n",
      "Epoch: 1... Training loss: 0.00239... Test loss: 0.00248\n",
      "Epoch: 1... Training loss: 0.00225... Test loss: 0.00302\n",
      "Epoch: 1... Training loss: 0.00215... Test loss: 0.00266\n",
      "Epoch: 1... Training loss: 0.00208... Test loss: 0.00295\n",
      "Epoch: 1... Training loss: 0.00205... Test loss: 0.00277\n",
      "Epoch: 1... Training loss: 0.00192... Test loss: 0.00277\n",
      "Epoch: 1... Training loss: 0.00208... Test loss: 0.00267\n",
      "Epoch: 1... Training loss: 0.00187... Test loss: 0.00276\n",
      "Epoch: 1... Training loss: 0.00178... Test loss: 0.00224\n",
      "Epoch: 1... Training loss: 0.00175... Test loss: 0.00229\n",
      "Epoch: 1... Training loss: 0.00172... Test loss: 0.00188\n",
      "Epoch: 1... Training loss: 0.00158... Test loss: 0.00233\n",
      "Epoch: 1... Training loss: 0.00163... Test loss: 0.00152\n",
      "Epoch: 1... Training loss: 0.00154... Test loss: 0.00203\n",
      "Epoch: 1... Training loss: 0.00156... Test loss: 0.00162\n",
      "Epoch: 1... Training loss: 0.00143... Test loss: 0.0017\n",
      "Epoch: 1... Training loss: 0.00139... Test loss: 0.00141\n",
      "Epoch: 1... Training loss: 0.00139... Test loss: 0.00163\n",
      "Epoch: 1... Training loss: 0.00131... Test loss: 0.00126\n",
      "Epoch: 1... Training loss: 0.00122... Test loss: 0.00172\n",
      "Epoch: 1... Training loss: 0.00134... Test loss: 0.00141\n",
      "Epoch: 1... Training loss: 0.00115... Test loss: 0.00126\n",
      "Epoch: 1... Training loss: 0.00111... Test loss: 0.00121\n",
      "Epoch: 1... Training loss: 0.00106... Test loss: 0.00133\n",
      "Epoch: 1... Training loss: 0.00105... Test loss: 0.00111\n",
      "Epoch: 1... Training loss: 0.00098... Test loss: 0.00113\n",
      "Epoch: 1... Training loss: 0.00093... Test loss: 0.00102\n",
      "Epoch: 1... Training loss: 0.00087... Test loss: 0.00093\n",
      "Epoch: 1... Training loss: 0.00088... Test loss: 0.00097\n",
      "Epoch: 1... Training loss: 0.00086... Test loss: 0.00094\n",
      "Epoch: 1... Training loss: 0.00082... Test loss: 0.00126\n",
      "Epoch: 1... Training loss: 0.0008... Test loss: 0.00086\n",
      "Epoch: 1... Training loss: 0.00073... Test loss: 0.00092\n",
      "Epoch: 1... Training loss: 0.00069... Test loss: 0.00082\n",
      "Epoch: 1... Training loss: 0.00065... Test loss: 0.00095\n",
      "Epoch: 1... Training loss: 0.00063... Test loss: 0.00067\n",
      "Epoch: 1... Training loss: 0.00063... Test loss: 0.00115\n",
      "Epoch: 1... Training loss: 0.00058... Test loss: 0.00076\n",
      "Epoch: 1... Training loss: 0.00057... Test loss: 0.00055\n",
      "Epoch: 1... Training loss: 0.00059... Test loss: 0.00068\n",
      "Epoch: 1... Training loss: 0.00052... Test loss: 0.00054\n",
      "Epoch: 1... Training loss: 0.00049... Test loss: 0.00055\n",
      "Epoch: 1... Training loss: 0.00047... Test loss: 0.0005\n",
      "Epoch: 1... Training loss: 0.00049... Test loss: 0.00048\n",
      "Epoch: 1... Training loss: 0.00041... Test loss: 0.00058\n",
      "Epoch: 1... Training loss: 0.00039... Test loss: 0.00043\n",
      "Epoch: 1... Training loss: 0.00039... Test loss: 0.00046\n",
      "Epoch: 1... Training loss: 0.00036... Test loss: 0.00039\n",
      "Epoch: 1... Training loss: 0.00035... Test loss: 0.00037\n",
      "Epoch: 1... Training loss: 0.00033... Test loss: 0.00046\n",
      "Epoch: 1... Training loss: 0.00035... Test loss: 0.0005\n",
      "Epoch: 1... Training loss: 0.00035... Test loss: 0.00039\n",
      "Epoch: 1... Training loss: 0.00029... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.00035... Test loss: 0.00031\n",
      "Epoch: 1... Training loss: 0.00029... Test loss: 0.00035\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00024\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00026... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 8e-05\n",
      "Epoch: 1... Training loss: 8e-05... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 8e-05... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 0.0001\n",
      "237.95900463924045\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1... Training loss: 0.00314... Test loss: 0.00354\n",
      "Epoch: 1... Training loss: 0.0031... Test loss: 0.00426\n",
      "Epoch: 1... Training loss: 0.00306... Test loss: 0.0032\n",
      "Epoch: 1... Training loss: 0.00293... Test loss: 0.00419\n",
      "Epoch: 1... Training loss: 0.00285... Test loss: 0.0032\n",
      "Epoch: 1... Training loss: 0.00279... Test loss: 0.00385\n",
      "Epoch: 1... Training loss: 0.00269... Test loss: 0.00398\n",
      "Epoch: 1... Training loss: 0.00263... Test loss: 0.00362\n",
      "Epoch: 1... Training loss: 0.00259... Test loss: 0.00384\n",
      "Epoch: 1... Training loss: 0.00244... Test loss: 0.00356\n",
      "Epoch: 1... Training loss: 0.00241... Test loss: 0.00278\n",
      "Epoch: 1... Training loss: 0.0023... Test loss: 0.00272\n",
      "Epoch: 1... Training loss: 0.00223... Test loss: 0.00244\n",
      "Epoch: 1... Training loss: 0.00217... Test loss: 0.00279\n",
      "Epoch: 1... Training loss: 0.00207... Test loss: 0.00296\n",
      "Epoch: 1... Training loss: 0.00199... Test loss: 0.00227\n",
      "Epoch: 1... Training loss: 0.00189... Test loss: 0.00276\n",
      "Epoch: 1... Training loss: 0.00195... Test loss: 0.00228\n",
      "Epoch: 1... Training loss: 0.00176... Test loss: 0.00294\n",
      "Epoch: 1... Training loss: 0.00182... Test loss: 0.00208\n",
      "Epoch: 1... Training loss: 0.0016... Test loss: 0.00216\n",
      "Epoch: 1... Training loss: 0.00167... Test loss: 0.00173\n",
      "Epoch: 1... Training loss: 0.0016... Test loss: 0.00225\n",
      "Epoch: 1... Training loss: 0.00148... Test loss: 0.00166\n",
      "Epoch: 1... Training loss: 0.00136... Test loss: 0.00213\n",
      "Epoch: 1... Training loss: 0.00138... Test loss: 0.00147\n",
      "Epoch: 1... Training loss: 0.00125... Test loss: 0.00163\n",
      "Epoch: 1... Training loss: 0.00122... Test loss: 0.0013\n",
      "Epoch: 1... Training loss: 0.00116... Test loss: 0.00171\n",
      "Epoch: 1... Training loss: 0.00114... Test loss: 0.00129\n",
      "Epoch: 1... Training loss: 0.00118... Test loss: 0.00185\n",
      "Epoch: 1... Training loss: 0.00106... Test loss: 0.00115\n",
      "Epoch: 1... Training loss: 0.00099... Test loss: 0.00142\n",
      "Epoch: 1... Training loss: 0.00099... Test loss: 0.00094\n",
      "Epoch: 1... Training loss: 0.00089... Test loss: 0.00111\n",
      "Epoch: 1... Training loss: 0.00087... Test loss: 0.00084\n",
      "Epoch: 1... Training loss: 0.00081... Test loss: 0.00135\n",
      "Epoch: 1... Training loss: 0.00081... Test loss: 0.001\n",
      "Epoch: 1... Training loss: 0.00074... Test loss: 0.00093\n",
      "Epoch: 1... Training loss: 0.00068... Test loss: 0.00092\n",
      "Epoch: 1... Training loss: 0.0007... Test loss: 0.00085\n",
      "Epoch: 1... Training loss: 0.0006... Test loss: 0.00084\n",
      "Epoch: 1... Training loss: 0.0006... Test loss: 0.00089\n",
      "Epoch: 1... Training loss: 0.00056... Test loss: 0.00082\n",
      "Epoch: 1... Training loss: 0.00057... Test loss: 0.00076\n",
      "Epoch: 1... Training loss: 0.00052... Test loss: 0.00072\n",
      "Epoch: 1... Training loss: 0.00049... Test loss: 0.00052\n",
      "Epoch: 1... Training loss: 0.00049... Test loss: 0.00083\n",
      "Epoch: 1... Training loss: 0.00047... Test loss: 0.00043\n",
      "Epoch: 1... Training loss: 0.00041... Test loss: 0.0006\n",
      "Epoch: 1... Training loss: 0.00037... Test loss: 0.00036\n",
      "Epoch: 1... Training loss: 0.00035... Test loss: 0.00052\n",
      "Epoch: 1... Training loss: 0.00033... Test loss: 0.0004\n",
      "Epoch: 1... Training loss: 0.00036... Test loss: 0.00036\n",
      "Epoch: 1... Training loss: 0.00032... Test loss: 0.00032\n",
      "Epoch: 1... Training loss: 0.00032... Test loss: 0.00047\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00038\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00033\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00034\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 8e-05... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 8e-05... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 8e-05... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 8e-05... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 8e-05\n",
      "Epoch: 1... Training loss: 8e-05... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 7e-05... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 8e-05... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 8e-05... Test loss: 7e-05\n",
      "Epoch: 1... Training loss: 7e-05... Test loss: 9e-05\n",
      "213.64919058862142\n",
      "Epoch: 1... Training loss: 1.17615... Test loss: 0.52513\n",
      "Epoch: 1... Training loss: 0.53482... Test loss: 0.21519\n",
      "Epoch: 1... Training loss: 0.28598... Test loss: 0.12233\n",
      "Epoch: 1... Training loss: 0.21982... Test loss: 0.07287\n",
      "Epoch: 1... Training loss: 0.13342... Test loss: 0.05046\n",
      "Epoch: 1... Training loss: 0.10438... Test loss: 0.04632\n",
      "Epoch: 1... Training loss: 0.08641... Test loss: 0.03605\n",
      "Epoch: 1... Training loss: 0.07696... Test loss: 0.05049\n",
      "Epoch: 1... Training loss: 0.06606... Test loss: 0.03057\n",
      "Epoch: 1... Training loss: 0.05645... Test loss: 0.02214\n",
      "Epoch: 1... Training loss: 0.05077... Test loss: 0.02036\n",
      "Epoch: 1... Training loss: 0.04616... Test loss: 0.02948\n",
      "Epoch: 1... Training loss: 0.04285... Test loss: 0.01745\n",
      "Epoch: 1... Training loss: 0.03843... Test loss: 0.03196\n",
      "Epoch: 1... Training loss: 0.03746... Test loss: 0.01369\n",
      "Epoch: 1... Training loss: 0.03401... Test loss: 0.02767\n",
      "Epoch: 1... Training loss: 0.03257... Test loss: 0.01316\n",
      "Epoch: 1... Training loss: 0.03127... Test loss: 0.01481\n",
      "Epoch: 1... Training loss: 0.02895... Test loss: 0.02317\n",
      "Epoch: 1... Training loss: 0.0267... Test loss: 0.01486\n",
      "Epoch: 1... Training loss: 0.02525... Test loss: 0.01241\n",
      "Epoch: 1... Training loss: 0.02409... Test loss: 0.02034\n",
      "Epoch: 1... Training loss: 0.02287... Test loss: 0.00996\n",
      "Epoch: 1... Training loss: 0.02137... Test loss: 0.01675\n",
      "Epoch: 1... Training loss: 0.01984... Test loss: 0.00877\n",
      "Epoch: 1... Training loss: 0.01903... Test loss: 0.01575\n",
      "Epoch: 1... Training loss: 0.01842... Test loss: 0.00859\n",
      "Epoch: 1... Training loss: 0.01791... Test loss: 0.01288\n",
      "Epoch: 1... Training loss: 0.01716... Test loss: 0.00941\n",
      "Epoch: 1... Training loss: 0.01643... Test loss: 0.01318\n",
      "Epoch: 1... Training loss: 0.01593... Test loss: 0.00755\n",
      "Epoch: 1... Training loss: 0.0156... Test loss: 0.01178\n",
      "Epoch: 1... Training loss: 0.01515... Test loss: 0.01009\n",
      "Epoch: 1... Training loss: 0.01464... Test loss: 0.00797\n",
      "Epoch: 1... Training loss: 0.01413... Test loss: 0.0115\n",
      "Epoch: 1... Training loss: 0.01364... Test loss: 0.00732\n",
      "Epoch: 1... Training loss: 0.01321... Test loss: 0.00971\n",
      "Epoch: 1... Training loss: 0.01261... Test loss: 0.00843\n",
      "Epoch: 1... Training loss: 0.01217... Test loss: 0.00808\n",
      "Epoch: 1... Training loss: 0.0118... Test loss: 0.0097\n",
      "Epoch: 1... Training loss: 0.01146... Test loss: 0.00753\n",
      "Epoch: 1... Training loss: 0.01115... Test loss: 0.01061\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1... Training loss: 0.01077... Test loss: 0.00656\n",
      "Epoch: 1... Training loss: 0.01058... Test loss: 0.00889\n",
      "Epoch: 1... Training loss: 0.01012... Test loss: 0.00711\n",
      "Epoch: 1... Training loss: 0.00977... Test loss: 0.00909\n",
      "Epoch: 1... Training loss: 0.00929... Test loss: 0.00668\n",
      "Epoch: 1... Training loss: 0.00902... Test loss: 0.00977\n",
      "Epoch: 1... Training loss: 0.00878... Test loss: 0.00608\n",
      "Epoch: 1... Training loss: 0.00864... Test loss: 0.0088\n",
      "Epoch: 1... Training loss: 0.00831... Test loss: 0.00598\n",
      "Epoch: 1... Training loss: 0.00816... Test loss: 0.00806\n",
      "Epoch: 1... Training loss: 0.00777... Test loss: 0.00594\n",
      "Epoch: 1... Training loss: 0.00766... Test loss: 0.00756\n",
      "Epoch: 1... Training loss: 0.00731... Test loss: 0.00515\n",
      "Epoch: 1... Training loss: 0.00715... Test loss: 0.00708\n",
      "Epoch: 1... Training loss: 0.00687... Test loss: 0.00467\n",
      "Epoch: 1... Training loss: 0.00668... Test loss: 0.00641\n",
      "Epoch: 1... Training loss: 0.00651... Test loss: 0.00508\n",
      "Epoch: 1... Training loss: 0.00634... Test loss: 0.00636\n",
      "Epoch: 1... Training loss: 0.00613... Test loss: 0.00452\n",
      "Epoch: 1... Training loss: 0.00596... Test loss: 0.0059\n",
      "Epoch: 1... Training loss: 0.00577... Test loss: 0.00516\n",
      "Epoch: 1... Training loss: 0.00573... Test loss: 0.00522\n",
      "Epoch: 1... Training loss: 0.00889... Test loss: 0.01498\n",
      "Epoch: 1... Training loss: 0.01001... Test loss: 0.01088\n",
      "Epoch: 1... Training loss: 0.01027... Test loss: 0.01314\n",
      "Epoch: 1... Training loss: 0.01001... Test loss: 0.01042\n",
      "Epoch: 1... Training loss: 0.00928... Test loss: 0.01269\n",
      "Epoch: 1... Training loss: 0.00968... Test loss: 0.009\n",
      "Epoch: 1... Training loss: 0.00988... Test loss: 0.01114\n",
      "Epoch: 1... Training loss: 0.00829... Test loss: 0.00962\n",
      "Epoch: 1... Training loss: 0.00909... Test loss: 0.01188\n",
      "Epoch: 1... Training loss: 0.00809... Test loss: 0.00863\n",
      "Epoch: 1... Training loss: 0.0081... Test loss: 0.00842\n",
      "Epoch: 1... Training loss: 0.00759... Test loss: 0.00937\n",
      "Epoch: 1... Training loss: 0.00764... Test loss: 0.00687\n",
      "Epoch: 1... Training loss: 0.00708... Test loss: 0.01112\n",
      "Epoch: 1... Training loss: 0.00657... Test loss: 0.0072\n",
      "Epoch: 1... Training loss: 0.0061... Test loss: 0.01217\n",
      "Epoch: 1... Training loss: 0.00613... Test loss: 0.00679\n",
      "Epoch: 1... Training loss: 0.00649... Test loss: 0.00885\n",
      "Epoch: 1... Training loss: 0.00614... Test loss: 0.00675\n",
      "Epoch: 1... Training loss: 0.00605... Test loss: 0.00856\n",
      "Epoch: 1... Training loss: 0.00573... Test loss: 0.00677\n",
      "Epoch: 1... Training loss: 0.00542... Test loss: 0.00676\n",
      "Epoch: 1... Training loss: 0.00514... Test loss: 0.00761\n",
      "Epoch: 1... Training loss: 0.00492... Test loss: 0.00668\n",
      "Epoch: 1... Training loss: 0.0051... Test loss: 0.00555\n",
      "Epoch: 1... Training loss: 0.00449... Test loss: 0.00609\n",
      "Epoch: 1... Training loss: 0.00441... Test loss: 0.00519\n",
      "Epoch: 1... Training loss: 0.00424... Test loss: 0.00473\n",
      "Epoch: 1... Training loss: 0.00427... Test loss: 0.00475\n",
      "Epoch: 1... Training loss: 0.00418... Test loss: 0.00449\n",
      "Epoch: 1... Training loss: 0.00372... Test loss: 0.00442\n",
      "Epoch: 1... Training loss: 0.0036... Test loss: 0.00454\n",
      "Epoch: 1... Training loss: 0.00356... Test loss: 0.0035\n",
      "Epoch: 1... Training loss: 0.00344... Test loss: 0.00419\n",
      "Epoch: 1... Training loss: 0.00336... Test loss: 0.00335\n",
      "Epoch: 1... Training loss: 0.00324... Test loss: 0.0041\n",
      "Epoch: 1... Training loss: 0.00313... Test loss: 0.00291\n",
      "Epoch: 1... Training loss: 0.00296... Test loss: 0.00488\n",
      "Epoch: 1... Training loss: 0.00295... Test loss: 0.00291\n",
      "Epoch: 1... Training loss: 0.00277... Test loss: 0.00423\n",
      "Epoch: 1... Training loss: 0.00292... Test loss: 0.00306\n",
      "Epoch: 1... Training loss: 0.00269... Test loss: 0.00418\n",
      "Epoch: 1... Training loss: 0.00264... Test loss: 0.00314\n",
      "Epoch: 1... Training loss: 0.00257... Test loss: 0.00309\n",
      "Epoch: 1... Training loss: 0.00247... Test loss: 0.00334\n",
      "Epoch: 1... Training loss: 0.00236... Test loss: 0.00278\n",
      "Epoch: 1... Training loss: 0.00232... Test loss: 0.00273\n",
      "Epoch: 1... Training loss: 0.00218... Test loss: 0.00296\n",
      "Epoch: 1... Training loss: 0.00218... Test loss: 0.00266\n",
      "Epoch: 1... Training loss: 0.00205... Test loss: 0.00264\n",
      "Epoch: 1... Training loss: 0.00209... Test loss: 0.00253\n",
      "Epoch: 1... Training loss: 0.00188... Test loss: 0.00283\n",
      "Epoch: 1... Training loss: 0.00189... Test loss: 0.00206\n",
      "Epoch: 1... Training loss: 0.00175... Test loss: 0.00263\n",
      "Epoch: 1... Training loss: 0.00183... Test loss: 0.00221\n",
      "Epoch: 1... Training loss: 0.00165... Test loss: 0.00202\n",
      "Epoch: 1... Training loss: 0.0016... Test loss: 0.00169\n",
      "Epoch: 1... Training loss: 0.00156... Test loss: 0.00162\n",
      "Epoch: 1... Training loss: 0.00149... Test loss: 0.00168\n",
      "Epoch: 1... Training loss: 0.00142... Test loss: 0.00132\n",
      "Epoch: 1... Training loss: 0.00136... Test loss: 0.00188\n",
      "Epoch: 1... Training loss: 0.00133... Test loss: 0.00147\n",
      "Epoch: 1... Training loss: 0.0013... Test loss: 0.00138\n",
      "Epoch: 1... Training loss: 0.00127... Test loss: 0.00142\n",
      "Epoch: 1... Training loss: 0.00125... Test loss: 0.00158\n",
      "Epoch: 1... Training loss: 0.00119... Test loss: 0.00125\n",
      "Epoch: 1... Training loss: 0.00105... Test loss: 0.00133\n",
      "Epoch: 1... Training loss: 0.00098... Test loss: 0.00129\n",
      "Epoch: 1... Training loss: 0.00093... Test loss: 0.00122\n",
      "Epoch: 1... Training loss: 0.00092... Test loss: 0.00114\n",
      "Epoch: 1... Training loss: 0.00084... Test loss: 0.0011\n",
      "Epoch: 1... Training loss: 0.0008... Test loss: 0.0009\n",
      "Epoch: 1... Training loss: 0.00078... Test loss: 0.0009\n",
      "Epoch: 1... Training loss: 0.0008... Test loss: 0.00116\n",
      "Epoch: 1... Training loss: 0.00075... Test loss: 0.00083\n",
      "Epoch: 1... Training loss: 0.00073... Test loss: 0.00105\n",
      "Epoch: 1... Training loss: 0.00069... Test loss: 0.00069\n",
      "Epoch: 1... Training loss: 0.00064... Test loss: 0.00083\n",
      "Epoch: 1... Training loss: 0.00058... Test loss: 0.00055\n",
      "Epoch: 1... Training loss: 0.00057... Test loss: 0.00072\n",
      "Epoch: 1... Training loss: 0.00054... Test loss: 0.0006\n",
      "Epoch: 1... Training loss: 0.00052... Test loss: 0.00067\n",
      "Epoch: 1... Training loss: 0.00051... Test loss: 0.00047\n",
      "Epoch: 1... Training loss: 0.00048... Test loss: 0.0006\n",
      "Epoch: 1... Training loss: 0.0005... Test loss: 0.00047\n",
      "Epoch: 1... Training loss: 0.00044... Test loss: 0.00038\n",
      "Epoch: 1... Training loss: 0.00043... Test loss: 0.00058\n",
      "Epoch: 1... Training loss: 0.00043... Test loss: 0.00046\n",
      "Epoch: 1... Training loss: 0.00042... Test loss: 0.00055\n",
      "Epoch: 1... Training loss: 0.00035... Test loss: 0.00042\n",
      "Epoch: 1... Training loss: 0.00036... Test loss: 0.00038\n",
      "Epoch: 1... Training loss: 0.00036... Test loss: 0.00041\n",
      "Epoch: 1... Training loss: 0.00031... Test loss: 0.0004\n",
      "Epoch: 1... Training loss: 0.00031... Test loss: 0.00032\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.00033\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00024\n",
      "Epoch: 1... Training loss: 0.00026... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.0003\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 8e-05... Test loss: 0.00013\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1... Training loss: 9e-05... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 8e-05... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 8e-05... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 8e-05\n",
      "Epoch: 1... Training loss: 7e-05... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 7e-05\n",
      "Epoch: 1... Training loss: 6e-05... Test loss: 8e-05\n",
      "Epoch: 1... Training loss: 8e-05... Test loss: 8e-05\n",
      "Epoch: 1... Training loss: 8e-05... Test loss: 8e-05\n",
      "Epoch: 1... Training loss: 8e-05... Test loss: 8e-05\n",
      "Epoch: 1... Training loss: 8e-05... Test loss: 6e-05\n",
      "Epoch: 1... Training loss: 7e-05... Test loss: 7e-05\n",
      "Epoch: 1... Training loss: 7e-05... Test loss: 6e-05\n",
      "232.7404486181331\n",
      "Epoch: 1... Training loss: 1.08916... Test loss: 0.46852\n",
      "Epoch: 1... Training loss: 0.5077... Test loss: 0.1877\n",
      "Epoch: 1... Training loss: 0.32706... Test loss: 0.12198\n",
      "Epoch: 1... Training loss: 0.21552... Test loss: 0.11388\n",
      "Epoch: 1... Training loss: 0.19362... Test loss: 0.07912\n",
      "Epoch: 1... Training loss: 0.13187... Test loss: 0.09275\n",
      "Epoch: 1... Training loss: 0.10774... Test loss: 0.08362\n",
      "Epoch: 1... Training loss: 0.09229... Test loss: 0.04701\n",
      "Epoch: 1... Training loss: 0.07432... Test loss: 0.07239\n",
      "Epoch: 1... Training loss: 0.06318... Test loss: 0.04512\n",
      "Epoch: 1... Training loss: 0.05503... Test loss: 0.07649\n",
      "Epoch: 1... Training loss: 0.0483... Test loss: 0.03734\n",
      "Epoch: 1... Training loss: 0.04353... Test loss: 0.03582\n",
      "Epoch: 1... Training loss: 0.03973... Test loss: 0.06414\n",
      "Epoch: 1... Training loss: 0.03738... Test loss: 0.02857\n",
      "Epoch: 1... Training loss: 0.0341... Test loss: 0.07177\n",
      "Epoch: 1... Training loss: 0.03284... Test loss: 0.02652\n",
      "Epoch: 1... Training loss: 0.03028... Test loss: 0.05505\n",
      "Epoch: 1... Training loss: 0.02823... Test loss: 0.0165\n",
      "Epoch: 1... Training loss: 0.0264... Test loss: 0.03657\n",
      "Epoch: 1... Training loss: 0.02521... Test loss: 0.02849\n",
      "Epoch: 1... Training loss: 0.02408... Test loss: 0.04766\n",
      "Epoch: 1... Training loss: 0.02353... Test loss: 0.01413\n",
      "Epoch: 1... Training loss: 0.02205... Test loss: 0.04049\n",
      "Epoch: 1... Training loss: 0.02146... Test loss: 0.01316\n",
      "Epoch: 1... Training loss: 0.02003... Test loss: 0.03423\n",
      "Epoch: 1... Training loss: 0.01931... Test loss: 0.01367\n",
      "Epoch: 1... Training loss: 0.0184... Test loss: 0.03335\n",
      "Epoch: 1... Training loss: 0.01801... Test loss: 0.01435\n",
      "Epoch: 1... Training loss: 0.01687... Test loss: 0.02795\n",
      "Epoch: 1... Training loss: 0.01655... Test loss: 0.01219\n",
      "Epoch: 1... Training loss: 0.01566... Test loss: 0.02625\n",
      "Epoch: 1... Training loss: 0.01505... Test loss: 0.01161\n",
      "Epoch: 1... Training loss: 0.01412... Test loss: 0.02634\n",
      "Epoch: 1... Training loss: 0.01413... Test loss: 0.01095\n",
      "Epoch: 1... Training loss: 0.01327... Test loss: 0.02402\n",
      "Epoch: 1... Training loss: 0.01286... Test loss: 0.01119\n",
      "Epoch: 1... Training loss: 0.01251... Test loss: 0.02178\n",
      "Epoch: 1... Training loss: 0.01232... Test loss: 0.01176\n",
      "Epoch: 1... Training loss: 0.01196... Test loss: 0.01788\n",
      "Epoch: 1... Training loss: 0.01135... Test loss: 0.00993\n",
      "Epoch: 1... Training loss: 0.01088... Test loss: 0.017\n",
      "Epoch: 1... Training loss: 0.01046... Test loss: 0.00875\n",
      "Epoch: 1... Training loss: 0.01019... Test loss: 0.01497\n",
      "Epoch: 1... Training loss: 0.00994... Test loss: 0.0093\n",
      "Epoch: 1... Training loss: 0.00962... Test loss: 0.01436\n",
      "Epoch: 1... Training loss: 0.0092... Test loss: 0.00862\n",
      "Epoch: 1... Training loss: 0.00884... Test loss: 0.0132\n",
      "Epoch: 1... Training loss: 0.00868... Test loss: 0.00815\n",
      "Epoch: 1... Training loss: 0.00843... Test loss: 0.01253\n",
      "Epoch: 1... Training loss: 0.00826... Test loss: 0.00776\n",
      "Epoch: 1... Training loss: 0.00808... Test loss: 0.01022\n",
      "Epoch: 1... Training loss: 0.0077... Test loss: 0.00808\n",
      "Epoch: 1... Training loss: 0.00759... Test loss: 0.00956\n",
      "Epoch: 1... Training loss: 0.00738... Test loss: 0.0078\n",
      "Epoch: 1... Training loss: 0.00714... Test loss: 0.00837\n",
      "Epoch: 1... Training loss: 0.00693... Test loss: 0.00795\n",
      "Epoch: 1... Training loss: 0.00668... Test loss: 0.00722\n",
      "Epoch: 1... Training loss: 0.00657... Test loss: 0.00792\n",
      "Epoch: 1... Training loss: 0.00626... Test loss: 0.00684\n",
      "Epoch: 1... Training loss: 0.0061... Test loss: 0.00775\n",
      "Epoch: 1... Training loss: 0.00591... Test loss: 0.00666\n",
      "Epoch: 1... Training loss: 0.00564... Test loss: 0.00712\n",
      "Epoch: 1... Training loss: 0.00547... Test loss: 0.00577\n",
      "Epoch: 1... Training loss: 0.01215... Test loss: 0.02436\n",
      "Epoch: 1... Training loss: 0.01217... Test loss: 0.01483\n",
      "Epoch: 1... Training loss: 0.01157... Test loss: 0.02952\n",
      "Epoch: 1... Training loss: 0.00942... Test loss: 0.01246\n",
      "Epoch: 1... Training loss: 0.00808... Test loss: 0.02455\n",
      "Epoch: 1... Training loss: 0.00922... Test loss: 0.01198\n",
      "Epoch: 1... Training loss: 0.00874... Test loss: 0.023\n",
      "Epoch: 1... Training loss: 0.00825... Test loss: 0.01176\n",
      "Epoch: 1... Training loss: 0.00769... Test loss: 0.01493\n",
      "Epoch: 1... Training loss: 0.00822... Test loss: 0.01103\n",
      "Epoch: 1... Training loss: 0.00815... Test loss: 0.01759\n",
      "Epoch: 1... Training loss: 0.00751... Test loss: 0.0083\n",
      "Epoch: 1... Training loss: 0.00733... Test loss: 0.01292\n",
      "Epoch: 1... Training loss: 0.00719... Test loss: 0.00786\n",
      "Epoch: 1... Training loss: 0.00595... Test loss: 0.01106\n",
      "Epoch: 1... Training loss: 0.00621... Test loss: 0.00778\n",
      "Epoch: 1... Training loss: 0.00627... Test loss: 0.00915\n",
      "Epoch: 1... Training loss: 0.00605... Test loss: 0.00787\n",
      "Epoch: 1... Training loss: 0.00588... Test loss: 0.00821\n",
      "Epoch: 1... Training loss: 0.00559... Test loss: 0.00683\n",
      "Epoch: 1... Training loss: 0.00565... Test loss: 0.00704\n",
      "Epoch: 1... Training loss: 0.00524... Test loss: 0.00731\n",
      "Epoch: 1... Training loss: 0.00501... Test loss: 0.00711\n",
      "Epoch: 1... Training loss: 0.00473... Test loss: 0.00629\n",
      "Epoch: 1... Training loss: 0.00458... Test loss: 0.00649\n",
      "Epoch: 1... Training loss: 0.00421... Test loss: 0.00588\n",
      "Epoch: 1... Training loss: 0.0041... Test loss: 0.00558\n",
      "Epoch: 1... Training loss: 0.00393... Test loss: 0.00476\n",
      "Epoch: 1... Training loss: 0.00395... Test loss: 0.00453\n",
      "Epoch: 1... Training loss: 0.00364... Test loss: 0.00441\n",
      "Epoch: 1... Training loss: 0.0035... Test loss: 0.00464\n",
      "Epoch: 1... Training loss: 0.00351... Test loss: 0.00359\n",
      "Epoch: 1... Training loss: 0.00358... Test loss: 0.00471\n",
      "Epoch: 1... Training loss: 0.00334... Test loss: 0.00413\n",
      "Epoch: 1... Training loss: 0.00317... Test loss: 0.00425\n",
      "Epoch: 1... Training loss: 0.00314... Test loss: 0.00353\n",
      "Epoch: 1... Training loss: 0.00284... Test loss: 0.00456\n",
      "Epoch: 1... Training loss: 0.00288... Test loss: 0.00294\n",
      "Epoch: 1... Training loss: 0.00271... Test loss: 0.00377\n",
      "Epoch: 1... Training loss: 0.00281... Test loss: 0.00276\n",
      "Epoch: 1... Training loss: 0.00277... Test loss: 0.00367\n",
      "Epoch: 1... Training loss: 0.00261... Test loss: 0.00283\n",
      "Epoch: 1... Training loss: 0.00255... Test loss: 0.00256\n",
      "Epoch: 1... Training loss: 0.00238... Test loss: 0.00248\n",
      "Epoch: 1... Training loss: 0.00236... Test loss: 0.00296\n",
      "Epoch: 1... Training loss: 0.0023... Test loss: 0.00235\n",
      "Epoch: 1... Training loss: 0.00217... Test loss: 0.00254\n",
      "Epoch: 1... Training loss: 0.00213... Test loss: 0.00255\n",
      "Epoch: 1... Training loss: 0.00203... Test loss: 0.00282\n",
      "Epoch: 1... Training loss: 0.002... Test loss: 0.00228\n",
      "Epoch: 1... Training loss: 0.0019... Test loss: 0.00202\n",
      "Epoch: 1... Training loss: 0.00189... Test loss: 0.00214\n",
      "Epoch: 1... Training loss: 0.00179... Test loss: 0.00179\n",
      "Epoch: 1... Training loss: 0.00174... Test loss: 0.00186\n",
      "Epoch: 1... Training loss: 0.0019... Test loss: 0.00167\n",
      "Epoch: 1... Training loss: 0.00161... Test loss: 0.00182\n",
      "Epoch: 1... Training loss: 0.0016... Test loss: 0.00161\n",
      "Epoch: 1... Training loss: 0.0015... Test loss: 0.00183\n",
      "Epoch: 1... Training loss: 0.00146... Test loss: 0.0015\n",
      "Epoch: 1... Training loss: 0.00147... Test loss: 0.00206\n",
      "Epoch: 1... Training loss: 0.00132... Test loss: 0.00133\n",
      "Epoch: 1... Training loss: 0.0013... Test loss: 0.00183\n",
      "Epoch: 1... Training loss: 0.00127... Test loss: 0.00137\n",
      "Epoch: 1... Training loss: 0.00118... Test loss: 0.0016\n",
      "Epoch: 1... Training loss: 0.00116... Test loss: 0.00151\n",
      "Epoch: 1... Training loss: 0.00111... Test loss: 0.00137\n",
      "Epoch: 1... Training loss: 0.00102... Test loss: 0.00129\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1... Training loss: 0.00099... Test loss: 0.00117\n",
      "Epoch: 1... Training loss: 0.00097... Test loss: 0.00137\n",
      "Epoch: 1... Training loss: 0.00095... Test loss: 0.00103\n",
      "Epoch: 1... Training loss: 0.00092... Test loss: 0.00123\n",
      "Epoch: 1... Training loss: 0.0009... Test loss: 0.0009\n",
      "Epoch: 1... Training loss: 0.00085... Test loss: 0.00105\n",
      "Epoch: 1... Training loss: 0.00089... Test loss: 0.00076\n",
      "Epoch: 1... Training loss: 0.00078... Test loss: 0.00082\n",
      "Epoch: 1... Training loss: 0.00078... Test loss: 0.00065\n",
      "Epoch: 1... Training loss: 0.00074... Test loss: 0.00076\n",
      "Epoch: 1... Training loss: 0.00074... Test loss: 0.00065\n",
      "Epoch: 1... Training loss: 0.00074... Test loss: 0.0006\n",
      "Epoch: 1... Training loss: 0.00066... Test loss: 0.00058\n",
      "Epoch: 1... Training loss: 0.00068... Test loss: 0.00076\n",
      "Epoch: 1... Training loss: 0.00063... Test loss: 0.00047\n",
      "Epoch: 1... Training loss: 0.0006... Test loss: 0.00079\n",
      "Epoch: 1... Training loss: 0.00061... Test loss: 0.00056\n",
      "Epoch: 1... Training loss: 0.00057... Test loss: 0.00089\n",
      "Epoch: 1... Training loss: 0.00055... Test loss: 0.00045\n",
      "Epoch: 1... Training loss: 0.00052... Test loss: 0.00069\n",
      "Epoch: 1... Training loss: 0.0005... Test loss: 0.00045\n",
      "Epoch: 1... Training loss: 0.00054... Test loss: 0.00068\n",
      "Epoch: 1... Training loss: 0.00045... Test loss: 0.00043\n",
      "Epoch: 1... Training loss: 0.00044... Test loss: 0.0006\n",
      "Epoch: 1... Training loss: 0.00044... Test loss: 0.00043\n",
      "Epoch: 1... Training loss: 0.00042... Test loss: 0.0004\n",
      "Epoch: 1... Training loss: 0.00037... Test loss: 0.00046\n",
      "Epoch: 1... Training loss: 0.00045... Test loss: 0.00033\n",
      "Epoch: 1... Training loss: 0.00037... Test loss: 0.00043\n",
      "Epoch: 1... Training loss: 0.00043... Test loss: 0.00024\n",
      "Epoch: 1... Training loss: 0.00035... Test loss: 0.0005\n",
      "Epoch: 1... Training loss: 0.00041... Test loss: 0.00034\n",
      "Epoch: 1... Training loss: 0.00037... Test loss: 0.00033\n",
      "Epoch: 1... Training loss: 0.00036... Test loss: 0.0003\n",
      "Epoch: 1... Training loss: 0.00035... Test loss: 0.00036\n",
      "Epoch: 1... Training loss: 0.00036... Test loss: 0.00028\n",
      "Epoch: 1... Training loss: 0.00032... Test loss: 0.00043\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00031\n",
      "Epoch: 1... Training loss: 0.00029... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00031\n",
      "Epoch: 1... Training loss: 0.00026... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00021\n",
      "331.99768877308816\n",
      "Epoch: 1... Training loss: 1.13945... Test loss: 0.52866\n",
      "Epoch: 1... Training loss: 0.48336... Test loss: 0.15967\n",
      "Epoch: 1... Training loss: 0.31303... Test loss: 0.09443\n",
      "Epoch: 1... Training loss: 0.1843... Test loss: 0.07015\n",
      "Epoch: 1... Training loss: 0.13883... Test loss: 0.03583\n",
      "Epoch: 1... Training loss: 0.11301... Test loss: 0.04245\n",
      "Epoch: 1... Training loss: 0.09592... Test loss: 0.03165\n",
      "Epoch: 1... Training loss: 0.07862... Test loss: 0.04507\n",
      "Epoch: 1... Training loss: 0.06026... Test loss: 0.02644\n",
      "Epoch: 1... Training loss: 0.05002... Test loss: 0.04806\n",
      "Epoch: 1... Training loss: 0.0465... Test loss: 0.02263\n",
      "Epoch: 1... Training loss: 0.04166... Test loss: 0.01894\n",
      "Epoch: 1... Training loss: 0.03581... Test loss: 0.02511\n",
      "Epoch: 1... Training loss: 0.03295... Test loss: 0.01767\n",
      "Epoch: 1... Training loss: 0.03148... Test loss: 0.02441\n",
      "Epoch: 1... Training loss: 0.02985... Test loss: 0.0299\n",
      "Epoch: 1... Training loss: 0.02845... Test loss: 0.00946\n",
      "Epoch: 1... Training loss: 0.02684... Test loss: 0.02336\n",
      "Epoch: 1... Training loss: 0.02508... Test loss: 0.01071\n",
      "Epoch: 1... Training loss: 0.02304... Test loss: 0.02857\n",
      "Epoch: 1... Training loss: 0.02278... Test loss: 0.01234\n",
      "Epoch: 1... Training loss: 0.02143... Test loss: 0.02431\n",
      "Epoch: 1... Training loss: 0.02061... Test loss: 0.02441\n",
      "Epoch: 1... Training loss: 0.0203... Test loss: 0.00883\n",
      "Epoch: 1... Training loss: 0.01912... Test loss: 0.01869\n",
      "Epoch: 1... Training loss: 0.01812... Test loss: 0.00971\n",
      "Epoch: 1... Training loss: 0.01763... Test loss: 0.01446\n",
      "Epoch: 1... Training loss: 0.01632... Test loss: 0.00757\n",
      "Epoch: 1... Training loss: 0.01568... Test loss: 0.01181\n",
      "Epoch: 1... Training loss: 0.01496... Test loss: 0.00912\n",
      "Epoch: 1... Training loss: 0.01451... Test loss: 0.01214\n",
      "Epoch: 1... Training loss: 0.0142... Test loss: 0.01005\n",
      "Epoch: 1... Training loss: 0.0137... Test loss: 0.00853\n",
      "Epoch: 1... Training loss: 0.01301... Test loss: 0.01306\n",
      "Epoch: 1... Training loss: 0.0126... Test loss: 0.00787\n",
      "Epoch: 1... Training loss: 0.01216... Test loss: 0.01172\n",
      "Epoch: 1... Training loss: 0.01199... Test loss: 0.00651\n",
      "Epoch: 1... Training loss: 0.01146... Test loss: 0.01101\n",
      "Epoch: 1... Training loss: 0.01137... Test loss: 0.00555\n",
      "Epoch: 1... Training loss: 0.01088... Test loss: 0.01201\n",
      "Epoch: 1... Training loss: 0.01068... Test loss: 0.00568\n",
      "Epoch: 1... Training loss: 0.01032... Test loss: 0.01057\n",
      "Epoch: 1... Training loss: 0.00983... Test loss: 0.00621\n",
      "Epoch: 1... Training loss: 0.00967... Test loss: 0.01012\n",
      "Epoch: 1... Training loss: 0.00936... Test loss: 0.00816\n",
      "Epoch: 1... Training loss: 0.0089... Test loss: 0.00885\n",
      "Epoch: 1... Training loss: 0.00869... Test loss: 0.00836\n",
      "Epoch: 1... Training loss: 0.00844... Test loss: 0.00653\n",
      "Epoch: 1... Training loss: 0.00811... Test loss: 0.0068\n",
      "Epoch: 1... Training loss: 0.00765... Test loss: 0.00665\n",
      "Epoch: 1... Training loss: 0.0074... Test loss: 0.00541\n",
      "Epoch: 1... Training loss: 0.00714... Test loss: 0.00732\n",
      "Epoch: 1... Training loss: 0.00684... Test loss: 0.00478\n",
      "Epoch: 1... Training loss: 0.00663... Test loss: 0.00681\n",
      "Epoch: 1... Training loss: 0.0063... Test loss: 0.00641\n",
      "Epoch: 1... Training loss: 0.00611... Test loss: 0.00592\n",
      "Epoch: 1... Training loss: 0.00589... Test loss: 0.00642\n",
      "Epoch: 1... Training loss: 0.00573... Test loss: 0.00565\n",
      "Epoch: 1... Training loss: 0.00557... Test loss: 0.00567\n",
      "Epoch: 1... Training loss: 0.00532... Test loss: 0.00586\n",
      "Epoch: 1... Training loss: 0.00512... Test loss: 0.00509\n",
      "Epoch: 1... Training loss: 0.0049... Test loss: 0.0057\n",
      "Epoch: 1... Training loss: 0.00465... Test loss: 0.00516\n",
      "Epoch: 1... Training loss: 0.00457... Test loss: 0.0053\n",
      "Epoch: 1... Training loss: 0.00667... Test loss: 0.00979\n",
      "Epoch: 1... Training loss: 0.00754... Test loss: 0.01196\n",
      "Epoch: 1... Training loss: 0.00691... Test loss: 0.00866\n",
      "Epoch: 1... Training loss: 0.00765... Test loss: 0.00933\n",
      "Epoch: 1... Training loss: 0.0077... Test loss: 0.00612\n",
      "Epoch: 1... Training loss: 0.00877... Test loss: 0.01293\n",
      "Epoch: 1... Training loss: 0.00772... Test loss: 0.00851\n",
      "Epoch: 1... Training loss: 0.00877... Test loss: 0.00735\n",
      "Epoch: 1... Training loss: 0.00857... Test loss: 0.01071\n",
      "Epoch: 1... Training loss: 0.0069... Test loss: 0.0075\n",
      "Epoch: 1... Training loss: 0.00637... Test loss: 0.00966\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1... Training loss: 0.00639... Test loss: 0.00743\n",
      "Epoch: 1... Training loss: 0.00607... Test loss: 0.00869\n",
      "Epoch: 1... Training loss: 0.00597... Test loss: 0.00747\n",
      "Epoch: 1... Training loss: 0.0063... Test loss: 0.00716\n",
      "Epoch: 1... Training loss: 0.00516... Test loss: 0.00816\n",
      "Epoch: 1... Training loss: 0.00506... Test loss: 0.00698\n",
      "Epoch: 1... Training loss: 0.00524... Test loss: 0.00673\n",
      "Epoch: 1... Training loss: 0.00481... Test loss: 0.00588\n",
      "Epoch: 1... Training loss: 0.005... Test loss: 0.00644\n",
      "Epoch: 1... Training loss: 0.00464... Test loss: 0.0049\n",
      "Epoch: 1... Training loss: 0.00436... Test loss: 0.00641\n",
      "Epoch: 1... Training loss: 0.00428... Test loss: 0.00505\n",
      "Epoch: 1... Training loss: 0.0041... Test loss: 0.00602\n",
      "Epoch: 1... Training loss: 0.00387... Test loss: 0.00443\n",
      "Epoch: 1... Training loss: 0.00373... Test loss: 0.00575\n",
      "Epoch: 1... Training loss: 0.0035... Test loss: 0.00431\n",
      "Epoch: 1... Training loss: 0.0036... Test loss: 0.00398\n",
      "Epoch: 1... Training loss: 0.00343... Test loss: 0.00442\n",
      "Epoch: 1... Training loss: 0.0032... Test loss: 0.00298\n",
      "Epoch: 1... Training loss: 0.00307... Test loss: 0.00407\n",
      "Epoch: 1... Training loss: 0.00305... Test loss: 0.00317\n",
      "Epoch: 1... Training loss: 0.00314... Test loss: 0.00369\n",
      "Epoch: 1... Training loss: 0.00295... Test loss: 0.00268\n",
      "Epoch: 1... Training loss: 0.00279... Test loss: 0.0032\n",
      "Epoch: 1... Training loss: 0.00274... Test loss: 0.00276\n",
      "Epoch: 1... Training loss: 0.00257... Test loss: 0.00306\n",
      "Epoch: 1... Training loss: 0.0026... Test loss: 0.00256\n",
      "Epoch: 1... Training loss: 0.00261... Test loss: 0.00294\n",
      "Epoch: 1... Training loss: 0.00246... Test loss: 0.00273\n",
      "Epoch: 1... Training loss: 0.0024... Test loss: 0.00279\n",
      "Epoch: 1... Training loss: 0.00233... Test loss: 0.00235\n",
      "Epoch: 1... Training loss: 0.00217... Test loss: 0.00298\n",
      "Epoch: 1... Training loss: 0.00204... Test loss: 0.0022\n",
      "Epoch: 1... Training loss: 0.00202... Test loss: 0.00247\n",
      "Epoch: 1... Training loss: 0.00197... Test loss: 0.00203\n",
      "Epoch: 1... Training loss: 0.00197... Test loss: 0.00231\n",
      "Epoch: 1... Training loss: 0.00189... Test loss: 0.00217\n",
      "Epoch: 1... Training loss: 0.00179... Test loss: 0.00199\n",
      "Epoch: 1... Training loss: 0.00185... Test loss: 0.00182\n",
      "Epoch: 1... Training loss: 0.0016... Test loss: 0.00175\n",
      "Epoch: 1... Training loss: 0.00158... Test loss: 0.00181\n",
      "Epoch: 1... Training loss: 0.00152... Test loss: 0.00161\n",
      "Epoch: 1... Training loss: 0.0014... Test loss: 0.00206\n",
      "Epoch: 1... Training loss: 0.00145... Test loss: 0.00171\n",
      "Epoch: 1... Training loss: 0.00133... Test loss: 0.00187\n",
      "Epoch: 1... Training loss: 0.00129... Test loss: 0.0014\n",
      "Epoch: 1... Training loss: 0.00123... Test loss: 0.00125\n",
      "Epoch: 1... Training loss: 0.00114... Test loss: 0.00146\n",
      "Epoch: 1... Training loss: 0.00112... Test loss: 0.00129\n",
      "Epoch: 1... Training loss: 0.00105... Test loss: 0.00154\n",
      "Epoch: 1... Training loss: 0.00103... Test loss: 0.00148\n",
      "Epoch: 1... Training loss: 0.00094... Test loss: 0.00163\n",
      "Epoch: 1... Training loss: 0.00096... Test loss: 0.00145\n",
      "Epoch: 1... Training loss: 0.00093... Test loss: 0.00109\n",
      "Epoch: 1... Training loss: 0.0008... Test loss: 0.00117\n",
      "Epoch: 1... Training loss: 0.00081... Test loss: 0.00087\n",
      "Epoch: 1... Training loss: 0.00081... Test loss: 0.00115\n",
      "Epoch: 1... Training loss: 0.00075... Test loss: 0.00085\n",
      "Epoch: 1... Training loss: 0.00068... Test loss: 0.00087\n",
      "Epoch: 1... Training loss: 0.0007... Test loss: 0.00085\n",
      "Epoch: 1... Training loss: 0.00065... Test loss: 0.00078\n",
      "Epoch: 1... Training loss: 0.00059... Test loss: 0.00061\n",
      "Epoch: 1... Training loss: 0.00057... Test loss: 0.00066\n",
      "Epoch: 1... Training loss: 0.00055... Test loss: 0.00051\n",
      "Epoch: 1... Training loss: 0.0005... Test loss: 0.00064\n",
      "Epoch: 1... Training loss: 0.00051... Test loss: 0.00058\n",
      "Epoch: 1... Training loss: 0.00047... Test loss: 0.0005\n",
      "Epoch: 1... Training loss: 0.00045... Test loss: 0.00047\n",
      "Epoch: 1... Training loss: 0.00047... Test loss: 0.00053\n",
      "Epoch: 1... Training loss: 0.00044... Test loss: 0.00055\n",
      "Epoch: 1... Training loss: 0.00039... Test loss: 0.00046\n",
      "Epoch: 1... Training loss: 0.00038... Test loss: 0.00061\n",
      "Epoch: 1... Training loss: 0.00038... Test loss: 0.00038\n",
      "Epoch: 1... Training loss: 0.00033... Test loss: 0.00057\n",
      "Epoch: 1... Training loss: 0.00032... Test loss: 0.00038\n",
      "Epoch: 1... Training loss: 0.00032... Test loss: 0.00031\n",
      "Epoch: 1... Training loss: 0.00034... Test loss: 0.00034\n",
      "Epoch: 1... Training loss: 0.00038... Test loss: 0.00036\n",
      "Epoch: 1... Training loss: 0.00032... Test loss: 0.0003\n",
      "Epoch: 1... Training loss: 0.00035... Test loss: 0.00034\n",
      "Epoch: 1... Training loss: 0.00033... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.00032... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.00032... Test loss: 0.00035\n",
      "Epoch: 1... Training loss: 0.00032... Test loss: 0.00028\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00032\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00024\n",
      "Epoch: 1... Training loss: 0.00026... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.00026... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 8e-05... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 8e-05... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 7e-05\n",
      "228.81158754625358\n",
      "Epoch: 1... Training loss: 1.24143... Test loss: 0.5339\n",
      "Epoch: 1... Training loss: 0.55293... Test loss: 0.20953\n",
      "Epoch: 1... Training loss: 0.32404... Test loss: 0.12368\n",
      "Epoch: 1... Training loss: 0.21802... Test loss: 0.0914\n",
      "Epoch: 1... Training loss: 0.14851... Test loss: 0.04765\n",
      "Epoch: 1... Training loss: 0.11998... Test loss: 0.04846\n",
      "Epoch: 1... Training loss: 0.09899... Test loss: 0.02891\n",
      "Epoch: 1... Training loss: 0.07415... Test loss: 0.02359\n",
      "Epoch: 1... Training loss: 0.064... Test loss: 0.02059\n",
      "Epoch: 1... Training loss: 0.05041... Test loss: 0.01573\n",
      "Epoch: 1... Training loss: 0.04522... Test loss: 0.01475\n",
      "Epoch: 1... Training loss: 0.0381... Test loss: 0.01916\n",
      "Epoch: 1... Training loss: 0.03229... Test loss: 0.01972\n",
      "Epoch: 1... Training loss: 0.03311... Test loss: 0.01119\n",
      "Epoch: 1... Training loss: 0.02922... Test loss: 0.00762\n",
      "Epoch: 1... Training loss: 0.02812... Test loss: 0.00953\n",
      "Epoch: 1... Training loss: 0.02541... Test loss: 0.00676\n",
      "Epoch: 1... Training loss: 0.02512... Test loss: 0.00923\n",
      "Epoch: 1... Training loss: 0.02353... Test loss: 0.00566\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1... Training loss: 0.023... Test loss: 0.01225\n",
      "Epoch: 1... Training loss: 0.02159... Test loss: 0.00588\n",
      "Epoch: 1... Training loss: 0.02046... Test loss: 0.00868\n",
      "Epoch: 1... Training loss: 0.01996... Test loss: 0.00591\n",
      "Epoch: 1... Training loss: 0.01875... Test loss: 0.00818\n",
      "Epoch: 1... Training loss: 0.01855... Test loss: 0.00834\n",
      "Epoch: 1... Training loss: 0.01753... Test loss: 0.00564\n",
      "Epoch: 1... Training loss: 0.01693... Test loss: 0.01172\n",
      "Epoch: 1... Training loss: 0.0157... Test loss: 0.00579\n",
      "Epoch: 1... Training loss: 0.01511... Test loss: 0.01392\n",
      "Epoch: 1... Training loss: 0.01493... Test loss: 0.00486\n",
      "Epoch: 1... Training loss: 0.01402... Test loss: 0.01179\n",
      "Epoch: 1... Training loss: 0.0141... Test loss: 0.00825\n",
      "Epoch: 1... Training loss: 0.01324... Test loss: 0.00801\n",
      "Epoch: 1... Training loss: 0.01287... Test loss: 0.00744\n",
      "Epoch: 1... Training loss: 0.01239... Test loss: 0.0088\n",
      "Epoch: 1... Training loss: 0.01196... Test loss: 0.00789\n",
      "Epoch: 1... Training loss: 0.01153... Test loss: 0.00661\n",
      "Epoch: 1... Training loss: 0.01159... Test loss: 0.00722\n",
      "Epoch: 1... Training loss: 0.01094... Test loss: 0.00604\n",
      "Epoch: 1... Training loss: 0.01071... Test loss: 0.0082\n",
      "Epoch: 1... Training loss: 0.01027... Test loss: 0.00521\n",
      "Epoch: 1... Training loss: 0.01008... Test loss: 0.00812\n",
      "Epoch: 1... Training loss: 0.00958... Test loss: 0.00542\n",
      "Epoch: 1... Training loss: 0.00929... Test loss: 0.00897\n",
      "Epoch: 1... Training loss: 0.00892... Test loss: 0.00535\n",
      "Epoch: 1... Training loss: 0.00895... Test loss: 0.00884\n",
      "Epoch: 1... Training loss: 0.00847... Test loss: 0.00667\n",
      "Epoch: 1... Training loss: 0.0083... Test loss: 0.00969\n",
      "Epoch: 1... Training loss: 0.00802... Test loss: 0.00566\n",
      "Epoch: 1... Training loss: 0.00784... Test loss: 0.00921\n",
      "Epoch: 1... Training loss: 0.00767... Test loss: 0.00508\n",
      "Epoch: 1... Training loss: 0.00755... Test loss: 0.00768\n",
      "Epoch: 1... Training loss: 0.00728... Test loss: 0.00531\n",
      "Epoch: 1... Training loss: 0.00715... Test loss: 0.00719\n",
      "Epoch: 1... Training loss: 0.00691... Test loss: 0.00562\n",
      "Epoch: 1... Training loss: 0.00682... Test loss: 0.00679\n",
      "Epoch: 1... Training loss: 0.00666... Test loss: 0.0053\n",
      "Epoch: 1... Training loss: 0.00652... Test loss: 0.00625\n",
      "Epoch: 1... Training loss: 0.00631... Test loss: 0.00513\n",
      "Epoch: 1... Training loss: 0.00616... Test loss: 0.0053\n",
      "Epoch: 1... Training loss: 0.00599... Test loss: 0.0044\n",
      "Epoch: 1... Training loss: 0.006... Test loss: 0.00462\n",
      "Epoch: 1... Training loss: 0.00568... Test loss: 0.00482\n",
      "Epoch: 1... Training loss: 0.00561... Test loss: 0.00455\n",
      "Epoch: 1... Training loss: 0.02386... Test loss: 0.01181\n",
      "Epoch: 1... Training loss: 0.0117... Test loss: 0.01596\n",
      "Epoch: 1... Training loss: 0.01507... Test loss: 0.01586\n",
      "Epoch: 1... Training loss: 0.00946... Test loss: 0.01752\n",
      "Epoch: 1... Training loss: 0.00848... Test loss: 0.0114\n",
      "Epoch: 1... Training loss: 0.0086... Test loss: 0.01272\n",
      "Epoch: 1... Training loss: 0.00853... Test loss: 0.01256\n",
      "Epoch: 1... Training loss: 0.00792... Test loss: 0.01154\n",
      "Epoch: 1... Training loss: 0.00833... Test loss: 0.01097\n",
      "Epoch: 1... Training loss: 0.00832... Test loss: 0.01394\n",
      "Epoch: 1... Training loss: 0.0079... Test loss: 0.01147\n",
      "Epoch: 1... Training loss: 0.0074... Test loss: 0.01234\n",
      "Epoch: 1... Training loss: 0.00736... Test loss: 0.01061\n",
      "Epoch: 1... Training loss: 0.00657... Test loss: 0.01197\n",
      "Epoch: 1... Training loss: 0.00602... Test loss: 0.01045\n",
      "Epoch: 1... Training loss: 0.006... Test loss: 0.00906\n",
      "Epoch: 1... Training loss: 0.00592... Test loss: 0.00787\n",
      "Epoch: 1... Training loss: 0.00605... Test loss: 0.00864\n",
      "Epoch: 1... Training loss: 0.00567... Test loss: 0.00759\n",
      "Epoch: 1... Training loss: 0.00517... Test loss: 0.00853\n",
      "Epoch: 1... Training loss: 0.00497... Test loss: 0.00664\n",
      "Epoch: 1... Training loss: 0.00516... Test loss: 0.00709\n",
      "Epoch: 1... Training loss: 0.00492... Test loss: 0.00557\n",
      "Epoch: 1... Training loss: 0.00468... Test loss: 0.00685\n",
      "Epoch: 1... Training loss: 0.00446... Test loss: 0.00514\n",
      "Epoch: 1... Training loss: 0.00433... Test loss: 0.00622\n",
      "Epoch: 1... Training loss: 0.00438... Test loss: 0.00498\n",
      "Epoch: 1... Training loss: 0.00421... Test loss: 0.00583\n",
      "Epoch: 1... Training loss: 0.00414... Test loss: 0.00466\n",
      "Epoch: 1... Training loss: 0.00378... Test loss: 0.00503\n",
      "Epoch: 1... Training loss: 0.00366... Test loss: 0.00408\n",
      "Epoch: 1... Training loss: 0.00344... Test loss: 0.00422\n",
      "Epoch: 1... Training loss: 0.00333... Test loss: 0.00388\n",
      "Epoch: 1... Training loss: 0.00338... Test loss: 0.00444\n",
      "Epoch: 1... Training loss: 0.00312... Test loss: 0.00406\n",
      "Epoch: 1... Training loss: 0.00302... Test loss: 0.00381\n",
      "Epoch: 1... Training loss: 0.00288... Test loss: 0.00375\n",
      "Epoch: 1... Training loss: 0.00283... Test loss: 0.0033\n",
      "Epoch: 1... Training loss: 0.00303... Test loss: 0.00381\n",
      "Epoch: 1... Training loss: 0.00267... Test loss: 0.00342\n",
      "Epoch: 1... Training loss: 0.00289... Test loss: 0.00396\n",
      "Epoch: 1... Training loss: 0.00253... Test loss: 0.00302\n",
      "Epoch: 1... Training loss: 0.00258... Test loss: 0.00342\n",
      "Epoch: 1... Training loss: 0.00247... Test loss: 0.00328\n",
      "Epoch: 1... Training loss: 0.00246... Test loss: 0.00325\n",
      "Epoch: 1... Training loss: 0.00243... Test loss: 0.00284\n",
      "Epoch: 1... Training loss: 0.00248... Test loss: 0.00304\n",
      "Epoch: 1... Training loss: 0.00224... Test loss: 0.00246\n",
      "Epoch: 1... Training loss: 0.00221... Test loss: 0.00318\n",
      "Epoch: 1... Training loss: 0.00214... Test loss: 0.00224\n",
      "Epoch: 1... Training loss: 0.00207... Test loss: 0.00244\n",
      "Epoch: 1... Training loss: 0.002... Test loss: 0.00244\n",
      "Epoch: 1... Training loss: 0.00195... Test loss: 0.00214\n",
      "Epoch: 1... Training loss: 0.00198... Test loss: 0.002\n",
      "Epoch: 1... Training loss: 0.00187... Test loss: 0.00207\n",
      "Epoch: 1... Training loss: 0.00178... Test loss: 0.00219\n",
      "Epoch: 1... Training loss: 0.00165... Test loss: 0.00195\n",
      "Epoch: 1... Training loss: 0.00168... Test loss: 0.00203\n",
      "Epoch: 1... Training loss: 0.00156... Test loss: 0.00187\n",
      "Epoch: 1... Training loss: 0.00156... Test loss: 0.00183\n",
      "Epoch: 1... Training loss: 0.00144... Test loss: 0.00168\n",
      "Epoch: 1... Training loss: 0.00151... Test loss: 0.00173\n",
      "Epoch: 1... Training loss: 0.00131... Test loss: 0.0017\n",
      "Epoch: 1... Training loss: 0.00129... Test loss: 0.00151\n",
      "Epoch: 1... Training loss: 0.00127... Test loss: 0.00159\n",
      "Epoch: 1... Training loss: 0.00128... Test loss: 0.00175\n",
      "Epoch: 1... Training loss: 0.00124... Test loss: 0.00105\n",
      "Epoch: 1... Training loss: 0.00116... Test loss: 0.00144\n",
      "Epoch: 1... Training loss: 0.00112... Test loss: 0.00103\n",
      "Epoch: 1... Training loss: 0.00108... Test loss: 0.00137\n",
      "Epoch: 1... Training loss: 0.00103... Test loss: 0.00115\n",
      "Epoch: 1... Training loss: 0.00097... Test loss: 0.00133\n",
      "Epoch: 1... Training loss: 0.00094... Test loss: 0.00117\n",
      "Epoch: 1... Training loss: 0.00088... Test loss: 0.00106\n",
      "Epoch: 1... Training loss: 0.00086... Test loss: 0.00094\n",
      "Epoch: 1... Training loss: 0.00085... Test loss: 0.00093\n",
      "Epoch: 1... Training loss: 0.00081... Test loss: 0.00084\n",
      "Epoch: 1... Training loss: 0.00073... Test loss: 0.00105\n",
      "Epoch: 1... Training loss: 0.00074... Test loss: 0.00078\n",
      "Epoch: 1... Training loss: 0.00072... Test loss: 0.00101\n",
      "Epoch: 1... Training loss: 0.00066... Test loss: 0.00089\n",
      "Epoch: 1... Training loss: 0.00061... Test loss: 0.00073\n",
      "Epoch: 1... Training loss: 0.0006... Test loss: 0.00062\n",
      "Epoch: 1... Training loss: 0.00054... Test loss: 0.00058\n",
      "Epoch: 1... Training loss: 0.00051... Test loss: 0.00041\n",
      "Epoch: 1... Training loss: 0.00048... Test loss: 0.00051\n",
      "Epoch: 1... Training loss: 0.00048... Test loss: 0.00057\n",
      "Epoch: 1... Training loss: 0.00047... Test loss: 0.0004\n",
      "Epoch: 1... Training loss: 0.00043... Test loss: 0.00055\n",
      "Epoch: 1... Training loss: 0.00045... Test loss: 0.00045\n",
      "Epoch: 1... Training loss: 0.0004... Test loss: 0.00046\n",
      "Epoch: 1... Training loss: 0.00037... Test loss: 0.00039\n",
      "Epoch: 1... Training loss: 0.00034... Test loss: 0.00049\n",
      "Epoch: 1... Training loss: 0.00036... Test loss: 0.00034\n",
      "Epoch: 1... Training loss: 0.00033... Test loss: 0.00038\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00038\n",
      "Epoch: 1... Training loss: 0.00032... Test loss: 0.0003\n",
      "Epoch: 1... Training loss: 0.00038... Test loss: 0.0003\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00049\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1... Training loss: 0.00032... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.00028\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00036\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00028\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 8e-05\n",
      "Epoch: 1... Training loss: 8e-05... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.0001\n",
      "266.4877347853035\n",
      "Epoch: 1... Training loss: 1.03429... Test loss: 0.36464\n",
      "Epoch: 1... Training loss: 0.51512... Test loss: 0.18778\n",
      "Epoch: 1... Training loss: 0.29757... Test loss: 0.10806\n",
      "Epoch: 1... Training loss: 0.20793... Test loss: 0.06884\n",
      "Epoch: 1... Training loss: 0.16377... Test loss: 0.06183\n",
      "Epoch: 1... Training loss: 0.13262... Test loss: 0.04342\n",
      "Epoch: 1... Training loss: 0.10014... Test loss: 0.03269\n",
      "Epoch: 1... Training loss: 0.08557... Test loss: 0.02392\n",
      "Epoch: 1... Training loss: 0.073... Test loss: 0.039\n",
      "Epoch: 1... Training loss: 0.06827... Test loss: 0.01509\n",
      "Epoch: 1... Training loss: 0.05798... Test loss: 0.0305\n",
      "Epoch: 1... Training loss: 0.05641... Test loss: 0.01079\n",
      "Epoch: 1... Training loss: 0.05053... Test loss: 0.02846\n",
      "Epoch: 1... Training loss: 0.04613... Test loss: 0.01239\n",
      "Epoch: 1... Training loss: 0.04304... Test loss: 0.03386\n",
      "Epoch: 1... Training loss: 0.03865... Test loss: 0.00993\n",
      "Epoch: 1... Training loss: 0.03635... Test loss: 0.0222\n",
      "Epoch: 1... Training loss: 0.03452... Test loss: 0.01775\n",
      "Epoch: 1... Training loss: 0.03318... Test loss: 0.01675\n",
      "Epoch: 1... Training loss: 0.03077... Test loss: 0.02859\n",
      "Epoch: 1... Training loss: 0.02964... Test loss: 0.01014\n",
      "Epoch: 1... Training loss: 0.0277... Test loss: 0.02516\n",
      "Epoch: 1... Training loss: 0.02621... Test loss: 0.01135\n",
      "Epoch: 1... Training loss: 0.02574... Test loss: 0.02505\n",
      "Epoch: 1... Training loss: 0.02373... Test loss: 0.0121\n",
      "Epoch: 1... Training loss: 0.02177... Test loss: 0.02488\n",
      "Epoch: 1... Training loss: 0.02106... Test loss: 0.01114\n",
      "Epoch: 1... Training loss: 0.01978... Test loss: 0.01854\n",
      "Epoch: 1... Training loss: 0.0192... Test loss: 0.01544\n",
      "Epoch: 1... Training loss: 0.01806... Test loss: 0.02044\n",
      "Epoch: 1... Training loss: 0.0175... Test loss: 0.01278\n",
      "Epoch: 1... Training loss: 0.01636... Test loss: 0.02101\n",
      "Epoch: 1... Training loss: 0.01564... Test loss: 0.01212\n",
      "Epoch: 1... Training loss: 0.01544... Test loss: 0.01799\n",
      "Epoch: 1... Training loss: 0.01505... Test loss: 0.01097\n",
      "Epoch: 1... Training loss: 0.01457... Test loss: 0.01747\n",
      "Epoch: 1... Training loss: 0.0141... Test loss: 0.00835\n",
      "Epoch: 1... Training loss: 0.01368... Test loss: 0.01631\n",
      "Epoch: 1... Training loss: 0.01333... Test loss: 0.00915\n",
      "Epoch: 1... Training loss: 0.01298... Test loss: 0.01513\n",
      "Epoch: 1... Training loss: 0.01245... Test loss: 0.0106\n",
      "Epoch: 1... Training loss: 0.01207... Test loss: 0.01287\n",
      "Epoch: 1... Training loss: 0.01152... Test loss: 0.01345\n",
      "Epoch: 1... Training loss: 0.0112... Test loss: 0.00952\n",
      "Epoch: 1... Training loss: 0.01098... Test loss: 0.01333\n",
      "Epoch: 1... Training loss: 0.01056... Test loss: 0.00802\n",
      "Epoch: 1... Training loss: 0.01024... Test loss: 0.01159\n",
      "Epoch: 1... Training loss: 0.01018... Test loss: 0.00814\n",
      "Epoch: 1... Training loss: 0.00958... Test loss: 0.00817\n",
      "Epoch: 1... Training loss: 0.00931... Test loss: 0.00927\n",
      "Epoch: 1... Training loss: 0.00899... Test loss: 0.00706\n",
      "Epoch: 1... Training loss: 0.00874... Test loss: 0.00921\n",
      "Epoch: 1... Training loss: 0.00839... Test loss: 0.00642\n",
      "Epoch: 1... Training loss: 0.00814... Test loss: 0.00854\n",
      "Epoch: 1... Training loss: 0.00789... Test loss: 0.00584\n",
      "Epoch: 1... Training loss: 0.00769... Test loss: 0.00777\n",
      "Epoch: 1... Training loss: 0.0074... Test loss: 0.00627\n",
      "Epoch: 1... Training loss: 0.00727... Test loss: 0.00761\n",
      "Epoch: 1... Training loss: 0.00705... Test loss: 0.00679\n",
      "Epoch: 1... Training loss: 0.00677... Test loss: 0.00722\n",
      "Epoch: 1... Training loss: 0.00653... Test loss: 0.00644\n",
      "Epoch: 1... Training loss: 0.00623... Test loss: 0.00643\n",
      "Epoch: 1... Training loss: 0.00604... Test loss: 0.0069\n",
      "Epoch: 1... Training loss: 0.00583... Test loss: 0.0067\n",
      "Epoch: 1... Training loss: 0.01013... Test loss: 0.0113\n",
      "Epoch: 1... Training loss: 0.01125... Test loss: 0.01559\n",
      "Epoch: 1... Training loss: 0.00995... Test loss: 0.01213\n",
      "Epoch: 1... Training loss: 0.00936... Test loss: 0.01162\n",
      "Epoch: 1... Training loss: 0.00933... Test loss: 0.01555\n",
      "Epoch: 1... Training loss: 0.0083... Test loss: 0.01143\n",
      "Epoch: 1... Training loss: 0.00865... Test loss: 0.0124\n",
      "Epoch: 1... Training loss: 0.00905... Test loss: 0.01181\n",
      "Epoch: 1... Training loss: 0.0088... Test loss: 0.01044\n",
      "Epoch: 1... Training loss: 0.00869... Test loss: 0.01423\n",
      "Epoch: 1... Training loss: 0.0082... Test loss: 0.01102\n",
      "Epoch: 1... Training loss: 0.00751... Test loss: 0.01814\n",
      "Epoch: 1... Training loss: 0.00708... Test loss: 0.0112\n",
      "Epoch: 1... Training loss: 0.00719... Test loss: 0.01093\n",
      "Epoch: 1... Training loss: 0.00666... Test loss: 0.00874\n",
      "Epoch: 1... Training loss: 0.00605... Test loss: 0.01011\n",
      "Epoch: 1... Training loss: 0.0066... Test loss: 0.00886\n",
      "Epoch: 1... Training loss: 0.00618... Test loss: 0.00558\n",
      "Epoch: 1... Training loss: 0.00565... Test loss: 0.011\n",
      "Epoch: 1... Training loss: 0.00536... Test loss: 0.00577\n",
      "Epoch: 1... Training loss: 0.00532... Test loss: 0.00849\n",
      "Epoch: 1... Training loss: 0.0052... Test loss: 0.00589\n",
      "Epoch: 1... Training loss: 0.00519... Test loss: 0.00708\n",
      "Epoch: 1... Training loss: 0.00459... Test loss: 0.00718\n",
      "Epoch: 1... Training loss: 0.00468... Test loss: 0.00657\n",
      "Epoch: 1... Training loss: 0.00435... Test loss: 0.00745\n",
      "Epoch: 1... Training loss: 0.00408... Test loss: 0.00541\n",
      "Epoch: 1... Training loss: 0.00411... Test loss: 0.0067\n",
      "Epoch: 1... Training loss: 0.00395... Test loss: 0.00465\n",
      "Epoch: 1... Training loss: 0.00378... Test loss: 0.00519\n",
      "Epoch: 1... Training loss: 0.0037... Test loss: 0.00392\n",
      "Epoch: 1... Training loss: 0.00347... Test loss: 0.00532\n",
      "Epoch: 1... Training loss: 0.00339... Test loss: 0.0035\n",
      "Epoch: 1... Training loss: 0.00329... Test loss: 0.00436\n",
      "Epoch: 1... Training loss: 0.00318... Test loss: 0.0032\n",
      "Epoch: 1... Training loss: 0.00306... Test loss: 0.00357\n",
      "Epoch: 1... Training loss: 0.00314... Test loss: 0.0029\n",
      "Epoch: 1... Training loss: 0.00284... Test loss: 0.00352\n",
      "Epoch: 1... Training loss: 0.00278... Test loss: 0.00313\n",
      "Epoch: 1... Training loss: 0.00265... Test loss: 0.00401\n",
      "Epoch: 1... Training loss: 0.00264... Test loss: 0.0035\n",
      "Epoch: 1... Training loss: 0.00247... Test loss: 0.00397\n",
      "Epoch: 1... Training loss: 0.00255... Test loss: 0.00315\n",
      "Epoch: 1... Training loss: 0.00251... Test loss: 0.00324\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1... Training loss: 0.00241... Test loss: 0.00271\n",
      "Epoch: 1... Training loss: 0.00218... Test loss: 0.00286\n",
      "Epoch: 1... Training loss: 0.00219... Test loss: 0.00239\n",
      "Epoch: 1... Training loss: 0.00211... Test loss: 0.00271\n",
      "Epoch: 1... Training loss: 0.00217... Test loss: 0.00224\n",
      "Epoch: 1... Training loss: 0.00195... Test loss: 0.00257\n",
      "Epoch: 1... Training loss: 0.00194... Test loss: 0.00204\n",
      "Epoch: 1... Training loss: 0.00191... Test loss: 0.00255\n",
      "Epoch: 1... Training loss: 0.00179... Test loss: 0.0023\n",
      "Epoch: 1... Training loss: 0.00175... Test loss: 0.00244\n",
      "Epoch: 1... Training loss: 0.00164... Test loss: 0.00192\n",
      "Epoch: 1... Training loss: 0.00162... Test loss: 0.00219\n",
      "Epoch: 1... Training loss: 0.00158... Test loss: 0.00185\n",
      "Epoch: 1... Training loss: 0.00152... Test loss: 0.00156\n",
      "Epoch: 1... Training loss: 0.00143... Test loss: 0.00174\n",
      "Epoch: 1... Training loss: 0.00149... Test loss: 0.00187\n",
      "Epoch: 1... Training loss: 0.0013... Test loss: 0.00164\n",
      "Epoch: 1... Training loss: 0.00133... Test loss: 0.00219\n",
      "Epoch: 1... Training loss: 0.00123... Test loss: 0.00149\n",
      "Epoch: 1... Training loss: 0.00119... Test loss: 0.00152\n",
      "Epoch: 1... Training loss: 0.00107... Test loss: 0.00124\n",
      "Epoch: 1... Training loss: 0.0011... Test loss: 0.00126\n",
      "Epoch: 1... Training loss: 0.00099... Test loss: 0.0011\n",
      "Epoch: 1... Training loss: 0.00095... Test loss: 0.00117\n",
      "Epoch: 1... Training loss: 0.00094... Test loss: 0.00111\n",
      "Epoch: 1... Training loss: 0.0009... Test loss: 0.00078\n",
      "Epoch: 1... Training loss: 0.00081... Test loss: 0.00111\n",
      "Epoch: 1... Training loss: 0.0008... Test loss: 0.00075\n",
      "Epoch: 1... Training loss: 0.00071... Test loss: 0.00096\n",
      "Epoch: 1... Training loss: 0.00068... Test loss: 0.00059\n",
      "Epoch: 1... Training loss: 0.00065... Test loss: 0.0008\n",
      "Epoch: 1... Training loss: 0.00065... Test loss: 0.00081\n",
      "Epoch: 1... Training loss: 0.00061... Test loss: 0.00084\n",
      "Epoch: 1... Training loss: 0.00062... Test loss: 0.00068\n",
      "Epoch: 1... Training loss: 0.00057... Test loss: 0.0007\n",
      "Epoch: 1... Training loss: 0.00053... Test loss: 0.0007\n",
      "Epoch: 1... Training loss: 0.00052... Test loss: 0.00065\n",
      "Epoch: 1... Training loss: 0.0005... Test loss: 0.00069\n",
      "Epoch: 1... Training loss: 0.00047... Test loss: 0.00055\n",
      "Epoch: 1... Training loss: 0.00044... Test loss: 0.00064\n",
      "Epoch: 1... Training loss: 0.00046... Test loss: 0.00046\n",
      "Epoch: 1... Training loss: 0.00046... Test loss: 0.00046\n",
      "Epoch: 1... Training loss: 0.0004... Test loss: 0.00036\n",
      "Epoch: 1... Training loss: 0.00038... Test loss: 0.00054\n",
      "Epoch: 1... Training loss: 0.00037... Test loss: 0.00035\n",
      "Epoch: 1... Training loss: 0.00043... Test loss: 0.0004\n",
      "Epoch: 1... Training loss: 0.00036... Test loss: 0.00037\n",
      "Epoch: 1... Training loss: 0.00037... Test loss: 0.00036\n",
      "Epoch: 1... Training loss: 0.00035... Test loss: 0.00031\n",
      "Epoch: 1... Training loss: 0.00036... Test loss: 0.00034\n",
      "Epoch: 1... Training loss: 0.00034... Test loss: 0.00033\n",
      "Epoch: 1... Training loss: 0.00034... Test loss: 0.00035\n",
      "Epoch: 1... Training loss: 0.00031... Test loss: 0.00028\n",
      "Epoch: 1... Training loss: 0.00033... Test loss: 0.00038\n",
      "Epoch: 1... Training loss: 0.00032... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.00033... Test loss: 0.00036\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00029... Test loss: 0.0003\n",
      "Epoch: 1... Training loss: 0.00026... Test loss: 0.00032\n",
      "Epoch: 1... Training loss: 0.00032... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.00026... Test loss: 0.00028\n",
      "Epoch: 1... Training loss: 0.00031... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.00026... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00024\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.00024\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00011\n",
      "226.38958698697388\n",
      "Epoch: 1... Training loss: 1.05637... Test loss: 0.48626\n",
      "Epoch: 1... Training loss: 0.52518... Test loss: 0.20979\n",
      "Epoch: 1... Training loss: 0.29332... Test loss: 0.13426\n",
      "Epoch: 1... Training loss: 0.23416... Test loss: 0.07471\n",
      "Epoch: 1... Training loss: 0.17165... Test loss: 0.07894\n",
      "Epoch: 1... Training loss: 0.13261... Test loss: 0.04628\n",
      "Epoch: 1... Training loss: 0.10269... Test loss: 0.03992\n",
      "Epoch: 1... Training loss: 0.09175... Test loss: 0.0248\n",
      "Epoch: 1... Training loss: 0.07731... Test loss: 0.02711\n",
      "Epoch: 1... Training loss: 0.07115... Test loss: 0.0324\n",
      "Epoch: 1... Training loss: 0.06049... Test loss: 0.02923\n",
      "Epoch: 1... Training loss: 0.05624... Test loss: 0.02857\n",
      "Epoch: 1... Training loss: 0.04916... Test loss: 0.0358\n",
      "Epoch: 1... Training loss: 0.04441... Test loss: 0.02277\n",
      "Epoch: 1... Training loss: 0.04173... Test loss: 0.04191\n",
      "Epoch: 1... Training loss: 0.03737... Test loss: 0.02199\n",
      "Epoch: 1... Training loss: 0.03418... Test loss: 0.038\n",
      "Epoch: 1... Training loss: 0.03203... Test loss: 0.02585\n",
      "Epoch: 1... Training loss: 0.03137... Test loss: 0.02699\n",
      "Epoch: 1... Training loss: 0.0279... Test loss: 0.03847\n",
      "Epoch: 1... Training loss: 0.02693... Test loss: 0.02135\n",
      "Epoch: 1... Training loss: 0.02527... Test loss: 0.03797\n",
      "Epoch: 1... Training loss: 0.02378... Test loss: 0.02146\n",
      "Epoch: 1... Training loss: 0.02249... Test loss: 0.0269\n",
      "Epoch: 1... Training loss: 0.02198... Test loss: 0.02853\n",
      "Epoch: 1... Training loss: 0.02081... Test loss: 0.01838\n",
      "Epoch: 1... Training loss: 0.01998... Test loss: 0.02723\n",
      "Epoch: 1... Training loss: 0.01916... Test loss: 0.01703\n",
      "Epoch: 1... Training loss: 0.01834... Test loss: 0.02507\n",
      "Epoch: 1... Training loss: 0.01782... Test loss: 0.01816\n",
      "Epoch: 1... Training loss: 0.01713... Test loss: 0.02161\n",
      "Epoch: 1... Training loss: 0.01651... Test loss: 0.0196\n",
      "Epoch: 1... Training loss: 0.01576... Test loss: 0.01939\n",
      "Epoch: 1... Training loss: 0.01493... Test loss: 0.02181\n",
      "Epoch: 1... Training loss: 0.01473... Test loss: 0.01446\n",
      "Epoch: 1... Training loss: 0.01393... Test loss: 0.02028\n",
      "Epoch: 1... Training loss: 0.01359... Test loss: 0.0128\n",
      "Epoch: 1... Training loss: 0.01283... Test loss: 0.01764\n",
      "Epoch: 1... Training loss: 0.01259... Test loss: 0.01125\n",
      "Epoch: 1... Training loss: 0.01192... Test loss: 0.01428\n",
      "Epoch: 1... Training loss: 0.01158... Test loss: 0.01136\n",
      "Epoch: 1... Training loss: 0.0109... Test loss: 0.01241\n",
      "Epoch: 1... Training loss: 0.01061... Test loss: 0.01218\n",
      "Epoch: 1... Training loss: 0.01026... Test loss: 0.01125\n",
      "Epoch: 1... Training loss: 0.00987... Test loss: 0.01251\n",
      "Epoch: 1... Training loss: 0.00943... Test loss: 0.01075\n",
      "Epoch: 1... Training loss: 0.009... Test loss: 0.0117\n",
      "Epoch: 1... Training loss: 0.00867... Test loss: 0.00958\n",
      "Epoch: 1... Training loss: 0.00828... Test loss: 0.01048\n",
      "Epoch: 1... Training loss: 0.00819... Test loss: 0.00907\n",
      "Epoch: 1... Training loss: 0.00793... Test loss: 0.00943\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1... Training loss: 0.00758... Test loss: 0.00804\n",
      "Epoch: 1... Training loss: 0.00732... Test loss: 0.00832\n",
      "Epoch: 1... Training loss: 0.0071... Test loss: 0.00739\n",
      "Epoch: 1... Training loss: 0.00684... Test loss: 0.00786\n",
      "Epoch: 1... Training loss: 0.00658... Test loss: 0.00784\n",
      "Epoch: 1... Training loss: 0.0064... Test loss: 0.00684\n",
      "Epoch: 1... Training loss: 0.00629... Test loss: 0.00728\n",
      "Epoch: 1... Training loss: 0.00598... Test loss: 0.00588\n",
      "Epoch: 1... Training loss: 0.00594... Test loss: 0.00739\n",
      "Epoch: 1... Training loss: 0.0058... Test loss: 0.00631\n",
      "Epoch: 1... Training loss: 0.00563... Test loss: 0.00761\n",
      "Epoch: 1... Training loss: 0.00541... Test loss: 0.00563\n",
      "Epoch: 1... Training loss: 0.00529... Test loss: 0.00706\n",
      "Epoch: 1... Training loss: 0.00828... Test loss: 0.0077\n",
      "Epoch: 1... Training loss: 0.00837... Test loss: 0.01483\n",
      "Epoch: 1... Training loss: 0.00983... Test loss: 0.01302\n",
      "Epoch: 1... Training loss: 0.01105... Test loss: 0.0108\n",
      "Epoch: 1... Training loss: 0.0083... Test loss: 0.0132\n",
      "Epoch: 1... Training loss: 0.00976... Test loss: 0.01374\n",
      "Epoch: 1... Training loss: 0.00924... Test loss: 0.01221\n",
      "Epoch: 1... Training loss: 0.00751... Test loss: 0.01524\n",
      "Epoch: 1... Training loss: 0.00732... Test loss: 0.00931\n",
      "Epoch: 1... Training loss: 0.00763... Test loss: 0.0125\n",
      "Epoch: 1... Training loss: 0.00721... Test loss: 0.0113\n",
      "Epoch: 1... Training loss: 0.00739... Test loss: 0.00996\n",
      "Epoch: 1... Training loss: 0.00761... Test loss: 0.01158\n",
      "Epoch: 1... Training loss: 0.00652... Test loss: 0.01065\n",
      "Epoch: 1... Training loss: 0.00618... Test loss: 0.00763\n",
      "Epoch: 1... Training loss: 0.00621... Test loss: 0.00925\n",
      "Epoch: 1... Training loss: 0.00576... Test loss: 0.00682\n",
      "Epoch: 1... Training loss: 0.00566... Test loss: 0.00827\n",
      "Epoch: 1... Training loss: 0.00518... Test loss: 0.00683\n",
      "Epoch: 1... Training loss: 0.00517... Test loss: 0.00965\n",
      "Epoch: 1... Training loss: 0.00475... Test loss: 0.00599\n",
      "Epoch: 1... Training loss: 0.0047... Test loss: 0.00804\n",
      "Epoch: 1... Training loss: 0.00472... Test loss: 0.00513\n",
      "Epoch: 1... Training loss: 0.00427... Test loss: 0.00665\n",
      "Epoch: 1... Training loss: 0.00428... Test loss: 0.0046\n",
      "Epoch: 1... Training loss: 0.00406... Test loss: 0.00595\n",
      "Epoch: 1... Training loss: 0.00387... Test loss: 0.00424\n",
      "Epoch: 1... Training loss: 0.0037... Test loss: 0.0057\n",
      "Epoch: 1... Training loss: 0.0038... Test loss: 0.00352\n",
      "Epoch: 1... Training loss: 0.00358... Test loss: 0.00552\n",
      "Epoch: 1... Training loss: 0.00336... Test loss: 0.00374\n",
      "Epoch: 1... Training loss: 0.00326... Test loss: 0.00406\n",
      "Epoch: 1... Training loss: 0.00314... Test loss: 0.00314\n",
      "Epoch: 1... Training loss: 0.00313... Test loss: 0.00406\n",
      "Epoch: 1... Training loss: 0.00298... Test loss: 0.00289\n",
      "Epoch: 1... Training loss: 0.00293... Test loss: 0.00347\n",
      "Epoch: 1... Training loss: 0.00279... Test loss: 0.00352\n",
      "Epoch: 1... Training loss: 0.00264... Test loss: 0.0031\n",
      "Epoch: 1... Training loss: 0.00259... Test loss: 0.00337\n",
      "Epoch: 1... Training loss: 0.00255... Test loss: 0.00276\n",
      "Epoch: 1... Training loss: 0.0025... Test loss: 0.00352\n",
      "Epoch: 1... Training loss: 0.00248... Test loss: 0.003\n",
      "Epoch: 1... Training loss: 0.00234... Test loss: 0.0031\n",
      "Epoch: 1... Training loss: 0.00236... Test loss: 0.00267\n",
      "Epoch: 1... Training loss: 0.00216... Test loss: 0.00305\n",
      "Epoch: 1... Training loss: 0.00212... Test loss: 0.00269\n",
      "Epoch: 1... Training loss: 0.00203... Test loss: 0.00288\n",
      "Epoch: 1... Training loss: 0.0019... Test loss: 0.00232\n",
      "Epoch: 1... Training loss: 0.00191... Test loss: 0.00349\n",
      "Epoch: 1... Training loss: 0.00181... Test loss: 0.00218\n",
      "Epoch: 1... Training loss: 0.00175... Test loss: 0.00257\n",
      "Epoch: 1... Training loss: 0.00173... Test loss: 0.00173\n",
      "Epoch: 1... Training loss: 0.00161... Test loss: 0.00216\n",
      "Epoch: 1... Training loss: 0.00163... Test loss: 0.00163\n",
      "Epoch: 1... Training loss: 0.00146... Test loss: 0.00229\n",
      "Epoch: 1... Training loss: 0.00144... Test loss: 0.00146\n",
      "Epoch: 1... Training loss: 0.00136... Test loss: 0.00173\n",
      "Epoch: 1... Training loss: 0.00134... Test loss: 0.00165\n",
      "Epoch: 1... Training loss: 0.00132... Test loss: 0.00152\n",
      "Epoch: 1... Training loss: 0.00128... Test loss: 0.00195\n",
      "Epoch: 1... Training loss: 0.00123... Test loss: 0.00159\n",
      "Epoch: 1... Training loss: 0.00114... Test loss: 0.00161\n",
      "Epoch: 1... Training loss: 0.00118... Test loss: 0.00132\n",
      "Epoch: 1... Training loss: 0.00102... Test loss: 0.00132\n",
      "Epoch: 1... Training loss: 0.00106... Test loss: 0.00128\n",
      "Epoch: 1... Training loss: 0.00101... Test loss: 0.0013\n",
      "Epoch: 1... Training loss: 0.00093... Test loss: 0.001\n",
      "Epoch: 1... Training loss: 0.00093... Test loss: 0.00108\n",
      "Epoch: 1... Training loss: 0.00091... Test loss: 0.00109\n",
      "Epoch: 1... Training loss: 0.00083... Test loss: 0.0012\n",
      "Epoch: 1... Training loss: 0.00081... Test loss: 0.00104\n",
      "Epoch: 1... Training loss: 0.00079... Test loss: 0.00095\n",
      "Epoch: 1... Training loss: 0.00076... Test loss: 0.00089\n",
      "Epoch: 1... Training loss: 0.00072... Test loss: 0.00079\n",
      "Epoch: 1... Training loss: 0.00074... Test loss: 0.00086\n",
      "Epoch: 1... Training loss: 0.00065... Test loss: 0.00058\n",
      "Epoch: 1... Training loss: 0.0006... Test loss: 0.00074\n",
      "Epoch: 1... Training loss: 0.00064... Test loss: 0.00062\n",
      "Epoch: 1... Training loss: 0.00054... Test loss: 0.00054\n",
      "Epoch: 1... Training loss: 0.00057... Test loss: 0.0006\n",
      "Epoch: 1... Training loss: 0.00055... Test loss: 0.0005\n",
      "Epoch: 1... Training loss: 0.00053... Test loss: 0.00058\n",
      "Epoch: 1... Training loss: 0.00053... Test loss: 0.0006\n",
      "Epoch: 1... Training loss: 0.00053... Test loss: 0.00061\n",
      "Epoch: 1... Training loss: 0.00055... Test loss: 0.00057\n",
      "Epoch: 1... Training loss: 0.00046... Test loss: 0.00041\n",
      "Epoch: 1... Training loss: 0.0004... Test loss: 0.00051\n",
      "Epoch: 1... Training loss: 0.00043... Test loss: 0.00039\n",
      "Epoch: 1... Training loss: 0.0004... Test loss: 0.0005\n",
      "Epoch: 1... Training loss: 0.00041... Test loss: 0.00031\n",
      "Epoch: 1... Training loss: 0.00041... Test loss: 0.0004\n",
      "Epoch: 1... Training loss: 0.00039... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00034... Test loss: 0.00037\n",
      "Epoch: 1... Training loss: 0.00034... Test loss: 0.00034\n",
      "Epoch: 1... Training loss: 0.00035... Test loss: 0.00035\n",
      "Epoch: 1... Training loss: 0.00034... Test loss: 0.00035\n",
      "Epoch: 1... Training loss: 0.00035... Test loss: 0.00032\n",
      "Epoch: 1... Training loss: 0.00032... Test loss: 0.00033\n",
      "Epoch: 1... Training loss: 0.00038... Test loss: 0.00039\n",
      "Epoch: 1... Training loss: 0.00033... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.00029... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00026... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00031\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.00034... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 7e-05\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 8e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 7e-05\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 0.0001\n",
      "235.537767225469\n",
      "Epoch: 1... Training loss: 1.2775... Test loss: 0.61669\n",
      "Epoch: 1... Training loss: 0.58653... Test loss: 0.24572\n",
      "Epoch: 1... Training loss: 0.31444... Test loss: 0.1306\n",
      "Epoch: 1... Training loss: 0.20016... Test loss: 0.07945\n",
      "Epoch: 1... Training loss: 0.15583... Test loss: 0.06449\n",
      "Epoch: 1... Training loss: 0.11395... Test loss: 0.04329\n",
      "Epoch: 1... Training loss: 0.0977... Test loss: 0.05884\n",
      "Epoch: 1... Training loss: 0.08821... Test loss: 0.02922\n",
      "Epoch: 1... Training loss: 0.07264... Test loss: 0.0363\n",
      "Epoch: 1... Training loss: 0.06247... Test loss: 0.02205\n",
      "Epoch: 1... Training loss: 0.05614... Test loss: 0.03584\n",
      "Epoch: 1... Training loss: 0.05711... Test loss: 0.02103\n",
      "Epoch: 1... Training loss: 0.04792... Test loss: 0.02569\n",
      "Epoch: 1... Training loss: 0.04431... Test loss: 0.02361\n",
      "Epoch: 1... Training loss: 0.04037... Test loss: 0.01296\n",
      "Epoch: 1... Training loss: 0.03607... Test loss: 0.02534\n",
      "Epoch: 1... Training loss: 0.03389... Test loss: 0.0131\n",
      "Epoch: 1... Training loss: 0.03177... Test loss: 0.02672\n",
      "Epoch: 1... Training loss: 0.02993... Test loss: 0.01382\n",
      "Epoch: 1... Training loss: 0.0287... Test loss: 0.02372\n",
      "Epoch: 1... Training loss: 0.02718... Test loss: 0.01671\n",
      "Epoch: 1... Training loss: 0.02627... Test loss: 0.02028\n",
      "Epoch: 1... Training loss: 0.02498... Test loss: 0.02358\n",
      "Epoch: 1... Training loss: 0.02332... Test loss: 0.01676\n",
      "Epoch: 1... Training loss: 0.02238... Test loss: 0.02406\n",
      "Epoch: 1... Training loss: 0.02147... Test loss: 0.01618\n",
      "Epoch: 1... Training loss: 0.02066... Test loss: 0.02275\n",
      "Epoch: 1... Training loss: 0.01998... Test loss: 0.01536\n",
      "Epoch: 1... Training loss: 0.01909... Test loss: 0.02163\n",
      "Epoch: 1... Training loss: 0.01846... Test loss: 0.01469\n",
      "Epoch: 1... Training loss: 0.01748... Test loss: 0.02103\n",
      "Epoch: 1... Training loss: 0.01723... Test loss: 0.01572\n",
      "Epoch: 1... Training loss: 0.01625... Test loss: 0.01677\n",
      "Epoch: 1... Training loss: 0.01575... Test loss: 0.01619\n",
      "Epoch: 1... Training loss: 0.01495... Test loss: 0.01583\n",
      "Epoch: 1... Training loss: 0.01456... Test loss: 0.01411\n",
      "Epoch: 1... Training loss: 0.01431... Test loss: 0.01535\n",
      "Epoch: 1... Training loss: 0.01343... Test loss: 0.013\n",
      "Epoch: 1... Training loss: 0.01292... Test loss: 0.01312\n",
      "Epoch: 1... Training loss: 0.01255... Test loss: 0.0125\n",
      "Epoch: 1... Training loss: 0.01212... Test loss: 0.0128\n",
      "Epoch: 1... Training loss: 0.01168... Test loss: 0.00999\n",
      "Epoch: 1... Training loss: 0.01145... Test loss: 0.01275\n",
      "Epoch: 1... Training loss: 0.01113... Test loss: 0.00885\n",
      "Epoch: 1... Training loss: 0.01076... Test loss: 0.01199\n",
      "Epoch: 1... Training loss: 0.01045... Test loss: 0.0092\n",
      "Epoch: 1... Training loss: 0.01021... Test loss: 0.01142\n",
      "Epoch: 1... Training loss: 0.00998... Test loss: 0.00819\n",
      "Epoch: 1... Training loss: 0.00961... Test loss: 0.01043\n",
      "Epoch: 1... Training loss: 0.0092... Test loss: 0.0068\n",
      "Epoch: 1... Training loss: 0.0089... Test loss: 0.00911\n",
      "Epoch: 1... Training loss: 0.00857... Test loss: 0.00731\n",
      "Epoch: 1... Training loss: 0.00832... Test loss: 0.0091\n",
      "Epoch: 1... Training loss: 0.00816... Test loss: 0.00678\n",
      "Epoch: 1... Training loss: 0.00781... Test loss: 0.00795\n",
      "Epoch: 1... Training loss: 0.00771... Test loss: 0.00739\n",
      "Epoch: 1... Training loss: 0.00738... Test loss: 0.00751\n",
      "Epoch: 1... Training loss: 0.00703... Test loss: 0.00747\n",
      "Epoch: 1... Training loss: 0.00681... Test loss: 0.00713\n",
      "Epoch: 1... Training loss: 0.00654... Test loss: 0.00742\n",
      "Epoch: 1... Training loss: 0.0063... Test loss: 0.00578\n",
      "Epoch: 1... Training loss: 0.00605... Test loss: 0.00629\n",
      "Epoch: 1... Training loss: 0.00594... Test loss: 0.00641\n",
      "Epoch: 1... Training loss: 0.00568... Test loss: 0.00584\n",
      "Epoch: 1... Training loss: 0.01214... Test loss: 0.02364\n",
      "Epoch: 1... Training loss: 0.01009... Test loss: 0.01302\n",
      "Epoch: 1... Training loss: 0.00994... Test loss: 0.0162\n",
      "Epoch: 1... Training loss: 0.00973... Test loss: 0.01079\n",
      "Epoch: 1... Training loss: 0.01065... Test loss: 0.0141\n",
      "Epoch: 1... Training loss: 0.01067... Test loss: 0.00908\n",
      "Epoch: 1... Training loss: 0.00968... Test loss: 0.0173\n",
      "Epoch: 1... Training loss: 0.00904... Test loss: 0.01132\n",
      "Epoch: 1... Training loss: 0.00855... Test loss: 0.01327\n",
      "Epoch: 1... Training loss: 0.00774... Test loss: 0.01442\n",
      "Epoch: 1... Training loss: 0.00852... Test loss: 0.01089\n",
      "Epoch: 1... Training loss: 0.00787... Test loss: 0.01222\n",
      "Epoch: 1... Training loss: 0.00731... Test loss: 0.00907\n",
      "Epoch: 1... Training loss: 0.00761... Test loss: 0.00943\n",
      "Epoch: 1... Training loss: 0.00675... Test loss: 0.00882\n",
      "Epoch: 1... Training loss: 0.00625... Test loss: 0.0096\n",
      "Epoch: 1... Training loss: 0.00618... Test loss: 0.00786\n",
      "Epoch: 1... Training loss: 0.00593... Test loss: 0.0061\n",
      "Epoch: 1... Training loss: 0.00569... Test loss: 0.00916\n",
      "Epoch: 1... Training loss: 0.00523... Test loss: 0.00809\n",
      "Epoch: 1... Training loss: 0.00554... Test loss: 0.00661\n",
      "Epoch: 1... Training loss: 0.00508... Test loss: 0.00679\n",
      "Epoch: 1... Training loss: 0.00534... Test loss: 0.00658\n",
      "Epoch: 1... Training loss: 0.00495... Test loss: 0.0072\n",
      "Epoch: 1... Training loss: 0.0049... Test loss: 0.00645\n",
      "Epoch: 1... Training loss: 0.00443... Test loss: 0.00672\n",
      "Epoch: 1... Training loss: 0.00415... Test loss: 0.00587\n",
      "Epoch: 1... Training loss: 0.00427... Test loss: 0.00546\n",
      "Epoch: 1... Training loss: 0.00412... Test loss: 0.00602\n",
      "Epoch: 1... Training loss: 0.00381... Test loss: 0.00457\n",
      "Epoch: 1... Training loss: 0.00374... Test loss: 0.00525\n",
      "Epoch: 1... Training loss: 0.00362... Test loss: 0.00385\n",
      "Epoch: 1... Training loss: 0.00357... Test loss: 0.0051\n",
      "Epoch: 1... Training loss: 0.00345... Test loss: 0.00397\n",
      "Epoch: 1... Training loss: 0.0032... Test loss: 0.00362\n",
      "Epoch: 1... Training loss: 0.00326... Test loss: 0.00327\n",
      "Epoch: 1... Training loss: 0.00303... Test loss: 0.0043\n",
      "Epoch: 1... Training loss: 0.00306... Test loss: 0.00327\n",
      "Epoch: 1... Training loss: 0.00288... Test loss: 0.00309\n",
      "Epoch: 1... Training loss: 0.00284... Test loss: 0.00312\n",
      "Epoch: 1... Training loss: 0.00272... Test loss: 0.00363\n",
      "Epoch: 1... Training loss: 0.00259... Test loss: 0.00301\n",
      "Epoch: 1... Training loss: 0.00244... Test loss: 0.0032\n",
      "Epoch: 1... Training loss: 0.00249... Test loss: 0.00303\n",
      "Epoch: 1... Training loss: 0.00229... Test loss: 0.00307\n",
      "Epoch: 1... Training loss: 0.00227... Test loss: 0.00245\n",
      "Epoch: 1... Training loss: 0.00218... Test loss: 0.00258\n",
      "Epoch: 1... Training loss: 0.00211... Test loss: 0.00247\n",
      "Epoch: 1... Training loss: 0.00212... Test loss: 0.00254\n",
      "Epoch: 1... Training loss: 0.00195... Test loss: 0.00256\n",
      "Epoch: 1... Training loss: 0.00186... Test loss: 0.00243\n",
      "Epoch: 1... Training loss: 0.00187... Test loss: 0.00265\n",
      "Epoch: 1... Training loss: 0.00168... Test loss: 0.00239\n",
      "Epoch: 1... Training loss: 0.00161... Test loss: 0.00223\n",
      "Epoch: 1... Training loss: 0.00158... Test loss: 0.00187\n",
      "Epoch: 1... Training loss: 0.00148... Test loss: 0.00197\n",
      "Epoch: 1... Training loss: 0.00142... Test loss: 0.0018\n",
      "Epoch: 1... Training loss: 0.00143... Test loss: 0.00184\n",
      "Epoch: 1... Training loss: 0.00135... Test loss: 0.00168\n",
      "Epoch: 1... Training loss: 0.00127... Test loss: 0.00135\n",
      "Epoch: 1... Training loss: 0.00129... Test loss: 0.00151\n",
      "Epoch: 1... Training loss: 0.00114... Test loss: 0.00117\n",
      "Epoch: 1... Training loss: 0.00113... Test loss: 0.00183\n",
      "Epoch: 1... Training loss: 0.00107... Test loss: 0.00115\n",
      "Epoch: 1... Training loss: 0.00101... Test loss: 0.00186\n",
      "Epoch: 1... Training loss: 0.001... Test loss: 0.00117\n",
      "Epoch: 1... Training loss: 0.00092... Test loss: 0.00151\n",
      "Epoch: 1... Training loss: 0.0009... Test loss: 0.00095\n",
      "Epoch: 1... Training loss: 0.00083... Test loss: 0.0012\n",
      "Epoch: 1... Training loss: 0.00085... Test loss: 0.00096\n",
      "Epoch: 1... Training loss: 0.00078... Test loss: 0.00103\n",
      "Epoch: 1... Training loss: 0.0008... Test loss: 0.00073\n",
      "Epoch: 1... Training loss: 0.00077... Test loss: 0.00094\n",
      "Epoch: 1... Training loss: 0.00078... Test loss: 0.0008\n",
      "Epoch: 1... Training loss: 0.0007... Test loss: 0.00101\n",
      "Epoch: 1... Training loss: 0.00068... Test loss: 0.00062\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1... Training loss: 0.00064... Test loss: 0.0009\n",
      "Epoch: 1... Training loss: 0.00061... Test loss: 0.00058\n",
      "Epoch: 1... Training loss: 0.00057... Test loss: 0.00074\n",
      "Epoch: 1... Training loss: 0.00056... Test loss: 0.00055\n",
      "Epoch: 1... Training loss: 0.00057... Test loss: 0.00062\n",
      "Epoch: 1... Training loss: 0.0005... Test loss: 0.00052\n",
      "Epoch: 1... Training loss: 0.00047... Test loss: 0.00056\n",
      "Epoch: 1... Training loss: 0.0005... Test loss: 0.00063\n",
      "Epoch: 1... Training loss: 0.00046... Test loss: 0.00043\n",
      "Epoch: 1... Training loss: 0.00042... Test loss: 0.00052\n",
      "Epoch: 1... Training loss: 0.0004... Test loss: 0.00041\n",
      "Epoch: 1... Training loss: 0.00038... Test loss: 0.00049\n",
      "Epoch: 1... Training loss: 0.00042... Test loss: 0.00037\n",
      "Epoch: 1... Training loss: 0.00034... Test loss: 0.00044\n",
      "Epoch: 1... Training loss: 0.00033... Test loss: 0.00028\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.00042\n",
      "Epoch: 1... Training loss: 0.00029... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00039\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00029... Test loss: 0.00031\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.00031\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00028\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00024\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00026... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 8e-05\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.0001\n",
      "237.99022854142822\n",
      "Epoch: 1... Training loss: 1.17506... Test loss: 0.48372\n",
      "Epoch: 1... Training loss: 0.55203... Test loss: 0.20938\n",
      "Epoch: 1... Training loss: 0.29517... Test loss: 0.09989\n",
      "Epoch: 1... Training loss: 0.21272... Test loss: 0.06106\n",
      "Epoch: 1... Training loss: 0.16885... Test loss: 0.06894\n",
      "Epoch: 1... Training loss: 0.12389... Test loss: 0.06561\n",
      "Epoch: 1... Training loss: 0.09064... Test loss: 0.06064\n",
      "Epoch: 1... Training loss: 0.07574... Test loss: 0.06012\n",
      "Epoch: 1... Training loss: 0.05997... Test loss: 0.05791\n",
      "Epoch: 1... Training loss: 0.05407... Test loss: 0.03305\n",
      "Epoch: 1... Training loss: 0.04803... Test loss: 0.07241\n",
      "Epoch: 1... Training loss: 0.04981... Test loss: 0.02817\n",
      "Epoch: 1... Training loss: 0.04034... Test loss: 0.05778\n",
      "Epoch: 1... Training loss: 0.04114... Test loss: 0.02233\n",
      "Epoch: 1... Training loss: 0.03476... Test loss: 0.01402\n",
      "Epoch: 1... Training loss: 0.03139... Test loss: 0.02513\n",
      "Epoch: 1... Training loss: 0.03002... Test loss: 0.00834\n",
      "Epoch: 1... Training loss: 0.02692... Test loss: 0.02212\n",
      "Epoch: 1... Training loss: 0.02683... Test loss: 0.02397\n",
      "Epoch: 1... Training loss: 0.02431... Test loss: 0.01621\n",
      "Epoch: 1... Training loss: 0.02379... Test loss: 0.01518\n",
      "Epoch: 1... Training loss: 0.02211... Test loss: 0.01988\n",
      "Epoch: 1... Training loss: 0.02117... Test loss: 0.01451\n",
      "Epoch: 1... Training loss: 0.01946... Test loss: 0.01661\n",
      "Epoch: 1... Training loss: 0.01886... Test loss: 0.01188\n",
      "Epoch: 1... Training loss: 0.01767... Test loss: 0.01529\n",
      "Epoch: 1... Training loss: 0.01694... Test loss: 0.01047\n",
      "Epoch: 1... Training loss: 0.01615... Test loss: 0.01318\n",
      "Epoch: 1... Training loss: 0.01584... Test loss: 0.01121\n",
      "Epoch: 1... Training loss: 0.01514... Test loss: 0.01154\n",
      "Epoch: 1... Training loss: 0.01492... Test loss: 0.01414\n",
      "Epoch: 1... Training loss: 0.01433... Test loss: 0.00875\n",
      "Epoch: 1... Training loss: 0.01374... Test loss: 0.01418\n",
      "Epoch: 1... Training loss: 0.01313... Test loss: 0.01215\n",
      "Epoch: 1... Training loss: 0.01268... Test loss: 0.00802\n",
      "Epoch: 1... Training loss: 0.01207... Test loss: 0.01267\n",
      "Epoch: 1... Training loss: 0.01139... Test loss: 0.00985\n",
      "Epoch: 1... Training loss: 0.01114... Test loss: 0.01328\n",
      "Epoch: 1... Training loss: 0.01075... Test loss: 0.00789\n",
      "Epoch: 1... Training loss: 0.01039... Test loss: 0.01164\n",
      "Epoch: 1... Training loss: 0.00991... Test loss: 0.00742\n",
      "Epoch: 1... Training loss: 0.00948... Test loss: 0.01078\n",
      "Epoch: 1... Training loss: 0.00925... Test loss: 0.00675\n",
      "Epoch: 1... Training loss: 0.00909... Test loss: 0.00917\n",
      "Epoch: 1... Training loss: 0.00867... Test loss: 0.00726\n",
      "Epoch: 1... Training loss: 0.00848... Test loss: 0.00641\n",
      "Epoch: 1... Training loss: 0.00812... Test loss: 0.00819\n",
      "Epoch: 1... Training loss: 0.00781... Test loss: 0.00583\n",
      "Epoch: 1... Training loss: 0.00763... Test loss: 0.00768\n",
      "Epoch: 1... Training loss: 0.00732... Test loss: 0.00481\n",
      "Epoch: 1... Training loss: 0.00712... Test loss: 0.00789\n",
      "Epoch: 1... Training loss: 0.00688... Test loss: 0.00525\n",
      "Epoch: 1... Training loss: 0.00662... Test loss: 0.00702\n",
      "Epoch: 1... Training loss: 0.00632... Test loss: 0.00599\n",
      "Epoch: 1... Training loss: 0.0062... Test loss: 0.00623\n",
      "Epoch: 1... Training loss: 0.00607... Test loss: 0.00622\n",
      "Epoch: 1... Training loss: 0.00589... Test loss: 0.00513\n",
      "Epoch: 1... Training loss: 0.00564... Test loss: 0.00623\n",
      "Epoch: 1... Training loss: 0.0055... Test loss: 0.00528\n",
      "Epoch: 1... Training loss: 0.00526... Test loss: 0.00594\n",
      "Epoch: 1... Training loss: 0.0052... Test loss: 0.00675\n",
      "Epoch: 1... Training loss: 0.00497... Test loss: 0.00539\n",
      "Epoch: 1... Training loss: 0.00486... Test loss: 0.00577\n",
      "Epoch: 1... Training loss: 0.00479... Test loss: 0.00504\n",
      "Epoch: 1... Training loss: 0.01617... Test loss: 0.01134\n",
      "Epoch: 1... Training loss: 0.00865... Test loss: 0.00954\n",
      "Epoch: 1... Training loss: 0.00956... Test loss: 0.01122\n",
      "Epoch: 1... Training loss: 0.0097... Test loss: 0.01293\n",
      "Epoch: 1... Training loss: 0.00749... Test loss: 0.0173\n",
      "Epoch: 1... Training loss: 0.00825... Test loss: 0.01134\n",
      "Epoch: 1... Training loss: 0.00708... Test loss: 0.01344\n",
      "Epoch: 1... Training loss: 0.00703... Test loss: 0.00811\n",
      "Epoch: 1... Training loss: 0.00663... Test loss: 0.0109\n",
      "Epoch: 1... Training loss: 0.00695... Test loss: 0.00896\n",
      "Epoch: 1... Training loss: 0.00654... Test loss: 0.00848\n",
      "Epoch: 1... Training loss: 0.0063... Test loss: 0.00793\n",
      "Epoch: 1... Training loss: 0.00689... Test loss: 0.0069\n",
      "Epoch: 1... Training loss: 0.00567... Test loss: 0.00701\n",
      "Epoch: 1... Training loss: 0.00526... Test loss: 0.00849\n",
      "Epoch: 1... Training loss: 0.00523... Test loss: 0.00748\n",
      "Epoch: 1... Training loss: 0.0052... Test loss: 0.00669\n",
      "Epoch: 1... Training loss: 0.00533... Test loss: 0.00578\n",
      "Epoch: 1... Training loss: 0.005... Test loss: 0.00606\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1... Training loss: 0.00441... Test loss: 0.0069\n",
      "Epoch: 1... Training loss: 0.005... Test loss: 0.00598\n",
      "Epoch: 1... Training loss: 0.00421... Test loss: 0.00687\n",
      "Epoch: 1... Training loss: 0.00437... Test loss: 0.00578\n",
      "Epoch: 1... Training loss: 0.0043... Test loss: 0.00467\n",
      "Epoch: 1... Training loss: 0.00435... Test loss: 0.00485\n",
      "Epoch: 1... Training loss: 0.00394... Test loss: 0.00476\n",
      "Epoch: 1... Training loss: 0.00364... Test loss: 0.0047\n",
      "Epoch: 1... Training loss: 0.00365... Test loss: 0.00366\n",
      "Epoch: 1... Training loss: 0.00349... Test loss: 0.0049\n",
      "Epoch: 1... Training loss: 0.00332... Test loss: 0.00337\n",
      "Epoch: 1... Training loss: 0.00325... Test loss: 0.00398\n",
      "Epoch: 1... Training loss: 0.00304... Test loss: 0.0035\n",
      "Epoch: 1... Training loss: 0.00314... Test loss: 0.00443\n",
      "Epoch: 1... Training loss: 0.00307... Test loss: 0.00359\n",
      "Epoch: 1... Training loss: 0.00283... Test loss: 0.00346\n",
      "Epoch: 1... Training loss: 0.00283... Test loss: 0.00307\n",
      "Epoch: 1... Training loss: 0.00264... Test loss: 0.00383\n",
      "Epoch: 1... Training loss: 0.00253... Test loss: 0.00299\n",
      "Epoch: 1... Training loss: 0.00252... Test loss: 0.00299\n",
      "Epoch: 1... Training loss: 0.00248... Test loss: 0.00332\n",
      "Epoch: 1... Training loss: 0.00225... Test loss: 0.0024\n",
      "Epoch: 1... Training loss: 0.00222... Test loss: 0.00267\n",
      "Epoch: 1... Training loss: 0.0022... Test loss: 0.00237\n",
      "Epoch: 1... Training loss: 0.00217... Test loss: 0.00196\n",
      "Epoch: 1... Training loss: 0.00215... Test loss: 0.00274\n",
      "Epoch: 1... Training loss: 0.00206... Test loss: 0.00214\n",
      "Epoch: 1... Training loss: 0.00208... Test loss: 0.00266\n",
      "Epoch: 1... Training loss: 0.00202... Test loss: 0.00192\n",
      "Epoch: 1... Training loss: 0.00184... Test loss: 0.00238\n",
      "Epoch: 1... Training loss: 0.00178... Test loss: 0.00199\n",
      "Epoch: 1... Training loss: 0.00172... Test loss: 0.00227\n",
      "Epoch: 1... Training loss: 0.00165... Test loss: 0.0016\n",
      "Epoch: 1... Training loss: 0.00157... Test loss: 0.00236\n",
      "Epoch: 1... Training loss: 0.00155... Test loss: 0.00168\n",
      "Epoch: 1... Training loss: 0.00157... Test loss: 0.00216\n",
      "Epoch: 1... Training loss: 0.00147... Test loss: 0.00142\n",
      "Epoch: 1... Training loss: 0.00141... Test loss: 0.00177\n",
      "Epoch: 1... Training loss: 0.00138... Test loss: 0.00163\n",
      "Epoch: 1... Training loss: 0.00133... Test loss: 0.00127\n",
      "Epoch: 1... Training loss: 0.00128... Test loss: 0.00174\n",
      "Epoch: 1... Training loss: 0.00126... Test loss: 0.00134\n",
      "Epoch: 1... Training loss: 0.00119... Test loss: 0.00155\n",
      "Epoch: 1... Training loss: 0.00116... Test loss: 0.0012\n",
      "Epoch: 1... Training loss: 0.00111... Test loss: 0.00121\n",
      "Epoch: 1... Training loss: 0.00108... Test loss: 0.00102\n",
      "Epoch: 1... Training loss: 0.00098... Test loss: 0.00125\n",
      "Epoch: 1... Training loss: 0.00096... Test loss: 0.0011\n",
      "Epoch: 1... Training loss: 0.00095... Test loss: 0.00103\n",
      "Epoch: 1... Training loss: 0.00096... Test loss: 0.00094\n",
      "Epoch: 1... Training loss: 0.00083... Test loss: 0.00109\n",
      "Epoch: 1... Training loss: 0.00082... Test loss: 0.001\n",
      "Epoch: 1... Training loss: 0.0008... Test loss: 0.00092\n",
      "Epoch: 1... Training loss: 0.00076... Test loss: 0.00081\n",
      "Epoch: 1... Training loss: 0.00078... Test loss: 0.00081\n",
      "Epoch: 1... Training loss: 0.00066... Test loss: 0.00097\n",
      "Epoch: 1... Training loss: 0.00069... Test loss: 0.00087\n",
      "Epoch: 1... Training loss: 0.00061... Test loss: 0.00079\n",
      "Epoch: 1... Training loss: 0.0006... Test loss: 0.00062\n",
      "Epoch: 1... Training loss: 0.00055... Test loss: 0.00061\n",
      "Epoch: 1... Training loss: 0.00052... Test loss: 0.00065\n",
      "Epoch: 1... Training loss: 0.00055... Test loss: 0.00063\n",
      "Epoch: 1... Training loss: 0.00052... Test loss: 0.00051\n",
      "Epoch: 1... Training loss: 0.00053... Test loss: 0.00067\n",
      "Epoch: 1... Training loss: 0.00047... Test loss: 0.00039\n",
      "Epoch: 1... Training loss: 0.00047... Test loss: 0.00071\n",
      "Epoch: 1... Training loss: 0.0004... Test loss: 0.00037\n",
      "Epoch: 1... Training loss: 0.00037... Test loss: 0.00053\n",
      "Epoch: 1... Training loss: 0.00038... Test loss: 0.00038\n",
      "Epoch: 1... Training loss: 0.00036... Test loss: 0.00048\n",
      "Epoch: 1... Training loss: 0.00043... Test loss: 0.00037\n",
      "Epoch: 1... Training loss: 0.00038... Test loss: 0.00035\n",
      "Epoch: 1... Training loss: 0.00034... Test loss: 0.00038\n",
      "Epoch: 1... Training loss: 0.00032... Test loss: 0.00041\n",
      "Epoch: 1... Training loss: 0.00032... Test loss: 0.00031\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.00043\n",
      "Epoch: 1... Training loss: 0.00029... Test loss: 0.00031\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00033\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00032\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00024\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00024\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 8e-05\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 8e-05\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 7e-05\n",
      "Epoch: 1... Training loss: 7e-05... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 7e-05... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 7e-05\n",
      "Epoch: 1... Training loss: 6e-05... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 8e-05\n",
      "Epoch: 1... Training loss: 7e-05... Test loss: 8e-05\n",
      "Epoch: 1... Training loss: 8e-05... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 8e-05... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 8e-05... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 8e-05... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 8e-05\n",
      "Epoch: 1... Training loss: 8e-05... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.0001\n",
      "249.73217641335214\n",
      "Epoch: 1... Training loss: 0.85575... Test loss: 0.22074\n",
      "Epoch: 1... Training loss: 0.41219... Test loss: 0.08377\n",
      "Epoch: 1... Training loss: 0.22714... Test loss: 0.04729\n",
      "Epoch: 1... Training loss: 0.14749... Test loss: 0.02887\n",
      "Epoch: 1... Training loss: 0.11223... Test loss: 0.02174\n",
      "Epoch: 1... Training loss: 0.08018... Test loss: 0.01773\n",
      "Epoch: 1... Training loss: 0.07073... Test loss: 0.0108\n",
      "Epoch: 1... Training loss: 0.06017... Test loss: 0.00827\n",
      "Epoch: 1... Training loss: 0.05219... Test loss: 0.01027\n",
      "Epoch: 1... Training loss: 0.04698... Test loss: 0.006\n",
      "Epoch: 1... Training loss: 0.04133... Test loss: 0.00686\n",
      "Epoch: 1... Training loss: 0.04004... Test loss: 0.00451\n",
      "Epoch: 1... Training loss: 0.0372... Test loss: 0.00889\n",
      "Epoch: 1... Training loss: 0.03407... Test loss: 0.00336\n",
      "Epoch: 1... Training loss: 0.03238... Test loss: 0.00718\n",
      "Epoch: 1... Training loss: 0.02912... Test loss: 0.00261\n",
      "Epoch: 1... Training loss: 0.02834... Test loss: 0.0049\n",
      "Epoch: 1... Training loss: 0.02644... Test loss: 0.00193\n",
      "Epoch: 1... Training loss: 0.02574... Test loss: 0.00887\n",
      "Epoch: 1... Training loss: 0.02407... Test loss: 0.00168\n",
      "Epoch: 1... Training loss: 0.02345... Test loss: 0.00801\n",
      "Epoch: 1... Training loss: 0.02261... Test loss: 0.0027\n",
      "Epoch: 1... Training loss: 0.02169... Test loss: 0.01086\n",
      "Epoch: 1... Training loss: 0.02085... Test loss: 0.00283\n",
      "Epoch: 1... Training loss: 0.01992... Test loss: 0.01193\n",
      "Epoch: 1... Training loss: 0.01869... Test loss: 0.00372\n",
      "Epoch: 1... Training loss: 0.01809... Test loss: 0.01304\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1... Training loss: 0.01738... Test loss: 0.00357\n",
      "Epoch: 1... Training loss: 0.01651... Test loss: 0.01109\n",
      "Epoch: 1... Training loss: 0.01601... Test loss: 0.00698\n",
      "Epoch: 1... Training loss: 0.01584... Test loss: 0.0047\n",
      "Epoch: 1... Training loss: 0.01515... Test loss: 0.01312\n",
      "Epoch: 1... Training loss: 0.01452... Test loss: 0.00441\n",
      "Epoch: 1... Training loss: 0.01428... Test loss: 0.01315\n",
      "Epoch: 1... Training loss: 0.01342... Test loss: 0.00627\n",
      "Epoch: 1... Training loss: 0.01304... Test loss: 0.01277\n",
      "Epoch: 1... Training loss: 0.01253... Test loss: 0.00666\n",
      "Epoch: 1... Training loss: 0.01237... Test loss: 0.01069\n",
      "Epoch: 1... Training loss: 0.01177... Test loss: 0.00651\n",
      "Epoch: 1... Training loss: 0.01142... Test loss: 0.01122\n",
      "Epoch: 1... Training loss: 0.01066... Test loss: 0.00567\n",
      "Epoch: 1... Training loss: 0.01034... Test loss: 0.0128\n",
      "Epoch: 1... Training loss: 0.01... Test loss: 0.00657\n",
      "Epoch: 1... Training loss: 0.00952... Test loss: 0.00991\n",
      "Epoch: 1... Training loss: 0.00894... Test loss: 0.00636\n",
      "Epoch: 1... Training loss: 0.00844... Test loss: 0.01081\n",
      "Epoch: 1... Training loss: 0.00822... Test loss: 0.00607\n",
      "Epoch: 1... Training loss: 0.00805... Test loss: 0.00934\n",
      "Epoch: 1... Training loss: 0.00778... Test loss: 0.00848\n",
      "Epoch: 1... Training loss: 0.0076... Test loss: 0.00734\n",
      "Epoch: 1... Training loss: 0.00745... Test loss: 0.00632\n",
      "Epoch: 1... Training loss: 0.00708... Test loss: 0.00699\n",
      "Epoch: 1... Training loss: 0.00696... Test loss: 0.00588\n",
      "Epoch: 1... Training loss: 0.00667... Test loss: 0.00712\n",
      "Epoch: 1... Training loss: 0.00633... Test loss: 0.00541\n",
      "Epoch: 1... Training loss: 0.00623... Test loss: 0.00791\n",
      "Epoch: 1... Training loss: 0.00609... Test loss: 0.00459\n",
      "Epoch: 1... Training loss: 0.00595... Test loss: 0.0079\n",
      "Epoch: 1... Training loss: 0.00581... Test loss: 0.00474\n",
      "Epoch: 1... Training loss: 0.0056... Test loss: 0.00735\n",
      "Epoch: 1... Training loss: 0.00544... Test loss: 0.00545\n",
      "Epoch: 1... Training loss: 0.00528... Test loss: 0.00557\n",
      "Epoch: 1... Training loss: 0.00507... Test loss: 0.00491\n",
      "Epoch: 1... Training loss: 0.00487... Test loss: 0.00508\n",
      "Epoch: 1... Training loss: 0.00806... Test loss: 0.01118\n",
      "Epoch: 1... Training loss: 0.0083... Test loss: 0.0092\n",
      "Epoch: 1... Training loss: 0.00812... Test loss: 0.01225\n",
      "Epoch: 1... Training loss: 0.00828... Test loss: 0.00812\n",
      "Epoch: 1... Training loss: 0.00772... Test loss: 0.01042\n",
      "Epoch: 1... Training loss: 0.00912... Test loss: 0.00948\n",
      "Epoch: 1... Training loss: 0.00806... Test loss: 0.01165\n",
      "Epoch: 1... Training loss: 0.00655... Test loss: 0.01079\n",
      "Epoch: 1... Training loss: 0.00689... Test loss: 0.00934\n",
      "Epoch: 1... Training loss: 0.00653... Test loss: 0.00933\n",
      "Epoch: 1... Training loss: 0.0066... Test loss: 0.00733\n",
      "Epoch: 1... Training loss: 0.00665... Test loss: 0.00725\n",
      "Epoch: 1... Training loss: 0.00611... Test loss: 0.01032\n",
      "Epoch: 1... Training loss: 0.00595... Test loss: 0.00588\n",
      "Epoch: 1... Training loss: 0.00532... Test loss: 0.00928\n",
      "Epoch: 1... Training loss: 0.00535... Test loss: 0.00592\n",
      "Epoch: 1... Training loss: 0.00505... Test loss: 0.00799\n",
      "Epoch: 1... Training loss: 0.00588... Test loss: 0.00775\n",
      "Epoch: 1... Training loss: 0.00539... Test loss: 0.00583\n",
      "Epoch: 1... Training loss: 0.00476... Test loss: 0.00589\n",
      "Epoch: 1... Training loss: 0.00497... Test loss: 0.00559\n",
      "Epoch: 1... Training loss: 0.00432... Test loss: 0.00602\n",
      "Epoch: 1... Training loss: 0.00426... Test loss: 0.00471\n",
      "Epoch: 1... Training loss: 0.00426... Test loss: 0.00568\n",
      "Epoch: 1... Training loss: 0.00423... Test loss: 0.00402\n",
      "Epoch: 1... Training loss: 0.0041... Test loss: 0.00504\n",
      "Epoch: 1... Training loss: 0.00374... Test loss: 0.00402\n",
      "Epoch: 1... Training loss: 0.00392... Test loss: 0.00423\n",
      "Epoch: 1... Training loss: 0.0038... Test loss: 0.00514\n",
      "Epoch: 1... Training loss: 0.00345... Test loss: 0.00359\n",
      "Epoch: 1... Training loss: 0.00331... Test loss: 0.00492\n",
      "Epoch: 1... Training loss: 0.00312... Test loss: 0.00385\n",
      "Epoch: 1... Training loss: 0.00303... Test loss: 0.00361\n",
      "Epoch: 1... Training loss: 0.00294... Test loss: 0.00339\n",
      "Epoch: 1... Training loss: 0.00291... Test loss: 0.00344\n",
      "Epoch: 1... Training loss: 0.00286... Test loss: 0.00216\n",
      "Epoch: 1... Training loss: 0.00272... Test loss: 0.00368\n",
      "Epoch: 1... Training loss: 0.00274... Test loss: 0.00309\n",
      "Epoch: 1... Training loss: 0.0026... Test loss: 0.00295\n",
      "Epoch: 1... Training loss: 0.00265... Test loss: 0.00258\n",
      "Epoch: 1... Training loss: 0.00265... Test loss: 0.00357\n",
      "Epoch: 1... Training loss: 0.00251... Test loss: 0.00259\n",
      "Epoch: 1... Training loss: 0.00229... Test loss: 0.00289\n",
      "Epoch: 1... Training loss: 0.00231... Test loss: 0.00267\n",
      "Epoch: 1... Training loss: 0.00219... Test loss: 0.00288\n",
      "Epoch: 1... Training loss: 0.0021... Test loss: 0.00252\n",
      "Epoch: 1... Training loss: 0.00204... Test loss: 0.00237\n",
      "Epoch: 1... Training loss: 0.00197... Test loss: 0.00203\n",
      "Epoch: 1... Training loss: 0.00195... Test loss: 0.00248\n",
      "Epoch: 1... Training loss: 0.00185... Test loss: 0.00155\n",
      "Epoch: 1... Training loss: 0.00178... Test loss: 0.00221\n",
      "Epoch: 1... Training loss: 0.00178... Test loss: 0.00165\n",
      "Epoch: 1... Training loss: 0.00166... Test loss: 0.00221\n",
      "Epoch: 1... Training loss: 0.00164... Test loss: 0.00193\n",
      "Epoch: 1... Training loss: 0.00155... Test loss: 0.00178\n",
      "Epoch: 1... Training loss: 0.00157... Test loss: 0.00143\n",
      "Epoch: 1... Training loss: 0.0014... Test loss: 0.00136\n",
      "Epoch: 1... Training loss: 0.00135... Test loss: 0.00132\n",
      "Epoch: 1... Training loss: 0.00135... Test loss: 0.00153\n",
      "Epoch: 1... Training loss: 0.0013... Test loss: 0.00162\n",
      "Epoch: 1... Training loss: 0.00121... Test loss: 0.00103\n",
      "Epoch: 1... Training loss: 0.00116... Test loss: 0.00138\n",
      "Epoch: 1... Training loss: 0.00119... Test loss: 0.00103\n",
      "Epoch: 1... Training loss: 0.00103... Test loss: 0.00112\n",
      "Epoch: 1... Training loss: 0.00103... Test loss: 0.00083\n",
      "Epoch: 1... Training loss: 0.00096... Test loss: 0.00137\n",
      "Epoch: 1... Training loss: 0.00092... Test loss: 0.00089\n",
      "Epoch: 1... Training loss: 0.00086... Test loss: 0.00131\n",
      "Epoch: 1... Training loss: 0.00082... Test loss: 0.00071\n",
      "Epoch: 1... Training loss: 0.00072... Test loss: 0.00137\n",
      "Epoch: 1... Training loss: 0.00078... Test loss: 0.00061\n",
      "Epoch: 1... Training loss: 0.00073... Test loss: 0.00083\n",
      "Epoch: 1... Training loss: 0.00069... Test loss: 0.00075\n",
      "Epoch: 1... Training loss: 0.00079... Test loss: 0.00084\n",
      "Epoch: 1... Training loss: 0.00062... Test loss: 0.00068\n",
      "Epoch: 1... Training loss: 0.00058... Test loss: 0.00075\n",
      "Epoch: 1... Training loss: 0.00066... Test loss: 0.00078\n",
      "Epoch: 1... Training loss: 0.00058... Test loss: 0.00066\n",
      "Epoch: 1... Training loss: 0.00053... Test loss: 0.00054\n",
      "Epoch: 1... Training loss: 0.00055... Test loss: 0.00058\n",
      "Epoch: 1... Training loss: 0.00052... Test loss: 0.00052\n",
      "Epoch: 1... Training loss: 0.00055... Test loss: 0.00056\n",
      "Epoch: 1... Training loss: 0.00049... Test loss: 0.00045\n",
      "Epoch: 1... Training loss: 0.00048... Test loss: 0.00053\n",
      "Epoch: 1... Training loss: 0.00045... Test loss: 0.00056\n",
      "Epoch: 1... Training loss: 0.00045... Test loss: 0.00054\n",
      "Epoch: 1... Training loss: 0.00042... Test loss: 0.00055\n",
      "Epoch: 1... Training loss: 0.00043... Test loss: 0.0005\n",
      "Epoch: 1... Training loss: 0.00037... Test loss: 0.00043\n",
      "Epoch: 1... Training loss: 0.00035... Test loss: 0.00044\n",
      "Epoch: 1... Training loss: 0.00034... Test loss: 0.00038\n",
      "Epoch: 1... Training loss: 0.00038... Test loss: 0.00041\n",
      "Epoch: 1... Training loss: 0.00031... Test loss: 0.00034\n",
      "Epoch: 1... Training loss: 0.00031... Test loss: 0.00033\n",
      "Epoch: 1... Training loss: 0.00033... Test loss: 0.00035\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.00026... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.00031\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00028\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00028\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00018\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 7e-05\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 7e-05\n",
      "Epoch: 1... Training loss: 8e-05... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 8e-05\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 8e-05... Test loss: 8e-05\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 7e-05\n",
      "205.62228558724746\n",
      "Epoch: 1... Training loss: 0.95112... Test loss: 0.29\n",
      "Epoch: 1... Training loss: 0.49111... Test loss: 0.13932\n",
      "Epoch: 1... Training loss: 0.29077... Test loss: 0.06552\n",
      "Epoch: 1... Training loss: 0.18918... Test loss: 0.04648\n",
      "Epoch: 1... Training loss: 0.1443... Test loss: 0.03131\n",
      "Epoch: 1... Training loss: 0.1051... Test loss: 0.02832\n",
      "Epoch: 1... Training loss: 0.07154... Test loss: 0.02156\n",
      "Epoch: 1... Training loss: 0.05897... Test loss: 0.01728\n",
      "Epoch: 1... Training loss: 0.05334... Test loss: 0.01364\n",
      "Epoch: 1... Training loss: 0.04668... Test loss: 0.01038\n",
      "Epoch: 1... Training loss: 0.0421... Test loss: 0.00916\n",
      "Epoch: 1... Training loss: 0.04117... Test loss: 0.00848\n",
      "Epoch: 1... Training loss: 0.03748... Test loss: 0.0075\n",
      "Epoch: 1... Training loss: 0.03637... Test loss: 0.00665\n",
      "Epoch: 1... Training loss: 0.03164... Test loss: 0.006\n",
      "Epoch: 1... Training loss: 0.02852... Test loss: 0.00473\n",
      "Epoch: 1... Training loss: 0.02638... Test loss: 0.00463\n",
      "Epoch: 1... Training loss: 0.02481... Test loss: 0.00356\n",
      "Epoch: 1... Training loss: 0.02269... Test loss: 0.00434\n",
      "Epoch: 1... Training loss: 0.02159... Test loss: 0.00285\n",
      "Epoch: 1... Training loss: 0.02037... Test loss: 0.00354\n",
      "Epoch: 1... Training loss: 0.01931... Test loss: 0.00201\n",
      "Epoch: 1... Training loss: 0.01862... Test loss: 0.00398\n",
      "Epoch: 1... Training loss: 0.0175... Test loss: 0.00152\n",
      "Epoch: 1... Training loss: 0.01721... Test loss: 0.00349\n",
      "Epoch: 1... Training loss: 0.01605... Test loss: 0.00287\n",
      "Epoch: 1... Training loss: 0.0155... Test loss: 0.00191\n",
      "Epoch: 1... Training loss: 0.01467... Test loss: 0.00667\n",
      "Epoch: 1... Training loss: 0.01508... Test loss: 0.00136\n",
      "Epoch: 1... Training loss: 0.01378... Test loss: 0.00541\n",
      "Epoch: 1... Training loss: 0.01339... Test loss: 0.00231\n",
      "Epoch: 1... Training loss: 0.01271... Test loss: 0.0061\n",
      "Epoch: 1... Training loss: 0.01224... Test loss: 0.0028\n",
      "Epoch: 1... Training loss: 0.01184... Test loss: 0.00726\n",
      "Epoch: 1... Training loss: 0.01153... Test loss: 0.00296\n",
      "Epoch: 1... Training loss: 0.01115... Test loss: 0.00635\n",
      "Epoch: 1... Training loss: 0.01098... Test loss: 0.00257\n",
      "Epoch: 1... Training loss: 0.01057... Test loss: 0.00535\n",
      "Epoch: 1... Training loss: 0.01036... Test loss: 0.00483\n",
      "Epoch: 1... Training loss: 0.00985... Test loss: 0.00599\n",
      "Epoch: 1... Training loss: 0.00974... Test loss: 0.00434\n",
      "Epoch: 1... Training loss: 0.00946... Test loss: 0.00649\n",
      "Epoch: 1... Training loss: 0.00906... Test loss: 0.0044\n",
      "Epoch: 1... Training loss: 0.00857... Test loss: 0.0073\n",
      "Epoch: 1... Training loss: 0.00822... Test loss: 0.00464\n",
      "Epoch: 1... Training loss: 0.00786... Test loss: 0.00701\n",
      "Epoch: 1... Training loss: 0.0075... Test loss: 0.00504\n",
      "Epoch: 1... Training loss: 0.00738... Test loss: 0.00555\n",
      "Epoch: 1... Training loss: 0.00722... Test loss: 0.00453\n",
      "Epoch: 1... Training loss: 0.00709... Test loss: 0.00562\n",
      "Epoch: 1... Training loss: 0.00689... Test loss: 0.00413\n",
      "Epoch: 1... Training loss: 0.00678... Test loss: 0.00532\n",
      "Epoch: 1... Training loss: 0.00648... Test loss: 0.00405\n",
      "Epoch: 1... Training loss: 0.00631... Test loss: 0.00571\n",
      "Epoch: 1... Training loss: 0.00607... Test loss: 0.00462\n",
      "Epoch: 1... Training loss: 0.00603... Test loss: 0.00493\n",
      "Epoch: 1... Training loss: 0.00582... Test loss: 0.00561\n",
      "Epoch: 1... Training loss: 0.00564... Test loss: 0.00411\n",
      "Epoch: 1... Training loss: 0.00558... Test loss: 0.00626\n",
      "Epoch: 1... Training loss: 0.00544... Test loss: 0.00468\n",
      "Epoch: 1... Training loss: 0.0053... Test loss: 0.0067\n",
      "Epoch: 1... Training loss: 0.0051... Test loss: 0.00484\n",
      "Epoch: 1... Training loss: 0.00493... Test loss: 0.00631\n",
      "Epoch: 1... Training loss: 0.00483... Test loss: 0.00449\n",
      "Epoch: 1... Training loss: 0.00735... Test loss: 0.01298\n",
      "Epoch: 1... Training loss: 0.0116... Test loss: 0.0107\n",
      "Epoch: 1... Training loss: 0.00817... Test loss: 0.01498\n",
      "Epoch: 1... Training loss: 0.01048... Test loss: 0.01108\n",
      "Epoch: 1... Training loss: 0.00826... Test loss: 0.02038\n",
      "Epoch: 1... Training loss: 0.00671... Test loss: 0.00802\n",
      "Epoch: 1... Training loss: 0.00641... Test loss: 0.01205\n",
      "Epoch: 1... Training loss: 0.00727... Test loss: 0.0086\n",
      "Epoch: 1... Training loss: 0.00674... Test loss: 0.00804\n",
      "Epoch: 1... Training loss: 0.00639... Test loss: 0.00717\n",
      "Epoch: 1... Training loss: 0.00644... Test loss: 0.00716\n",
      "Epoch: 1... Training loss: 0.00633... Test loss: 0.0081\n",
      "Epoch: 1... Training loss: 0.00583... Test loss: 0.00603\n",
      "Epoch: 1... Training loss: 0.00549... Test loss: 0.00691\n",
      "Epoch: 1... Training loss: 0.00572... Test loss: 0.00722\n",
      "Epoch: 1... Training loss: 0.00542... Test loss: 0.00678\n",
      "Epoch: 1... Training loss: 0.00529... Test loss: 0.00623\n",
      "Epoch: 1... Training loss: 0.0051... Test loss: 0.00807\n",
      "Epoch: 1... Training loss: 0.0049... Test loss: 0.00455\n",
      "Epoch: 1... Training loss: 0.00462... Test loss: 0.00824\n",
      "Epoch: 1... Training loss: 0.00486... Test loss: 0.00473\n",
      "Epoch: 1... Training loss: 0.00422... Test loss: 0.00665\n",
      "Epoch: 1... Training loss: 0.00413... Test loss: 0.00469\n",
      "Epoch: 1... Training loss: 0.00393... Test loss: 0.00675\n",
      "Epoch: 1... Training loss: 0.00415... Test loss: 0.00349\n",
      "Epoch: 1... Training loss: 0.00363... Test loss: 0.00658\n",
      "Epoch: 1... Training loss: 0.00346... Test loss: 0.00356\n",
      "Epoch: 1... Training loss: 0.00377... Test loss: 0.00466\n",
      "Epoch: 1... Training loss: 0.00341... Test loss: 0.0036\n",
      "Epoch: 1... Training loss: 0.00327... Test loss: 0.00372\n",
      "Epoch: 1... Training loss: 0.00309... Test loss: 0.0033\n",
      "Epoch: 1... Training loss: 0.0029... Test loss: 0.00398\n",
      "Epoch: 1... Training loss: 0.00303... Test loss: 0.00327\n",
      "Epoch: 1... Training loss: 0.00292... Test loss: 0.00462\n",
      "Epoch: 1... Training loss: 0.0027... Test loss: 0.00293\n",
      "Epoch: 1... Training loss: 0.00265... Test loss: 0.0032\n",
      "Epoch: 1... Training loss: 0.00249... Test loss: 0.00303\n",
      "Epoch: 1... Training loss: 0.00241... Test loss: 0.0033\n",
      "Epoch: 1... Training loss: 0.00242... Test loss: 0.00312\n",
      "Epoch: 1... Training loss: 0.00232... Test loss: 0.00304\n",
      "Epoch: 1... Training loss: 0.00225... Test loss: 0.00267\n",
      "Epoch: 1... Training loss: 0.00225... Test loss: 0.0027\n",
      "Epoch: 1... Training loss: 0.00213... Test loss: 0.00277\n",
      "Epoch: 1... Training loss: 0.0022... Test loss: 0.00234\n",
      "Epoch: 1... Training loss: 0.00204... Test loss: 0.00188\n",
      "Epoch: 1... Training loss: 0.00204... Test loss: 0.0023\n",
      "Epoch: 1... Training loss: 0.00189... Test loss: 0.00226\n",
      "Epoch: 1... Training loss: 0.00193... Test loss: 0.00203\n",
      "Epoch: 1... Training loss: 0.00169... Test loss: 0.00189\n",
      "Epoch: 1... Training loss: 0.0017... Test loss: 0.00198\n",
      "Epoch: 1... Training loss: 0.00158... Test loss: 0.00175\n",
      "Epoch: 1... Training loss: 0.00159... Test loss: 0.00198\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1... Training loss: 0.00154... Test loss: 0.00167\n",
      "Epoch: 1... Training loss: 0.0014... Test loss: 0.00177\n",
      "Epoch: 1... Training loss: 0.00152... Test loss: 0.00131\n",
      "Epoch: 1... Training loss: 0.00129... Test loss: 0.00183\n",
      "Epoch: 1... Training loss: 0.0014... Test loss: 0.00173\n",
      "Epoch: 1... Training loss: 0.00131... Test loss: 0.00175\n",
      "Epoch: 1... Training loss: 0.00121... Test loss: 0.00134\n",
      "Epoch: 1... Training loss: 0.00116... Test loss: 0.00166\n",
      "Epoch: 1... Training loss: 0.00116... Test loss: 0.00144\n",
      "Epoch: 1... Training loss: 0.00108... Test loss: 0.00113\n",
      "Epoch: 1... Training loss: 0.00104... Test loss: 0.00137\n",
      "Epoch: 1... Training loss: 0.00094... Test loss: 0.00126\n",
      "Epoch: 1... Training loss: 0.00101... Test loss: 0.0011\n",
      "Epoch: 1... Training loss: 0.00091... Test loss: 0.00097\n",
      "Epoch: 1... Training loss: 0.00086... Test loss: 0.00094\n",
      "Epoch: 1... Training loss: 0.00076... Test loss: 0.00087\n",
      "Epoch: 1... Training loss: 0.00081... Test loss: 0.00099\n",
      "Epoch: 1... Training loss: 0.00076... Test loss: 0.00091\n",
      "Epoch: 1... Training loss: 0.00069... Test loss: 0.00056\n",
      "Epoch: 1... Training loss: 0.00067... Test loss: 0.00091\n",
      "Epoch: 1... Training loss: 0.00063... Test loss: 0.00063\n",
      "Epoch: 1... Training loss: 0.00057... Test loss: 0.00069\n",
      "Epoch: 1... Training loss: 0.00055... Test loss: 0.00059\n",
      "Epoch: 1... Training loss: 0.0005... Test loss: 0.00069\n",
      "Epoch: 1... Training loss: 0.0005... Test loss: 0.00052\n",
      "Epoch: 1... Training loss: 0.00045... Test loss: 0.00068\n",
      "Epoch: 1... Training loss: 0.00045... Test loss: 0.00044\n",
      "Epoch: 1... Training loss: 0.00051... Test loss: 0.00063\n",
      "Epoch: 1... Training loss: 0.00043... Test loss: 0.00049\n",
      "Epoch: 1... Training loss: 0.00047... Test loss: 0.00058\n",
      "Epoch: 1... Training loss: 0.00038... Test loss: 0.0004\n",
      "Epoch: 1... Training loss: 0.0004... Test loss: 0.00057\n",
      "Epoch: 1... Training loss: 0.00037... Test loss: 0.00036\n",
      "Epoch: 1... Training loss: 0.00039... Test loss: 0.00028\n",
      "Epoch: 1... Training loss: 0.00033... Test loss: 0.00032\n",
      "Epoch: 1... Training loss: 0.00032... Test loss: 0.00032\n",
      "Epoch: 1... Training loss: 0.00031... Test loss: 0.00034\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.00031... Test loss: 0.0003\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00031\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00031\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 8e-05... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 8e-05... Test loss: 8e-05\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 8e-05... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 8e-05\n",
      "Epoch: 1... Training loss: 8e-05... Test loss: 8e-05\n",
      "Epoch: 1... Training loss: 8e-05... Test loss: 8e-05\n",
      "Epoch: 1... Training loss: 7e-05... Test loss: 6e-05\n",
      "217.3220254793414\n",
      "Epoch: 1... Training loss: 1.06876... Test loss: 0.41942\n",
      "Epoch: 1... Training loss: 0.51834... Test loss: 0.17499\n",
      "Epoch: 1... Training loss: 0.32719... Test loss: 0.1167\n",
      "Epoch: 1... Training loss: 0.22607... Test loss: 0.07338\n",
      "Epoch: 1... Training loss: 0.16259... Test loss: 0.04814\n",
      "Epoch: 1... Training loss: 0.12696... Test loss: 0.03481\n",
      "Epoch: 1... Training loss: 0.09933... Test loss: 0.02552\n",
      "Epoch: 1... Training loss: 0.08286... Test loss: 0.0203\n",
      "Epoch: 1... Training loss: 0.06822... Test loss: 0.01583\n",
      "Epoch: 1... Training loss: 0.05897... Test loss: 0.01196\n",
      "Epoch: 1... Training loss: 0.05194... Test loss: 0.00998\n",
      "Epoch: 1... Training loss: 0.04372... Test loss: 0.00809\n",
      "Epoch: 1... Training loss: 0.04115... Test loss: 0.00905\n",
      "Epoch: 1... Training loss: 0.03461... Test loss: 0.00636\n",
      "Epoch: 1... Training loss: 0.03342... Test loss: 0.00787\n",
      "Epoch: 1... Training loss: 0.03114... Test loss: 0.00877\n",
      "Epoch: 1... Training loss: 0.02877... Test loss: 0.01059\n",
      "Epoch: 1... Training loss: 0.0275... Test loss: 0.01131\n",
      "Epoch: 1... Training loss: 0.02558... Test loss: 0.01245\n",
      "Epoch: 1... Training loss: 0.02515... Test loss: 0.01765\n",
      "Epoch: 1... Training loss: 0.02241... Test loss: 0.01257\n",
      "Epoch: 1... Training loss: 0.02144... Test loss: 0.01898\n",
      "Epoch: 1... Training loss: 0.0194... Test loss: 0.01353\n",
      "Epoch: 1... Training loss: 0.01901... Test loss: 0.01245\n",
      "Epoch: 1... Training loss: 0.01823... Test loss: 0.01324\n",
      "Epoch: 1... Training loss: 0.01775... Test loss: 0.01447\n",
      "Epoch: 1... Training loss: 0.01648... Test loss: 0.01159\n",
      "Epoch: 1... Training loss: 0.01617... Test loss: 0.01393\n",
      "Epoch: 1... Training loss: 0.01499... Test loss: 0.00864\n",
      "Epoch: 1... Training loss: 0.01459... Test loss: 0.01663\n",
      "Epoch: 1... Training loss: 0.01423... Test loss: 0.0042\n",
      "Epoch: 1... Training loss: 0.01382... Test loss: 0.01427\n",
      "Epoch: 1... Training loss: 0.01336... Test loss: 0.00661\n",
      "Epoch: 1... Training loss: 0.01284... Test loss: 0.01252\n",
      "Epoch: 1... Training loss: 0.01253... Test loss: 0.00615\n",
      "Epoch: 1... Training loss: 0.01205... Test loss: 0.01054\n",
      "Epoch: 1... Training loss: 0.01148... Test loss: 0.0117\n",
      "Epoch: 1... Training loss: 0.01135... Test loss: 0.00724\n",
      "Epoch: 1... Training loss: 0.01092... Test loss: 0.01533\n",
      "Epoch: 1... Training loss: 0.01081... Test loss: 0.00577\n",
      "Epoch: 1... Training loss: 0.01023... Test loss: 0.0125\n",
      "Epoch: 1... Training loss: 0.00976... Test loss: 0.00729\n",
      "Epoch: 1... Training loss: 0.00918... Test loss: 0.00743\n",
      "Epoch: 1... Training loss: 0.00923... Test loss: 0.00807\n",
      "Epoch: 1... Training loss: 0.00871... Test loss: 0.00454\n",
      "Epoch: 1... Training loss: 0.00868... Test loss: 0.0093\n",
      "Epoch: 1... Training loss: 0.0082... Test loss: 0.00401\n",
      "Epoch: 1... Training loss: 0.00785... Test loss: 0.00968\n",
      "Epoch: 1... Training loss: 0.00767... Test loss: 0.00587\n",
      "Epoch: 1... Training loss: 0.00755... Test loss: 0.00657\n",
      "Epoch: 1... Training loss: 0.0073... Test loss: 0.00578\n",
      "Epoch: 1... Training loss: 0.00717... Test loss: 0.0067\n",
      "Epoch: 1... Training loss: 0.00684... Test loss: 0.00671\n",
      "Epoch: 1... Training loss: 0.00666... Test loss: 0.00573\n",
      "Epoch: 1... Training loss: 0.0064... Test loss: 0.00596\n",
      "Epoch: 1... Training loss: 0.00631... Test loss: 0.00531\n",
      "Epoch: 1... Training loss: 0.00602... Test loss: 0.00588\n",
      "Epoch: 1... Training loss: 0.00591... Test loss: 0.00472\n",
      "Epoch: 1... Training loss: 0.00563... Test loss: 0.00628\n",
      "Epoch: 1... Training loss: 0.00552... Test loss: 0.0045\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1... Training loss: 0.00528... Test loss: 0.00591\n",
      "Epoch: 1... Training loss: 0.00515... Test loss: 0.0051\n",
      "Epoch: 1... Training loss: 0.00496... Test loss: 0.00547\n",
      "Epoch: 1... Training loss: 0.00481... Test loss: 0.00515\n",
      "Epoch: 1... Training loss: 0.0123... Test loss: 0.01004\n",
      "Epoch: 1... Training loss: 0.01092... Test loss: 0.01084\n",
      "Epoch: 1... Training loss: 0.00931... Test loss: 0.0102\n",
      "Epoch: 1... Training loss: 0.00842... Test loss: 0.00837\n",
      "Epoch: 1... Training loss: 0.00765... Test loss: 0.01107\n",
      "Epoch: 1... Training loss: 0.00925... Test loss: 0.00913\n",
      "Epoch: 1... Training loss: 0.00803... Test loss: 0.01097\n",
      "Epoch: 1... Training loss: 0.00772... Test loss: 0.01365\n",
      "Epoch: 1... Training loss: 0.00668... Test loss: 0.00992\n",
      "Epoch: 1... Training loss: 0.00681... Test loss: 0.01347\n",
      "Epoch: 1... Training loss: 0.00766... Test loss: 0.01148\n",
      "Epoch: 1... Training loss: 0.00648... Test loss: 0.00896\n",
      "Epoch: 1... Training loss: 0.0068... Test loss: 0.00841\n",
      "Epoch: 1... Training loss: 0.00625... Test loss: 0.008\n",
      "Epoch: 1... Training loss: 0.00525... Test loss: 0.00881\n",
      "Epoch: 1... Training loss: 0.00512... Test loss: 0.00685\n",
      "Epoch: 1... Training loss: 0.00535... Test loss: 0.00579\n",
      "Epoch: 1... Training loss: 0.00483... Test loss: 0.00755\n",
      "Epoch: 1... Training loss: 0.00497... Test loss: 0.00629\n",
      "Epoch: 1... Training loss: 0.00485... Test loss: 0.00587\n",
      "Epoch: 1... Training loss: 0.00504... Test loss: 0.00541\n",
      "Epoch: 1... Training loss: 0.00462... Test loss: 0.00655\n",
      "Epoch: 1... Training loss: 0.00445... Test loss: 0.00645\n",
      "Epoch: 1... Training loss: 0.0042... Test loss: 0.0054\n",
      "Epoch: 1... Training loss: 0.00398... Test loss: 0.00683\n",
      "Epoch: 1... Training loss: 0.00366... Test loss: 0.004\n",
      "Epoch: 1... Training loss: 0.00379... Test loss: 0.00544\n",
      "Epoch: 1... Training loss: 0.00352... Test loss: 0.00405\n",
      "Epoch: 1... Training loss: 0.00358... Test loss: 0.00465\n",
      "Epoch: 1... Training loss: 0.00319... Test loss: 0.00413\n",
      "Epoch: 1... Training loss: 0.00328... Test loss: 0.00414\n",
      "Epoch: 1... Training loss: 0.00318... Test loss: 0.00355\n",
      "Epoch: 1... Training loss: 0.00305... Test loss: 0.00318\n",
      "Epoch: 1... Training loss: 0.0028... Test loss: 0.00373\n",
      "Epoch: 1... Training loss: 0.00275... Test loss: 0.00293\n",
      "Epoch: 1... Training loss: 0.00275... Test loss: 0.00321\n",
      "Epoch: 1... Training loss: 0.00257... Test loss: 0.00296\n",
      "Epoch: 1... Training loss: 0.00246... Test loss: 0.00292\n",
      "Epoch: 1... Training loss: 0.00233... Test loss: 0.00344\n",
      "Epoch: 1... Training loss: 0.00235... Test loss: 0.00275\n",
      "Epoch: 1... Training loss: 0.00224... Test loss: 0.00279\n",
      "Epoch: 1... Training loss: 0.00225... Test loss: 0.00316\n",
      "Epoch: 1... Training loss: 0.00224... Test loss: 0.00249\n",
      "Epoch: 1... Training loss: 0.00212... Test loss: 0.00283\n",
      "Epoch: 1... Training loss: 0.00208... Test loss: 0.00216\n",
      "Epoch: 1... Training loss: 0.00201... Test loss: 0.00266\n",
      "Epoch: 1... Training loss: 0.00191... Test loss: 0.00206\n",
      "Epoch: 1... Training loss: 0.00191... Test loss: 0.00211\n",
      "Epoch: 1... Training loss: 0.00179... Test loss: 0.00224\n",
      "Epoch: 1... Training loss: 0.00185... Test loss: 0.00198\n",
      "Epoch: 1... Training loss: 0.00178... Test loss: 0.00198\n",
      "Epoch: 1... Training loss: 0.00161... Test loss: 0.00187\n",
      "Epoch: 1... Training loss: 0.00168... Test loss: 0.00189\n",
      "Epoch: 1... Training loss: 0.00156... Test loss: 0.00184\n",
      "Epoch: 1... Training loss: 0.0016... Test loss: 0.00172\n",
      "Epoch: 1... Training loss: 0.0015... Test loss: 0.00177\n",
      "Epoch: 1... Training loss: 0.00142... Test loss: 0.00155\n",
      "Epoch: 1... Training loss: 0.00141... Test loss: 0.00137\n",
      "Epoch: 1... Training loss: 0.00135... Test loss: 0.00155\n",
      "Epoch: 1... Training loss: 0.00132... Test loss: 0.00136\n",
      "Epoch: 1... Training loss: 0.00122... Test loss: 0.0012\n",
      "Epoch: 1... Training loss: 0.00115... Test loss: 0.00106\n",
      "Epoch: 1... Training loss: 0.00106... Test loss: 0.0013\n",
      "Epoch: 1... Training loss: 0.00103... Test loss: 0.00126\n",
      "Epoch: 1... Training loss: 0.00101... Test loss: 0.00111\n",
      "Epoch: 1... Training loss: 0.00097... Test loss: 0.00107\n",
      "Epoch: 1... Training loss: 0.00091... Test loss: 0.00114\n",
      "Epoch: 1... Training loss: 0.00085... Test loss: 0.00094\n",
      "Epoch: 1... Training loss: 0.0009... Test loss: 0.00103\n",
      "Epoch: 1... Training loss: 0.00085... Test loss: 0.00082\n",
      "Epoch: 1... Training loss: 0.00075... Test loss: 0.00106\n",
      "Epoch: 1... Training loss: 0.00073... Test loss: 0.00077\n",
      "Epoch: 1... Training loss: 0.00067... Test loss: 0.00097\n",
      "Epoch: 1... Training loss: 0.00069... Test loss: 0.00057\n",
      "Epoch: 1... Training loss: 0.00064... Test loss: 0.001\n",
      "Epoch: 1... Training loss: 0.0006... Test loss: 0.00057\n",
      "Epoch: 1... Training loss: 0.00061... Test loss: 0.00086\n",
      "Epoch: 1... Training loss: 0.00058... Test loss: 0.00062\n",
      "Epoch: 1... Training loss: 0.00059... Test loss: 0.00075\n",
      "Epoch: 1... Training loss: 0.00054... Test loss: 0.00059\n",
      "Epoch: 1... Training loss: 0.00054... Test loss: 0.0005\n",
      "Epoch: 1... Training loss: 0.00049... Test loss: 0.0005\n",
      "Epoch: 1... Training loss: 0.0005... Test loss: 0.00051\n",
      "Epoch: 1... Training loss: 0.0005... Test loss: 0.0004\n",
      "Epoch: 1... Training loss: 0.00048... Test loss: 0.0005\n",
      "Epoch: 1... Training loss: 0.00044... Test loss: 0.00045\n",
      "Epoch: 1... Training loss: 0.00042... Test loss: 0.00043\n",
      "Epoch: 1... Training loss: 0.00043... Test loss: 0.00042\n",
      "Epoch: 1... Training loss: 0.00038... Test loss: 0.00041\n",
      "Epoch: 1... Training loss: 0.00039... Test loss: 0.00048\n",
      "Epoch: 1... Training loss: 0.00039... Test loss: 0.00036\n",
      "Epoch: 1... Training loss: 0.00035... Test loss: 0.00049\n",
      "Epoch: 1... Training loss: 0.00037... Test loss: 0.00034\n",
      "Epoch: 1... Training loss: 0.00032... Test loss: 0.00037\n",
      "Epoch: 1... Training loss: 0.00031... Test loss: 0.00035\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00033\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00031\n",
      "Epoch: 1... Training loss: 0.00032... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00028\n",
      "Epoch: 1... Training loss: 0.00034... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00026... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00028\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00026... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 8e-05... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 8e-05... Test loss: 0.00011\n",
      "215.42330729064997\n",
      "Epoch: 1... Training loss: 1.11053... Test loss: 0.45437\n",
      "Epoch: 1... Training loss: 0.47712... Test loss: 0.15912\n",
      "Epoch: 1... Training loss: 0.26538... Test loss: 0.0994\n",
      "Epoch: 1... Training loss: 0.19817... Test loss: 0.06043\n",
      "Epoch: 1... Training loss: 0.13056... Test loss: 0.06387\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1... Training loss: 0.09119... Test loss: 0.05501\n",
      "Epoch: 1... Training loss: 0.07837... Test loss: 0.05399\n",
      "Epoch: 1... Training loss: 0.07116... Test loss: 0.0166\n",
      "Epoch: 1... Training loss: 0.06518... Test loss: 0.04368\n",
      "Epoch: 1... Training loss: 0.05254... Test loss: 0.02532\n",
      "Epoch: 1... Training loss: 0.04883... Test loss: 0.03711\n",
      "Epoch: 1... Training loss: 0.042... Test loss: 0.0268\n",
      "Epoch: 1... Training loss: 0.0367... Test loss: 0.03506\n",
      "Epoch: 1... Training loss: 0.03349... Test loss: 0.02138\n",
      "Epoch: 1... Training loss: 0.03257... Test loss: 0.02889\n",
      "Epoch: 1... Training loss: 0.03088... Test loss: 0.01536\n",
      "Epoch: 1... Training loss: 0.02847... Test loss: 0.02774\n",
      "Epoch: 1... Training loss: 0.02739... Test loss: 0.00985\n",
      "Epoch: 1... Training loss: 0.02553... Test loss: 0.02762\n",
      "Epoch: 1... Training loss: 0.02466... Test loss: 0.00905\n",
      "Epoch: 1... Training loss: 0.02345... Test loss: 0.01638\n",
      "Epoch: 1... Training loss: 0.02252... Test loss: 0.01236\n",
      "Epoch: 1... Training loss: 0.02039... Test loss: 0.01543\n",
      "Epoch: 1... Training loss: 0.01998... Test loss: 0.01174\n",
      "Epoch: 1... Training loss: 0.0187... Test loss: 0.01353\n",
      "Epoch: 1... Training loss: 0.01838... Test loss: 0.00695\n",
      "Epoch: 1... Training loss: 0.01719... Test loss: 0.01681\n",
      "Epoch: 1... Training loss: 0.01662... Test loss: 0.01453\n",
      "Epoch: 1... Training loss: 0.01582... Test loss: 0.0097\n",
      "Epoch: 1... Training loss: 0.01518... Test loss: 0.02054\n",
      "Epoch: 1... Training loss: 0.0148... Test loss: 0.0088\n",
      "Epoch: 1... Training loss: 0.01447... Test loss: 0.01543\n",
      "Epoch: 1... Training loss: 0.01403... Test loss: 0.00825\n",
      "Epoch: 1... Training loss: 0.01301... Test loss: 0.01725\n",
      "Epoch: 1... Training loss: 0.01252... Test loss: 0.00654\n",
      "Epoch: 1... Training loss: 0.01208... Test loss: 0.01527\n",
      "Epoch: 1... Training loss: 0.01146... Test loss: 0.00712\n",
      "Epoch: 1... Training loss: 0.01098... Test loss: 0.01493\n",
      "Epoch: 1... Training loss: 0.0108... Test loss: 0.00787\n",
      "Epoch: 1... Training loss: 0.01022... Test loss: 0.01716\n",
      "Epoch: 1... Training loss: 0.0098... Test loss: 0.00894\n",
      "Epoch: 1... Training loss: 0.01002... Test loss: 0.00684\n",
      "Epoch: 1... Training loss: 0.00942... Test loss: 0.01242\n",
      "Epoch: 1... Training loss: 0.00889... Test loss: 0.0078\n",
      "Epoch: 1... Training loss: 0.00855... Test loss: 0.01082\n",
      "Epoch: 1... Training loss: 0.00819... Test loss: 0.00784\n",
      "Epoch: 1... Training loss: 0.00783... Test loss: 0.00688\n",
      "Epoch: 1... Training loss: 0.00749... Test loss: 0.00952\n",
      "Epoch: 1... Training loss: 0.00714... Test loss: 0.00549\n",
      "Epoch: 1... Training loss: 0.00683... Test loss: 0.01085\n",
      "Epoch: 1... Training loss: 0.00677... Test loss: 0.00631\n",
      "Epoch: 1... Training loss: 0.00654... Test loss: 0.00727\n",
      "Epoch: 1... Training loss: 0.00637... Test loss: 0.00544\n",
      "Epoch: 1... Training loss: 0.00616... Test loss: 0.00638\n",
      "Epoch: 1... Training loss: 0.00605... Test loss: 0.00562\n",
      "Epoch: 1... Training loss: 0.00585... Test loss: 0.00553\n",
      "Epoch: 1... Training loss: 0.00564... Test loss: 0.00563\n",
      "Epoch: 1... Training loss: 0.00543... Test loss: 0.00559\n",
      "Epoch: 1... Training loss: 0.0053... Test loss: 0.00504\n",
      "Epoch: 1... Training loss: 0.0051... Test loss: 0.00466\n",
      "Epoch: 1... Training loss: 0.00489... Test loss: 0.00565\n",
      "Epoch: 1... Training loss: 0.00471... Test loss: 0.00443\n",
      "Epoch: 1... Training loss: 0.00452... Test loss: 0.00558\n",
      "Epoch: 1... Training loss: 0.00442... Test loss: 0.00369\n",
      "Epoch: 1... Training loss: 0.00775... Test loss: 0.00832\n",
      "Epoch: 1... Training loss: 0.008... Test loss: 0.00861\n",
      "Epoch: 1... Training loss: 0.00813... Test loss: 0.00924\n",
      "Epoch: 1... Training loss: 0.00706... Test loss: 0.01095\n",
      "Epoch: 1... Training loss: 0.00675... Test loss: 0.0094\n",
      "Epoch: 1... Training loss: 0.00802... Test loss: 0.01312\n",
      "Epoch: 1... Training loss: 0.00747... Test loss: 0.00676\n",
      "Epoch: 1... Training loss: 0.00659... Test loss: 0.01365\n",
      "Epoch: 1... Training loss: 0.00632... Test loss: 0.00853\n",
      "Epoch: 1... Training loss: 0.00649... Test loss: 0.01077\n",
      "Epoch: 1... Training loss: 0.00678... Test loss: 0.00775\n",
      "Epoch: 1... Training loss: 0.00597... Test loss: 0.00758\n",
      "Epoch: 1... Training loss: 0.00639... Test loss: 0.00673\n",
      "Epoch: 1... Training loss: 0.00572... Test loss: 0.00855\n",
      "Epoch: 1... Training loss: 0.00521... Test loss: 0.00701\n",
      "Epoch: 1... Training loss: 0.00489... Test loss: 0.00737\n",
      "Epoch: 1... Training loss: 0.00491... Test loss: 0.00582\n",
      "Epoch: 1... Training loss: 0.00449... Test loss: 0.00859\n",
      "Epoch: 1... Training loss: 0.00454... Test loss: 0.00556\n",
      "Epoch: 1... Training loss: 0.00399... Test loss: 0.00658\n",
      "Epoch: 1... Training loss: 0.00411... Test loss: 0.00554\n",
      "Epoch: 1... Training loss: 0.00395... Test loss: 0.00565\n",
      "Epoch: 1... Training loss: 0.0042... Test loss: 0.00292\n",
      "Epoch: 1... Training loss: 0.00371... Test loss: 0.00596\n",
      "Epoch: 1... Training loss: 0.00359... Test loss: 0.00346\n",
      "Epoch: 1... Training loss: 0.00353... Test loss: 0.00461\n",
      "Epoch: 1... Training loss: 0.0034... Test loss: 0.00316\n",
      "Epoch: 1... Training loss: 0.00324... Test loss: 0.0042\n",
      "Epoch: 1... Training loss: 0.00326... Test loss: 0.00338\n",
      "Epoch: 1... Training loss: 0.00314... Test loss: 0.00346\n",
      "Epoch: 1... Training loss: 0.003... Test loss: 0.00293\n",
      "Epoch: 1... Training loss: 0.00301... Test loss: 0.00316\n",
      "Epoch: 1... Training loss: 0.00284... Test loss: 0.00299\n",
      "Epoch: 1... Training loss: 0.00284... Test loss: 0.00311\n",
      "Epoch: 1... Training loss: 0.00264... Test loss: 0.00261\n",
      "Epoch: 1... Training loss: 0.0026... Test loss: 0.00363\n",
      "Epoch: 1... Training loss: 0.00255... Test loss: 0.00269\n",
      "Epoch: 1... Training loss: 0.00236... Test loss: 0.00275\n",
      "Epoch: 1... Training loss: 0.00228... Test loss: 0.00252\n",
      "Epoch: 1... Training loss: 0.0023... Test loss: 0.00255\n",
      "Epoch: 1... Training loss: 0.00219... Test loss: 0.00274\n",
      "Epoch: 1... Training loss: 0.00209... Test loss: 0.00217\n",
      "Epoch: 1... Training loss: 0.00202... Test loss: 0.00294\n",
      "Epoch: 1... Training loss: 0.00219... Test loss: 0.0022\n",
      "Epoch: 1... Training loss: 0.00187... Test loss: 0.00266\n",
      "Epoch: 1... Training loss: 0.00186... Test loss: 0.00207\n",
      "Epoch: 1... Training loss: 0.00193... Test loss: 0.00185\n",
      "Epoch: 1... Training loss: 0.00184... Test loss: 0.00242\n",
      "Epoch: 1... Training loss: 0.00171... Test loss: 0.00174\n",
      "Epoch: 1... Training loss: 0.00165... Test loss: 0.00238\n",
      "Epoch: 1... Training loss: 0.00158... Test loss: 0.00157\n",
      "Epoch: 1... Training loss: 0.00155... Test loss: 0.00204\n",
      "Epoch: 1... Training loss: 0.00145... Test loss: 0.00188\n",
      "Epoch: 1... Training loss: 0.00141... Test loss: 0.00181\n",
      "Epoch: 1... Training loss: 0.00135... Test loss: 0.0015\n",
      "Epoch: 1... Training loss: 0.00129... Test loss: 0.00179\n",
      "Epoch: 1... Training loss: 0.00125... Test loss: 0.00126\n",
      "Epoch: 1... Training loss: 0.00116... Test loss: 0.0017\n",
      "Epoch: 1... Training loss: 0.00115... Test loss: 0.00112\n",
      "Epoch: 1... Training loss: 0.0011... Test loss: 0.00169\n",
      "Epoch: 1... Training loss: 0.00104... Test loss: 0.00105\n",
      "Epoch: 1... Training loss: 0.00098... Test loss: 0.00145\n",
      "Epoch: 1... Training loss: 0.00096... Test loss: 0.00115\n",
      "Epoch: 1... Training loss: 0.00089... Test loss: 0.00148\n",
      "Epoch: 1... Training loss: 0.00087... Test loss: 0.00092\n",
      "Epoch: 1... Training loss: 0.00083... Test loss: 0.00105\n",
      "Epoch: 1... Training loss: 0.00077... Test loss: 0.00113\n",
      "Epoch: 1... Training loss: 0.00077... Test loss: 0.00081\n",
      "Epoch: 1... Training loss: 0.00075... Test loss: 0.00087\n",
      "Epoch: 1... Training loss: 0.00071... Test loss: 0.00053\n",
      "Epoch: 1... Training loss: 0.00068... Test loss: 0.00082\n",
      "Epoch: 1... Training loss: 0.00065... Test loss: 0.00054\n",
      "Epoch: 1... Training loss: 0.0006... Test loss: 0.00065\n",
      "Epoch: 1... Training loss: 0.00063... Test loss: 0.00072\n",
      "Epoch: 1... Training loss: 0.00058... Test loss: 0.00066\n",
      "Epoch: 1... Training loss: 0.00053... Test loss: 0.00062\n",
      "Epoch: 1... Training loss: 0.00056... Test loss: 0.00056\n",
      "Epoch: 1... Training loss: 0.00057... Test loss: 0.0006\n",
      "Epoch: 1... Training loss: 0.00053... Test loss: 0.0006\n",
      "Epoch: 1... Training loss: 0.00047... Test loss: 0.00058\n",
      "Epoch: 1... Training loss: 0.00047... Test loss: 0.00059\n",
      "Epoch: 1... Training loss: 0.00048... Test loss: 0.00045\n",
      "Epoch: 1... Training loss: 0.00048... Test loss: 0.00063\n",
      "Epoch: 1... Training loss: 0.00045... Test loss: 0.00042\n",
      "Epoch: 1... Training loss: 0.00047... Test loss: 0.00053\n",
      "Epoch: 1... Training loss: 0.00047... Test loss: 0.00043\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1... Training loss: 0.00043... Test loss: 0.00032\n",
      "Epoch: 1... Training loss: 0.0004... Test loss: 0.00042\n",
      "Epoch: 1... Training loss: 0.0004... Test loss: 0.00031\n",
      "Epoch: 1... Training loss: 0.00039... Test loss: 0.00039\n",
      "Epoch: 1... Training loss: 0.00038... Test loss: 0.00034\n",
      "Epoch: 1... Training loss: 0.00041... Test loss: 0.00033\n",
      "Epoch: 1... Training loss: 0.00036... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.00033... Test loss: 0.00034\n",
      "Epoch: 1... Training loss: 0.00029... Test loss: 0.00031\n",
      "Epoch: 1... Training loss: 0.00032... Test loss: 0.00031\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00038\n",
      "Epoch: 1... Training loss: 0.00034... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00034\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.00024\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00028\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00024\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00024\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 7e-05... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 8e-05\n",
      "Epoch: 1... Training loss: 8e-05... Test loss: 8e-05\n",
      "Epoch: 1... Training loss: 6e-05... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 8e-05... Test loss: 0.0001\n",
      "228.9178443615092\n",
      "Epoch: 1... Training loss: 0.82103... Test loss: 0.15548\n",
      "Epoch: 1... Training loss: 0.42021... Test loss: 0.09811\n",
      "Epoch: 1... Training loss: 0.24951... Test loss: 0.06352\n",
      "Epoch: 1... Training loss: 0.17034... Test loss: 0.03455\n",
      "Epoch: 1... Training loss: 0.13256... Test loss: 0.02227\n",
      "Epoch: 1... Training loss: 0.1019... Test loss: 0.02023\n",
      "Epoch: 1... Training loss: 0.08214... Test loss: 0.01535\n",
      "Epoch: 1... Training loss: 0.07233... Test loss: 0.01436\n",
      "Epoch: 1... Training loss: 0.06219... Test loss: 0.01646\n",
      "Epoch: 1... Training loss: 0.05837... Test loss: 0.00719\n",
      "Epoch: 1... Training loss: 0.04977... Test loss: 0.01227\n",
      "Epoch: 1... Training loss: 0.04394... Test loss: 0.00598\n",
      "Epoch: 1... Training loss: 0.04162... Test loss: 0.01125\n",
      "Epoch: 1... Training loss: 0.0372... Test loss: 0.00516\n",
      "Epoch: 1... Training loss: 0.03589... Test loss: 0.0103\n",
      "Epoch: 1... Training loss: 0.03231... Test loss: 0.00394\n",
      "Epoch: 1... Training loss: 0.03047... Test loss: 0.0105\n",
      "Epoch: 1... Training loss: 0.02852... Test loss: 0.00331\n",
      "Epoch: 1... Training loss: 0.02665... Test loss: 0.00976\n",
      "Epoch: 1... Training loss: 0.02537... Test loss: 0.00298\n",
      "Epoch: 1... Training loss: 0.02423... Test loss: 0.0099\n",
      "Epoch: 1... Training loss: 0.02239... Test loss: 0.00367\n",
      "Epoch: 1... Training loss: 0.02104... Test loss: 0.01181\n",
      "Epoch: 1... Training loss: 0.01972... Test loss: 0.00416\n",
      "Epoch: 1... Training loss: 0.01915... Test loss: 0.01347\n",
      "Epoch: 1... Training loss: 0.01826... Test loss: 0.00436\n",
      "Epoch: 1... Training loss: 0.01766... Test loss: 0.01253\n",
      "Epoch: 1... Training loss: 0.01702... Test loss: 0.00572\n",
      "Epoch: 1... Training loss: 0.01657... Test loss: 0.01138\n",
      "Epoch: 1... Training loss: 0.01599... Test loss: 0.00716\n",
      "Epoch: 1... Training loss: 0.01555... Test loss: 0.01086\n",
      "Epoch: 1... Training loss: 0.0149... Test loss: 0.00805\n",
      "Epoch: 1... Training loss: 0.01431... Test loss: 0.01121\n",
      "Epoch: 1... Training loss: 0.0137... Test loss: 0.00666\n",
      "Epoch: 1... Training loss: 0.01328... Test loss: 0.01068\n",
      "Epoch: 1... Training loss: 0.01289... Test loss: 0.008\n",
      "Epoch: 1... Training loss: 0.01229... Test loss: 0.00916\n",
      "Epoch: 1... Training loss: 0.01192... Test loss: 0.00838\n",
      "Epoch: 1... Training loss: 0.0114... Test loss: 0.00563\n",
      "Epoch: 1... Training loss: 0.01101... Test loss: 0.00973\n",
      "Epoch: 1... Training loss: 0.01065... Test loss: 0.00431\n",
      "Epoch: 1... Training loss: 0.01031... Test loss: 0.00898\n",
      "Epoch: 1... Training loss: 0.01001... Test loss: 0.00444\n",
      "Epoch: 1... Training loss: 0.00977... Test loss: 0.00917\n",
      "Epoch: 1... Training loss: 0.00949... Test loss: 0.00505\n",
      "Epoch: 1... Training loss: 0.00921... Test loss: 0.00779\n",
      "Epoch: 1... Training loss: 0.00891... Test loss: 0.00681\n",
      "Epoch: 1... Training loss: 0.00848... Test loss: 0.00829\n",
      "Epoch: 1... Training loss: 0.00836... Test loss: 0.00635\n",
      "Epoch: 1... Training loss: 0.00804... Test loss: 0.00747\n",
      "Epoch: 1... Training loss: 0.00778... Test loss: 0.00593\n",
      "Epoch: 1... Training loss: 0.00758... Test loss: 0.00681\n",
      "Epoch: 1... Training loss: 0.00733... Test loss: 0.00551\n",
      "Epoch: 1... Training loss: 0.00709... Test loss: 0.00596\n",
      "Epoch: 1... Training loss: 0.00688... Test loss: 0.00546\n",
      "Epoch: 1... Training loss: 0.00667... Test loss: 0.00575\n",
      "Epoch: 1... Training loss: 0.00637... Test loss: 0.00525\n",
      "Epoch: 1... Training loss: 0.00612... Test loss: 0.0051\n",
      "Epoch: 1... Training loss: 0.00595... Test loss: 0.0052\n",
      "Epoch: 1... Training loss: 0.00574... Test loss: 0.005\n",
      "Epoch: 1... Training loss: 0.00553... Test loss: 0.00463\n",
      "Epoch: 1... Training loss: 0.00531... Test loss: 0.00476\n",
      "Epoch: 1... Training loss: 0.00514... Test loss: 0.00438\n",
      "Epoch: 1... Training loss: 0.0049... Test loss: 0.004\n",
      "Epoch: 1... Training loss: 0.00979... Test loss: 0.01348\n",
      "Epoch: 1... Training loss: 0.0095... Test loss: 0.01534\n",
      "Epoch: 1... Training loss: 0.00833... Test loss: 0.01463\n",
      "Epoch: 1... Training loss: 0.00799... Test loss: 0.01067\n",
      "Epoch: 1... Training loss: 0.00829... Test loss: 0.00981\n",
      "Epoch: 1... Training loss: 0.00779... Test loss: 0.01886\n",
      "Epoch: 1... Training loss: 0.00716... Test loss: 0.01087\n",
      "Epoch: 1... Training loss: 0.00788... Test loss: 0.01091\n",
      "Epoch: 1... Training loss: 0.00734... Test loss: 0.01046\n",
      "Epoch: 1... Training loss: 0.0068... Test loss: 0.01071\n",
      "Epoch: 1... Training loss: 0.0068... Test loss: 0.00809\n",
      "Epoch: 1... Training loss: 0.00736... Test loss: 0.01214\n",
      "Epoch: 1... Training loss: 0.0059... Test loss: 0.00867\n",
      "Epoch: 1... Training loss: 0.00562... Test loss: 0.00838\n",
      "Epoch: 1... Training loss: 0.00535... Test loss: 0.00961\n",
      "Epoch: 1... Training loss: 0.00554... Test loss: 0.00665\n",
      "Epoch: 1... Training loss: 0.00548... Test loss: 0.00884\n",
      "Epoch: 1... Training loss: 0.00474... Test loss: 0.00655\n",
      "Epoch: 1... Training loss: 0.00515... Test loss: 0.00814\n",
      "Epoch: 1... Training loss: 0.00457... Test loss: 0.00706\n",
      "Epoch: 1... Training loss: 0.00428... Test loss: 0.00508\n",
      "Epoch: 1... Training loss: 0.00415... Test loss: 0.00651\n",
      "Epoch: 1... Training loss: 0.00431... Test loss: 0.00453\n",
      "Epoch: 1... Training loss: 0.00398... Test loss: 0.00601\n",
      "Epoch: 1... Training loss: 0.00383... Test loss: 0.00422\n",
      "Epoch: 1... Training loss: 0.00379... Test loss: 0.00586\n",
      "Epoch: 1... Training loss: 0.00354... Test loss: 0.00386\n",
      "Epoch: 1... Training loss: 0.00345... Test loss: 0.00519\n",
      "Epoch: 1... Training loss: 0.00362... Test loss: 0.00434\n",
      "Epoch: 1... Training loss: 0.00334... Test loss: 0.0038\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1... Training loss: 0.00311... Test loss: 0.00417\n",
      "Epoch: 1... Training loss: 0.00321... Test loss: 0.00327\n",
      "Epoch: 1... Training loss: 0.00305... Test loss: 0.00428\n",
      "Epoch: 1... Training loss: 0.00293... Test loss: 0.00302\n",
      "Epoch: 1... Training loss: 0.00295... Test loss: 0.00445\n",
      "Epoch: 1... Training loss: 0.0027... Test loss: 0.00291\n",
      "Epoch: 1... Training loss: 0.00265... Test loss: 0.0039\n",
      "Epoch: 1... Training loss: 0.00253... Test loss: 0.00287\n",
      "Epoch: 1... Training loss: 0.00247... Test loss: 0.00338\n",
      "Epoch: 1... Training loss: 0.00233... Test loss: 0.00271\n",
      "Epoch: 1... Training loss: 0.00231... Test loss: 0.00291\n",
      "Epoch: 1... Training loss: 0.00216... Test loss: 0.00283\n",
      "Epoch: 1... Training loss: 0.00214... Test loss: 0.00219\n",
      "Epoch: 1... Training loss: 0.00202... Test loss: 0.00214\n",
      "Epoch: 1... Training loss: 0.00213... Test loss: 0.00226\n",
      "Epoch: 1... Training loss: 0.00191... Test loss: 0.00236\n",
      "Epoch: 1... Training loss: 0.00185... Test loss: 0.00198\n",
      "Epoch: 1... Training loss: 0.00182... Test loss: 0.00202\n",
      "Epoch: 1... Training loss: 0.00175... Test loss: 0.00199\n",
      "Epoch: 1... Training loss: 0.00167... Test loss: 0.00169\n",
      "Epoch: 1... Training loss: 0.00164... Test loss: 0.00195\n",
      "Epoch: 1... Training loss: 0.00166... Test loss: 0.00178\n",
      "Epoch: 1... Training loss: 0.00151... Test loss: 0.00187\n",
      "Epoch: 1... Training loss: 0.00141... Test loss: 0.00172\n",
      "Epoch: 1... Training loss: 0.00143... Test loss: 0.00199\n",
      "Epoch: 1... Training loss: 0.00132... Test loss: 0.00149\n",
      "Epoch: 1... Training loss: 0.00117... Test loss: 0.00169\n",
      "Epoch: 1... Training loss: 0.00121... Test loss: 0.00139\n",
      "Epoch: 1... Training loss: 0.00114... Test loss: 0.00157\n",
      "Epoch: 1... Training loss: 0.0011... Test loss: 0.00117\n",
      "Epoch: 1... Training loss: 0.00104... Test loss: 0.00116\n",
      "Epoch: 1... Training loss: 0.00099... Test loss: 0.00091\n",
      "Epoch: 1... Training loss: 0.00095... Test loss: 0.00115\n",
      "Epoch: 1... Training loss: 0.00094... Test loss: 0.00094\n",
      "Epoch: 1... Training loss: 0.00086... Test loss: 0.00118\n",
      "Epoch: 1... Training loss: 0.00086... Test loss: 0.00096\n",
      "Epoch: 1... Training loss: 0.00082... Test loss: 0.00092\n",
      "Epoch: 1... Training loss: 0.00075... Test loss: 0.00086\n",
      "Epoch: 1... Training loss: 0.0008... Test loss: 0.00061\n",
      "Epoch: 1... Training loss: 0.00073... Test loss: 0.00066\n",
      "Epoch: 1... Training loss: 0.00071... Test loss: 0.00052\n",
      "Epoch: 1... Training loss: 0.00061... Test loss: 0.00085\n",
      "Epoch: 1... Training loss: 0.0006... Test loss: 0.00048\n",
      "Epoch: 1... Training loss: 0.00058... Test loss: 0.00058\n",
      "Epoch: 1... Training loss: 0.00058... Test loss: 0.00083\n",
      "Epoch: 1... Training loss: 0.00056... Test loss: 0.00046\n",
      "Epoch: 1... Training loss: 0.00053... Test loss: 0.00058\n",
      "Epoch: 1... Training loss: 0.00051... Test loss: 0.00063\n",
      "Epoch: 1... Training loss: 0.00048... Test loss: 0.00055\n",
      "Epoch: 1... Training loss: 0.00043... Test loss: 0.00055\n",
      "Epoch: 1... Training loss: 0.00041... Test loss: 0.00045\n",
      "Epoch: 1... Training loss: 0.00041... Test loss: 0.00052\n",
      "Epoch: 1... Training loss: 0.00041... Test loss: 0.00035\n",
      "Epoch: 1... Training loss: 0.0004... Test loss: 0.00038\n",
      "Epoch: 1... Training loss: 0.00032... Test loss: 0.00046\n",
      "Epoch: 1... Training loss: 0.00036... Test loss: 0.00039\n",
      "Epoch: 1... Training loss: 0.00032... Test loss: 0.00043\n",
      "Epoch: 1... Training loss: 0.00031... Test loss: 0.00036\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00037\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.0004\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00026... Test loss: 0.00036\n",
      "Epoch: 1... Training loss: 0.00026... Test loss: 0.00024\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00035\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00024\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00024\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 8e-05\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 8e-05\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 6e-05\n",
      "Epoch: 1... Training loss: 8e-05... Test loss: 7e-05\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 8e-05\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 8e-05\n",
      "Epoch: 1... Training loss: 8e-05... Test loss: 7e-05\n",
      "Epoch: 1... Training loss: 7e-05... Test loss: 9e-05\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 9e-05\n",
      "255.48774844506988\n"
     ]
    }
   ],
   "source": [
    "loss_list = []\n",
    "\n",
    "for k in range(50):\n",
    "\n",
    "    model = im2spec((image_patch, image_patch), 64, 10)\n",
    "    error_predictor = rewards_model(10).to(device)\n",
    "    criterion = torch.nn.MSELoss()\n",
    "    optimizer = optim.Adam(error_predictor.parameters(), lr=0.01)\n",
    "    env = environment(pola, image, spectra, model, start, image_patch, image_size)\n",
    "\n",
    "    for i in range(initialize):\n",
    "        env.update_pos()\n",
    "        env.step(1, False)\n",
    "        \n",
    "    for j in range(10*initialize):\n",
    "        err_train(env.X, env.reward, criterion, optimizer, autoencoder)\n",
    "\n",
    "    count = 0\n",
    "    while env.num_measure < 200:\n",
    "        env.update_pos()\n",
    "        \n",
    "        r_set = np.array(error_predictor(feature_extractor(autoencoder, np.array(env.all_X[-10:]))).detach())\n",
    "        r_set = r_set.reshape(r_set.shape[0])\n",
    "        \n",
    "        if error_predictor(feature_extractor(autoencoder, np.array([env.all_X[-1]]))).item() < (r_set.mean() + 2*r_set.std()*np.exp(-1*count /100)):\n",
    "            action = 0\n",
    "            count += 1\n",
    "        else:\n",
    "            count = 0\n",
    "            action = 1\n",
    "            for j in range(10):\n",
    "                ind_initial = random.sample(list(range(0, initialize)), 5)\n",
    "                X_initial = list(np.array(env.X)[ind_initial, :, :])\n",
    "                reward_initial = list(env.reward[ind_initial])\n",
    "                \n",
    "                ind_middle = random.sample(list(range(min(initialize, len(env.X) - 5), len(env.X))), 5)\n",
    "                X_middle = list(np.array(env.X)[ind_middle, :, :])\n",
    "                reward_middle = list(env.reward[ind_middle])\n",
    "\n",
    "                err_train(np.array(env.X[-10:] + X_initial + X_middle), list(env.reward[-10:]) + reward_initial + reward_middle, criterion, optimizer, autoencoder)\n",
    "\n",
    "        env.step(action, True)\n",
    "\n",
    "    y_pred = model(torch.tensor(X))\n",
    "    \n",
    "    err = np.zeros([100 - 2*radius, 100 - 2*radius])\n",
    "    for i in range(len(pos_X)):\n",
    "        err[pos_X[i][0]-radius, pos_X[i][1]-radius] = (((y_pred - torch.tensor(y))**2).sum(axis = 2)/y.shape[2]).reshape((100 - 2*radius)**2)[i]\n",
    "\n",
    "    err_pred_tensor = error_predictor(feature_extractor(model, X)).reshape(X.shape[0])\n",
    "    err_pred = np.zeros([100 - 2*radius, 100 - 2*radius])\n",
    "    for i in range(len(pos_X)):\n",
    "        err_pred[pos_X[i][0]-radius, pos_X[i][1]-radius] = err_pred_tensor[i]\n",
    "    \n",
    "    loss = err.sum()\n",
    "    print(loss)\n",
    "    \n",
    "    loss_list.append(loss)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(err, cmap='hot', interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.24475690722465515"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "err.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1... Training loss: 1.24475... Test loss: 0.56937\n",
      "Epoch: 1... Training loss: 0.6063... Test loss: 0.23719\n",
      "Epoch: 1... Training loss: 0.34113... Test loss: 0.14495\n",
      "Epoch: 1... Training loss: 0.22925... Test loss: 0.09614\n",
      "Epoch: 1... Training loss: 0.16437... Test loss: 0.08131\n",
      "Epoch: 1... Training loss: 0.13068... Test loss: 0.03963\n",
      "Epoch: 1... Training loss: 0.1096... Test loss: 0.04332\n",
      "Epoch: 1... Training loss: 0.09254... Test loss: 0.06471\n",
      "Epoch: 1... Training loss: 0.08161... Test loss: 0.02278\n",
      "Epoch: 1... Training loss: 0.07106... Test loss: 0.03718\n",
      "Epoch: 1... Training loss: 0.06353... Test loss: 0.03105\n",
      "Epoch: 1... Training loss: 0.05745... Test loss: 0.04818\n",
      "Epoch: 1... Training loss: 0.0516... Test loss: 0.01551\n",
      "Epoch: 1... Training loss: 0.04569... Test loss: 0.03497\n",
      "Epoch: 1... Training loss: 0.04173... Test loss: 0.02558\n",
      "Epoch: 1... Training loss: 0.03814... Test loss: 0.01139\n",
      "Epoch: 1... Training loss: 0.03679... Test loss: 0.04196\n",
      "Epoch: 1... Training loss: 0.03388... Test loss: 0.00857\n",
      "Epoch: 1... Training loss: 0.03205... Test loss: 0.03536\n",
      "Epoch: 1... Training loss: 0.02908... Test loss: 0.01224\n",
      "Epoch: 1... Training loss: 0.02682... Test loss: 0.02768\n",
      "Epoch: 1... Training loss: 0.02478... Test loss: 0.01221\n",
      "Epoch: 1... Training loss: 0.02348... Test loss: 0.03064\n",
      "Epoch: 1... Training loss: 0.02234... Test loss: 0.00848\n",
      "Epoch: 1... Training loss: 0.0215... Test loss: 0.02739\n",
      "Epoch: 1... Training loss: 0.02099... Test loss: 0.0175\n",
      "Epoch: 1... Training loss: 0.02043... Test loss: 0.00947\n",
      "Epoch: 1... Training loss: 0.01853... Test loss: 0.02075\n",
      "Epoch: 1... Training loss: 0.01791... Test loss: 0.01354\n",
      "Epoch: 1... Training loss: 0.01729... Test loss: 0.01604\n",
      "Epoch: 1... Training loss: 0.01676... Test loss: 0.01236\n",
      "Epoch: 1... Training loss: 0.01641... Test loss: 0.01086\n",
      "Epoch: 1... Training loss: 0.01582... Test loss: 0.01042\n",
      "Epoch: 1... Training loss: 0.01487... Test loss: 0.01828\n",
      "Epoch: 1... Training loss: 0.01432... Test loss: 0.00776\n",
      "Epoch: 1... Training loss: 0.0138... Test loss: 0.01586\n",
      "Epoch: 1... Training loss: 0.01297... Test loss: 0.00751\n",
      "Epoch: 1... Training loss: 0.01272... Test loss: 0.01727\n",
      "Epoch: 1... Training loss: 0.01206... Test loss: 0.01061\n",
      "Epoch: 1... Training loss: 0.01165... Test loss: 0.01288\n",
      "Epoch: 1... Training loss: 0.01121... Test loss: 0.01439\n",
      "Epoch: 1... Training loss: 0.01098... Test loss: 0.00798\n",
      "Epoch: 1... Training loss: 0.01064... Test loss: 0.01158\n",
      "Epoch: 1... Training loss: 0.01012... Test loss: 0.00812\n",
      "Epoch: 1... Training loss: 0.00985... Test loss: 0.01116\n",
      "Epoch: 1... Training loss: 0.00964... Test loss: 0.00702\n",
      "Epoch: 1... Training loss: 0.00936... Test loss: 0.01063\n",
      "Epoch: 1... Training loss: 0.00896... Test loss: 0.00994\n",
      "Epoch: 1... Training loss: 0.00878... Test loss: 0.00984\n",
      "Epoch: 1... Training loss: 0.00853... Test loss: 0.01119\n",
      "Epoch: 1... Training loss: 0.00823... Test loss: 0.00799\n",
      "Epoch: 1... Training loss: 0.00799... Test loss: 0.01034\n",
      "Epoch: 1... Training loss: 0.00778... Test loss: 0.00644\n",
      "Epoch: 1... Training loss: 0.00759... Test loss: 0.01041\n",
      "Epoch: 1... Training loss: 0.00737... Test loss: 0.00773\n",
      "Epoch: 1... Training loss: 0.00717... Test loss: 0.00919\n",
      "Epoch: 1... Training loss: 0.00696... Test loss: 0.00825\n",
      "Epoch: 1... Training loss: 0.00677... Test loss: 0.00819\n",
      "Epoch: 1... Training loss: 0.00651... Test loss: 0.00675\n",
      "Epoch: 1... Training loss: 0.00634... Test loss: 0.0074\n",
      "Epoch: 1... Training loss: 0.00615... Test loss: 0.00604\n",
      "Epoch: 1... Training loss: 0.00601... Test loss: 0.00726\n",
      "Epoch: 1... Training loss: 0.00589... Test loss: 0.00485\n",
      "Epoch: 1... Training loss: 0.00578... Test loss: 0.00655\n",
      "Epoch: 1... Training loss: 0.01458... Test loss: 0.00765\n",
      "Epoch: 1... Training loss: 0.00971... Test loss: 0.01332\n",
      "Epoch: 1... Training loss: 0.01303... Test loss: 0.01218\n",
      "Epoch: 1... Training loss: 0.0099... Test loss: 0.01231\n",
      "Epoch: 1... Training loss: 0.00919... Test loss: 0.01136\n",
      "Epoch: 1... Training loss: 0.01043... Test loss: 0.0119\n",
      "Epoch: 1... Training loss: 0.00947... Test loss: 0.01367\n",
      "Epoch: 1... Training loss: 0.00917... Test loss: 0.0115\n",
      "Epoch: 1... Training loss: 0.00828... Test loss: 0.01013\n",
      "Epoch: 1... Training loss: 0.00842... Test loss: 0.00959\n",
      "Epoch: 1... Training loss: 0.00933... Test loss: 0.00918\n",
      "Epoch: 1... Training loss: 0.00837... Test loss: 0.01221\n",
      "Epoch: 1... Training loss: 0.00754... Test loss: 0.0092\n",
      "Epoch: 1... Training loss: 0.00711... Test loss: 0.01083\n",
      "Epoch: 1... Training loss: 0.00723... Test loss: 0.0086\n",
      "Epoch: 1... Training loss: 0.007... Test loss: 0.01092\n",
      "Epoch: 1... Training loss: 0.0066... Test loss: 0.00745\n",
      "Epoch: 1... Training loss: 0.00679... Test loss: 0.00953\n",
      "Epoch: 1... Training loss: 0.00633... Test loss: 0.00744\n",
      "Epoch: 1... Training loss: 0.00634... Test loss: 0.00653\n",
      "Epoch: 1... Training loss: 0.00573... Test loss: 0.00739\n",
      "Epoch: 1... Training loss: 0.00602... Test loss: 0.00608\n",
      "Epoch: 1... Training loss: 0.00572... Test loss: 0.0082\n",
      "Epoch: 1... Training loss: 0.00562... Test loss: 0.00561\n",
      "Epoch: 1... Training loss: 0.00517... Test loss: 0.00746\n",
      "Epoch: 1... Training loss: 0.00541... Test loss: 0.00542\n",
      "Epoch: 1... Training loss: 0.00501... Test loss: 0.0057\n",
      "Epoch: 1... Training loss: 0.00479... Test loss: 0.00498\n",
      "Epoch: 1... Training loss: 0.00508... Test loss: 0.00536\n",
      "Epoch: 1... Training loss: 0.0047... Test loss: 0.00502\n",
      "Epoch: 1... Training loss: 0.00446... Test loss: 0.0043\n",
      "Epoch: 1... Training loss: 0.00434... Test loss: 0.00505\n",
      "Epoch: 1... Training loss: 0.00417... Test loss: 0.00438\n",
      "Epoch: 1... Training loss: 0.00414... Test loss: 0.00444\n",
      "Epoch: 1... Training loss: 0.00406... Test loss: 0.00417\n",
      "Epoch: 1... Training loss: 0.00381... Test loss: 0.00428\n",
      "Epoch: 1... Training loss: 0.00381... Test loss: 0.00446\n",
      "Epoch: 1... Training loss: 0.00356... Test loss: 0.00395\n",
      "Epoch: 1... Training loss: 0.00366... Test loss: 0.0042\n",
      "Epoch: 1... Training loss: 0.00342... Test loss: 0.00438\n",
      "Epoch: 1... Training loss: 0.00349... Test loss: 0.0036\n",
      "Epoch: 1... Training loss: 0.00332... Test loss: 0.00433\n",
      "Epoch: 1... Training loss: 0.00328... Test loss: 0.00382\n",
      "Epoch: 1... Training loss: 0.00313... Test loss: 0.00404\n",
      "Epoch: 1... Training loss: 0.0031... Test loss: 0.00381\n",
      "Epoch: 1... Training loss: 0.00308... Test loss: 0.00358\n",
      "Epoch: 1... Training loss: 0.00307... Test loss: 0.00337\n",
      "Epoch: 1... Training loss: 0.00296... Test loss: 0.00342\n",
      "Epoch: 1... Training loss: 0.00289... Test loss: 0.003\n",
      "Epoch: 1... Training loss: 0.00274... Test loss: 0.00327\n",
      "Epoch: 1... Training loss: 0.00277... Test loss: 0.00246\n",
      "Epoch: 1... Training loss: 0.00251... Test loss: 0.00315\n",
      "Epoch: 1... Training loss: 0.00256... Test loss: 0.00243\n",
      "Epoch: 1... Training loss: 0.00248... Test loss: 0.00303\n",
      "Epoch: 1... Training loss: 0.00234... Test loss: 0.00244\n",
      "Epoch: 1... Training loss: 0.00236... Test loss: 0.00275\n",
      "Epoch: 1... Training loss: 0.0023... Test loss: 0.00227\n",
      "Epoch: 1... Training loss: 0.00232... Test loss: 0.00266\n",
      "Epoch: 1... Training loss: 0.00215... Test loss: 0.00205\n",
      "Epoch: 1... Training loss: 0.00212... Test loss: 0.00253\n",
      "Epoch: 1... Training loss: 0.0021... Test loss: 0.00217\n",
      "Epoch: 1... Training loss: 0.00195... Test loss: 0.00214\n",
      "Epoch: 1... Training loss: 0.00185... Test loss: 0.00206\n",
      "Epoch: 1... Training loss: 0.00188... Test loss: 0.00185\n",
      "Epoch: 1... Training loss: 0.00182... Test loss: 0.00207\n",
      "Epoch: 1... Training loss: 0.0018... Test loss: 0.00175\n",
      "Epoch: 1... Training loss: 0.00174... Test loss: 0.00209\n",
      "Epoch: 1... Training loss: 0.00178... Test loss: 0.00183\n",
      "Epoch: 1... Training loss: 0.00167... Test loss: 0.00166\n",
      "Epoch: 1... Training loss: 0.00171... Test loss: 0.00187\n",
      "Epoch: 1... Training loss: 0.00162... Test loss: 0.0015\n",
      "Epoch: 1... Training loss: 0.00157... Test loss: 0.00177\n",
      "Epoch: 1... Training loss: 0.00156... Test loss: 0.00149\n",
      "Epoch: 1... Training loss: 0.00145... Test loss: 0.00153\n",
      "Epoch: 1... Training loss: 0.00146... Test loss: 0.00143\n",
      "Epoch: 1... Training loss: 0.00142... Test loss: 0.00149\n",
      "Epoch: 1... Training loss: 0.0014... Test loss: 0.00145\n",
      "Epoch: 1... Training loss: 0.00136... Test loss: 0.00155\n",
      "Epoch: 1... Training loss: 0.00129... Test loss: 0.00142\n",
      "Epoch: 1... Training loss: 0.0013... Test loss: 0.00136\n",
      "Epoch: 1... Training loss: 0.00124... Test loss: 0.00146\n",
      "Epoch: 1... Training loss: 0.00123... Test loss: 0.00111\n",
      "Epoch: 1... Training loss: 0.00118... Test loss: 0.00137\n",
      "Epoch: 1... Training loss: 0.00117... Test loss: 0.00112\n",
      "Epoch: 1... Training loss: 0.00107... Test loss: 0.00134\n",
      "Epoch: 1... Training loss: 0.00106... Test loss: 0.0011\n",
      "Epoch: 1... Training loss: 0.00104... Test loss: 0.00118\n",
      "Epoch: 1... Training loss: 0.00098... Test loss: 0.00102\n",
      "Epoch: 1... Training loss: 0.00107... Test loss: 0.0011\n",
      "Epoch: 1... Training loss: 0.00098... Test loss: 0.00108\n",
      "Epoch: 1... Training loss: 0.001... Test loss: 0.00112\n",
      "Epoch: 1... Training loss: 0.00096... Test loss: 0.00109\n",
      "Epoch: 1... Training loss: 0.00086... Test loss: 0.00105\n",
      "Epoch: 1... Training loss: 0.00092... Test loss: 0.00084\n",
      "Epoch: 1... Training loss: 0.00081... Test loss: 0.0008\n",
      "Epoch: 1... Training loss: 0.00077... Test loss: 0.00087\n",
      "Epoch: 1... Training loss: 0.00076... Test loss: 0.00085\n",
      "Epoch: 1... Training loss: 0.00073... Test loss: 0.00086\n",
      "Epoch: 1... Training loss: 0.00075... Test loss: 0.00069\n",
      "Epoch: 1... Training loss: 0.0007... Test loss: 0.00076\n",
      "Epoch: 1... Training loss: 0.00067... Test loss: 0.00064\n",
      "Epoch: 1... Training loss: 0.00062... Test loss: 0.00082\n",
      "Epoch: 1... Training loss: 0.0006... Test loss: 0.00068\n",
      "Epoch: 1... Training loss: 0.00058... Test loss: 0.00074\n",
      "Epoch: 1... Training loss: 0.00057... Test loss: 0.00064\n",
      "Epoch: 1... Training loss: 0.00052... Test loss: 0.00069\n",
      "Epoch: 1... Training loss: 0.00055... Test loss: 0.00051\n",
      "Epoch: 1... Training loss: 0.00059... Test loss: 0.00063\n",
      "Epoch: 1... Training loss: 0.00051... Test loss: 0.0005\n",
      "Epoch: 1... Training loss: 0.00044... Test loss: 0.00061\n",
      "Epoch: 1... Training loss: 0.00045... Test loss: 0.00047\n",
      "Epoch: 1... Training loss: 0.00042... Test loss: 0.00055\n",
      "Epoch: 1... Training loss: 0.00047... Test loss: 0.00044\n",
      "Epoch: 1... Training loss: 0.00045... Test loss: 0.00047\n",
      "Epoch: 1... Training loss: 0.00043... Test loss: 0.00044\n",
      "Epoch: 1... Training loss: 0.00041... Test loss: 0.00039\n",
      "Epoch: 1... Training loss: 0.00039... Test loss: 0.00045\n",
      "Epoch: 1... Training loss: 0.00037... Test loss: 0.00043\n",
      "Epoch: 1... Training loss: 0.00035... Test loss: 0.00031\n",
      "Epoch: 1... Training loss: 0.00032... Test loss: 0.00041\n",
      "Epoch: 1... Training loss: 0.00031... Test loss: 0.0003\n",
      "Epoch: 1... Training loss: 0.00036... Test loss: 0.00031\n",
      "Epoch: 1... Training loss: 0.00029... Test loss: 0.00028\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00033\n",
      "Epoch: 1... Training loss: 0.00026... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.0003\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00028\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00013\n",
      "251.27578422095394\n",
      "Epoch: 1... Training loss: 1.13394... Test loss: 0.47175\n",
      "Epoch: 1... Training loss: 0.57208... Test loss: 0.24526\n",
      "Epoch: 1... Training loss: 0.33089... Test loss: 0.10988\n",
      "Epoch: 1... Training loss: 0.21645... Test loss: 0.07929\n",
      "Epoch: 1... Training loss: 0.15186... Test loss: 0.06484\n",
      "Epoch: 1... Training loss: 0.11738... Test loss: 0.03369\n",
      "Epoch: 1... Training loss: 0.09124... Test loss: 0.03289\n",
      "Epoch: 1... Training loss: 0.077... Test loss: 0.0207\n",
      "Epoch: 1... Training loss: 0.06909... Test loss: 0.01712\n",
      "Epoch: 1... Training loss: 0.06042... Test loss: 0.02043\n",
      "Epoch: 1... Training loss: 0.05574... Test loss: 0.01375\n",
      "Epoch: 1... Training loss: 0.04754... Test loss: 0.02266\n",
      "Epoch: 1... Training loss: 0.04303... Test loss: 0.00995\n",
      "Epoch: 1... Training loss: 0.04028... Test loss: 0.01647\n",
      "Epoch: 1... Training loss: 0.03692... Test loss: 0.0124\n",
      "Epoch: 1... Training loss: 0.03477... Test loss: 0.018\n",
      "Epoch: 1... Training loss: 0.03258... Test loss: 0.00885\n",
      "Epoch: 1... Training loss: 0.03076... Test loss: 0.02025\n",
      "Epoch: 1... Training loss: 0.02921... Test loss: 0.01295\n",
      "Epoch: 1... Training loss: 0.02804... Test loss: 0.00618\n",
      "Epoch: 1... Training loss: 0.02594... Test loss: 0.01622\n",
      "Epoch: 1... Training loss: 0.02502... Test loss: 0.00706\n",
      "Epoch: 1... Training loss: 0.02421... Test loss: 0.01347\n",
      "Epoch: 1... Training loss: 0.02257... Test loss: 0.0111\n",
      "Epoch: 1... Training loss: 0.02173... Test loss: 0.01441\n",
      "Epoch: 1... Training loss: 0.0209... Test loss: 0.00722\n",
      "Epoch: 1... Training loss: 0.02006... Test loss: 0.01612\n",
      "Epoch: 1... Training loss: 0.01879... Test loss: 0.00733\n",
      "Epoch: 1... Training loss: 0.0183... Test loss: 0.01664\n",
      "Epoch: 1... Training loss: 0.01774... Test loss: 0.01032\n",
      "Epoch: 1... Training loss: 0.01689... Test loss: 0.01868\n",
      "Epoch: 1... Training loss: 0.01658... Test loss: 0.00857\n",
      "Epoch: 1... Training loss: 0.016... Test loss: 0.01728\n",
      "Epoch: 1... Training loss: 0.01568... Test loss: 0.00643\n",
      "Epoch: 1... Training loss: 0.01458... Test loss: 0.01476\n",
      "Epoch: 1... Training loss: 0.01424... Test loss: 0.00652\n",
      "Epoch: 1... Training loss: 0.01344... Test loss: 0.01342\n",
      "Epoch: 1... Training loss: 0.01293... Test loss: 0.00722\n",
      "Epoch: 1... Training loss: 0.01216... Test loss: 0.01225\n",
      "Epoch: 1... Training loss: 0.01183... Test loss: 0.00899\n",
      "Epoch: 1... Training loss: 0.01151... Test loss: 0.01059\n",
      "Epoch: 1... Training loss: 0.01114... Test loss: 0.0098\n",
      "Epoch: 1... Training loss: 0.01066... Test loss: 0.00724\n",
      "Epoch: 1... Training loss: 0.01052... Test loss: 0.01064\n",
      "Epoch: 1... Training loss: 0.01006... Test loss: 0.00719\n",
      "Epoch: 1... Training loss: 0.00987... Test loss: 0.0102\n",
      "Epoch: 1... Training loss: 0.00939... Test loss: 0.00669\n",
      "Epoch: 1... Training loss: 0.00926... Test loss: 0.00987\n",
      "Epoch: 1... Training loss: 0.00897... Test loss: 0.00722\n",
      "Epoch: 1... Training loss: 0.00882... Test loss: 0.01034\n",
      "Epoch: 1... Training loss: 0.00853... Test loss: 0.0062\n",
      "Epoch: 1... Training loss: 0.00838... Test loss: 0.01021\n",
      "Epoch: 1... Training loss: 0.00818... Test loss: 0.00651\n",
      "Epoch: 1... Training loss: 0.00805... Test loss: 0.00911\n",
      "Epoch: 1... Training loss: 0.00782... Test loss: 0.00605\n",
      "Epoch: 1... Training loss: 0.00777... Test loss: 0.00827\n",
      "Epoch: 1... Training loss: 0.0075... Test loss: 0.00599\n",
      "Epoch: 1... Training loss: 0.0074... Test loss: 0.00752\n",
      "Epoch: 1... Training loss: 0.00715... Test loss: 0.00609\n",
      "Epoch: 1... Training loss: 0.00708... Test loss: 0.00709\n",
      "Epoch: 1... Training loss: 0.00682... Test loss: 0.00613\n",
      "Epoch: 1... Training loss: 0.00664... Test loss: 0.0068\n",
      "Epoch: 1... Training loss: 0.00645... Test loss: 0.00546\n",
      "Epoch: 1... Training loss: 0.00626... Test loss: 0.00627\n",
      "Epoch: 1... Training loss: 0.01481... Test loss: 0.01089\n",
      "Epoch: 1... Training loss: 0.01347... Test loss: 0.01469\n",
      "Epoch: 1... Training loss: 0.01267... Test loss: 0.03254\n",
      "Epoch: 1... Training loss: 0.01049... Test loss: 0.01449\n",
      "Epoch: 1... Training loss: 0.01063... Test loss: 0.02137\n",
      "Epoch: 1... Training loss: 0.0104... Test loss: 0.01663\n",
      "Epoch: 1... Training loss: 0.00959... Test loss: 0.01807\n",
      "Epoch: 1... Training loss: 0.00971... Test loss: 0.01377\n",
      "Epoch: 1... Training loss: 0.0095... Test loss: 0.01233\n",
      "Epoch: 1... Training loss: 0.0096... Test loss: 0.0125\n",
      "Epoch: 1... Training loss: 0.00946... Test loss: 0.0106\n",
      "Epoch: 1... Training loss: 0.00808... Test loss: 0.01159\n",
      "Epoch: 1... Training loss: 0.00798... Test loss: 0.00886\n",
      "Epoch: 1... Training loss: 0.00783... Test loss: 0.01179\n",
      "Epoch: 1... Training loss: 0.00782... Test loss: 0.00757\n",
      "Epoch: 1... Training loss: 0.00806... Test loss: 0.01124\n",
      "Epoch: 1... Training loss: 0.00728... Test loss: 0.00763\n",
      "Epoch: 1... Training loss: 0.00722... Test loss: 0.0102\n",
      "Epoch: 1... Training loss: 0.00685... Test loss: 0.00809\n",
      "Epoch: 1... Training loss: 0.00651... Test loss: 0.00787\n",
      "Epoch: 1... Training loss: 0.00632... Test loss: 0.00809\n",
      "Epoch: 1... Training loss: 0.00626... Test loss: 0.00745\n",
      "Epoch: 1... Training loss: 0.00597... Test loss: 0.00762\n",
      "Epoch: 1... Training loss: 0.00577... Test loss: 0.006\n",
      "Epoch: 1... Training loss: 0.00553... Test loss: 0.00722\n",
      "Epoch: 1... Training loss: 0.00551... Test loss: 0.00492\n",
      "Epoch: 1... Training loss: 0.00545... Test loss: 0.00864\n",
      "Epoch: 1... Training loss: 0.00543... Test loss: 0.00543\n",
      "Epoch: 1... Training loss: 0.00516... Test loss: 0.00626\n",
      "Epoch: 1... Training loss: 0.00495... Test loss: 0.00505\n",
      "Epoch: 1... Training loss: 0.00492... Test loss: 0.00582\n",
      "Epoch: 1... Training loss: 0.00482... Test loss: 0.00526\n",
      "Epoch: 1... Training loss: 0.00455... Test loss: 0.00582\n",
      "Epoch: 1... Training loss: 0.00442... Test loss: 0.0053\n",
      "Epoch: 1... Training loss: 0.00422... Test loss: 0.00489\n",
      "Epoch: 1... Training loss: 0.00423... Test loss: 0.00455\n",
      "Epoch: 1... Training loss: 0.0041... Test loss: 0.00512\n",
      "Epoch: 1... Training loss: 0.00407... Test loss: 0.00492\n",
      "Epoch: 1... Training loss: 0.00385... Test loss: 0.00434\n",
      "Epoch: 1... Training loss: 0.00388... Test loss: 0.00523\n",
      "Epoch: 1... Training loss: 0.00379... Test loss: 0.00442\n",
      "Epoch: 1... Training loss: 0.00389... Test loss: 0.00466\n",
      "Epoch: 1... Training loss: 0.00364... Test loss: 0.00398\n",
      "Epoch: 1... Training loss: 0.00346... Test loss: 0.00418\n",
      "Epoch: 1... Training loss: 0.00347... Test loss: 0.00402\n",
      "Epoch: 1... Training loss: 0.00326... Test loss: 0.00421\n",
      "Epoch: 1... Training loss: 0.00329... Test loss: 0.00404\n",
      "Epoch: 1... Training loss: 0.0032... Test loss: 0.00384\n",
      "Epoch: 1... Training loss: 0.00319... Test loss: 0.0035\n",
      "Epoch: 1... Training loss: 0.00323... Test loss: 0.00365\n",
      "Epoch: 1... Training loss: 0.00306... Test loss: 0.00331\n",
      "Epoch: 1... Training loss: 0.00293... Test loss: 0.00355\n",
      "Epoch: 1... Training loss: 0.00279... Test loss: 0.00294\n",
      "Epoch: 1... Training loss: 0.00282... Test loss: 0.00333\n",
      "Epoch: 1... Training loss: 0.00269... Test loss: 0.00304\n",
      "Epoch: 1... Training loss: 0.00271... Test loss: 0.00291\n",
      "Epoch: 1... Training loss: 0.00276... Test loss: 0.00285\n",
      "Epoch: 1... Training loss: 0.00247... Test loss: 0.00288\n",
      "Epoch: 1... Training loss: 0.00244... Test loss: 0.00269\n",
      "Epoch: 1... Training loss: 0.0024... Test loss: 0.00261\n",
      "Epoch: 1... Training loss: 0.00232... Test loss: 0.00267\n",
      "Epoch: 1... Training loss: 0.00232... Test loss: 0.00281\n",
      "Epoch: 1... Training loss: 0.00223... Test loss: 0.00268\n",
      "Epoch: 1... Training loss: 0.00238... Test loss: 0.00243\n",
      "Epoch: 1... Training loss: 0.00217... Test loss: 0.00233\n",
      "Epoch: 1... Training loss: 0.00213... Test loss: 0.00219\n",
      "Epoch: 1... Training loss: 0.00197... Test loss: 0.00194\n",
      "Epoch: 1... Training loss: 0.00194... Test loss: 0.00205\n",
      "Epoch: 1... Training loss: 0.00193... Test loss: 0.00191\n",
      "Epoch: 1... Training loss: 0.0019... Test loss: 0.00203\n",
      "Epoch: 1... Training loss: 0.00177... Test loss: 0.00178\n",
      "Epoch: 1... Training loss: 0.00174... Test loss: 0.00178\n",
      "Epoch: 1... Training loss: 0.00176... Test loss: 0.00182\n",
      "Epoch: 1... Training loss: 0.00167... Test loss: 0.00197\n",
      "Epoch: 1... Training loss: 0.00169... Test loss: 0.00177\n",
      "Epoch: 1... Training loss: 0.00164... Test loss: 0.00183\n",
      "Epoch: 1... Training loss: 0.00153... Test loss: 0.00169\n",
      "Epoch: 1... Training loss: 0.0016... Test loss: 0.00171\n",
      "Epoch: 1... Training loss: 0.00145... Test loss: 0.00162\n",
      "Epoch: 1... Training loss: 0.0014... Test loss: 0.00161\n",
      "Epoch: 1... Training loss: 0.00141... Test loss: 0.00149\n",
      "Epoch: 1... Training loss: 0.00132... Test loss: 0.00158\n",
      "Epoch: 1... Training loss: 0.00141... Test loss: 0.00148\n",
      "Epoch: 1... Training loss: 0.00134... Test loss: 0.00135\n",
      "Epoch: 1... Training loss: 0.00123... Test loss: 0.00145\n",
      "Epoch: 1... Training loss: 0.00123... Test loss: 0.00142\n",
      "Epoch: 1... Training loss: 0.00118... Test loss: 0.00132\n",
      "Epoch: 1... Training loss: 0.00113... Test loss: 0.00122\n",
      "Epoch: 1... Training loss: 0.0011... Test loss: 0.00117\n",
      "Epoch: 1... Training loss: 0.00111... Test loss: 0.00124\n",
      "Epoch: 1... Training loss: 0.00105... Test loss: 0.00118\n",
      "Epoch: 1... Training loss: 0.001... Test loss: 0.00115\n",
      "Epoch: 1... Training loss: 0.00098... Test loss: 0.001\n",
      "Epoch: 1... Training loss: 0.00097... Test loss: 0.00107\n",
      "Epoch: 1... Training loss: 0.00092... Test loss: 0.00101\n",
      "Epoch: 1... Training loss: 0.00087... Test loss: 0.00098\n",
      "Epoch: 1... Training loss: 0.00092... Test loss: 0.0009\n",
      "Epoch: 1... Training loss: 0.00098... Test loss: 0.00095\n",
      "Epoch: 1... Training loss: 0.0008... Test loss: 0.00079\n",
      "Epoch: 1... Training loss: 0.0008... Test loss: 0.00097\n",
      "Epoch: 1... Training loss: 0.00076... Test loss: 0.0008\n",
      "Epoch: 1... Training loss: 0.00079... Test loss: 0.00076\n",
      "Epoch: 1... Training loss: 0.00081... Test loss: 0.00073\n",
      "Epoch: 1... Training loss: 0.00072... Test loss: 0.00073\n",
      "Epoch: 1... Training loss: 0.0007... Test loss: 0.00059\n",
      "Epoch: 1... Training loss: 0.00072... Test loss: 0.00071\n",
      "Epoch: 1... Training loss: 0.00073... Test loss: 0.00062\n",
      "Epoch: 1... Training loss: 0.00069... Test loss: 0.00071\n",
      "Epoch: 1... Training loss: 0.00061... Test loss: 0.00069\n",
      "Epoch: 1... Training loss: 0.00059... Test loss: 0.00061\n",
      "Epoch: 1... Training loss: 0.00059... Test loss: 0.00069\n",
      "Epoch: 1... Training loss: 0.00063... Test loss: 0.00063\n",
      "Epoch: 1... Training loss: 0.00054... Test loss: 0.00066\n",
      "Epoch: 1... Training loss: 0.00059... Test loss: 0.00065\n",
      "Epoch: 1... Training loss: 0.00052... Test loss: 0.00063\n",
      "Epoch: 1... Training loss: 0.00054... Test loss: 0.00061\n",
      "Epoch: 1... Training loss: 0.00051... Test loss: 0.00062\n",
      "Epoch: 1... Training loss: 0.00046... Test loss: 0.0005\n",
      "Epoch: 1... Training loss: 0.00042... Test loss: 0.00056\n",
      "Epoch: 1... Training loss: 0.00044... Test loss: 0.00045\n",
      "Epoch: 1... Training loss: 0.00043... Test loss: 0.00052\n",
      "Epoch: 1... Training loss: 0.00042... Test loss: 0.00042\n",
      "Epoch: 1... Training loss: 0.00037... Test loss: 0.00049\n",
      "Epoch: 1... Training loss: 0.00034... Test loss: 0.00035\n",
      "Epoch: 1... Training loss: 0.00033... Test loss: 0.00042\n",
      "Epoch: 1... Training loss: 0.00031... Test loss: 0.00034\n",
      "Epoch: 1... Training loss: 0.00031... Test loss: 0.00039\n",
      "Epoch: 1... Training loss: 0.00034... Test loss: 0.00034\n",
      "Epoch: 1... Training loss: 0.00029... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.00026... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.00029... Test loss: 0.0003\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00018\n",
      "265.3481223251438\n",
      "Epoch: 1... Training loss: 1.14375... Test loss: 0.47532\n",
      "Epoch: 1... Training loss: 0.54655... Test loss: 0.2037\n",
      "Epoch: 1... Training loss: 0.31902... Test loss: 0.11291\n",
      "Epoch: 1... Training loss: 0.23169... Test loss: 0.0709\n",
      "Epoch: 1... Training loss: 0.17007... Test loss: 0.05389\n",
      "Epoch: 1... Training loss: 0.13383... Test loss: 0.05992\n",
      "Epoch: 1... Training loss: 0.11075... Test loss: 0.04739\n",
      "Epoch: 1... Training loss: 0.09403... Test loss: 0.05443\n",
      "Epoch: 1... Training loss: 0.08052... Test loss: 0.05943\n",
      "Epoch: 1... Training loss: 0.0715... Test loss: 0.02127\n",
      "Epoch: 1... Training loss: 0.06526... Test loss: 0.04324\n",
      "Epoch: 1... Training loss: 0.0603... Test loss: 0.02092\n",
      "Epoch: 1... Training loss: 0.0518... Test loss: 0.03667\n",
      "Epoch: 1... Training loss: 0.04617... Test loss: 0.01841\n",
      "Epoch: 1... Training loss: 0.04297... Test loss: 0.02077\n",
      "Epoch: 1... Training loss: 0.04122... Test loss: 0.01826\n",
      "Epoch: 1... Training loss: 0.03755... Test loss: 0.01361\n",
      "Epoch: 1... Training loss: 0.03486... Test loss: 0.02458\n",
      "Epoch: 1... Training loss: 0.03452... Test loss: 0.01676\n",
      "Epoch: 1... Training loss: 0.02994... Test loss: 0.02648\n",
      "Epoch: 1... Training loss: 0.02889... Test loss: 0.01405\n",
      "Epoch: 1... Training loss: 0.02701... Test loss: 0.02088\n",
      "Epoch: 1... Training loss: 0.02605... Test loss: 0.01484\n",
      "Epoch: 1... Training loss: 0.02484... Test loss: 0.01734\n",
      "Epoch: 1... Training loss: 0.02345... Test loss: 0.02026\n",
      "Epoch: 1... Training loss: 0.02288... Test loss: 0.00977\n",
      "Epoch: 1... Training loss: 0.02129... Test loss: 0.01986\n",
      "Epoch: 1... Training loss: 0.02056... Test loss: 0.009\n",
      "Epoch: 1... Training loss: 0.01987... Test loss: 0.01718\n",
      "Epoch: 1... Training loss: 0.01887... Test loss: 0.00917\n",
      "Epoch: 1... Training loss: 0.01818... Test loss: 0.01894\n",
      "Epoch: 1... Training loss: 0.01765... Test loss: 0.01128\n",
      "Epoch: 1... Training loss: 0.01693... Test loss: 0.0189\n",
      "Epoch: 1... Training loss: 0.0165... Test loss: 0.01115\n",
      "Epoch: 1... Training loss: 0.01596... Test loss: 0.01674\n",
      "Epoch: 1... Training loss: 0.0151... Test loss: 0.0104\n",
      "Epoch: 1... Training loss: 0.01454... Test loss: 0.01733\n",
      "Epoch: 1... Training loss: 0.01443... Test loss: 0.00891\n",
      "Epoch: 1... Training loss: 0.0139... Test loss: 0.01537\n",
      "Epoch: 1... Training loss: 0.01317... Test loss: 0.00899\n",
      "Epoch: 1... Training loss: 0.01303... Test loss: 0.01278\n",
      "Epoch: 1... Training loss: 0.0124... Test loss: 0.00823\n",
      "Epoch: 1... Training loss: 0.0121... Test loss: 0.01318\n",
      "Epoch: 1... Training loss: 0.0118... Test loss: 0.00844\n",
      "Epoch: 1... Training loss: 0.01146... Test loss: 0.01205\n",
      "Epoch: 1... Training loss: 0.01101... Test loss: 0.01127\n",
      "Epoch: 1... Training loss: 0.01066... Test loss: 0.01156\n",
      "Epoch: 1... Training loss: 0.01034... Test loss: 0.0112\n",
      "Epoch: 1... Training loss: 0.0101... Test loss: 0.01226\n",
      "Epoch: 1... Training loss: 0.00985... Test loss: 0.01108\n",
      "Epoch: 1... Training loss: 0.00967... Test loss: 0.01\n",
      "Epoch: 1... Training loss: 0.00938... Test loss: 0.01313\n",
      "Epoch: 1... Training loss: 0.0091... Test loss: 0.00906\n",
      "Epoch: 1... Training loss: 0.00884... Test loss: 0.01298\n",
      "Epoch: 1... Training loss: 0.00874... Test loss: 0.00925\n",
      "Epoch: 1... Training loss: 0.00833... Test loss: 0.01071\n",
      "Epoch: 1... Training loss: 0.00818... Test loss: 0.00856\n",
      "Epoch: 1... Training loss: 0.00789... Test loss: 0.00991\n",
      "Epoch: 1... Training loss: 0.00776... Test loss: 0.00739\n",
      "Epoch: 1... Training loss: 0.00754... Test loss: 0.00871\n",
      "Epoch: 1... Training loss: 0.00736... Test loss: 0.00743\n",
      "Epoch: 1... Training loss: 0.00722... Test loss: 0.00793\n",
      "Epoch: 1... Training loss: 0.00703... Test loss: 0.00701\n",
      "Epoch: 1... Training loss: 0.00676... Test loss: 0.00784\n",
      "Epoch: 1... Training loss: 0.01318... Test loss: 0.0173\n",
      "Epoch: 1... Training loss: 0.01429... Test loss: 0.01778\n",
      "Epoch: 1... Training loss: 0.0122... Test loss: 0.01307\n",
      "Epoch: 1... Training loss: 0.0117... Test loss: 0.01346\n",
      "Epoch: 1... Training loss: 0.01216... Test loss: 0.01534\n",
      "Epoch: 1... Training loss: 0.01205... Test loss: 0.01464\n",
      "Epoch: 1... Training loss: 0.01066... Test loss: 0.01457\n",
      "Epoch: 1... Training loss: 0.01065... Test loss: 0.01245\n",
      "Epoch: 1... Training loss: 0.00999... Test loss: 0.01329\n",
      "Epoch: 1... Training loss: 0.01022... Test loss: 0.01064\n",
      "Epoch: 1... Training loss: 0.00973... Test loss: 0.0131\n",
      "Epoch: 1... Training loss: 0.00947... Test loss: 0.01135\n",
      "Epoch: 1... Training loss: 0.0087... Test loss: 0.01256\n",
      "Epoch: 1... Training loss: 0.00837... Test loss: 0.00987\n",
      "Epoch: 1... Training loss: 0.00852... Test loss: 0.01087\n",
      "Epoch: 1... Training loss: 0.00759... Test loss: 0.00921\n",
      "Epoch: 1... Training loss: 0.00817... Test loss: 0.0111\n",
      "Epoch: 1... Training loss: 0.00772... Test loss: 0.01004\n",
      "Epoch: 1... Training loss: 0.00754... Test loss: 0.00947\n",
      "Epoch: 1... Training loss: 0.00693... Test loss: 0.00817\n",
      "Epoch: 1... Training loss: 0.00705... Test loss: 0.00797\n",
      "Epoch: 1... Training loss: 0.00684... Test loss: 0.01052\n",
      "Epoch: 1... Training loss: 0.0064... Test loss: 0.00704\n",
      "Epoch: 1... Training loss: 0.00653... Test loss: 0.00825\n",
      "Epoch: 1... Training loss: 0.00587... Test loss: 0.00593\n",
      "Epoch: 1... Training loss: 0.00594... Test loss: 0.00898\n",
      "Epoch: 1... Training loss: 0.00569... Test loss: 0.00582\n",
      "Epoch: 1... Training loss: 0.00543... Test loss: 0.00703\n",
      "Epoch: 1... Training loss: 0.00552... Test loss: 0.00589\n",
      "Epoch: 1... Training loss: 0.00504... Test loss: 0.00795\n",
      "Epoch: 1... Training loss: 0.00505... Test loss: 0.00558\n",
      "Epoch: 1... Training loss: 0.00497... Test loss: 0.00644\n",
      "Epoch: 1... Training loss: 0.00485... Test loss: 0.00516\n",
      "Epoch: 1... Training loss: 0.00455... Test loss: 0.00548\n",
      "Epoch: 1... Training loss: 0.00462... Test loss: 0.00546\n",
      "Epoch: 1... Training loss: 0.00436... Test loss: 0.00595\n",
      "Epoch: 1... Training loss: 0.00432... Test loss: 0.00532\n",
      "Epoch: 1... Training loss: 0.00421... Test loss: 0.0048\n",
      "Epoch: 1... Training loss: 0.00415... Test loss: 0.00445\n",
      "Epoch: 1... Training loss: 0.00404... Test loss: 0.0052\n",
      "Epoch: 1... Training loss: 0.00399... Test loss: 0.00474\n",
      "Epoch: 1... Training loss: 0.00382... Test loss: 0.00515\n",
      "Epoch: 1... Training loss: 0.0038... Test loss: 0.00363\n",
      "Epoch: 1... Training loss: 0.00362... Test loss: 0.00456\n",
      "Epoch: 1... Training loss: 0.00363... Test loss: 0.00357\n",
      "Epoch: 1... Training loss: 0.00358... Test loss: 0.00521\n",
      "Epoch: 1... Training loss: 0.00352... Test loss: 0.00353\n",
      "Epoch: 1... Training loss: 0.00356... Test loss: 0.00346\n",
      "Epoch: 1... Training loss: 0.00349... Test loss: 0.00284\n",
      "Epoch: 1... Training loss: 0.00335... Test loss: 0.00352\n",
      "Epoch: 1... Training loss: 0.00331... Test loss: 0.00329\n",
      "Epoch: 1... Training loss: 0.0031... Test loss: 0.00361\n",
      "Epoch: 1... Training loss: 0.00314... Test loss: 0.00314\n",
      "Epoch: 1... Training loss: 0.00292... Test loss: 0.00348\n",
      "Epoch: 1... Training loss: 0.00304... Test loss: 0.00331\n",
      "Epoch: 1... Training loss: 0.00283... Test loss: 0.00304\n",
      "Epoch: 1... Training loss: 0.00273... Test loss: 0.00335\n",
      "Epoch: 1... Training loss: 0.00276... Test loss: 0.00304\n",
      "Epoch: 1... Training loss: 0.00269... Test loss: 0.00289\n",
      "Epoch: 1... Training loss: 0.00248... Test loss: 0.00277\n",
      "Epoch: 1... Training loss: 0.00247... Test loss: 0.00293\n",
      "Epoch: 1... Training loss: 0.00247... Test loss: 0.00252\n",
      "Epoch: 1... Training loss: 0.0024... Test loss: 0.00287\n",
      "Epoch: 1... Training loss: 0.0023... Test loss: 0.00202\n",
      "Epoch: 1... Training loss: 0.00222... Test loss: 0.00297\n",
      "Epoch: 1... Training loss: 0.00216... Test loss: 0.00201\n",
      "Epoch: 1... Training loss: 0.00216... Test loss: 0.00256\n",
      "Epoch: 1... Training loss: 0.00206... Test loss: 0.00194\n",
      "Epoch: 1... Training loss: 0.00202... Test loss: 0.00271\n",
      "Epoch: 1... Training loss: 0.00202... Test loss: 0.00196\n",
      "Epoch: 1... Training loss: 0.00203... Test loss: 0.00246\n",
      "Epoch: 1... Training loss: 0.00189... Test loss: 0.00201\n",
      "Epoch: 1... Training loss: 0.00189... Test loss: 0.00203\n",
      "Epoch: 1... Training loss: 0.00184... Test loss: 0.00178\n",
      "Epoch: 1... Training loss: 0.00174... Test loss: 0.00204\n",
      "Epoch: 1... Training loss: 0.00168... Test loss: 0.00178\n",
      "Epoch: 1... Training loss: 0.0017... Test loss: 0.00204\n",
      "Epoch: 1... Training loss: 0.00161... Test loss: 0.00167\n",
      "Epoch: 1... Training loss: 0.00157... Test loss: 0.00188\n",
      "Epoch: 1... Training loss: 0.00145... Test loss: 0.0014\n",
      "Epoch: 1... Training loss: 0.00147... Test loss: 0.00165\n",
      "Epoch: 1... Training loss: 0.00142... Test loss: 0.00146\n",
      "Epoch: 1... Training loss: 0.00135... Test loss: 0.0014\n",
      "Epoch: 1... Training loss: 0.00132... Test loss: 0.00137\n",
      "Epoch: 1... Training loss: 0.00126... Test loss: 0.0016\n",
      "Epoch: 1... Training loss: 0.00127... Test loss: 0.00125\n",
      "Epoch: 1... Training loss: 0.00119... Test loss: 0.00149\n",
      "Epoch: 1... Training loss: 0.00112... Test loss: 0.00121\n",
      "Epoch: 1... Training loss: 0.00108... Test loss: 0.00119\n",
      "Epoch: 1... Training loss: 0.00106... Test loss: 0.0011\n",
      "Epoch: 1... Training loss: 0.00104... Test loss: 0.00101\n",
      "Epoch: 1... Training loss: 0.00106... Test loss: 0.00098\n",
      "Epoch: 1... Training loss: 0.00097... Test loss: 0.00107\n",
      "Epoch: 1... Training loss: 0.00105... Test loss: 0.00093\n",
      "Epoch: 1... Training loss: 0.00095... Test loss: 0.00103\n",
      "Epoch: 1... Training loss: 0.00099... Test loss: 0.00075\n",
      "Epoch: 1... Training loss: 0.00084... Test loss: 0.00105\n",
      "Epoch: 1... Training loss: 0.00082... Test loss: 0.00081\n",
      "Epoch: 1... Training loss: 0.00076... Test loss: 0.00098\n",
      "Epoch: 1... Training loss: 0.00081... Test loss: 0.00077\n",
      "Epoch: 1... Training loss: 0.00077... Test loss: 0.00093\n",
      "Epoch: 1... Training loss: 0.00072... Test loss: 0.00063\n",
      "Epoch: 1... Training loss: 0.00071... Test loss: 0.00074\n",
      "Epoch: 1... Training loss: 0.0007... Test loss: 0.00065\n",
      "Epoch: 1... Training loss: 0.00064... Test loss: 0.00076\n",
      "Epoch: 1... Training loss: 0.00063... Test loss: 0.00066\n",
      "Epoch: 1... Training loss: 0.00063... Test loss: 0.00067\n",
      "Epoch: 1... Training loss: 0.00063... Test loss: 0.00061\n",
      "Epoch: 1... Training loss: 0.00066... Test loss: 0.00068\n",
      "Epoch: 1... Training loss: 0.00057... Test loss: 0.00061\n",
      "Epoch: 1... Training loss: 0.00065... Test loss: 0.00068\n",
      "Epoch: 1... Training loss: 0.00053... Test loss: 0.00051\n",
      "Epoch: 1... Training loss: 0.00054... Test loss: 0.0006\n",
      "Epoch: 1... Training loss: 0.00053... Test loss: 0.00053\n",
      "Epoch: 1... Training loss: 0.00058... Test loss: 0.0006\n",
      "Epoch: 1... Training loss: 0.00056... Test loss: 0.00049\n",
      "Epoch: 1... Training loss: 0.00054... Test loss: 0.00054\n",
      "Epoch: 1... Training loss: 0.0005... Test loss: 0.00053\n",
      "Epoch: 1... Training loss: 0.00061... Test loss: 0.00053\n",
      "Epoch: 1... Training loss: 0.0005... Test loss: 0.00048\n",
      "Epoch: 1... Training loss: 0.00046... Test loss: 0.00042\n",
      "Epoch: 1... Training loss: 0.00044... Test loss: 0.00045\n",
      "Epoch: 1... Training loss: 0.00042... Test loss: 0.00043\n",
      "Epoch: 1... Training loss: 0.00041... Test loss: 0.00041\n",
      "Epoch: 1... Training loss: 0.0004... Test loss: 0.00037\n",
      "Epoch: 1... Training loss: 0.0004... Test loss: 0.00038\n",
      "Epoch: 1... Training loss: 0.00036... Test loss: 0.00033\n",
      "Epoch: 1... Training loss: 0.00034... Test loss: 0.00042\n",
      "Epoch: 1... Training loss: 0.00035... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.00035... Test loss: 0.00035\n",
      "Epoch: 1... Training loss: 0.00032... Test loss: 0.00034\n",
      "Epoch: 1... Training loss: 0.00033... Test loss: 0.00038\n",
      "Epoch: 1... Training loss: 0.00034... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00033... Test loss: 0.00035\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00035\n",
      "Epoch: 1... Training loss: 0.00026... Test loss: 0.00026\n",
      "349.2105051577091\n",
      "Epoch: 1... Training loss: 1.00722... Test loss: 0.37415\n",
      "Epoch: 1... Training loss: 0.46657... Test loss: 0.14744\n",
      "Epoch: 1... Training loss: 0.31448... Test loss: 0.10368\n",
      "Epoch: 1... Training loss: 0.20678... Test loss: 0.06633\n",
      "Epoch: 1... Training loss: 0.14654... Test loss: 0.06252\n",
      "Epoch: 1... Training loss: 0.11227... Test loss: 0.03305\n",
      "Epoch: 1... Training loss: 0.10089... Test loss: 0.05337\n",
      "Epoch: 1... Training loss: 0.07789... Test loss: 0.05333\n",
      "Epoch: 1... Training loss: 0.07102... Test loss: 0.03013\n",
      "Epoch: 1... Training loss: 0.06207... Test loss: 0.06218\n",
      "Epoch: 1... Training loss: 0.05598... Test loss: 0.01926\n",
      "Epoch: 1... Training loss: 0.04691... Test loss: 0.04613\n",
      "Epoch: 1... Training loss: 0.04258... Test loss: 0.01433\n",
      "Epoch: 1... Training loss: 0.03785... Test loss: 0.03624\n",
      "Epoch: 1... Training loss: 0.03591... Test loss: 0.01099\n",
      "Epoch: 1... Training loss: 0.03318... Test loss: 0.01882\n",
      "Epoch: 1... Training loss: 0.02989... Test loss: 0.01762\n",
      "Epoch: 1... Training loss: 0.02836... Test loss: 0.02755\n",
      "Epoch: 1... Training loss: 0.02616... Test loss: 0.00898\n",
      "Epoch: 1... Training loss: 0.02486... Test loss: 0.02502\n",
      "Epoch: 1... Training loss: 0.02357... Test loss: 0.00991\n",
      "Epoch: 1... Training loss: 0.02256... Test loss: 0.02131\n",
      "Epoch: 1... Training loss: 0.02023... Test loss: 0.00959\n",
      "Epoch: 1... Training loss: 0.01989... Test loss: 0.01839\n",
      "Epoch: 1... Training loss: 0.01861... Test loss: 0.00695\n",
      "Epoch: 1... Training loss: 0.01822... Test loss: 0.01803\n",
      "Epoch: 1... Training loss: 0.01725... Test loss: 0.00669\n",
      "Epoch: 1... Training loss: 0.01674... Test loss: 0.01661\n",
      "Epoch: 1... Training loss: 0.01623... Test loss: 0.00856\n",
      "Epoch: 1... Training loss: 0.01506... Test loss: 0.01784\n",
      "Epoch: 1... Training loss: 0.01476... Test loss: 0.00895\n",
      "Epoch: 1... Training loss: 0.01386... Test loss: 0.01434\n",
      "Epoch: 1... Training loss: 0.0137... Test loss: 0.01082\n",
      "Epoch: 1... Training loss: 0.01271... Test loss: 0.0109\n",
      "Epoch: 1... Training loss: 0.01228... Test loss: 0.01199\n",
      "Epoch: 1... Training loss: 0.01162... Test loss: 0.00709\n",
      "Epoch: 1... Training loss: 0.01139... Test loss: 0.01306\n",
      "Epoch: 1... Training loss: 0.01112... Test loss: 0.00833\n",
      "Epoch: 1... Training loss: 0.01078... Test loss: 0.01051\n",
      "Epoch: 1... Training loss: 0.01038... Test loss: 0.00747\n",
      "Epoch: 1... Training loss: 0.01013... Test loss: 0.0086\n",
      "Epoch: 1... Training loss: 0.00973... Test loss: 0.00805\n",
      "Epoch: 1... Training loss: 0.00936... Test loss: 0.00995\n",
      "Epoch: 1... Training loss: 0.00926... Test loss: 0.00634\n",
      "Epoch: 1... Training loss: 0.00877... Test loss: 0.01156\n",
      "Epoch: 1... Training loss: 0.00864... Test loss: 0.00617\n",
      "Epoch: 1... Training loss: 0.00824... Test loss: 0.00986\n",
      "Epoch: 1... Training loss: 0.00797... Test loss: 0.00595\n",
      "Epoch: 1... Training loss: 0.00774... Test loss: 0.00901\n",
      "Epoch: 1... Training loss: 0.00755... Test loss: 0.00481\n",
      "Epoch: 1... Training loss: 0.00722... Test loss: 0.00826\n",
      "Epoch: 1... Training loss: 0.00705... Test loss: 0.00487\n",
      "Epoch: 1... Training loss: 0.00676... Test loss: 0.0081\n",
      "Epoch: 1... Training loss: 0.00676... Test loss: 0.0051\n",
      "Epoch: 1... Training loss: 0.00648... Test loss: 0.00708\n",
      "Epoch: 1... Training loss: 0.00633... Test loss: 0.00603\n",
      "Epoch: 1... Training loss: 0.00621... Test loss: 0.00665\n",
      "Epoch: 1... Training loss: 0.00606... Test loss: 0.0058\n",
      "Epoch: 1... Training loss: 0.00581... Test loss: 0.00672\n",
      "Epoch: 1... Training loss: 0.00574... Test loss: 0.00458\n",
      "Epoch: 1... Training loss: 0.00559... Test loss: 0.00657\n",
      "Epoch: 1... Training loss: 0.00548... Test loss: 0.00411\n",
      "Epoch: 1... Training loss: 0.00536... Test loss: 0.00607\n",
      "Epoch: 1... Training loss: 0.00522... Test loss: 0.00387\n",
      "Epoch: 1... Training loss: 0.00831... Test loss: 0.0131\n",
      "Epoch: 1... Training loss: 0.00984... Test loss: 0.01076\n",
      "Epoch: 1... Training loss: 0.00862... Test loss: 0.00891\n",
      "Epoch: 1... Training loss: 0.01033... Test loss: 0.00968\n",
      "Epoch: 1... Training loss: 0.00878... Test loss: 0.01222\n",
      "Epoch: 1... Training loss: 0.00929... Test loss: 0.00953\n",
      "Epoch: 1... Training loss: 0.00916... Test loss: 0.01055\n",
      "Epoch: 1... Training loss: 0.00834... Test loss: 0.01042\n",
      "Epoch: 1... Training loss: 0.00776... Test loss: 0.01008\n",
      "Epoch: 1... Training loss: 0.00714... Test loss: 0.00922\n",
      "Epoch: 1... Training loss: 0.00709... Test loss: 0.0079\n",
      "Epoch: 1... Training loss: 0.00762... Test loss: 0.00858\n",
      "Epoch: 1... Training loss: 0.00702... Test loss: 0.00813\n",
      "Epoch: 1... Training loss: 0.00702... Test loss: 0.00747\n",
      "Epoch: 1... Training loss: 0.00624... Test loss: 0.00829\n",
      "Epoch: 1... Training loss: 0.00648... Test loss: 0.00659\n",
      "Epoch: 1... Training loss: 0.00673... Test loss: 0.00659\n",
      "Epoch: 1... Training loss: 0.00646... Test loss: 0.00778\n",
      "Epoch: 1... Training loss: 0.00563... Test loss: 0.00688\n",
      "Epoch: 1... Training loss: 0.00637... Test loss: 0.00638\n",
      "Epoch: 1... Training loss: 0.00561... Test loss: 0.00724\n",
      "Epoch: 1... Training loss: 0.00544... Test loss: 0.00689\n",
      "Epoch: 1... Training loss: 0.0054... Test loss: 0.00642\n",
      "Epoch: 1... Training loss: 0.00492... Test loss: 0.00585\n",
      "Epoch: 1... Training loss: 0.00512... Test loss: 0.00563\n",
      "Epoch: 1... Training loss: 0.00492... Test loss: 0.0046\n",
      "Epoch: 1... Training loss: 0.00486... Test loss: 0.00506\n",
      "Epoch: 1... Training loss: 0.00454... Test loss: 0.00508\n",
      "Epoch: 1... Training loss: 0.00465... Test loss: 0.00464\n",
      "Epoch: 1... Training loss: 0.00464... Test loss: 0.00506\n",
      "Epoch: 1... Training loss: 0.00426... Test loss: 0.00426\n",
      "Epoch: 1... Training loss: 0.00423... Test loss: 0.00442\n",
      "Epoch: 1... Training loss: 0.00412... Test loss: 0.00439\n",
      "Epoch: 1... Training loss: 0.00401... Test loss: 0.00421\n",
      "Epoch: 1... Training loss: 0.00403... Test loss: 0.00429\n",
      "Epoch: 1... Training loss: 0.00368... Test loss: 0.00409\n",
      "Epoch: 1... Training loss: 0.00361... Test loss: 0.00392\n",
      "Epoch: 1... Training loss: 0.00349... Test loss: 0.00406\n",
      "Epoch: 1... Training loss: 0.00343... Test loss: 0.00345\n",
      "Epoch: 1... Training loss: 0.00336... Test loss: 0.00391\n",
      "Epoch: 1... Training loss: 0.00331... Test loss: 0.00312\n",
      "Epoch: 1... Training loss: 0.00333... Test loss: 0.00357\n",
      "Epoch: 1... Training loss: 0.0032... Test loss: 0.00304\n",
      "Epoch: 1... Training loss: 0.00321... Test loss: 0.00337\n",
      "Epoch: 1... Training loss: 0.00307... Test loss: 0.00298\n",
      "Epoch: 1... Training loss: 0.00293... Test loss: 0.00325\n",
      "Epoch: 1... Training loss: 0.00283... Test loss: 0.00299\n",
      "Epoch: 1... Training loss: 0.00278... Test loss: 0.00349\n",
      "Epoch: 1... Training loss: 0.00273... Test loss: 0.00267\n",
      "Epoch: 1... Training loss: 0.0026... Test loss: 0.00306\n",
      "Epoch: 1... Training loss: 0.00249... Test loss: 0.0026\n",
      "Epoch: 1... Training loss: 0.00244... Test loss: 0.00235\n",
      "Epoch: 1... Training loss: 0.00241... Test loss: 0.00259\n",
      "Epoch: 1... Training loss: 0.00242... Test loss: 0.00246\n",
      "Epoch: 1... Training loss: 0.00221... Test loss: 0.00265\n",
      "Epoch: 1... Training loss: 0.00222... Test loss: 0.00283\n",
      "Epoch: 1... Training loss: 0.00215... Test loss: 0.0025\n",
      "Epoch: 1... Training loss: 0.00212... Test loss: 0.00259\n",
      "Epoch: 1... Training loss: 0.00203... Test loss: 0.00241\n",
      "Epoch: 1... Training loss: 0.00194... Test loss: 0.00229\n",
      "Epoch: 1... Training loss: 0.00192... Test loss: 0.00229\n",
      "Epoch: 1... Training loss: 0.00188... Test loss: 0.00217\n",
      "Epoch: 1... Training loss: 0.00188... Test loss: 0.00201\n",
      "Epoch: 1... Training loss: 0.00179... Test loss: 0.00205\n",
      "Epoch: 1... Training loss: 0.00182... Test loss: 0.00199\n",
      "Epoch: 1... Training loss: 0.00174... Test loss: 0.00211\n",
      "Epoch: 1... Training loss: 0.00173... Test loss: 0.00188\n",
      "Epoch: 1... Training loss: 0.00165... Test loss: 0.00204\n",
      "Epoch: 1... Training loss: 0.00165... Test loss: 0.00153\n",
      "Epoch: 1... Training loss: 0.00155... Test loss: 0.00199\n",
      "Epoch: 1... Training loss: 0.00163... Test loss: 0.00163\n",
      "Epoch: 1... Training loss: 0.00157... Test loss: 0.00191\n",
      "Epoch: 1... Training loss: 0.00151... Test loss: 0.00156\n",
      "Epoch: 1... Training loss: 0.00143... Test loss: 0.00167\n",
      "Epoch: 1... Training loss: 0.00144... Test loss: 0.00152\n",
      "Epoch: 1... Training loss: 0.00134... Test loss: 0.00162\n",
      "Epoch: 1... Training loss: 0.00144... Test loss: 0.00141\n",
      "Epoch: 1... Training loss: 0.00136... Test loss: 0.00143\n",
      "Epoch: 1... Training loss: 0.00135... Test loss: 0.00137\n",
      "Epoch: 1... Training loss: 0.00129... Test loss: 0.00127\n",
      "Epoch: 1... Training loss: 0.00124... Test loss: 0.00136\n",
      "Epoch: 1... Training loss: 0.00117... Test loss: 0.00112\n",
      "Epoch: 1... Training loss: 0.0012... Test loss: 0.00118\n",
      "Epoch: 1... Training loss: 0.00118... Test loss: 0.00118\n",
      "Epoch: 1... Training loss: 0.00115... Test loss: 0.00124\n",
      "Epoch: 1... Training loss: 0.00116... Test loss: 0.0011\n",
      "Epoch: 1... Training loss: 0.00103... Test loss: 0.00117\n",
      "Epoch: 1... Training loss: 0.00105... Test loss: 0.00107\n",
      "Epoch: 1... Training loss: 0.00097... Test loss: 0.0009\n",
      "Epoch: 1... Training loss: 0.00102... Test loss: 0.00121\n",
      "Epoch: 1... Training loss: 0.00102... Test loss: 0.00085\n",
      "Epoch: 1... Training loss: 0.00089... Test loss: 0.00111\n",
      "Epoch: 1... Training loss: 0.00092... Test loss: 0.00088\n",
      "Epoch: 1... Training loss: 0.00084... Test loss: 0.00092\n",
      "Epoch: 1... Training loss: 0.00084... Test loss: 0.00065\n",
      "Epoch: 1... Training loss: 0.0008... Test loss: 0.00082\n",
      "Epoch: 1... Training loss: 0.00079... Test loss: 0.00073\n",
      "Epoch: 1... Training loss: 0.00079... Test loss: 0.00073\n",
      "Epoch: 1... Training loss: 0.00088... Test loss: 0.00068\n",
      "Epoch: 1... Training loss: 0.00073... Test loss: 0.00065\n",
      "Epoch: 1... Training loss: 0.00076... Test loss: 0.00075\n",
      "Epoch: 1... Training loss: 0.00074... Test loss: 0.0007\n",
      "Epoch: 1... Training loss: 0.00062... Test loss: 0.00064\n",
      "Epoch: 1... Training loss: 0.0007... Test loss: 0.00068\n",
      "Epoch: 1... Training loss: 0.00061... Test loss: 0.00066\n",
      "Epoch: 1... Training loss: 0.00058... Test loss: 0.0006\n",
      "Epoch: 1... Training loss: 0.00066... Test loss: 0.00064\n",
      "Epoch: 1... Training loss: 0.00052... Test loss: 0.00062\n",
      "Epoch: 1... Training loss: 0.00054... Test loss: 0.00052\n",
      "Epoch: 1... Training loss: 0.00048... Test loss: 0.00054\n",
      "Epoch: 1... Training loss: 0.00045... Test loss: 0.00052\n",
      "Epoch: 1... Training loss: 0.00044... Test loss: 0.0005\n",
      "Epoch: 1... Training loss: 0.00042... Test loss: 0.00057\n",
      "Epoch: 1... Training loss: 0.0004... Test loss: 0.00047\n",
      "Epoch: 1... Training loss: 0.00041... Test loss: 0.00042\n",
      "Epoch: 1... Training loss: 0.00033... Test loss: 0.00041\n",
      "Epoch: 1... Training loss: 0.00033... Test loss: 0.00042\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00037\n",
      "Epoch: 1... Training loss: 0.00031... Test loss: 0.00041\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.00033\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.00026... Test loss: 0.00035\n",
      "Epoch: 1... Training loss: 0.00026... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00028\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00013\n",
      "249.96101992757758\n",
      "Epoch: 1... Training loss: 1.20653... Test loss: 0.60278\n",
      "Epoch: 1... Training loss: 0.54082... Test loss: 0.18991\n",
      "Epoch: 1... Training loss: 0.31183... Test loss: 0.11783\n",
      "Epoch: 1... Training loss: 0.20519... Test loss: 0.08376\n",
      "Epoch: 1... Training loss: 0.15802... Test loss: 0.06848\n",
      "Epoch: 1... Training loss: 0.12682... Test loss: 0.05394\n",
      "Epoch: 1... Training loss: 0.10729... Test loss: 0.05565\n",
      "Epoch: 1... Training loss: 0.08731... Test loss: 0.0468\n",
      "Epoch: 1... Training loss: 0.0737... Test loss: 0.04928\n",
      "Epoch: 1... Training loss: 0.06535... Test loss: 0.02319\n",
      "Epoch: 1... Training loss: 0.05808... Test loss: 0.04033\n",
      "Epoch: 1... Training loss: 0.05427... Test loss: 0.0173\n",
      "Epoch: 1... Training loss: 0.04746... Test loss: 0.0351\n",
      "Epoch: 1... Training loss: 0.04439... Test loss: 0.01422\n",
      "Epoch: 1... Training loss: 0.04175... Test loss: 0.0315\n",
      "Epoch: 1... Training loss: 0.03918... Test loss: 0.01714\n",
      "Epoch: 1... Training loss: 0.03652... Test loss: 0.03372\n",
      "Epoch: 1... Training loss: 0.03469... Test loss: 0.01266\n",
      "Epoch: 1... Training loss: 0.03216... Test loss: 0.02953\n",
      "Epoch: 1... Training loss: 0.03106... Test loss: 0.01193\n",
      "Epoch: 1... Training loss: 0.02955... Test loss: 0.02181\n",
      "Epoch: 1... Training loss: 0.02755... Test loss: 0.01663\n",
      "Epoch: 1... Training loss: 0.02631... Test loss: 0.0302\n",
      "Epoch: 1... Training loss: 0.02504... Test loss: 0.01638\n",
      "Epoch: 1... Training loss: 0.02404... Test loss: 0.02567\n",
      "Epoch: 1... Training loss: 0.02337... Test loss: 0.01575\n",
      "Epoch: 1... Training loss: 0.02162... Test loss: 0.02161\n",
      "Epoch: 1... Training loss: 0.02086... Test loss: 0.01615\n",
      "Epoch: 1... Training loss: 0.01968... Test loss: 0.02021\n",
      "Epoch: 1... Training loss: 0.01897... Test loss: 0.01493\n",
      "Epoch: 1... Training loss: 0.01847... Test loss: 0.01814\n",
      "Epoch: 1... Training loss: 0.01696... Test loss: 0.01532\n",
      "Epoch: 1... Training loss: 0.01655... Test loss: 0.01779\n",
      "Epoch: 1... Training loss: 0.01523... Test loss: 0.01228\n",
      "Epoch: 1... Training loss: 0.01475... Test loss: 0.01649\n",
      "Epoch: 1... Training loss: 0.01401... Test loss: 0.01334\n",
      "Epoch: 1... Training loss: 0.01369... Test loss: 0.01581\n",
      "Epoch: 1... Training loss: 0.013... Test loss: 0.01177\n",
      "Epoch: 1... Training loss: 0.01265... Test loss: 0.01563\n",
      "Epoch: 1... Training loss: 0.01225... Test loss: 0.00924\n",
      "Epoch: 1... Training loss: 0.01185... Test loss: 0.01523\n",
      "Epoch: 1... Training loss: 0.01135... Test loss: 0.00863\n",
      "Epoch: 1... Training loss: 0.01116... Test loss: 0.01455\n",
      "Epoch: 1... Training loss: 0.01073... Test loss: 0.00793\n",
      "Epoch: 1... Training loss: 0.01055... Test loss: 0.01217\n",
      "Epoch: 1... Training loss: 0.01049... Test loss: 0.00902\n",
      "Epoch: 1... Training loss: 0.00994... Test loss: 0.01141\n",
      "Epoch: 1... Training loss: 0.00986... Test loss: 0.00803\n",
      "Epoch: 1... Training loss: 0.00951... Test loss: 0.01143\n",
      "Epoch: 1... Training loss: 0.0093... Test loss: 0.0086\n",
      "Epoch: 1... Training loss: 0.0089... Test loss: 0.01107\n",
      "Epoch: 1... Training loss: 0.00855... Test loss: 0.00843\n",
      "Epoch: 1... Training loss: 0.00824... Test loss: 0.01022\n",
      "Epoch: 1... Training loss: 0.00817... Test loss: 0.00829\n",
      "Epoch: 1... Training loss: 0.00787... Test loss: 0.0092\n",
      "Epoch: 1... Training loss: 0.0078... Test loss: 0.00753\n",
      "Epoch: 1... Training loss: 0.00742... Test loss: 0.00829\n",
      "Epoch: 1... Training loss: 0.00721... Test loss: 0.00816\n",
      "Epoch: 1... Training loss: 0.00695... Test loss: 0.00794\n",
      "Epoch: 1... Training loss: 0.00678... Test loss: 0.00819\n",
      "Epoch: 1... Training loss: 0.00649... Test loss: 0.00729\n",
      "Epoch: 1... Training loss: 0.00641... Test loss: 0.00694\n",
      "Epoch: 1... Training loss: 0.00619... Test loss: 0.00654\n",
      "Epoch: 1... Training loss: 0.00603... Test loss: 0.00672\n",
      "Epoch: 1... Training loss: 0.0154... Test loss: 0.01456\n",
      "Epoch: 1... Training loss: 0.01044... Test loss: 0.01199\n",
      "Epoch: 1... Training loss: 0.01222... Test loss: 0.01284\n",
      "Epoch: 1... Training loss: 0.01184... Test loss: 0.01257\n",
      "Epoch: 1... Training loss: 0.00964... Test loss: 0.01141\n",
      "Epoch: 1... Training loss: 0.01101... Test loss: 0.01309\n",
      "Epoch: 1... Training loss: 0.00988... Test loss: 0.01281\n",
      "Epoch: 1... Training loss: 0.00905... Test loss: 0.0119\n",
      "Epoch: 1... Training loss: 0.00939... Test loss: 0.01073\n",
      "Epoch: 1... Training loss: 0.00823... Test loss: 0.0109\n",
      "Epoch: 1... Training loss: 0.00861... Test loss: 0.00907\n",
      "Epoch: 1... Training loss: 0.00854... Test loss: 0.01129\n",
      "Epoch: 1... Training loss: 0.00855... Test loss: 0.00945\n",
      "Epoch: 1... Training loss: 0.00727... Test loss: 0.01023\n",
      "Epoch: 1... Training loss: 0.00776... Test loss: 0.00792\n",
      "Epoch: 1... Training loss: 0.0073... Test loss: 0.00947\n",
      "Epoch: 1... Training loss: 0.0067... Test loss: 0.00807\n",
      "Epoch: 1... Training loss: 0.00685... Test loss: 0.00794\n",
      "Epoch: 1... Training loss: 0.0068... Test loss: 0.00865\n",
      "Epoch: 1... Training loss: 0.0066... Test loss: 0.00831\n",
      "Epoch: 1... Training loss: 0.00626... Test loss: 0.0073\n",
      "Epoch: 1... Training loss: 0.00647... Test loss: 0.0076\n",
      "Epoch: 1... Training loss: 0.00618... Test loss: 0.00603\n",
      "Epoch: 1... Training loss: 0.00595... Test loss: 0.0067\n",
      "Epoch: 1... Training loss: 0.00567... Test loss: 0.00577\n",
      "Epoch: 1... Training loss: 0.00555... Test loss: 0.0064\n",
      "Epoch: 1... Training loss: 0.00518... Test loss: 0.00615\n",
      "Epoch: 1... Training loss: 0.00512... Test loss: 0.00595\n",
      "Epoch: 1... Training loss: 0.00513... Test loss: 0.00584\n",
      "Epoch: 1... Training loss: 0.00482... Test loss: 0.00518\n",
      "Epoch: 1... Training loss: 0.00464... Test loss: 0.00555\n",
      "Epoch: 1... Training loss: 0.0045... Test loss: 0.00481\n",
      "Epoch: 1... Training loss: 0.00459... Test loss: 0.00533\n",
      "Epoch: 1... Training loss: 0.00439... Test loss: 0.00497\n",
      "Epoch: 1... Training loss: 0.0041... Test loss: 0.00483\n",
      "Epoch: 1... Training loss: 0.00418... Test loss: 0.00452\n",
      "Epoch: 1... Training loss: 0.00406... Test loss: 0.00454\n",
      "Epoch: 1... Training loss: 0.00389... Test loss: 0.00443\n",
      "Epoch: 1... Training loss: 0.00387... Test loss: 0.00444\n",
      "Epoch: 1... Training loss: 0.0037... Test loss: 0.00453\n",
      "Epoch: 1... Training loss: 0.00372... Test loss: 0.00434\n",
      "Epoch: 1... Training loss: 0.0035... Test loss: 0.00404\n",
      "Epoch: 1... Training loss: 0.00341... Test loss: 0.00452\n",
      "Epoch: 1... Training loss: 0.0035... Test loss: 0.00389\n",
      "Epoch: 1... Training loss: 0.00333... Test loss: 0.00361\n",
      "Epoch: 1... Training loss: 0.00337... Test loss: 0.00348\n",
      "Epoch: 1... Training loss: 0.00321... Test loss: 0.00295\n",
      "Epoch: 1... Training loss: 0.00317... Test loss: 0.0034\n",
      "Epoch: 1... Training loss: 0.00317... Test loss: 0.00283\n",
      "Epoch: 1... Training loss: 0.00303... Test loss: 0.00344\n",
      "Epoch: 1... Training loss: 0.00295... Test loss: 0.00293\n",
      "Epoch: 1... Training loss: 0.00282... Test loss: 0.00328\n",
      "Epoch: 1... Training loss: 0.00279... Test loss: 0.00288\n",
      "Epoch: 1... Training loss: 0.00273... Test loss: 0.00296\n",
      "Epoch: 1... Training loss: 0.00264... Test loss: 0.00269\n",
      "Epoch: 1... Training loss: 0.0026... Test loss: 0.00301\n",
      "Epoch: 1... Training loss: 0.00249... Test loss: 0.00279\n",
      "Epoch: 1... Training loss: 0.00253... Test loss: 0.00276\n",
      "Epoch: 1... Training loss: 0.00237... Test loss: 0.00301\n",
      "Epoch: 1... Training loss: 0.00232... Test loss: 0.00223\n",
      "Epoch: 1... Training loss: 0.00225... Test loss: 0.0026\n",
      "Epoch: 1... Training loss: 0.00223... Test loss: 0.00213\n",
      "Epoch: 1... Training loss: 0.0022... Test loss: 0.0026\n",
      "Epoch: 1... Training loss: 0.00211... Test loss: 0.00207\n",
      "Epoch: 1... Training loss: 0.00195... Test loss: 0.0026\n",
      "Epoch: 1... Training loss: 0.00193... Test loss: 0.00204\n",
      "Epoch: 1... Training loss: 0.00185... Test loss: 0.0022\n",
      "Epoch: 1... Training loss: 0.00181... Test loss: 0.00182\n",
      "Epoch: 1... Training loss: 0.0019... Test loss: 0.00203\n",
      "Epoch: 1... Training loss: 0.00191... Test loss: 0.00167\n",
      "Epoch: 1... Training loss: 0.00177... Test loss: 0.00219\n",
      "Epoch: 1... Training loss: 0.00176... Test loss: 0.00166\n",
      "Epoch: 1... Training loss: 0.00161... Test loss: 0.00205\n",
      "Epoch: 1... Training loss: 0.00165... Test loss: 0.0015\n",
      "Epoch: 1... Training loss: 0.00154... Test loss: 0.00176\n",
      "Epoch: 1... Training loss: 0.0015... Test loss: 0.00137\n",
      "Epoch: 1... Training loss: 0.00152... Test loss: 0.00147\n",
      "Epoch: 1... Training loss: 0.00148... Test loss: 0.00131\n",
      "Epoch: 1... Training loss: 0.00144... Test loss: 0.00151\n",
      "Epoch: 1... Training loss: 0.00134... Test loss: 0.0013\n",
      "Epoch: 1... Training loss: 0.00128... Test loss: 0.00133\n",
      "Epoch: 1... Training loss: 0.00124... Test loss: 0.0014\n",
      "Epoch: 1... Training loss: 0.00118... Test loss: 0.00132\n",
      "Epoch: 1... Training loss: 0.00125... Test loss: 0.00138\n",
      "Epoch: 1... Training loss: 0.00114... Test loss: 0.00115\n",
      "Epoch: 1... Training loss: 0.00117... Test loss: 0.00136\n",
      "Epoch: 1... Training loss: 0.00106... Test loss: 0.00092\n",
      "Epoch: 1... Training loss: 0.00111... Test loss: 0.00131\n",
      "Epoch: 1... Training loss: 0.00108... Test loss: 0.00091\n",
      "Epoch: 1... Training loss: 0.00101... Test loss: 0.00127\n",
      "Epoch: 1... Training loss: 0.00113... Test loss: 0.0009\n",
      "Epoch: 1... Training loss: 0.00094... Test loss: 0.00093\n",
      "Epoch: 1... Training loss: 0.0009... Test loss: 0.0009\n",
      "Epoch: 1... Training loss: 0.00089... Test loss: 0.00096\n",
      "Epoch: 1... Training loss: 0.00086... Test loss: 0.00089\n",
      "Epoch: 1... Training loss: 0.00087... Test loss: 0.00089\n",
      "Epoch: 1... Training loss: 0.00084... Test loss: 0.00086\n",
      "Epoch: 1... Training loss: 0.00091... Test loss: 0.00095\n",
      "Epoch: 1... Training loss: 0.00078... Test loss: 0.00077\n",
      "Epoch: 1... Training loss: 0.00076... Test loss: 0.00106\n",
      "Epoch: 1... Training loss: 0.00069... Test loss: 0.00074\n",
      "Epoch: 1... Training loss: 0.00072... Test loss: 0.00096\n",
      "Epoch: 1... Training loss: 0.00069... Test loss: 0.00069\n",
      "Epoch: 1... Training loss: 0.00065... Test loss: 0.00081\n",
      "Epoch: 1... Training loss: 0.00061... Test loss: 0.00063\n",
      "Epoch: 1... Training loss: 0.0007... Test loss: 0.0006\n",
      "Epoch: 1... Training loss: 0.00063... Test loss: 0.00074\n",
      "Epoch: 1... Training loss: 0.00059... Test loss: 0.00045\n",
      "Epoch: 1... Training loss: 0.00052... Test loss: 0.00074\n",
      "Epoch: 1... Training loss: 0.00052... Test loss: 0.00045\n",
      "Epoch: 1... Training loss: 0.0005... Test loss: 0.00064\n",
      "Epoch: 1... Training loss: 0.00047... Test loss: 0.00042\n",
      "Epoch: 1... Training loss: 0.0005... Test loss: 0.00061\n",
      "Epoch: 1... Training loss: 0.00046... Test loss: 0.00042\n",
      "Epoch: 1... Training loss: 0.00043... Test loss: 0.00051\n",
      "Epoch: 1... Training loss: 0.00043... Test loss: 0.00037\n",
      "Epoch: 1... Training loss: 0.00044... Test loss: 0.0005\n",
      "Epoch: 1... Training loss: 0.00038... Test loss: 0.00044\n",
      "Epoch: 1... Training loss: 0.00038... Test loss: 0.00041\n",
      "Epoch: 1... Training loss: 0.00034... Test loss: 0.00041\n",
      "Epoch: 1... Training loss: 0.00039... Test loss: 0.00041\n",
      "Epoch: 1... Training loss: 0.00031... Test loss: 0.00036\n",
      "Epoch: 1... Training loss: 0.00029... Test loss: 0.00041\n",
      "Epoch: 1... Training loss: 0.00026... Test loss: 0.00036\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.00031\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00032\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00031\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00022\n",
      "296.70472701103427\n",
      "Epoch: 1... Training loss: 1.01579... Test loss: 0.41576\n",
      "Epoch: 1... Training loss: 0.48565... Test loss: 0.15248\n",
      "Epoch: 1... Training loss: 0.33874... Test loss: 0.08966\n",
      "Epoch: 1... Training loss: 0.19459... Test loss: 0.05565\n",
      "Epoch: 1... Training loss: 0.14664... Test loss: 0.03989\n",
      "Epoch: 1... Training loss: 0.11962... Test loss: 0.03389\n",
      "Epoch: 1... Training loss: 0.09098... Test loss: 0.02719\n",
      "Epoch: 1... Training loss: 0.07378... Test loss: 0.03379\n",
      "Epoch: 1... Training loss: 0.06796... Test loss: 0.01662\n",
      "Epoch: 1... Training loss: 0.05621... Test loss: 0.02443\n",
      "Epoch: 1... Training loss: 0.05201... Test loss: 0.01244\n",
      "Epoch: 1... Training loss: 0.04678... Test loss: 0.02029\n",
      "Epoch: 1... Training loss: 0.04083... Test loss: 0.01688\n",
      "Epoch: 1... Training loss: 0.03504... Test loss: 0.01807\n",
      "Epoch: 1... Training loss: 0.03354... Test loss: 0.0123\n",
      "Epoch: 1... Training loss: 0.03115... Test loss: 0.01706\n",
      "Epoch: 1... Training loss: 0.02976... Test loss: 0.01534\n",
      "Epoch: 1... Training loss: 0.02893... Test loss: 0.00921\n",
      "Epoch: 1... Training loss: 0.02623... Test loss: 0.01991\n",
      "Epoch: 1... Training loss: 0.0243... Test loss: 0.01065\n",
      "Epoch: 1... Training loss: 0.02316... Test loss: 0.01826\n",
      "Epoch: 1... Training loss: 0.02214... Test loss: 0.00808\n",
      "Epoch: 1... Training loss: 0.02091... Test loss: 0.01759\n",
      "Epoch: 1... Training loss: 0.02053... Test loss: 0.01\n",
      "Epoch: 1... Training loss: 0.01942... Test loss: 0.01247\n",
      "Epoch: 1... Training loss: 0.01892... Test loss: 0.01445\n",
      "Epoch: 1... Training loss: 0.01745... Test loss: 0.0056\n",
      "Epoch: 1... Training loss: 0.0169... Test loss: 0.01409\n",
      "Epoch: 1... Training loss: 0.01552... Test loss: 0.00819\n",
      "Epoch: 1... Training loss: 0.01533... Test loss: 0.01351\n",
      "Epoch: 1... Training loss: 0.01465... Test loss: 0.00477\n",
      "Epoch: 1... Training loss: 0.0141... Test loss: 0.01268\n",
      "Epoch: 1... Training loss: 0.01347... Test loss: 0.00537\n",
      "Epoch: 1... Training loss: 0.013... Test loss: 0.01156\n",
      "Epoch: 1... Training loss: 0.0126... Test loss: 0.00628\n",
      "Epoch: 1... Training loss: 0.01226... Test loss: 0.01245\n",
      "Epoch: 1... Training loss: 0.01204... Test loss: 0.00602\n",
      "Epoch: 1... Training loss: 0.01172... Test loss: 0.01105\n",
      "Epoch: 1... Training loss: 0.01133... Test loss: 0.00621\n",
      "Epoch: 1... Training loss: 0.01084... Test loss: 0.01147\n",
      "Epoch: 1... Training loss: 0.01057... Test loss: 0.00686\n",
      "Epoch: 1... Training loss: 0.01028... Test loss: 0.00999\n",
      "Epoch: 1... Training loss: 0.0098... Test loss: 0.00615\n",
      "Epoch: 1... Training loss: 0.00959... Test loss: 0.01028\n",
      "Epoch: 1... Training loss: 0.00932... Test loss: 0.00464\n",
      "Epoch: 1... Training loss: 0.0089... Test loss: 0.01028\n",
      "Epoch: 1... Training loss: 0.00866... Test loss: 0.00508\n",
      "Epoch: 1... Training loss: 0.00841... Test loss: 0.00885\n",
      "Epoch: 1... Training loss: 0.00825... Test loss: 0.00492\n",
      "Epoch: 1... Training loss: 0.00798... Test loss: 0.00874\n",
      "Epoch: 1... Training loss: 0.00777... Test loss: 0.00503\n",
      "Epoch: 1... Training loss: 0.0076... Test loss: 0.00866\n",
      "Epoch: 1... Training loss: 0.00757... Test loss: 0.00639\n",
      "Epoch: 1... Training loss: 0.00728... Test loss: 0.00662\n",
      "Epoch: 1... Training loss: 0.00711... Test loss: 0.00594\n",
      "Epoch: 1... Training loss: 0.00695... Test loss: 0.00658\n",
      "Epoch: 1... Training loss: 0.00679... Test loss: 0.00547\n",
      "Epoch: 1... Training loss: 0.00656... Test loss: 0.00656\n",
      "Epoch: 1... Training loss: 0.00645... Test loss: 0.00521\n",
      "Epoch: 1... Training loss: 0.00626... Test loss: 0.006\n",
      "Epoch: 1... Training loss: 0.00602... Test loss: 0.00596\n",
      "Epoch: 1... Training loss: 0.00595... Test loss: 0.00605\n",
      "Epoch: 1... Training loss: 0.00586... Test loss: 0.00487\n",
      "Epoch: 1... Training loss: 0.00561... Test loss: 0.00573\n",
      "Epoch: 1... Training loss: 0.01157... Test loss: 0.01356\n",
      "Epoch: 1... Training loss: 0.01164... Test loss: 0.01061\n",
      "Epoch: 1... Training loss: 0.01109... Test loss: 0.00867\n",
      "Epoch: 1... Training loss: 0.00862... Test loss: 0.01009\n",
      "Epoch: 1... Training loss: 0.00978... Test loss: 0.00661\n",
      "Epoch: 1... Training loss: 0.00877... Test loss: 0.01192\n",
      "Epoch: 1... Training loss: 0.00956... Test loss: 0.00743\n",
      "Epoch: 1... Training loss: 0.00929... Test loss: 0.01177\n",
      "Epoch: 1... Training loss: 0.00869... Test loss: 0.00875\n",
      "Epoch: 1... Training loss: 0.00837... Test loss: 0.01067\n",
      "Epoch: 1... Training loss: 0.00821... Test loss: 0.00788\n",
      "Epoch: 1... Training loss: 0.00816... Test loss: 0.01109\n",
      "Epoch: 1... Training loss: 0.00714... Test loss: 0.00752\n",
      "Epoch: 1... Training loss: 0.00741... Test loss: 0.00923\n",
      "Epoch: 1... Training loss: 0.00672... Test loss: 0.00813\n",
      "Epoch: 1... Training loss: 0.00689... Test loss: 0.00845\n",
      "Epoch: 1... Training loss: 0.00705... Test loss: 0.0068\n",
      "Epoch: 1... Training loss: 0.00652... Test loss: 0.00773\n",
      "Epoch: 1... Training loss: 0.00681... Test loss: 0.00655\n",
      "Epoch: 1... Training loss: 0.00607... Test loss: 0.00735\n",
      "Epoch: 1... Training loss: 0.00611... Test loss: 0.00604\n",
      "Epoch: 1... Training loss: 0.00586... Test loss: 0.00708\n",
      "Epoch: 1... Training loss: 0.00557... Test loss: 0.00533\n",
      "Epoch: 1... Training loss: 0.00523... Test loss: 0.00646\n",
      "Epoch: 1... Training loss: 0.0052... Test loss: 0.00607\n",
      "Epoch: 1... Training loss: 0.00509... Test loss: 0.00627\n",
      "Epoch: 1... Training loss: 0.00496... Test loss: 0.00422\n",
      "Epoch: 1... Training loss: 0.00477... Test loss: 0.00605\n",
      "Epoch: 1... Training loss: 0.00489... Test loss: 0.00482\n",
      "Epoch: 1... Training loss: 0.00446... Test loss: 0.00526\n",
      "Epoch: 1... Training loss: 0.00461... Test loss: 0.00481\n",
      "Epoch: 1... Training loss: 0.00469... Test loss: 0.00471\n",
      "Epoch: 1... Training loss: 0.00425... Test loss: 0.00455\n",
      "Epoch: 1... Training loss: 0.0043... Test loss: 0.00512\n",
      "Epoch: 1... Training loss: 0.00409... Test loss: 0.00417\n",
      "Epoch: 1... Training loss: 0.00376... Test loss: 0.00557\n",
      "Epoch: 1... Training loss: 0.00377... Test loss: 0.00421\n",
      "Epoch: 1... Training loss: 0.00374... Test loss: 0.00478\n",
      "Epoch: 1... Training loss: 0.00363... Test loss: 0.00396\n",
      "Epoch: 1... Training loss: 0.00359... Test loss: 0.00406\n",
      "Epoch: 1... Training loss: 0.00368... Test loss: 0.00411\n",
      "Epoch: 1... Training loss: 0.00348... Test loss: 0.00402\n",
      "Epoch: 1... Training loss: 0.00343... Test loss: 0.0039\n",
      "Epoch: 1... Training loss: 0.00338... Test loss: 0.00398\n",
      "Epoch: 1... Training loss: 0.00325... Test loss: 0.00342\n",
      "Epoch: 1... Training loss: 0.00314... Test loss: 0.00354\n",
      "Epoch: 1... Training loss: 0.00311... Test loss: 0.00293\n",
      "Epoch: 1... Training loss: 0.00298... Test loss: 0.00297\n",
      "Epoch: 1... Training loss: 0.00301... Test loss: 0.00308\n",
      "Epoch: 1... Training loss: 0.00297... Test loss: 0.00311\n",
      "Epoch: 1... Training loss: 0.00296... Test loss: 0.00294\n",
      "Epoch: 1... Training loss: 0.00279... Test loss: 0.00325\n",
      "Epoch: 1... Training loss: 0.00286... Test loss: 0.00282\n",
      "Epoch: 1... Training loss: 0.00272... Test loss: 0.0033\n",
      "Epoch: 1... Training loss: 0.00261... Test loss: 0.0025\n",
      "Epoch: 1... Training loss: 0.00261... Test loss: 0.00287\n",
      "Epoch: 1... Training loss: 0.00258... Test loss: 0.00267\n",
      "Epoch: 1... Training loss: 0.0025... Test loss: 0.00208\n",
      "Epoch: 1... Training loss: 0.00253... Test loss: 0.00287\n",
      "Epoch: 1... Training loss: 0.00237... Test loss: 0.00269\n",
      "Epoch: 1... Training loss: 0.0023... Test loss: 0.00279\n",
      "Epoch: 1... Training loss: 0.00224... Test loss: 0.00244\n",
      "Epoch: 1... Training loss: 0.00221... Test loss: 0.00234\n",
      "Epoch: 1... Training loss: 0.00213... Test loss: 0.00213\n",
      "Epoch: 1... Training loss: 0.00207... Test loss: 0.00239\n",
      "Epoch: 1... Training loss: 0.00207... Test loss: 0.00231\n",
      "Epoch: 1... Training loss: 0.00206... Test loss: 0.00222\n",
      "Epoch: 1... Training loss: 0.00199... Test loss: 0.00206\n",
      "Epoch: 1... Training loss: 0.00188... Test loss: 0.00213\n",
      "Epoch: 1... Training loss: 0.0018... Test loss: 0.0019\n",
      "Epoch: 1... Training loss: 0.00184... Test loss: 0.00201\n",
      "Epoch: 1... Training loss: 0.00179... Test loss: 0.00232\n",
      "Epoch: 1... Training loss: 0.00172... Test loss: 0.00183\n",
      "Epoch: 1... Training loss: 0.0017... Test loss: 0.00162\n",
      "Epoch: 1... Training loss: 0.00178... Test loss: 0.00159\n",
      "Epoch: 1... Training loss: 0.00156... Test loss: 0.00172\n",
      "Epoch: 1... Training loss: 0.00157... Test loss: 0.0017\n",
      "Epoch: 1... Training loss: 0.00141... Test loss: 0.00172\n",
      "Epoch: 1... Training loss: 0.00141... Test loss: 0.00168\n",
      "Epoch: 1... Training loss: 0.00135... Test loss: 0.00153\n",
      "Epoch: 1... Training loss: 0.00135... Test loss: 0.00146\n",
      "Epoch: 1... Training loss: 0.00133... Test loss: 0.00155\n",
      "Epoch: 1... Training loss: 0.00133... Test loss: 0.00146\n",
      "Epoch: 1... Training loss: 0.00128... Test loss: 0.00149\n",
      "Epoch: 1... Training loss: 0.0012... Test loss: 0.00132\n",
      "Epoch: 1... Training loss: 0.00115... Test loss: 0.00135\n",
      "Epoch: 1... Training loss: 0.00117... Test loss: 0.00126\n",
      "Epoch: 1... Training loss: 0.00112... Test loss: 0.00107\n",
      "Epoch: 1... Training loss: 0.00106... Test loss: 0.00145\n",
      "Epoch: 1... Training loss: 0.00116... Test loss: 0.00098\n",
      "Epoch: 1... Training loss: 0.00104... Test loss: 0.00136\n",
      "Epoch: 1... Training loss: 0.00102... Test loss: 0.00088\n",
      "Epoch: 1... Training loss: 0.00093... Test loss: 0.00139\n",
      "Epoch: 1... Training loss: 0.00091... Test loss: 0.00076\n",
      "Epoch: 1... Training loss: 0.00089... Test loss: 0.00101\n",
      "Epoch: 1... Training loss: 0.00091... Test loss: 0.0009\n",
      "Epoch: 1... Training loss: 0.00086... Test loss: 0.00114\n",
      "Epoch: 1... Training loss: 0.00095... Test loss: 0.00085\n",
      "Epoch: 1... Training loss: 0.00092... Test loss: 0.00098\n",
      "Epoch: 1... Training loss: 0.00081... Test loss: 0.00079\n",
      "Epoch: 1... Training loss: 0.00075... Test loss: 0.00111\n",
      "Epoch: 1... Training loss: 0.0007... Test loss: 0.00075\n",
      "Epoch: 1... Training loss: 0.00068... Test loss: 0.00084\n",
      "Epoch: 1... Training loss: 0.0007... Test loss: 0.00057\n",
      "Epoch: 1... Training loss: 0.00067... Test loss: 0.00084\n",
      "Epoch: 1... Training loss: 0.00066... Test loss: 0.00061\n",
      "Epoch: 1... Training loss: 0.0006... Test loss: 0.00081\n",
      "Epoch: 1... Training loss: 0.00055... Test loss: 0.00052\n",
      "Epoch: 1... Training loss: 0.00061... Test loss: 0.00063\n",
      "Epoch: 1... Training loss: 0.00053... Test loss: 0.00052\n",
      "Epoch: 1... Training loss: 0.00052... Test loss: 0.00055\n",
      "Epoch: 1... Training loss: 0.0005... Test loss: 0.00053\n",
      "Epoch: 1... Training loss: 0.0005... Test loss: 0.00048\n",
      "Epoch: 1... Training loss: 0.00052... Test loss: 0.00044\n",
      "Epoch: 1... Training loss: 0.00045... Test loss: 0.00049\n",
      "Epoch: 1... Training loss: 0.00042... Test loss: 0.00047\n",
      "Epoch: 1... Training loss: 0.00045... Test loss: 0.00041\n",
      "Epoch: 1... Training loss: 0.0004... Test loss: 0.00057\n",
      "Epoch: 1... Training loss: 0.00037... Test loss: 0.00033\n",
      "Epoch: 1... Training loss: 0.00036... Test loss: 0.00041\n",
      "Epoch: 1... Training loss: 0.00036... Test loss: 0.00031\n",
      "Epoch: 1... Training loss: 0.00032... Test loss: 0.00044\n",
      "Epoch: 1... Training loss: 0.00032... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00033\n",
      "Epoch: 1... Training loss: 0.00032... Test loss: 0.00028\n",
      "Epoch: 1... Training loss: 0.00026... Test loss: 0.00035\n",
      "Epoch: 1... Training loss: 0.00026... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00026... Test loss: 0.0003\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00028\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00021\n",
      "288.8404259252129\n",
      "Epoch: 1... Training loss: 1.24584... Test loss: 0.61417\n",
      "Epoch: 1... Training loss: 0.60258... Test loss: 0.24188\n",
      "Epoch: 1... Training loss: 0.34075... Test loss: 0.14117\n",
      "Epoch: 1... Training loss: 0.22236... Test loss: 0.08446\n",
      "Epoch: 1... Training loss: 0.15871... Test loss: 0.06\n",
      "Epoch: 1... Training loss: 0.12024... Test loss: 0.04118\n",
      "Epoch: 1... Training loss: 0.09632... Test loss: 0.03547\n",
      "Epoch: 1... Training loss: 0.08385... Test loss: 0.02847\n",
      "Epoch: 1... Training loss: 0.07202... Test loss: 0.03738\n",
      "Epoch: 1... Training loss: 0.06293... Test loss: 0.0226\n",
      "Epoch: 1... Training loss: 0.05579... Test loss: 0.03932\n",
      "Epoch: 1... Training loss: 0.04687... Test loss: 0.01597\n",
      "Epoch: 1... Training loss: 0.04465... Test loss: 0.03657\n",
      "Epoch: 1... Training loss: 0.04038... Test loss: 0.03522\n",
      "Epoch: 1... Training loss: 0.03813... Test loss: 0.01582\n",
      "Epoch: 1... Training loss: 0.03516... Test loss: 0.04182\n",
      "Epoch: 1... Training loss: 0.03214... Test loss: 0.01784\n",
      "Epoch: 1... Training loss: 0.02887... Test loss: 0.04899\n",
      "Epoch: 1... Training loss: 0.02895... Test loss: 0.01819\n",
      "Epoch: 1... Training loss: 0.02641... Test loss: 0.02677\n",
      "Epoch: 1... Training loss: 0.02608... Test loss: 0.02292\n",
      "Epoch: 1... Training loss: 0.02391... Test loss: 0.00662\n",
      "Epoch: 1... Training loss: 0.02256... Test loss: 0.02038\n",
      "Epoch: 1... Training loss: 0.02149... Test loss: 0.00838\n",
      "Epoch: 1... Training loss: 0.02064... Test loss: 0.02239\n",
      "Epoch: 1... Training loss: 0.01965... Test loss: 0.00797\n",
      "Epoch: 1... Training loss: 0.01876... Test loss: 0.01701\n",
      "Epoch: 1... Training loss: 0.01793... Test loss: 0.01571\n",
      "Epoch: 1... Training loss: 0.01728... Test loss: 0.01322\n",
      "Epoch: 1... Training loss: 0.01654... Test loss: 0.01228\n",
      "Epoch: 1... Training loss: 0.0156... Test loss: 0.02118\n",
      "Epoch: 1... Training loss: 0.01536... Test loss: 0.00816\n",
      "Epoch: 1... Training loss: 0.01472... Test loss: 0.01791\n",
      "Epoch: 1... Training loss: 0.01431... Test loss: 0.0077\n",
      "Epoch: 1... Training loss: 0.01374... Test loss: 0.01346\n",
      "Epoch: 1... Training loss: 0.01326... Test loss: 0.00757\n",
      "Epoch: 1... Training loss: 0.01282... Test loss: 0.01307\n",
      "Epoch: 1... Training loss: 0.01245... Test loss: 0.0068\n",
      "Epoch: 1... Training loss: 0.01167... Test loss: 0.01085\n",
      "Epoch: 1... Training loss: 0.01157... Test loss: 0.00746\n",
      "Epoch: 1... Training loss: 0.01101... Test loss: 0.00833\n",
      "Epoch: 1... Training loss: 0.01087... Test loss: 0.01124\n",
      "Epoch: 1... Training loss: 0.01055... Test loss: 0.00576\n",
      "Epoch: 1... Training loss: 0.01027... Test loss: 0.01242\n",
      "Epoch: 1... Training loss: 0.00998... Test loss: 0.00619\n",
      "Epoch: 1... Training loss: 0.00967... Test loss: 0.00923\n",
      "Epoch: 1... Training loss: 0.00919... Test loss: 0.00592\n",
      "Epoch: 1... Training loss: 0.0089... Test loss: 0.00814\n",
      "Epoch: 1... Training loss: 0.00864... Test loss: 0.0051\n",
      "Epoch: 1... Training loss: 0.00855... Test loss: 0.00823\n",
      "Epoch: 1... Training loss: 0.00831... Test loss: 0.00563\n",
      "Epoch: 1... Training loss: 0.00807... Test loss: 0.00816\n",
      "Epoch: 1... Training loss: 0.00792... Test loss: 0.00639\n",
      "Epoch: 1... Training loss: 0.00774... Test loss: 0.00788\n",
      "Epoch: 1... Training loss: 0.00744... Test loss: 0.00589\n",
      "Epoch: 1... Training loss: 0.00719... Test loss: 0.0071\n",
      "Epoch: 1... Training loss: 0.0069... Test loss: 0.00469\n",
      "Epoch: 1... Training loss: 0.00678... Test loss: 0.00679\n",
      "Epoch: 1... Training loss: 0.00656... Test loss: 0.00476\n",
      "Epoch: 1... Training loss: 0.00638... Test loss: 0.00661\n",
      "Epoch: 1... Training loss: 0.00622... Test loss: 0.00492\n",
      "Epoch: 1... Training loss: 0.00606... Test loss: 0.007\n",
      "Epoch: 1... Training loss: 0.0059... Test loss: 0.00472\n",
      "Epoch: 1... Training loss: 0.00579... Test loss: 0.00658\n",
      "Epoch: 1... Training loss: 0.00994... Test loss: 0.00646\n",
      "Epoch: 1... Training loss: 0.01191... Test loss: 0.01145\n",
      "Epoch: 1... Training loss: 0.01154... Test loss: 0.01022\n",
      "Epoch: 1... Training loss: 0.0119... Test loss: 0.01231\n",
      "Epoch: 1... Training loss: 0.01079... Test loss: 0.00877\n",
      "Epoch: 1... Training loss: 0.01041... Test loss: 0.01001\n",
      "Epoch: 1... Training loss: 0.00896... Test loss: 0.01083\n",
      "Epoch: 1... Training loss: 0.00977... Test loss: 0.0099\n",
      "Epoch: 1... Training loss: 0.0091... Test loss: 0.01023\n",
      "Epoch: 1... Training loss: 0.00852... Test loss: 0.00979\n",
      "Epoch: 1... Training loss: 0.00799... Test loss: 0.0101\n",
      "Epoch: 1... Training loss: 0.00862... Test loss: 0.00943\n",
      "Epoch: 1... Training loss: 0.00807... Test loss: 0.00992\n",
      "Epoch: 1... Training loss: 0.00762... Test loss: 0.00892\n",
      "Epoch: 1... Training loss: 0.0081... Test loss: 0.00935\n",
      "Epoch: 1... Training loss: 0.00751... Test loss: 0.00857\n",
      "Epoch: 1... Training loss: 0.00744... Test loss: 0.00898\n",
      "Epoch: 1... Training loss: 0.00719... Test loss: 0.00935\n",
      "Epoch: 1... Training loss: 0.00668... Test loss: 0.00749\n",
      "Epoch: 1... Training loss: 0.00678... Test loss: 0.00877\n",
      "Epoch: 1... Training loss: 0.00631... Test loss: 0.00685\n",
      "Epoch: 1... Training loss: 0.0063... Test loss: 0.00797\n",
      "Epoch: 1... Training loss: 0.0061... Test loss: 0.00674\n",
      "Epoch: 1... Training loss: 0.00571... Test loss: 0.00658\n",
      "Epoch: 1... Training loss: 0.00572... Test loss: 0.00615\n",
      "Epoch: 1... Training loss: 0.00566... Test loss: 0.00561\n",
      "Epoch: 1... Training loss: 0.00538... Test loss: 0.00583\n",
      "Epoch: 1... Training loss: 0.0054... Test loss: 0.00511\n",
      "Epoch: 1... Training loss: 0.00486... Test loss: 0.00557\n",
      "Epoch: 1... Training loss: 0.00488... Test loss: 0.00497\n",
      "Epoch: 1... Training loss: 0.00466... Test loss: 0.00458\n",
      "Epoch: 1... Training loss: 0.00471... Test loss: 0.00457\n",
      "Epoch: 1... Training loss: 0.00448... Test loss: 0.0048\n",
      "Epoch: 1... Training loss: 0.0042... Test loss: 0.00484\n",
      "Epoch: 1... Training loss: 0.00414... Test loss: 0.00454\n",
      "Epoch: 1... Training loss: 0.00406... Test loss: 0.00438\n",
      "Epoch: 1... Training loss: 0.00393... Test loss: 0.00438\n",
      "Epoch: 1... Training loss: 0.00385... Test loss: 0.00423\n",
      "Epoch: 1... Training loss: 0.00386... Test loss: 0.00367\n",
      "Epoch: 1... Training loss: 0.00376... Test loss: 0.00377\n",
      "Epoch: 1... Training loss: 0.0037... Test loss: 0.00403\n",
      "Epoch: 1... Training loss: 0.00377... Test loss: 0.0038\n",
      "Epoch: 1... Training loss: 0.00356... Test loss: 0.00397\n",
      "Epoch: 1... Training loss: 0.00355... Test loss: 0.0038\n",
      "Epoch: 1... Training loss: 0.00342... Test loss: 0.00381\n",
      "Epoch: 1... Training loss: 0.00355... Test loss: 0.00367\n",
      "Epoch: 1... Training loss: 0.00333... Test loss: 0.00372\n",
      "Epoch: 1... Training loss: 0.00327... Test loss: 0.0034\n",
      "Epoch: 1... Training loss: 0.00327... Test loss: 0.00335\n",
      "Epoch: 1... Training loss: 0.00323... Test loss: 0.00271\n",
      "Epoch: 1... Training loss: 0.00302... Test loss: 0.00329\n",
      "Epoch: 1... Training loss: 0.00302... Test loss: 0.00278\n",
      "Epoch: 1... Training loss: 0.00297... Test loss: 0.00328\n",
      "Epoch: 1... Training loss: 0.00293... Test loss: 0.0027\n",
      "Epoch: 1... Training loss: 0.00288... Test loss: 0.00324\n",
      "Epoch: 1... Training loss: 0.00279... Test loss: 0.00235\n",
      "Epoch: 1... Training loss: 0.00273... Test loss: 0.00281\n",
      "Epoch: 1... Training loss: 0.00282... Test loss: 0.00273\n",
      "Epoch: 1... Training loss: 0.00271... Test loss: 0.00298\n",
      "Epoch: 1... Training loss: 0.00261... Test loss: 0.00247\n",
      "Epoch: 1... Training loss: 0.0026... Test loss: 0.00296\n",
      "Epoch: 1... Training loss: 0.00243... Test loss: 0.00248\n",
      "Epoch: 1... Training loss: 0.00235... Test loss: 0.00262\n",
      "Epoch: 1... Training loss: 0.0023... Test loss: 0.00266\n",
      "Epoch: 1... Training loss: 0.00231... Test loss: 0.00287\n",
      "Epoch: 1... Training loss: 0.00226... Test loss: 0.00253\n",
      "Epoch: 1... Training loss: 0.00225... Test loss: 0.00267\n",
      "Epoch: 1... Training loss: 0.00217... Test loss: 0.00237\n",
      "Epoch: 1... Training loss: 0.00219... Test loss: 0.0026\n",
      "Epoch: 1... Training loss: 0.00198... Test loss: 0.00245\n",
      "Epoch: 1... Training loss: 0.00194... Test loss: 0.00225\n",
      "Epoch: 1... Training loss: 0.00191... Test loss: 0.00204\n",
      "Epoch: 1... Training loss: 0.00187... Test loss: 0.00205\n",
      "Epoch: 1... Training loss: 0.00189... Test loss: 0.00177\n",
      "Epoch: 1... Training loss: 0.00188... Test loss: 0.00214\n",
      "Epoch: 1... Training loss: 0.00174... Test loss: 0.00189\n",
      "Epoch: 1... Training loss: 0.0018... Test loss: 0.0022\n",
      "Epoch: 1... Training loss: 0.00169... Test loss: 0.00178\n",
      "Epoch: 1... Training loss: 0.00165... Test loss: 0.00208\n",
      "Epoch: 1... Training loss: 0.00159... Test loss: 0.00159\n",
      "Epoch: 1... Training loss: 0.00154... Test loss: 0.0019\n",
      "Epoch: 1... Training loss: 0.00155... Test loss: 0.00154\n",
      "Epoch: 1... Training loss: 0.00163... Test loss: 0.00175\n",
      "Epoch: 1... Training loss: 0.0015... Test loss: 0.00151\n",
      "Epoch: 1... Training loss: 0.00149... Test loss: 0.0015\n",
      "Epoch: 1... Training loss: 0.00142... Test loss: 0.00145\n",
      "Epoch: 1... Training loss: 0.0014... Test loss: 0.00132\n",
      "Epoch: 1... Training loss: 0.00141... Test loss: 0.0013\n",
      "Epoch: 1... Training loss: 0.00139... Test loss: 0.0014\n",
      "Epoch: 1... Training loss: 0.00132... Test loss: 0.00133\n",
      "Epoch: 1... Training loss: 0.00135... Test loss: 0.00124\n",
      "Epoch: 1... Training loss: 0.00132... Test loss: 0.00131\n",
      "Epoch: 1... Training loss: 0.00121... Test loss: 0.0012\n",
      "Epoch: 1... Training loss: 0.0012... Test loss: 0.00128\n",
      "Epoch: 1... Training loss: 0.00117... Test loss: 0.00125\n",
      "Epoch: 1... Training loss: 0.00114... Test loss: 0.00111\n",
      "Epoch: 1... Training loss: 0.00114... Test loss: 0.00103\n",
      "Epoch: 1... Training loss: 0.0011... Test loss: 0.00112\n",
      "Epoch: 1... Training loss: 0.00117... Test loss: 0.00119\n",
      "Epoch: 1... Training loss: 0.00104... Test loss: 0.00114\n",
      "Epoch: 1... Training loss: 0.001... Test loss: 0.00095\n",
      "Epoch: 1... Training loss: 0.001... Test loss: 0.00104\n",
      "Epoch: 1... Training loss: 0.00105... Test loss: 0.00093\n",
      "Epoch: 1... Training loss: 0.001... Test loss: 0.00099\n",
      "Epoch: 1... Training loss: 0.00097... Test loss: 0.00084\n",
      "Epoch: 1... Training loss: 0.00092... Test loss: 0.00077\n",
      "Epoch: 1... Training loss: 0.00091... Test loss: 0.00069\n",
      "Epoch: 1... Training loss: 0.00082... Test loss: 0.00085\n",
      "Epoch: 1... Training loss: 0.00078... Test loss: 0.0007\n",
      "Epoch: 1... Training loss: 0.00079... Test loss: 0.00087\n",
      "Epoch: 1... Training loss: 0.00081... Test loss: 0.0007\n",
      "Epoch: 1... Training loss: 0.00077... Test loss: 0.00093\n",
      "Epoch: 1... Training loss: 0.00075... Test loss: 0.00054\n",
      "Epoch: 1... Training loss: 0.00069... Test loss: 0.00075\n",
      "Epoch: 1... Training loss: 0.00064... Test loss: 0.00065\n",
      "Epoch: 1... Training loss: 0.00063... Test loss: 0.00068\n",
      "Epoch: 1... Training loss: 0.00061... Test loss: 0.00071\n",
      "Epoch: 1... Training loss: 0.00061... Test loss: 0.00072\n",
      "Epoch: 1... Training loss: 0.00054... Test loss: 0.00067\n",
      "Epoch: 1... Training loss: 0.00056... Test loss: 0.00058\n",
      "Epoch: 1... Training loss: 0.00049... Test loss: 0.00057\n",
      "Epoch: 1... Training loss: 0.00049... Test loss: 0.00058\n",
      "Epoch: 1... Training loss: 0.00049... Test loss: 0.00049\n",
      "Epoch: 1... Training loss: 0.00049... Test loss: 0.00057\n",
      "Epoch: 1... Training loss: 0.00042... Test loss: 0.00056\n",
      "Epoch: 1... Training loss: 0.00041... Test loss: 0.00051\n",
      "Epoch: 1... Training loss: 0.00043... Test loss: 0.00047\n",
      "Epoch: 1... Training loss: 0.00039... Test loss: 0.00045\n",
      "Epoch: 1... Training loss: 0.00036... Test loss: 0.00053\n",
      "Epoch: 1... Training loss: 0.00038... Test loss: 0.00038\n",
      "Epoch: 1... Training loss: 0.00034... Test loss: 0.00037\n",
      "Epoch: 1... Training loss: 0.00034... Test loss: 0.00032\n",
      "Epoch: 1... Training loss: 0.00034... Test loss: 0.00035\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.0003\n",
      "Epoch: 1... Training loss: 0.00029... Test loss: 0.0003\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.0003\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.00026\n",
      "314.3348051307257\n",
      "Epoch: 1... Training loss: 0.97335... Test loss: 0.29176\n",
      "Epoch: 1... Training loss: 0.50244... Test loss: 0.14851\n",
      "Epoch: 1... Training loss: 0.31218... Test loss: 0.07446\n",
      "Epoch: 1... Training loss: 0.19874... Test loss: 0.04577\n",
      "Epoch: 1... Training loss: 0.13874... Test loss: 0.03077\n",
      "Epoch: 1... Training loss: 0.1095... Test loss: 0.02279\n",
      "Epoch: 1... Training loss: 0.09392... Test loss: 0.01977\n",
      "Epoch: 1... Training loss: 0.08105... Test loss: 0.01508\n",
      "Epoch: 1... Training loss: 0.07049... Test loss: 0.0171\n",
      "Epoch: 1... Training loss: 0.0588... Test loss: 0.01216\n",
      "Epoch: 1... Training loss: 0.05555... Test loss: 0.01867\n",
      "Epoch: 1... Training loss: 0.04923... Test loss: 0.00885\n",
      "Epoch: 1... Training loss: 0.04227... Test loss: 0.01389\n",
      "Epoch: 1... Training loss: 0.03972... Test loss: 0.00782\n",
      "Epoch: 1... Training loss: 0.03633... Test loss: 0.0144\n",
      "Epoch: 1... Training loss: 0.03443... Test loss: 0.00722\n",
      "Epoch: 1... Training loss: 0.03102... Test loss: 0.01018\n",
      "Epoch: 1... Training loss: 0.02923... Test loss: 0.01062\n",
      "Epoch: 1... Training loss: 0.02713... Test loss: 0.00722\n",
      "Epoch: 1... Training loss: 0.02651... Test loss: 0.01533\n",
      "Epoch: 1... Training loss: 0.02502... Test loss: 0.0042\n",
      "Epoch: 1... Training loss: 0.02443... Test loss: 0.01632\n",
      "Epoch: 1... Training loss: 0.02255... Test loss: 0.00474\n",
      "Epoch: 1... Training loss: 0.02206... Test loss: 0.01592\n",
      "Epoch: 1... Training loss: 0.02026... Test loss: 0.00598\n",
      "Epoch: 1... Training loss: 0.01936... Test loss: 0.01152\n",
      "Epoch: 1... Training loss: 0.0189... Test loss: 0.00554\n",
      "Epoch: 1... Training loss: 0.01788... Test loss: 0.01378\n",
      "Epoch: 1... Training loss: 0.01704... Test loss: 0.0064\n",
      "Epoch: 1... Training loss: 0.01616... Test loss: 0.0117\n",
      "Epoch: 1... Training loss: 0.01573... Test loss: 0.00917\n",
      "Epoch: 1... Training loss: 0.01481... Test loss: 0.01465\n",
      "Epoch: 1... Training loss: 0.01431... Test loss: 0.00627\n",
      "Epoch: 1... Training loss: 0.01388... Test loss: 0.01059\n",
      "Epoch: 1... Training loss: 0.01296... Test loss: 0.00675\n",
      "Epoch: 1... Training loss: 0.01226... Test loss: 0.00962\n",
      "Epoch: 1... Training loss: 0.01178... Test loss: 0.00628\n",
      "Epoch: 1... Training loss: 0.01155... Test loss: 0.00838\n",
      "Epoch: 1... Training loss: 0.01093... Test loss: 0.00788\n",
      "Epoch: 1... Training loss: 0.01075... Test loss: 0.00849\n",
      "Epoch: 1... Training loss: 0.01015... Test loss: 0.00827\n",
      "Epoch: 1... Training loss: 0.01005... Test loss: 0.00613\n",
      "Epoch: 1... Training loss: 0.0097... Test loss: 0.00748\n",
      "Epoch: 1... Training loss: 0.00949... Test loss: 0.00648\n",
      "Epoch: 1... Training loss: 0.00923... Test loss: 0.00579\n",
      "Epoch: 1... Training loss: 0.00911... Test loss: 0.00795\n",
      "Epoch: 1... Training loss: 0.00874... Test loss: 0.00388\n",
      "Epoch: 1... Training loss: 0.00861... Test loss: 0.00738\n",
      "Epoch: 1... Training loss: 0.00838... Test loss: 0.00457\n",
      "Epoch: 1... Training loss: 0.00826... Test loss: 0.00787\n",
      "Epoch: 1... Training loss: 0.00786... Test loss: 0.00465\n",
      "Epoch: 1... Training loss: 0.00778... Test loss: 0.00765\n",
      "Epoch: 1... Training loss: 0.00735... Test loss: 0.00528\n",
      "Epoch: 1... Training loss: 0.00726... Test loss: 0.00646\n",
      "Epoch: 1... Training loss: 0.00703... Test loss: 0.00587\n",
      "Epoch: 1... Training loss: 0.00693... Test loss: 0.00599\n",
      "Epoch: 1... Training loss: 0.00675... Test loss: 0.00589\n",
      "Epoch: 1... Training loss: 0.00666... Test loss: 0.00554\n",
      "Epoch: 1... Training loss: 0.00648... Test loss: 0.00621\n",
      "Epoch: 1... Training loss: 0.00646... Test loss: 0.00515\n",
      "Epoch: 1... Training loss: 0.00626... Test loss: 0.00607\n",
      "Epoch: 1... Training loss: 0.00616... Test loss: 0.00476\n",
      "Epoch: 1... Training loss: 0.00585... Test loss: 0.0057\n",
      "Epoch: 1... Training loss: 0.00575... Test loss: 0.00516\n",
      "Epoch: 1... Training loss: 0.01482... Test loss: 0.01288\n",
      "Epoch: 1... Training loss: 0.01199... Test loss: 0.01072\n",
      "Epoch: 1... Training loss: 0.011... Test loss: 0.01307\n",
      "Epoch: 1... Training loss: 0.00988... Test loss: 0.00965\n",
      "Epoch: 1... Training loss: 0.01161... Test loss: 0.01055\n",
      "Epoch: 1... Training loss: 0.01007... Test loss: 0.01367\n",
      "Epoch: 1... Training loss: 0.01032... Test loss: 0.00937\n",
      "Epoch: 1... Training loss: 0.00863... Test loss: 0.01228\n",
      "Epoch: 1... Training loss: 0.00896... Test loss: 0.00843\n",
      "Epoch: 1... Training loss: 0.0089... Test loss: 0.01169\n",
      "Epoch: 1... Training loss: 0.00807... Test loss: 0.00948\n",
      "Epoch: 1... Training loss: 0.00829... Test loss: 0.00989\n",
      "Epoch: 1... Training loss: 0.00782... Test loss: 0.00965\n",
      "Epoch: 1... Training loss: 0.00735... Test loss: 0.00983\n",
      "Epoch: 1... Training loss: 0.0077... Test loss: 0.00837\n",
      "Epoch: 1... Training loss: 0.00677... Test loss: 0.0088\n",
      "Epoch: 1... Training loss: 0.00673... Test loss: 0.0074\n",
      "Epoch: 1... Training loss: 0.00676... Test loss: 0.00837\n",
      "Epoch: 1... Training loss: 0.00611... Test loss: 0.00739\n",
      "Epoch: 1... Training loss: 0.00658... Test loss: 0.00627\n",
      "Epoch: 1... Training loss: 0.00586... Test loss: 0.00751\n",
      "Epoch: 1... Training loss: 0.00557... Test loss: 0.00507\n",
      "Epoch: 1... Training loss: 0.00588... Test loss: 0.00685\n",
      "Epoch: 1... Training loss: 0.00568... Test loss: 0.0052\n",
      "Epoch: 1... Training loss: 0.00517... Test loss: 0.00711\n",
      "Epoch: 1... Training loss: 0.00561... Test loss: 0.00512\n",
      "Epoch: 1... Training loss: 0.00496... Test loss: 0.00625\n",
      "Epoch: 1... Training loss: 0.00498... Test loss: 0.0049\n",
      "Epoch: 1... Training loss: 0.0049... Test loss: 0.0049\n",
      "Epoch: 1... Training loss: 0.00487... Test loss: 0.00514\n",
      "Epoch: 1... Training loss: 0.00454... Test loss: 0.0057\n",
      "Epoch: 1... Training loss: 0.00441... Test loss: 0.00459\n",
      "Epoch: 1... Training loss: 0.00422... Test loss: 0.0048\n",
      "Epoch: 1... Training loss: 0.00419... Test loss: 0.0039\n",
      "Epoch: 1... Training loss: 0.00406... Test loss: 0.00415\n",
      "Epoch: 1... Training loss: 0.00396... Test loss: 0.00383\n",
      "Epoch: 1... Training loss: 0.00388... Test loss: 0.00406\n",
      "Epoch: 1... Training loss: 0.00383... Test loss: 0.00364\n",
      "Epoch: 1... Training loss: 0.00392... Test loss: 0.0037\n",
      "Epoch: 1... Training loss: 0.00371... Test loss: 0.00333\n",
      "Epoch: 1... Training loss: 0.00365... Test loss: 0.0034\n",
      "Epoch: 1... Training loss: 0.00352... Test loss: 0.00358\n",
      "Epoch: 1... Training loss: 0.00345... Test loss: 0.00369\n",
      "Epoch: 1... Training loss: 0.00341... Test loss: 0.00336\n",
      "Epoch: 1... Training loss: 0.00324... Test loss: 0.00355\n",
      "Epoch: 1... Training loss: 0.0032... Test loss: 0.00272\n",
      "Epoch: 1... Training loss: 0.00327... Test loss: 0.00362\n",
      "Epoch: 1... Training loss: 0.00312... Test loss: 0.00271\n",
      "Epoch: 1... Training loss: 0.00309... Test loss: 0.00388\n",
      "Epoch: 1... Training loss: 0.00309... Test loss: 0.00284\n",
      "Epoch: 1... Training loss: 0.00307... Test loss: 0.00349\n",
      "Epoch: 1... Training loss: 0.003... Test loss: 0.00269\n",
      "Epoch: 1... Training loss: 0.0029... Test loss: 0.00309\n",
      "Epoch: 1... Training loss: 0.00281... Test loss: 0.00282\n",
      "Epoch: 1... Training loss: 0.00273... Test loss: 0.00251\n",
      "Epoch: 1... Training loss: 0.00269... Test loss: 0.00251\n",
      "Epoch: 1... Training loss: 0.00276... Test loss: 0.00253\n",
      "Epoch: 1... Training loss: 0.00262... Test loss: 0.00276\n",
      "Epoch: 1... Training loss: 0.00256... Test loss: 0.00288\n",
      "Epoch: 1... Training loss: 0.00255... Test loss: 0.00225\n",
      "Epoch: 1... Training loss: 0.00248... Test loss: 0.00268\n",
      "Epoch: 1... Training loss: 0.00241... Test loss: 0.0023\n",
      "Epoch: 1... Training loss: 0.00229... Test loss: 0.0025\n",
      "Epoch: 1... Training loss: 0.0023... Test loss: 0.00224\n",
      "Epoch: 1... Training loss: 0.00225... Test loss: 0.00267\n",
      "Epoch: 1... Training loss: 0.00223... Test loss: 0.00213\n",
      "Epoch: 1... Training loss: 0.00218... Test loss: 0.00245\n",
      "Epoch: 1... Training loss: 0.00202... Test loss: 0.00201\n",
      "Epoch: 1... Training loss: 0.00208... Test loss: 0.00203\n",
      "Epoch: 1... Training loss: 0.00193... Test loss: 0.00205\n",
      "Epoch: 1... Training loss: 0.00198... Test loss: 0.00194\n",
      "Epoch: 1... Training loss: 0.00198... Test loss: 0.00203\n",
      "Epoch: 1... Training loss: 0.00192... Test loss: 0.00193\n",
      "Epoch: 1... Training loss: 0.00187... Test loss: 0.00204\n",
      "Epoch: 1... Training loss: 0.00191... Test loss: 0.00185\n",
      "Epoch: 1... Training loss: 0.00179... Test loss: 0.00179\n",
      "Epoch: 1... Training loss: 0.00176... Test loss: 0.00162\n",
      "Epoch: 1... Training loss: 0.00168... Test loss: 0.00176\n",
      "Epoch: 1... Training loss: 0.00163... Test loss: 0.00161\n",
      "Epoch: 1... Training loss: 0.00158... Test loss: 0.00173\n",
      "Epoch: 1... Training loss: 0.00155... Test loss: 0.00162\n",
      "Epoch: 1... Training loss: 0.00153... Test loss: 0.00162\n",
      "Epoch: 1... Training loss: 0.00157... Test loss: 0.00162\n",
      "Epoch: 1... Training loss: 0.00144... Test loss: 0.00151\n",
      "Epoch: 1... Training loss: 0.00139... Test loss: 0.00157\n",
      "Epoch: 1... Training loss: 0.00135... Test loss: 0.00138\n",
      "Epoch: 1... Training loss: 0.00127... Test loss: 0.00148\n",
      "Epoch: 1... Training loss: 0.0013... Test loss: 0.00146\n",
      "Epoch: 1... Training loss: 0.00125... Test loss: 0.00138\n",
      "Epoch: 1... Training loss: 0.00124... Test loss: 0.00139\n",
      "Epoch: 1... Training loss: 0.00112... Test loss: 0.00126\n",
      "Epoch: 1... Training loss: 0.00111... Test loss: 0.00144\n",
      "Epoch: 1... Training loss: 0.00107... Test loss: 0.00111\n",
      "Epoch: 1... Training loss: 0.0011... Test loss: 0.00121\n",
      "Epoch: 1... Training loss: 0.00101... Test loss: 0.00117\n",
      "Epoch: 1... Training loss: 0.00112... Test loss: 0.00116\n",
      "Epoch: 1... Training loss: 0.00096... Test loss: 0.00108\n",
      "Epoch: 1... Training loss: 0.00095... Test loss: 0.00112\n",
      "Epoch: 1... Training loss: 0.00094... Test loss: 0.00105\n",
      "Epoch: 1... Training loss: 0.00087... Test loss: 0.00109\n",
      "Epoch: 1... Training loss: 0.00087... Test loss: 0.00095\n",
      "Epoch: 1... Training loss: 0.0009... Test loss: 0.00093\n",
      "Epoch: 1... Training loss: 0.00081... Test loss: 0.00097\n",
      "Epoch: 1... Training loss: 0.00079... Test loss: 0.00083\n",
      "Epoch: 1... Training loss: 0.00075... Test loss: 0.00086\n",
      "Epoch: 1... Training loss: 0.00071... Test loss: 0.00083\n",
      "Epoch: 1... Training loss: 0.00069... Test loss: 0.00076\n",
      "Epoch: 1... Training loss: 0.00067... Test loss: 0.00076\n",
      "Epoch: 1... Training loss: 0.00073... Test loss: 0.0007\n",
      "Epoch: 1... Training loss: 0.00066... Test loss: 0.00069\n",
      "Epoch: 1... Training loss: 0.00061... Test loss: 0.00073\n",
      "Epoch: 1... Training loss: 0.00064... Test loss: 0.00065\n",
      "Epoch: 1... Training loss: 0.00064... Test loss: 0.00058\n",
      "Epoch: 1... Training loss: 0.00058... Test loss: 0.00069\n",
      "Epoch: 1... Training loss: 0.00059... Test loss: 0.00056\n",
      "Epoch: 1... Training loss: 0.0006... Test loss: 0.00063\n",
      "Epoch: 1... Training loss: 0.00056... Test loss: 0.00051\n",
      "Epoch: 1... Training loss: 0.0005... Test loss: 0.00062\n",
      "Epoch: 1... Training loss: 0.00053... Test loss: 0.00048\n",
      "Epoch: 1... Training loss: 0.00049... Test loss: 0.00053\n",
      "Epoch: 1... Training loss: 0.00051... Test loss: 0.00048\n",
      "Epoch: 1... Training loss: 0.00047... Test loss: 0.00055\n",
      "Epoch: 1... Training loss: 0.00045... Test loss: 0.00041\n",
      "Epoch: 1... Training loss: 0.00051... Test loss: 0.00044\n",
      "Epoch: 1... Training loss: 0.00043... Test loss: 0.00039\n",
      "Epoch: 1... Training loss: 0.00042... Test loss: 0.00044\n",
      "Epoch: 1... Training loss: 0.0004... Test loss: 0.00037\n",
      "Epoch: 1... Training loss: 0.00041... Test loss: 0.00038\n",
      "Epoch: 1... Training loss: 0.00036... Test loss: 0.00036\n",
      "Epoch: 1... Training loss: 0.00034... Test loss: 0.00037\n",
      "Epoch: 1... Training loss: 0.00036... Test loss: 0.00039\n",
      "Epoch: 1... Training loss: 0.00032... Test loss: 0.00033\n",
      "Epoch: 1... Training loss: 0.00031... Test loss: 0.00034\n",
      "Epoch: 1... Training loss: 0.00033... Test loss: 0.0003\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00036\n",
      "Epoch: 1... Training loss: 0.00029... Test loss: 0.00033\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00035\n",
      "377.59741854760796\n",
      "Epoch: 1... Training loss: 0.96613... Test loss: 0.31573\n",
      "Epoch: 1... Training loss: 0.45092... Test loss: 0.12752\n",
      "Epoch: 1... Training loss: 0.26805... Test loss: 0.06883\n",
      "Epoch: 1... Training loss: 0.19562... Test loss: 0.04762\n",
      "Epoch: 1... Training loss: 0.1414... Test loss: 0.0412\n",
      "Epoch: 1... Training loss: 0.09512... Test loss: 0.02883\n",
      "Epoch: 1... Training loss: 0.08362... Test loss: 0.02239\n",
      "Epoch: 1... Training loss: 0.07017... Test loss: 0.01876\n",
      "Epoch: 1... Training loss: 0.06029... Test loss: 0.01129\n",
      "Epoch: 1... Training loss: 0.05262... Test loss: 0.01084\n",
      "Epoch: 1... Training loss: 0.04711... Test loss: 0.00706\n",
      "Epoch: 1... Training loss: 0.04301... Test loss: 0.0084\n",
      "Epoch: 1... Training loss: 0.04001... Test loss: 0.00532\n",
      "Epoch: 1... Training loss: 0.03692... Test loss: 0.00743\n",
      "Epoch: 1... Training loss: 0.03358... Test loss: 0.00433\n",
      "Epoch: 1... Training loss: 0.03106... Test loss: 0.0038\n",
      "Epoch: 1... Training loss: 0.02929... Test loss: 0.00354\n",
      "Epoch: 1... Training loss: 0.02761... Test loss: 0.00706\n",
      "Epoch: 1... Training loss: 0.02574... Test loss: 0.00291\n",
      "Epoch: 1... Training loss: 0.02567... Test loss: 0.0059\n",
      "Epoch: 1... Training loss: 0.02356... Test loss: 0.00272\n",
      "Epoch: 1... Training loss: 0.02343... Test loss: 0.00887\n",
      "Epoch: 1... Training loss: 0.02117... Test loss: 0.00297\n",
      "Epoch: 1... Training loss: 0.02091... Test loss: 0.0088\n",
      "Epoch: 1... Training loss: 0.01906... Test loss: 0.00378\n",
      "Epoch: 1... Training loss: 0.0183... Test loss: 0.00696\n",
      "Epoch: 1... Training loss: 0.01736... Test loss: 0.00411\n",
      "Epoch: 1... Training loss: 0.01686... Test loss: 0.00628\n",
      "Epoch: 1... Training loss: 0.01609... Test loss: 0.00435\n",
      "Epoch: 1... Training loss: 0.01565... Test loss: 0.00924\n",
      "Epoch: 1... Training loss: 0.0151... Test loss: 0.00506\n",
      "Epoch: 1... Training loss: 0.01463... Test loss: 0.00882\n",
      "Epoch: 1... Training loss: 0.0142... Test loss: 0.00907\n",
      "Epoch: 1... Training loss: 0.01354... Test loss: 0.00691\n",
      "Epoch: 1... Training loss: 0.0133... Test loss: 0.01016\n",
      "Epoch: 1... Training loss: 0.01268... Test loss: 0.00587\n",
      "Epoch: 1... Training loss: 0.01261... Test loss: 0.01113\n",
      "Epoch: 1... Training loss: 0.01211... Test loss: 0.00491\n",
      "Epoch: 1... Training loss: 0.01208... Test loss: 0.00873\n",
      "Epoch: 1... Training loss: 0.01136... Test loss: 0.0056\n",
      "Epoch: 1... Training loss: 0.01098... Test loss: 0.00877\n",
      "Epoch: 1... Training loss: 0.01079... Test loss: 0.00536\n",
      "Epoch: 1... Training loss: 0.01037... Test loss: 0.00703\n",
      "Epoch: 1... Training loss: 0.00997... Test loss: 0.00675\n",
      "Epoch: 1... Training loss: 0.00951... Test loss: 0.00842\n",
      "Epoch: 1... Training loss: 0.00958... Test loss: 0.00589\n",
      "Epoch: 1... Training loss: 0.00908... Test loss: 0.00857\n",
      "Epoch: 1... Training loss: 0.00887... Test loss: 0.00491\n",
      "Epoch: 1... Training loss: 0.00862... Test loss: 0.00807\n",
      "Epoch: 1... Training loss: 0.0083... Test loss: 0.00462\n",
      "Epoch: 1... Training loss: 0.00785... Test loss: 0.0076\n",
      "Epoch: 1... Training loss: 0.0077... Test loss: 0.0043\n",
      "Epoch: 1... Training loss: 0.00746... Test loss: 0.0067\n",
      "Epoch: 1... Training loss: 0.00733... Test loss: 0.00537\n",
      "Epoch: 1... Training loss: 0.00722... Test loss: 0.00615\n",
      "Epoch: 1... Training loss: 0.00703... Test loss: 0.00531\n",
      "Epoch: 1... Training loss: 0.00693... Test loss: 0.00513\n",
      "Epoch: 1... Training loss: 0.00668... Test loss: 0.00559\n",
      "Epoch: 1... Training loss: 0.00656... Test loss: 0.00451\n",
      "Epoch: 1... Training loss: 0.00638... Test loss: 0.00605\n",
      "Epoch: 1... Training loss: 0.0063... Test loss: 0.00546\n",
      "Epoch: 1... Training loss: 0.0061... Test loss: 0.00566\n",
      "Epoch: 1... Training loss: 0.00597... Test loss: 0.00543\n",
      "Epoch: 1... Training loss: 0.00576... Test loss: 0.00518\n",
      "Epoch: 1... Training loss: 0.01797... Test loss: 0.01398\n",
      "Epoch: 1... Training loss: 0.0096... Test loss: 0.01231\n",
      "Epoch: 1... Training loss: 0.00999... Test loss: 0.01412\n",
      "Epoch: 1... Training loss: 0.01135... Test loss: 0.01439\n",
      "Epoch: 1... Training loss: 0.01041... Test loss: 0.01153\n",
      "Epoch: 1... Training loss: 0.0103... Test loss: 0.01254\n",
      "Epoch: 1... Training loss: 0.01058... Test loss: 0.01263\n",
      "Epoch: 1... Training loss: 0.00925... Test loss: 0.01108\n",
      "Epoch: 1... Training loss: 0.00867... Test loss: 0.01137\n",
      "Epoch: 1... Training loss: 0.00922... Test loss: 0.00959\n",
      "Epoch: 1... Training loss: 0.00913... Test loss: 0.01061\n",
      "Epoch: 1... Training loss: 0.00793... Test loss: 0.00732\n",
      "Epoch: 1... Training loss: 0.00817... Test loss: 0.00942\n",
      "Epoch: 1... Training loss: 0.0081... Test loss: 0.00848\n",
      "Epoch: 1... Training loss: 0.00737... Test loss: 0.01006\n",
      "Epoch: 1... Training loss: 0.00697... Test loss: 0.01016\n",
      "Epoch: 1... Training loss: 0.00727... Test loss: 0.00884\n",
      "Epoch: 1... Training loss: 0.00736... Test loss: 0.00885\n",
      "Epoch: 1... Training loss: 0.00687... Test loss: 0.00778\n",
      "Epoch: 1... Training loss: 0.00647... Test loss: 0.0076\n",
      "Epoch: 1... Training loss: 0.00646... Test loss: 0.00685\n",
      "Epoch: 1... Training loss: 0.00629... Test loss: 0.00721\n",
      "Epoch: 1... Training loss: 0.00591... Test loss: 0.00631\n",
      "Epoch: 1... Training loss: 0.00565... Test loss: 0.00604\n",
      "Epoch: 1... Training loss: 0.00562... Test loss: 0.00591\n",
      "Epoch: 1... Training loss: 0.00553... Test loss: 0.00586\n",
      "Epoch: 1... Training loss: 0.0055... Test loss: 0.00626\n",
      "Epoch: 1... Training loss: 0.00515... Test loss: 0.00528\n",
      "Epoch: 1... Training loss: 0.00502... Test loss: 0.0056\n",
      "Epoch: 1... Training loss: 0.00476... Test loss: 0.00538\n",
      "Epoch: 1... Training loss: 0.00496... Test loss: 0.00552\n",
      "Epoch: 1... Training loss: 0.00471... Test loss: 0.00484\n",
      "Epoch: 1... Training loss: 0.00463... Test loss: 0.00529\n",
      "Epoch: 1... Training loss: 0.0045... Test loss: 0.00464\n",
      "Epoch: 1... Training loss: 0.00441... Test loss: 0.00501\n",
      "Epoch: 1... Training loss: 0.00419... Test loss: 0.00423\n",
      "Epoch: 1... Training loss: 0.00424... Test loss: 0.00449\n",
      "Epoch: 1... Training loss: 0.00407... Test loss: 0.00435\n",
      "Epoch: 1... Training loss: 0.00402... Test loss: 0.00433\n",
      "Epoch: 1... Training loss: 0.00393... Test loss: 0.00397\n",
      "Epoch: 1... Training loss: 0.00373... Test loss: 0.00445\n",
      "Epoch: 1... Training loss: 0.00399... Test loss: 0.00372\n",
      "Epoch: 1... Training loss: 0.00364... Test loss: 0.00427\n",
      "Epoch: 1... Training loss: 0.00369... Test loss: 0.00352\n",
      "Epoch: 1... Training loss: 0.00372... Test loss: 0.00414\n",
      "Epoch: 1... Training loss: 0.0036... Test loss: 0.00329\n",
      "Epoch: 1... Training loss: 0.0036... Test loss: 0.00393\n",
      "Epoch: 1... Training loss: 0.00343... Test loss: 0.0035\n",
      "Epoch: 1... Training loss: 0.00331... Test loss: 0.00346\n",
      "Epoch: 1... Training loss: 0.00328... Test loss: 0.00365\n",
      "Epoch: 1... Training loss: 0.00326... Test loss: 0.00359\n",
      "Epoch: 1... Training loss: 0.00317... Test loss: 0.00334\n",
      "Epoch: 1... Training loss: 0.00313... Test loss: 0.00351\n",
      "Epoch: 1... Training loss: 0.00306... Test loss: 0.00327\n",
      "Epoch: 1... Training loss: 0.00291... Test loss: 0.00357\n",
      "Epoch: 1... Training loss: 0.00288... Test loss: 0.00305\n",
      "Epoch: 1... Training loss: 0.00284... Test loss: 0.00308\n",
      "Epoch: 1... Training loss: 0.00275... Test loss: 0.00338\n",
      "Epoch: 1... Training loss: 0.00272... Test loss: 0.0028\n",
      "Epoch: 1... Training loss: 0.0026... Test loss: 0.00293\n",
      "Epoch: 1... Training loss: 0.00276... Test loss: 0.00264\n",
      "Epoch: 1... Training loss: 0.00271... Test loss: 0.00272\n",
      "Epoch: 1... Training loss: 0.00248... Test loss: 0.00254\n",
      "Epoch: 1... Training loss: 0.0024... Test loss: 0.00268\n",
      "Epoch: 1... Training loss: 0.00235... Test loss: 0.00241\n",
      "Epoch: 1... Training loss: 0.00231... Test loss: 0.00258\n",
      "Epoch: 1... Training loss: 0.00228... Test loss: 0.00241\n",
      "Epoch: 1... Training loss: 0.00222... Test loss: 0.00259\n",
      "Epoch: 1... Training loss: 0.00221... Test loss: 0.00231\n",
      "Epoch: 1... Training loss: 0.00211... Test loss: 0.00233\n",
      "Epoch: 1... Training loss: 0.00201... Test loss: 0.0022\n",
      "Epoch: 1... Training loss: 0.00206... Test loss: 0.00233\n",
      "Epoch: 1... Training loss: 0.00189... Test loss: 0.00199\n",
      "Epoch: 1... Training loss: 0.00187... Test loss: 0.00204\n",
      "Epoch: 1... Training loss: 0.00186... Test loss: 0.00179\n",
      "Epoch: 1... Training loss: 0.0019... Test loss: 0.00196\n",
      "Epoch: 1... Training loss: 0.00178... Test loss: 0.00171\n",
      "Epoch: 1... Training loss: 0.0017... Test loss: 0.00188\n",
      "Epoch: 1... Training loss: 0.00166... Test loss: 0.00158\n",
      "Epoch: 1... Training loss: 0.00163... Test loss: 0.00198\n",
      "Epoch: 1... Training loss: 0.00168... Test loss: 0.00163\n",
      "Epoch: 1... Training loss: 0.00161... Test loss: 0.00165\n",
      "Epoch: 1... Training loss: 0.0016... Test loss: 0.00166\n",
      "Epoch: 1... Training loss: 0.00148... Test loss: 0.00179\n",
      "Epoch: 1... Training loss: 0.00145... Test loss: 0.0016\n",
      "Epoch: 1... Training loss: 0.00142... Test loss: 0.00161\n",
      "Epoch: 1... Training loss: 0.00138... Test loss: 0.00142\n",
      "Epoch: 1... Training loss: 0.00135... Test loss: 0.00154\n",
      "Epoch: 1... Training loss: 0.00129... Test loss: 0.00123\n",
      "Epoch: 1... Training loss: 0.00127... Test loss: 0.00142\n",
      "Epoch: 1... Training loss: 0.00131... Test loss: 0.00124\n",
      "Epoch: 1... Training loss: 0.00122... Test loss: 0.00152\n",
      "Epoch: 1... Training loss: 0.00111... Test loss: 0.00132\n",
      "Epoch: 1... Training loss: 0.00112... Test loss: 0.00144\n",
      "Epoch: 1... Training loss: 0.00107... Test loss: 0.00113\n",
      "Epoch: 1... Training loss: 0.001... Test loss: 0.00133\n",
      "Epoch: 1... Training loss: 0.00101... Test loss: 0.00093\n",
      "Epoch: 1... Training loss: 0.00097... Test loss: 0.00131\n",
      "Epoch: 1... Training loss: 0.00097... Test loss: 0.0009\n",
      "Epoch: 1... Training loss: 0.00089... Test loss: 0.00111\n",
      "Epoch: 1... Training loss: 0.00088... Test loss: 0.00089\n",
      "Epoch: 1... Training loss: 0.00085... Test loss: 0.00083\n",
      "Epoch: 1... Training loss: 0.00076... Test loss: 0.00085\n",
      "Epoch: 1... Training loss: 0.00079... Test loss: 0.00085\n",
      "Epoch: 1... Training loss: 0.00077... Test loss: 0.0007\n",
      "Epoch: 1... Training loss: 0.00073... Test loss: 0.00094\n",
      "Epoch: 1... Training loss: 0.00071... Test loss: 0.00068\n",
      "Epoch: 1... Training loss: 0.00067... Test loss: 0.001\n",
      "Epoch: 1... Training loss: 0.00064... Test loss: 0.00058\n",
      "Epoch: 1... Training loss: 0.0006... Test loss: 0.00094\n",
      "Epoch: 1... Training loss: 0.00057... Test loss: 0.00055\n",
      "Epoch: 1... Training loss: 0.00053... Test loss: 0.00072\n",
      "Epoch: 1... Training loss: 0.00053... Test loss: 0.00052\n",
      "Epoch: 1... Training loss: 0.00051... Test loss: 0.00056\n",
      "Epoch: 1... Training loss: 0.00047... Test loss: 0.00049\n",
      "Epoch: 1... Training loss: 0.00053... Test loss: 0.00047\n",
      "Epoch: 1... Training loss: 0.00046... Test loss: 0.00042\n",
      "Epoch: 1... Training loss: 0.00046... Test loss: 0.00047\n",
      "Epoch: 1... Training loss: 0.00047... Test loss: 0.00048\n",
      "Epoch: 1... Training loss: 0.00047... Test loss: 0.00049\n",
      "Epoch: 1... Training loss: 0.0004... Test loss: 0.00045\n",
      "Epoch: 1... Training loss: 0.00037... Test loss: 0.00038\n",
      "Epoch: 1... Training loss: 0.00033... Test loss: 0.00036\n",
      "Epoch: 1... Training loss: 0.00033... Test loss: 0.00033\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.00044\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.0003\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.00026... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00026... Test loss: 0.00039\n",
      "Epoch: 1... Training loss: 0.00026... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00018\n",
      "277.6960602266481\n",
      "Epoch: 1... Training loss: 0.91417... Test loss: 0.29442\n",
      "Epoch: 1... Training loss: 0.47975... Test loss: 0.17752\n",
      "Epoch: 1... Training loss: 0.27464... Test loss: 0.09738\n",
      "Epoch: 1... Training loss: 0.18028... Test loss: 0.06519\n",
      "Epoch: 1... Training loss: 0.13304... Test loss: 0.04818\n",
      "Epoch: 1... Training loss: 0.10238... Test loss: 0.05018\n",
      "Epoch: 1... Training loss: 0.09063... Test loss: 0.02271\n",
      "Epoch: 1... Training loss: 0.07733... Test loss: 0.0368\n",
      "Epoch: 1... Training loss: 0.06535... Test loss: 0.01682\n",
      "Epoch: 1... Training loss: 0.05787... Test loss: 0.03094\n",
      "Epoch: 1... Training loss: 0.05175... Test loss: 0.0177\n",
      "Epoch: 1... Training loss: 0.04689... Test loss: 0.02262\n",
      "Epoch: 1... Training loss: 0.04402... Test loss: 0.01774\n",
      "Epoch: 1... Training loss: 0.03801... Test loss: 0.02219\n",
      "Epoch: 1... Training loss: 0.03608... Test loss: 0.02523\n",
      "Epoch: 1... Training loss: 0.03361... Test loss: 0.02101\n",
      "Epoch: 1... Training loss: 0.03169... Test loss: 0.03995\n",
      "Epoch: 1... Training loss: 0.02932... Test loss: 0.02006\n",
      "Epoch: 1... Training loss: 0.02624... Test loss: 0.03386\n",
      "Epoch: 1... Training loss: 0.02364... Test loss: 0.01894\n",
      "Epoch: 1... Training loss: 0.02235... Test loss: 0.01714\n",
      "Epoch: 1... Training loss: 0.02105... Test loss: 0.02624\n",
      "Epoch: 1... Training loss: 0.0198... Test loss: 0.00951\n",
      "Epoch: 1... Training loss: 0.01832... Test loss: 0.02388\n",
      "Epoch: 1... Training loss: 0.01857... Test loss: 0.0098\n",
      "Epoch: 1... Training loss: 0.01712... Test loss: 0.02065\n",
      "Epoch: 1... Training loss: 0.0167... Test loss: 0.01013\n",
      "Epoch: 1... Training loss: 0.01585... Test loss: 0.02208\n",
      "Epoch: 1... Training loss: 0.01535... Test loss: 0.0098\n",
      "Epoch: 1... Training loss: 0.01468... Test loss: 0.02052\n",
      "Epoch: 1... Training loss: 0.01385... Test loss: 0.00966\n",
      "Epoch: 1... Training loss: 0.01347... Test loss: 0.0204\n",
      "Epoch: 1... Training loss: 0.0126... Test loss: 0.00809\n",
      "Epoch: 1... Training loss: 0.01225... Test loss: 0.01934\n",
      "Epoch: 1... Training loss: 0.01191... Test loss: 0.00754\n",
      "Epoch: 1... Training loss: 0.01191... Test loss: 0.01198\n",
      "Epoch: 1... Training loss: 0.01166... Test loss: 0.00934\n",
      "Epoch: 1... Training loss: 0.01114... Test loss: 0.00961\n",
      "Epoch: 1... Training loss: 0.01092... Test loss: 0.0115\n",
      "Epoch: 1... Training loss: 0.01049... Test loss: 0.00844\n",
      "Epoch: 1... Training loss: 0.01035... Test loss: 0.01263\n",
      "Epoch: 1... Training loss: 0.01001... Test loss: 0.00751\n",
      "Epoch: 1... Training loss: 0.00951... Test loss: 0.01182\n",
      "Epoch: 1... Training loss: 0.00929... Test loss: 0.00675\n",
      "Epoch: 1... Training loss: 0.00904... Test loss: 0.01108\n",
      "Epoch: 1... Training loss: 0.00886... Test loss: 0.0063\n",
      "Epoch: 1... Training loss: 0.00855... Test loss: 0.0101\n",
      "Epoch: 1... Training loss: 0.00833... Test loss: 0.00565\n",
      "Epoch: 1... Training loss: 0.00812... Test loss: 0.00897\n",
      "Epoch: 1... Training loss: 0.00773... Test loss: 0.0051\n",
      "Epoch: 1... Training loss: 0.00764... Test loss: 0.00817\n",
      "Epoch: 1... Training loss: 0.00743... Test loss: 0.0046\n",
      "Epoch: 1... Training loss: 0.00731... Test loss: 0.00785\n",
      "Epoch: 1... Training loss: 0.00707... Test loss: 0.00467\n",
      "Epoch: 1... Training loss: 0.00695... Test loss: 0.00708\n",
      "Epoch: 1... Training loss: 0.00678... Test loss: 0.00572\n",
      "Epoch: 1... Training loss: 0.00649... Test loss: 0.00562\n",
      "Epoch: 1... Training loss: 0.00643... Test loss: 0.00602\n",
      "Epoch: 1... Training loss: 0.00611... Test loss: 0.00536\n",
      "Epoch: 1... Training loss: 0.00607... Test loss: 0.00541\n",
      "Epoch: 1... Training loss: 0.00585... Test loss: 0.0056\n",
      "Epoch: 1... Training loss: 0.00586... Test loss: 0.00491\n",
      "Epoch: 1... Training loss: 0.00555... Test loss: 0.00541\n",
      "Epoch: 1... Training loss: 0.00549... Test loss: 0.00521\n",
      "Epoch: 1... Training loss: 0.00908... Test loss: 0.01192\n",
      "Epoch: 1... Training loss: 0.01701... Test loss: 0.00861\n",
      "Epoch: 1... Training loss: 0.00919... Test loss: 0.00641\n",
      "Epoch: 1... Training loss: 0.00956... Test loss: 0.01063\n",
      "Epoch: 1... Training loss: 0.00825... Test loss: 0.00932\n",
      "Epoch: 1... Training loss: 0.00946... Test loss: 0.00883\n",
      "Epoch: 1... Training loss: 0.00935... Test loss: 0.01069\n",
      "Epoch: 1... Training loss: 0.00942... Test loss: 0.01098\n",
      "Epoch: 1... Training loss: 0.00859... Test loss: 0.00822\n",
      "Epoch: 1... Training loss: 0.00922... Test loss: 0.00938\n",
      "Epoch: 1... Training loss: 0.00784... Test loss: 0.00825\n",
      "Epoch: 1... Training loss: 0.00799... Test loss: 0.00925\n",
      "Epoch: 1... Training loss: 0.00798... Test loss: 0.00889\n",
      "Epoch: 1... Training loss: 0.00691... Test loss: 0.00945\n",
      "Epoch: 1... Training loss: 0.00645... Test loss: 0.00759\n",
      "Epoch: 1... Training loss: 0.0065... Test loss: 0.00742\n",
      "Epoch: 1... Training loss: 0.00702... Test loss: 0.00822\n",
      "Epoch: 1... Training loss: 0.00649... Test loss: 0.00816\n",
      "Epoch: 1... Training loss: 0.00623... Test loss: 0.00746\n",
      "Epoch: 1... Training loss: 0.006... Test loss: 0.00749\n",
      "Epoch: 1... Training loss: 0.00566... Test loss: 0.00708\n",
      "Epoch: 1... Training loss: 0.00564... Test loss: 0.00626\n",
      "Epoch: 1... Training loss: 0.00538... Test loss: 0.00678\n",
      "Epoch: 1... Training loss: 0.00536... Test loss: 0.00488\n",
      "Epoch: 1... Training loss: 0.00524... Test loss: 0.00659\n",
      "Epoch: 1... Training loss: 0.00487... Test loss: 0.00555\n",
      "Epoch: 1... Training loss: 0.005... Test loss: 0.00526\n",
      "Epoch: 1... Training loss: 0.00472... Test loss: 0.00489\n",
      "Epoch: 1... Training loss: 0.00454... Test loss: 0.00485\n",
      "Epoch: 1... Training loss: 0.00445... Test loss: 0.00455\n",
      "Epoch: 1... Training loss: 0.00442... Test loss: 0.00495\n",
      "Epoch: 1... Training loss: 0.00421... Test loss: 0.00446\n",
      "Epoch: 1... Training loss: 0.00402... Test loss: 0.00491\n",
      "Epoch: 1... Training loss: 0.00397... Test loss: 0.00333\n",
      "Epoch: 1... Training loss: 0.00392... Test loss: 0.00455\n",
      "Epoch: 1... Training loss: 0.00362... Test loss: 0.0039\n",
      "Epoch: 1... Training loss: 0.00361... Test loss: 0.0041\n",
      "Epoch: 1... Training loss: 0.00347... Test loss: 0.0041\n",
      "Epoch: 1... Training loss: 0.00339... Test loss: 0.00387\n",
      "Epoch: 1... Training loss: 0.00341... Test loss: 0.00326\n",
      "Epoch: 1... Training loss: 0.00326... Test loss: 0.00347\n",
      "Epoch: 1... Training loss: 0.00323... Test loss: 0.00347\n",
      "Epoch: 1... Training loss: 0.00315... Test loss: 0.00377\n",
      "Epoch: 1... Training loss: 0.00307... Test loss: 0.00337\n",
      "Epoch: 1... Training loss: 0.00316... Test loss: 0.00324\n",
      "Epoch: 1... Training loss: 0.00306... Test loss: 0.00326\n",
      "Epoch: 1... Training loss: 0.00302... Test loss: 0.00306\n",
      "Epoch: 1... Training loss: 0.0028... Test loss: 0.00276\n",
      "Epoch: 1... Training loss: 0.00281... Test loss: 0.00328\n",
      "Epoch: 1... Training loss: 0.00279... Test loss: 0.00347\n",
      "Epoch: 1... Training loss: 0.00267... Test loss: 0.00303\n",
      "Epoch: 1... Training loss: 0.00268... Test loss: 0.00332\n",
      "Epoch: 1... Training loss: 0.00249... Test loss: 0.00345\n",
      "Epoch: 1... Training loss: 0.00256... Test loss: 0.00269\n",
      "Epoch: 1... Training loss: 0.00239... Test loss: 0.00332\n",
      "Epoch: 1... Training loss: 0.00233... Test loss: 0.00238\n",
      "Epoch: 1... Training loss: 0.00247... Test loss: 0.00338\n",
      "Epoch: 1... Training loss: 0.00226... Test loss: 0.00258\n",
      "Epoch: 1... Training loss: 0.00232... Test loss: 0.00281\n",
      "Epoch: 1... Training loss: 0.0022... Test loss: 0.00206\n",
      "Epoch: 1... Training loss: 0.00224... Test loss: 0.00247\n",
      "Epoch: 1... Training loss: 0.00212... Test loss: 0.00202\n",
      "Epoch: 1... Training loss: 0.00203... Test loss: 0.00272\n",
      "Epoch: 1... Training loss: 0.00198... Test loss: 0.00171\n",
      "Epoch: 1... Training loss: 0.00188... Test loss: 0.00211\n",
      "Epoch: 1... Training loss: 0.0019... Test loss: 0.00188\n",
      "Epoch: 1... Training loss: 0.00183... Test loss: 0.00201\n",
      "Epoch: 1... Training loss: 0.00181... Test loss: 0.00185\n",
      "Epoch: 1... Training loss: 0.00174... Test loss: 0.00196\n",
      "Epoch: 1... Training loss: 0.00174... Test loss: 0.00152\n",
      "Epoch: 1... Training loss: 0.00175... Test loss: 0.00185\n",
      "Epoch: 1... Training loss: 0.00162... Test loss: 0.00164\n",
      "Epoch: 1... Training loss: 0.00154... Test loss: 0.00185\n",
      "Epoch: 1... Training loss: 0.00147... Test loss: 0.0016\n",
      "Epoch: 1... Training loss: 0.00154... Test loss: 0.00175\n",
      "Epoch: 1... Training loss: 0.00157... Test loss: 0.00156\n",
      "Epoch: 1... Training loss: 0.00133... Test loss: 0.00169\n",
      "Epoch: 1... Training loss: 0.00133... Test loss: 0.00143\n",
      "Epoch: 1... Training loss: 0.00131... Test loss: 0.00155\n",
      "Epoch: 1... Training loss: 0.00135... Test loss: 0.00148\n",
      "Epoch: 1... Training loss: 0.00123... Test loss: 0.0013\n",
      "Epoch: 1... Training loss: 0.00122... Test loss: 0.00142\n",
      "Epoch: 1... Training loss: 0.0012... Test loss: 0.00115\n",
      "Epoch: 1... Training loss: 0.00121... Test loss: 0.0011\n",
      "Epoch: 1... Training loss: 0.00111... Test loss: 0.00108\n",
      "Epoch: 1... Training loss: 0.00108... Test loss: 0.00126\n",
      "Epoch: 1... Training loss: 0.00111... Test loss: 0.00141\n",
      "Epoch: 1... Training loss: 0.00103... Test loss: 0.00124\n",
      "Epoch: 1... Training loss: 0.00113... Test loss: 0.00121\n",
      "Epoch: 1... Training loss: 0.00095... Test loss: 0.00111\n",
      "Epoch: 1... Training loss: 0.00097... Test loss: 0.00091\n",
      "Epoch: 1... Training loss: 0.00092... Test loss: 0.00103\n",
      "Epoch: 1... Training loss: 0.00085... Test loss: 0.0007\n",
      "Epoch: 1... Training loss: 0.00091... Test loss: 0.00086\n",
      "Epoch: 1... Training loss: 0.00085... Test loss: 0.00091\n",
      "Epoch: 1... Training loss: 0.00078... Test loss: 0.00084\n",
      "Epoch: 1... Training loss: 0.0008... Test loss: 0.00091\n",
      "Epoch: 1... Training loss: 0.00076... Test loss: 0.00083\n",
      "Epoch: 1... Training loss: 0.00077... Test loss: 0.00072\n",
      "Epoch: 1... Training loss: 0.00071... Test loss: 0.00088\n",
      "Epoch: 1... Training loss: 0.0007... Test loss: 0.00072\n",
      "Epoch: 1... Training loss: 0.00064... Test loss: 0.00086\n",
      "Epoch: 1... Training loss: 0.00066... Test loss: 0.00057\n",
      "Epoch: 1... Training loss: 0.00066... Test loss: 0.00086\n",
      "Epoch: 1... Training loss: 0.00062... Test loss: 0.00052\n",
      "Epoch: 1... Training loss: 0.00062... Test loss: 0.00074\n",
      "Epoch: 1... Training loss: 0.00057... Test loss: 0.00049\n",
      "Epoch: 1... Training loss: 0.00064... Test loss: 0.00078\n",
      "Epoch: 1... Training loss: 0.00059... Test loss: 0.0006\n",
      "Epoch: 1... Training loss: 0.0005... Test loss: 0.00076\n",
      "Epoch: 1... Training loss: 0.00052... Test loss: 0.00047\n",
      "Epoch: 1... Training loss: 0.00052... Test loss: 0.00055\n",
      "Epoch: 1... Training loss: 0.0005... Test loss: 0.00052\n",
      "Epoch: 1... Training loss: 0.00046... Test loss: 0.0005\n",
      "Epoch: 1... Training loss: 0.00043... Test loss: 0.00052\n",
      "Epoch: 1... Training loss: 0.00045... Test loss: 0.00047\n",
      "Epoch: 1... Training loss: 0.0004... Test loss: 0.00045\n",
      "Epoch: 1... Training loss: 0.00041... Test loss: 0.00039\n",
      "Epoch: 1... Training loss: 0.00036... Test loss: 0.00036\n",
      "Epoch: 1... Training loss: 0.00033... Test loss: 0.00034\n",
      "Epoch: 1... Training loss: 0.00031... Test loss: 0.00039\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00037\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00028\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00017\n",
      "281.6748684201157\n",
      "Epoch: 1... Training loss: 0.87601... Test loss: 0.18747\n",
      "Epoch: 1... Training loss: 0.43019... Test loss: 0.13287\n",
      "Epoch: 1... Training loss: 0.25535... Test loss: 0.06327\n",
      "Epoch: 1... Training loss: 0.17096... Test loss: 0.03823\n",
      "Epoch: 1... Training loss: 0.13112... Test loss: 0.02552\n",
      "Epoch: 1... Training loss: 0.10945... Test loss: 0.02282\n",
      "Epoch: 1... Training loss: 0.09073... Test loss: 0.01688\n",
      "Epoch: 1... Training loss: 0.081... Test loss: 0.01578\n",
      "Epoch: 1... Training loss: 0.06937... Test loss: 0.01435\n",
      "Epoch: 1... Training loss: 0.0625... Test loss: 0.01043\n",
      "Epoch: 1... Training loss: 0.05746... Test loss: 0.01381\n",
      "Epoch: 1... Training loss: 0.05029... Test loss: 0.0064\n",
      "Epoch: 1... Training loss: 0.04697... Test loss: 0.00899\n",
      "Epoch: 1... Training loss: 0.04255... Test loss: 0.00656\n",
      "Epoch: 1... Training loss: 0.04019... Test loss: 0.01017\n",
      "Epoch: 1... Training loss: 0.0359... Test loss: 0.00469\n",
      "Epoch: 1... Training loss: 0.03547... Test loss: 0.01101\n",
      "Epoch: 1... Training loss: 0.03131... Test loss: 0.00428\n",
      "Epoch: 1... Training loss: 0.03013... Test loss: 0.01221\n",
      "Epoch: 1... Training loss: 0.02793... Test loss: 0.00536\n",
      "Epoch: 1... Training loss: 0.02708... Test loss: 0.01424\n",
      "Epoch: 1... Training loss: 0.02502... Test loss: 0.0063\n",
      "Epoch: 1... Training loss: 0.02344... Test loss: 0.01052\n",
      "Epoch: 1... Training loss: 0.02234... Test loss: 0.00569\n",
      "Epoch: 1... Training loss: 0.02128... Test loss: 0.01041\n",
      "Epoch: 1... Training loss: 0.02048... Test loss: 0.00688\n",
      "Epoch: 1... Training loss: 0.01943... Test loss: 0.0114\n",
      "Epoch: 1... Training loss: 0.01853... Test loss: 0.00764\n",
      "Epoch: 1... Training loss: 0.01756... Test loss: 0.01038\n",
      "Epoch: 1... Training loss: 0.01703... Test loss: 0.00805\n",
      "Epoch: 1... Training loss: 0.01642... Test loss: 0.01167\n",
      "Epoch: 1... Training loss: 0.01598... Test loss: 0.00457\n",
      "Epoch: 1... Training loss: 0.01533... Test loss: 0.01211\n",
      "Epoch: 1... Training loss: 0.01465... Test loss: 0.00462\n",
      "Epoch: 1... Training loss: 0.014... Test loss: 0.01145\n",
      "Epoch: 1... Training loss: 0.01374... Test loss: 0.00615\n",
      "Epoch: 1... Training loss: 0.013... Test loss: 0.00878\n",
      "Epoch: 1... Training loss: 0.01276... Test loss: 0.00777\n",
      "Epoch: 1... Training loss: 0.01217... Test loss: 0.00582\n",
      "Epoch: 1... Training loss: 0.01176... Test loss: 0.00815\n",
      "Epoch: 1... Training loss: 0.01151... Test loss: 0.00575\n",
      "Epoch: 1... Training loss: 0.01085... Test loss: 0.00974\n",
      "Epoch: 1... Training loss: 0.01044... Test loss: 0.00527\n",
      "Epoch: 1... Training loss: 0.01009... Test loss: 0.00914\n",
      "Epoch: 1... Training loss: 0.00993... Test loss: 0.00566\n",
      "Epoch: 1... Training loss: 0.0096... Test loss: 0.0087\n",
      "Epoch: 1... Training loss: 0.00939... Test loss: 0.00598\n",
      "Epoch: 1... Training loss: 0.00922... Test loss: 0.00688\n",
      "Epoch: 1... Training loss: 0.00881... Test loss: 0.0062\n",
      "Epoch: 1... Training loss: 0.00866... Test loss: 0.00732\n",
      "Epoch: 1... Training loss: 0.00839... Test loss: 0.0054\n",
      "Epoch: 1... Training loss: 0.00795... Test loss: 0.00723\n",
      "Epoch: 1... Training loss: 0.00782... Test loss: 0.00599\n",
      "Epoch: 1... Training loss: 0.00748... Test loss: 0.00569\n",
      "Epoch: 1... Training loss: 0.00731... Test loss: 0.00665\n",
      "Epoch: 1... Training loss: 0.00702... Test loss: 0.00576\n",
      "Epoch: 1... Training loss: 0.00694... Test loss: 0.00585\n",
      "Epoch: 1... Training loss: 0.00671... Test loss: 0.00421\n",
      "Epoch: 1... Training loss: 0.0067... Test loss: 0.00624\n",
      "Epoch: 1... Training loss: 0.00643... Test loss: 0.00447\n",
      "Epoch: 1... Training loss: 0.00632... Test loss: 0.00624\n",
      "Epoch: 1... Training loss: 0.0061... Test loss: 0.00414\n",
      "Epoch: 1... Training loss: 0.00601... Test loss: 0.00541\n",
      "Epoch: 1... Training loss: 0.00581... Test loss: 0.00457\n",
      "Epoch: 1... Training loss: 0.01817... Test loss: 0.01228\n",
      "Epoch: 1... Training loss: 0.00958... Test loss: 0.01002\n",
      "Epoch: 1... Training loss: 0.01336... Test loss: 0.00887\n",
      "Epoch: 1... Training loss: 0.00971... Test loss: 0.01557\n",
      "Epoch: 1... Training loss: 0.01198... Test loss: 0.01444\n",
      "Epoch: 1... Training loss: 0.00895... Test loss: 0.01535\n",
      "Epoch: 1... Training loss: 0.00902... Test loss: 0.0119\n",
      "Epoch: 1... Training loss: 0.00864... Test loss: 0.01492\n",
      "Epoch: 1... Training loss: 0.00869... Test loss: 0.01197\n",
      "Epoch: 1... Training loss: 0.00846... Test loss: 0.01072\n",
      "Epoch: 1... Training loss: 0.00826... Test loss: 0.01114\n",
      "Epoch: 1... Training loss: 0.00811... Test loss: 0.0087\n",
      "Epoch: 1... Training loss: 0.00722... Test loss: 0.01221\n",
      "Epoch: 1... Training loss: 0.00742... Test loss: 0.00676\n",
      "Epoch: 1... Training loss: 0.00703... Test loss: 0.01403\n",
      "Epoch: 1... Training loss: 0.0068... Test loss: 0.00783\n",
      "Epoch: 1... Training loss: 0.00665... Test loss: 0.01156\n",
      "Epoch: 1... Training loss: 0.00643... Test loss: 0.0075\n",
      "Epoch: 1... Training loss: 0.00641... Test loss: 0.00878\n",
      "Epoch: 1... Training loss: 0.00659... Test loss: 0.00688\n",
      "Epoch: 1... Training loss: 0.00624... Test loss: 0.00656\n",
      "Epoch: 1... Training loss: 0.00592... Test loss: 0.00857\n",
      "Epoch: 1... Training loss: 0.00579... Test loss: 0.00563\n",
      "Epoch: 1... Training loss: 0.00551... Test loss: 0.00841\n",
      "Epoch: 1... Training loss: 0.0054... Test loss: 0.00581\n",
      "Epoch: 1... Training loss: 0.00513... Test loss: 0.00633\n",
      "Epoch: 1... Training loss: 0.00502... Test loss: 0.00564\n",
      "Epoch: 1... Training loss: 0.00491... Test loss: 0.00522\n",
      "Epoch: 1... Training loss: 0.00458... Test loss: 0.0056\n",
      "Epoch: 1... Training loss: 0.00487... Test loss: 0.00538\n",
      "Epoch: 1... Training loss: 0.00448... Test loss: 0.00526\n",
      "Epoch: 1... Training loss: 0.00431... Test loss: 0.00562\n",
      "Epoch: 1... Training loss: 0.00406... Test loss: 0.00503\n",
      "Epoch: 1... Training loss: 0.00394... Test loss: 0.00421\n",
      "Epoch: 1... Training loss: 0.00402... Test loss: 0.00433\n",
      "Epoch: 1... Training loss: 0.00381... Test loss: 0.0044\n",
      "Epoch: 1... Training loss: 0.00378... Test loss: 0.0038\n",
      "Epoch: 1... Training loss: 0.0037... Test loss: 0.00398\n",
      "Epoch: 1... Training loss: 0.00367... Test loss: 0.00392\n",
      "Epoch: 1... Training loss: 0.00366... Test loss: 0.00382\n",
      "Epoch: 1... Training loss: 0.00365... Test loss: 0.00402\n",
      "Epoch: 1... Training loss: 0.00339... Test loss: 0.00373\n",
      "Epoch: 1... Training loss: 0.00325... Test loss: 0.00338\n",
      "Epoch: 1... Training loss: 0.00323... Test loss: 0.00382\n",
      "Epoch: 1... Training loss: 0.00327... Test loss: 0.00372\n",
      "Epoch: 1... Training loss: 0.00313... Test loss: 0.00389\n",
      "Epoch: 1... Training loss: 0.00303... Test loss: 0.00335\n",
      "Epoch: 1... Training loss: 0.00302... Test loss: 0.00307\n",
      "Epoch: 1... Training loss: 0.0029... Test loss: 0.00371\n",
      "Epoch: 1... Training loss: 0.00281... Test loss: 0.00311\n",
      "Epoch: 1... Training loss: 0.0028... Test loss: 0.00332\n",
      "Epoch: 1... Training loss: 0.00268... Test loss: 0.00274\n",
      "Epoch: 1... Training loss: 0.00263... Test loss: 0.00311\n",
      "Epoch: 1... Training loss: 0.00257... Test loss: 0.00253\n",
      "Epoch: 1... Training loss: 0.00271... Test loss: 0.00271\n",
      "Epoch: 1... Training loss: 0.00235... Test loss: 0.00235\n",
      "Epoch: 1... Training loss: 0.00223... Test loss: 0.00274\n",
      "Epoch: 1... Training loss: 0.00221... Test loss: 0.00209\n",
      "Epoch: 1... Training loss: 0.00213... Test loss: 0.00301\n",
      "Epoch: 1... Training loss: 0.00223... Test loss: 0.00236\n",
      "Epoch: 1... Training loss: 0.00213... Test loss: 0.00231\n",
      "Epoch: 1... Training loss: 0.00206... Test loss: 0.00204\n",
      "Epoch: 1... Training loss: 0.002... Test loss: 0.00198\n",
      "Epoch: 1... Training loss: 0.00197... Test loss: 0.00225\n",
      "Epoch: 1... Training loss: 0.00189... Test loss: 0.00193\n",
      "Epoch: 1... Training loss: 0.00187... Test loss: 0.00236\n",
      "Epoch: 1... Training loss: 0.00174... Test loss: 0.00196\n",
      "Epoch: 1... Training loss: 0.00174... Test loss: 0.00173\n",
      "Epoch: 1... Training loss: 0.00167... Test loss: 0.00193\n",
      "Epoch: 1... Training loss: 0.00165... Test loss: 0.00155\n",
      "Epoch: 1... Training loss: 0.00152... Test loss: 0.00193\n",
      "Epoch: 1... Training loss: 0.00148... Test loss: 0.00147\n",
      "Epoch: 1... Training loss: 0.00147... Test loss: 0.00178\n",
      "Epoch: 1... Training loss: 0.00153... Test loss: 0.0016\n",
      "Epoch: 1... Training loss: 0.00142... Test loss: 0.00171\n",
      "Epoch: 1... Training loss: 0.00132... Test loss: 0.00144\n",
      "Epoch: 1... Training loss: 0.00135... Test loss: 0.00178\n",
      "Epoch: 1... Training loss: 0.0013... Test loss: 0.00127\n",
      "Epoch: 1... Training loss: 0.00125... Test loss: 0.00155\n",
      "Epoch: 1... Training loss: 0.00122... Test loss: 0.00134\n",
      "Epoch: 1... Training loss: 0.00119... Test loss: 0.00141\n",
      "Epoch: 1... Training loss: 0.00113... Test loss: 0.00135\n",
      "Epoch: 1... Training loss: 0.00107... Test loss: 0.00112\n",
      "Epoch: 1... Training loss: 0.00106... Test loss: 0.00106\n",
      "Epoch: 1... Training loss: 0.00119... Test loss: 0.00111\n",
      "Epoch: 1... Training loss: 0.00096... Test loss: 0.0011\n",
      "Epoch: 1... Training loss: 0.00099... Test loss: 0.00112\n",
      "Epoch: 1... Training loss: 0.00107... Test loss: 0.0012\n",
      "Epoch: 1... Training loss: 0.00102... Test loss: 0.00086\n",
      "Epoch: 1... Training loss: 0.00096... Test loss: 0.00099\n",
      "Epoch: 1... Training loss: 0.00092... Test loss: 0.00078\n",
      "Epoch: 1... Training loss: 0.00092... Test loss: 0.00081\n",
      "Epoch: 1... Training loss: 0.00087... Test loss: 0.00081\n",
      "Epoch: 1... Training loss: 0.0008... Test loss: 0.00085\n",
      "Epoch: 1... Training loss: 0.00081... Test loss: 0.00077\n",
      "Epoch: 1... Training loss: 0.00077... Test loss: 0.00079\n",
      "Epoch: 1... Training loss: 0.00078... Test loss: 0.0007\n",
      "Epoch: 1... Training loss: 0.0008... Test loss: 0.00071\n",
      "Epoch: 1... Training loss: 0.00072... Test loss: 0.0007\n",
      "Epoch: 1... Training loss: 0.0007... Test loss: 0.00073\n",
      "Epoch: 1... Training loss: 0.0007... Test loss: 0.00066\n",
      "Epoch: 1... Training loss: 0.00069... Test loss: 0.00063\n",
      "Epoch: 1... Training loss: 0.00069... Test loss: 0.0008\n",
      "Epoch: 1... Training loss: 0.00068... Test loss: 0.00063\n",
      "Epoch: 1... Training loss: 0.00064... Test loss: 0.00073\n",
      "Epoch: 1... Training loss: 0.00061... Test loss: 0.00064\n",
      "Epoch: 1... Training loss: 0.00063... Test loss: 0.00064\n",
      "Epoch: 1... Training loss: 0.00055... Test loss: 0.00059\n",
      "Epoch: 1... Training loss: 0.00055... Test loss: 0.00066\n",
      "Epoch: 1... Training loss: 0.00054... Test loss: 0.0005\n",
      "Epoch: 1... Training loss: 0.00058... Test loss: 0.00053\n",
      "Epoch: 1... Training loss: 0.00051... Test loss: 0.00049\n",
      "Epoch: 1... Training loss: 0.00049... Test loss: 0.0006\n",
      "Epoch: 1... Training loss: 0.0005... Test loss: 0.00045\n",
      "Epoch: 1... Training loss: 0.0004... Test loss: 0.00071\n",
      "Epoch: 1... Training loss: 0.00044... Test loss: 0.00044\n",
      "Epoch: 1... Training loss: 0.00044... Test loss: 0.00041\n",
      "Epoch: 1... Training loss: 0.00042... Test loss: 0.00041\n",
      "Epoch: 1... Training loss: 0.00039... Test loss: 0.00044\n",
      "Epoch: 1... Training loss: 0.00035... Test loss: 0.00043\n",
      "Epoch: 1... Training loss: 0.00035... Test loss: 0.00032\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00034\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00026... Test loss: 0.00032\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00024\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00034\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00024\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00024\n",
      "Epoch: 1... Training loss: 0.00026... Test loss: 0.0003\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00012\n",
      "269.56229029380484\n",
      "Epoch: 1... Training loss: 1.11896... Test loss: 0.50369\n",
      "Epoch: 1... Training loss: 0.49563... Test loss: 0.17885\n",
      "Epoch: 1... Training loss: 0.30672... Test loss: 0.1257\n",
      "Epoch: 1... Training loss: 0.20473... Test loss: 0.07638\n",
      "Epoch: 1... Training loss: 0.14311... Test loss: 0.08227\n",
      "Epoch: 1... Training loss: 0.12041... Test loss: 0.05594\n",
      "Epoch: 1... Training loss: 0.08748... Test loss: 0.08129\n",
      "Epoch: 1... Training loss: 0.07655... Test loss: 0.04836\n",
      "Epoch: 1... Training loss: 0.06355... Test loss: 0.08475\n",
      "Epoch: 1... Training loss: 0.0576... Test loss: 0.03234\n",
      "Epoch: 1... Training loss: 0.05148... Test loss: 0.07149\n",
      "Epoch: 1... Training loss: 0.0467... Test loss: 0.02974\n",
      "Epoch: 1... Training loss: 0.0422... Test loss: 0.05042\n",
      "Epoch: 1... Training loss: 0.04135... Test loss: 0.02083\n",
      "Epoch: 1... Training loss: 0.03793... Test loss: 0.05145\n",
      "Epoch: 1... Training loss: 0.03635... Test loss: 0.02264\n",
      "Epoch: 1... Training loss: 0.03122... Test loss: 0.04707\n",
      "Epoch: 1... Training loss: 0.02868... Test loss: 0.01704\n",
      "Epoch: 1... Training loss: 0.02697... Test loss: 0.04046\n",
      "Epoch: 1... Training loss: 0.02622... Test loss: 0.01169\n",
      "Epoch: 1... Training loss: 0.02421... Test loss: 0.03515\n",
      "Epoch: 1... Training loss: 0.02373... Test loss: 0.01193\n",
      "Epoch: 1... Training loss: 0.02219... Test loss: 0.03271\n",
      "Epoch: 1... Training loss: 0.02212... Test loss: 0.01007\n",
      "Epoch: 1... Training loss: 0.02013... Test loss: 0.02767\n",
      "Epoch: 1... Training loss: 0.0197... Test loss: 0.01508\n",
      "Epoch: 1... Training loss: 0.01863... Test loss: 0.02243\n",
      "Epoch: 1... Training loss: 0.01819... Test loss: 0.01448\n",
      "Epoch: 1... Training loss: 0.01712... Test loss: 0.02178\n",
      "Epoch: 1... Training loss: 0.0169... Test loss: 0.01061\n",
      "Epoch: 1... Training loss: 0.01616... Test loss: 0.02893\n",
      "Epoch: 1... Training loss: 0.01543... Test loss: 0.00873\n",
      "Epoch: 1... Training loss: 0.01442... Test loss: 0.02428\n",
      "Epoch: 1... Training loss: 0.01413... Test loss: 0.00791\n",
      "Epoch: 1... Training loss: 0.01334... Test loss: 0.01819\n",
      "Epoch: 1... Training loss: 0.01309... Test loss: 0.00812\n",
      "Epoch: 1... Training loss: 0.01247... Test loss: 0.01524\n",
      "Epoch: 1... Training loss: 0.01249... Test loss: 0.00677\n",
      "Epoch: 1... Training loss: 0.01177... Test loss: 0.01451\n",
      "Epoch: 1... Training loss: 0.01177... Test loss: 0.00761\n",
      "Epoch: 1... Training loss: 0.01119... Test loss: 0.01229\n",
      "Epoch: 1... Training loss: 0.01111... Test loss: 0.00705\n",
      "Epoch: 1... Training loss: 0.01063... Test loss: 0.01109\n",
      "Epoch: 1... Training loss: 0.01058... Test loss: 0.00862\n",
      "Epoch: 1... Training loss: 0.01003... Test loss: 0.00873\n",
      "Epoch: 1... Training loss: 0.00982... Test loss: 0.00922\n",
      "Epoch: 1... Training loss: 0.00957... Test loss: 0.00882\n",
      "Epoch: 1... Training loss: 0.0094... Test loss: 0.00668\n",
      "Epoch: 1... Training loss: 0.00919... Test loss: 0.00918\n",
      "Epoch: 1... Training loss: 0.0089... Test loss: 0.00548\n",
      "Epoch: 1... Training loss: 0.00855... Test loss: 0.00954\n",
      "Epoch: 1... Training loss: 0.00836... Test loss: 0.00536\n",
      "Epoch: 1... Training loss: 0.00814... Test loss: 0.00878\n",
      "Epoch: 1... Training loss: 0.00785... Test loss: 0.00621\n",
      "Epoch: 1... Training loss: 0.00763... Test loss: 0.00766\n",
      "Epoch: 1... Training loss: 0.00746... Test loss: 0.00597\n",
      "Epoch: 1... Training loss: 0.0073... Test loss: 0.00687\n",
      "Epoch: 1... Training loss: 0.00715... Test loss: 0.00639\n",
      "Epoch: 1... Training loss: 0.00697... Test loss: 0.0057\n",
      "Epoch: 1... Training loss: 0.00677... Test loss: 0.00717\n",
      "Epoch: 1... Training loss: 0.00662... Test loss: 0.00551\n",
      "Epoch: 1... Training loss: 0.0065... Test loss: 0.00735\n",
      "Epoch: 1... Training loss: 0.00633... Test loss: 0.00534\n",
      "Epoch: 1... Training loss: 0.00614... Test loss: 0.00692\n",
      "Epoch: 1... Training loss: 0.0142... Test loss: 0.00908\n",
      "Epoch: 1... Training loss: 0.01219... Test loss: 0.01861\n",
      "Epoch: 1... Training loss: 0.01136... Test loss: 0.01317\n",
      "Epoch: 1... Training loss: 0.01241... Test loss: 0.0156\n",
      "Epoch: 1... Training loss: 0.01072... Test loss: 0.01095\n",
      "Epoch: 1... Training loss: 0.00961... Test loss: 0.01141\n",
      "Epoch: 1... Training loss: 0.00984... Test loss: 0.01402\n",
      "Epoch: 1... Training loss: 0.00967... Test loss: 0.01028\n",
      "Epoch: 1... Training loss: 0.00966... Test loss: 0.01259\n",
      "Epoch: 1... Training loss: 0.00916... Test loss: 0.00873\n",
      "Epoch: 1... Training loss: 0.00866... Test loss: 0.01152\n",
      "Epoch: 1... Training loss: 0.00907... Test loss: 0.01016\n",
      "Epoch: 1... Training loss: 0.00838... Test loss: 0.01006\n",
      "Epoch: 1... Training loss: 0.00845... Test loss: 0.00985\n",
      "Epoch: 1... Training loss: 0.0083... Test loss: 0.00879\n",
      "Epoch: 1... Training loss: 0.00817... Test loss: 0.00913\n",
      "Epoch: 1... Training loss: 0.00758... Test loss: 0.00901\n",
      "Epoch: 1... Training loss: 0.00763... Test loss: 0.00804\n",
      "Epoch: 1... Training loss: 0.00703... Test loss: 0.00912\n",
      "Epoch: 1... Training loss: 0.007... Test loss: 0.00754\n",
      "Epoch: 1... Training loss: 0.00654... Test loss: 0.00858\n",
      "Epoch: 1... Training loss: 0.00613... Test loss: 0.00679\n",
      "Epoch: 1... Training loss: 0.00638... Test loss: 0.00603\n",
      "Epoch: 1... Training loss: 0.00585... Test loss: 0.00687\n",
      "Epoch: 1... Training loss: 0.00577... Test loss: 0.00561\n",
      "Epoch: 1... Training loss: 0.00571... Test loss: 0.00613\n",
      "Epoch: 1... Training loss: 0.00538... Test loss: 0.00567\n",
      "Epoch: 1... Training loss: 0.00532... Test loss: 0.00558\n",
      "Epoch: 1... Training loss: 0.0052... Test loss: 0.00554\n",
      "Epoch: 1... Training loss: 0.00507... Test loss: 0.00518\n",
      "Epoch: 1... Training loss: 0.00495... Test loss: 0.00596\n",
      "Epoch: 1... Training loss: 0.00461... Test loss: 0.00571\n",
      "Epoch: 1... Training loss: 0.00461... Test loss: 0.00533\n",
      "Epoch: 1... Training loss: 0.00467... Test loss: 0.00479\n",
      "Epoch: 1... Training loss: 0.00435... Test loss: 0.00522\n",
      "Epoch: 1... Training loss: 0.00416... Test loss: 0.00482\n",
      "Epoch: 1... Training loss: 0.0041... Test loss: 0.00417\n",
      "Epoch: 1... Training loss: 0.00404... Test loss: 0.00518\n",
      "Epoch: 1... Training loss: 0.00395... Test loss: 0.0043\n",
      "Epoch: 1... Training loss: 0.00393... Test loss: 0.00436\n",
      "Epoch: 1... Training loss: 0.0038... Test loss: 0.00499\n",
      "Epoch: 1... Training loss: 0.00371... Test loss: 0.00468\n",
      "Epoch: 1... Training loss: 0.00383... Test loss: 0.00431\n",
      "Epoch: 1... Training loss: 0.00383... Test loss: 0.00402\n",
      "Epoch: 1... Training loss: 0.00364... Test loss: 0.00411\n",
      "Epoch: 1... Training loss: 0.00361... Test loss: 0.00367\n",
      "Epoch: 1... Training loss: 0.00351... Test loss: 0.00457\n",
      "Epoch: 1... Training loss: 0.00344... Test loss: 0.00395\n",
      "Epoch: 1... Training loss: 0.00334... Test loss: 0.00427\n",
      "Epoch: 1... Training loss: 0.0033... Test loss: 0.00362\n",
      "Epoch: 1... Training loss: 0.00333... Test loss: 0.00421\n",
      "Epoch: 1... Training loss: 0.00317... Test loss: 0.00298\n",
      "Epoch: 1... Training loss: 0.00321... Test loss: 0.00399\n",
      "Epoch: 1... Training loss: 0.00316... Test loss: 0.00335\n",
      "Epoch: 1... Training loss: 0.00298... Test loss: 0.00398\n",
      "Epoch: 1... Training loss: 0.00299... Test loss: 0.00325\n",
      "Epoch: 1... Training loss: 0.00289... Test loss: 0.00346\n",
      "Epoch: 1... Training loss: 0.00289... Test loss: 0.0033\n",
      "Epoch: 1... Training loss: 0.00278... Test loss: 0.00357\n",
      "Epoch: 1... Training loss: 0.0027... Test loss: 0.00325\n",
      "Epoch: 1... Training loss: 0.00263... Test loss: 0.00382\n",
      "Epoch: 1... Training loss: 0.00265... Test loss: 0.00257\n",
      "Epoch: 1... Training loss: 0.00247... Test loss: 0.00315\n",
      "Epoch: 1... Training loss: 0.00252... Test loss: 0.00249\n",
      "Epoch: 1... Training loss: 0.00238... Test loss: 0.00258\n",
      "Epoch: 1... Training loss: 0.00248... Test loss: 0.00211\n",
      "Epoch: 1... Training loss: 0.00228... Test loss: 0.00267\n",
      "Epoch: 1... Training loss: 0.00225... Test loss: 0.00232\n",
      "Epoch: 1... Training loss: 0.0022... Test loss: 0.00276\n",
      "Epoch: 1... Training loss: 0.00213... Test loss: 0.00204\n",
      "Epoch: 1... Training loss: 0.00211... Test loss: 0.00238\n",
      "Epoch: 1... Training loss: 0.00205... Test loss: 0.00195\n",
      "Epoch: 1... Training loss: 0.00215... Test loss: 0.00223\n",
      "Epoch: 1... Training loss: 0.00183... Test loss: 0.00214\n",
      "Epoch: 1... Training loss: 0.00193... Test loss: 0.00208\n",
      "Epoch: 1... Training loss: 0.0018... Test loss: 0.00199\n",
      "Epoch: 1... Training loss: 0.0017... Test loss: 0.00183\n",
      "Epoch: 1... Training loss: 0.00166... Test loss: 0.00189\n",
      "Epoch: 1... Training loss: 0.00165... Test loss: 0.00184\n",
      "Epoch: 1... Training loss: 0.00161... Test loss: 0.00159\n",
      "Epoch: 1... Training loss: 0.00166... Test loss: 0.00183\n",
      "Epoch: 1... Training loss: 0.00148... Test loss: 0.00118\n",
      "Epoch: 1... Training loss: 0.00156... Test loss: 0.00162\n",
      "Epoch: 1... Training loss: 0.00144... Test loss: 0.00137\n",
      "Epoch: 1... Training loss: 0.00136... Test loss: 0.00144\n",
      "Epoch: 1... Training loss: 0.00131... Test loss: 0.0013\n",
      "Epoch: 1... Training loss: 0.00139... Test loss: 0.00132\n",
      "Epoch: 1... Training loss: 0.00132... Test loss: 0.0012\n",
      "Epoch: 1... Training loss: 0.00131... Test loss: 0.00134\n",
      "Epoch: 1... Training loss: 0.00117... Test loss: 0.00109\n",
      "Epoch: 1... Training loss: 0.00118... Test loss: 0.00119\n",
      "Epoch: 1... Training loss: 0.0012... Test loss: 0.00097\n",
      "Epoch: 1... Training loss: 0.00111... Test loss: 0.00146\n",
      "Epoch: 1... Training loss: 0.00106... Test loss: 0.00106\n",
      "Epoch: 1... Training loss: 0.00098... Test loss: 0.00139\n",
      "Epoch: 1... Training loss: 0.00103... Test loss: 0.00109\n",
      "Epoch: 1... Training loss: 0.00098... Test loss: 0.00113\n",
      "Epoch: 1... Training loss: 0.00093... Test loss: 0.00117\n",
      "Epoch: 1... Training loss: 0.0009... Test loss: 0.00114\n",
      "Epoch: 1... Training loss: 0.00094... Test loss: 0.00097\n",
      "Epoch: 1... Training loss: 0.00087... Test loss: 0.00109\n",
      "Epoch: 1... Training loss: 0.00089... Test loss: 0.00092\n",
      "Epoch: 1... Training loss: 0.00078... Test loss: 0.00101\n",
      "Epoch: 1... Training loss: 0.00072... Test loss: 0.00081\n",
      "Epoch: 1... Training loss: 0.0007... Test loss: 0.00073\n",
      "Epoch: 1... Training loss: 0.00067... Test loss: 0.00074\n",
      "Epoch: 1... Training loss: 0.00067... Test loss: 0.00076\n",
      "Epoch: 1... Training loss: 0.00067... Test loss: 0.00076\n",
      "Epoch: 1... Training loss: 0.00064... Test loss: 0.00067\n",
      "Epoch: 1... Training loss: 0.00058... Test loss: 0.00067\n",
      "Epoch: 1... Training loss: 0.00057... Test loss: 0.00057\n",
      "Epoch: 1... Training loss: 0.00053... Test loss: 0.00065\n",
      "Epoch: 1... Training loss: 0.00051... Test loss: 0.00049\n",
      "Epoch: 1... Training loss: 0.00049... Test loss: 0.00058\n",
      "Epoch: 1... Training loss: 0.00051... Test loss: 0.00049\n",
      "Epoch: 1... Training loss: 0.00053... Test loss: 0.00055\n",
      "Epoch: 1... Training loss: 0.00047... Test loss: 0.0004\n",
      "Epoch: 1... Training loss: 0.00043... Test loss: 0.00054\n",
      "Epoch: 1... Training loss: 0.00043... Test loss: 0.00044\n",
      "Epoch: 1... Training loss: 0.00039... Test loss: 0.00044\n",
      "Epoch: 1... Training loss: 0.00045... Test loss: 0.0004\n",
      "Epoch: 1... Training loss: 0.00042... Test loss: 0.00036\n",
      "Epoch: 1... Training loss: 0.00038... Test loss: 0.00042\n",
      "Epoch: 1... Training loss: 0.0004... Test loss: 0.00033\n",
      "Epoch: 1... Training loss: 0.00038... Test loss: 0.00039\n",
      "Epoch: 1... Training loss: 0.00038... Test loss: 0.00028\n",
      "Epoch: 1... Training loss: 0.00033... Test loss: 0.00036\n",
      "Epoch: 1... Training loss: 0.00032... Test loss: 0.00028\n",
      "Epoch: 1... Training loss: 0.00033... Test loss: 0.00031\n",
      "Epoch: 1... Training loss: 0.00036... Test loss: 0.00031\n",
      "Epoch: 1... Training loss: 0.00029... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00026... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00028\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00028\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00021\n",
      "320.1547712330939\n",
      "Epoch: 1... Training loss: 0.95228... Test loss: 0.25285\n",
      "Epoch: 1... Training loss: 0.46318... Test loss: 0.14008\n",
      "Epoch: 1... Training loss: 0.29921... Test loss: 0.07086\n",
      "Epoch: 1... Training loss: 0.18338... Test loss: 0.04358\n",
      "Epoch: 1... Training loss: 0.14279... Test loss: 0.03055\n",
      "Epoch: 1... Training loss: 0.11134... Test loss: 0.02352\n",
      "Epoch: 1... Training loss: 0.09473... Test loss: 0.0204\n",
      "Epoch: 1... Training loss: 0.08265... Test loss: 0.01721\n",
      "Epoch: 1... Training loss: 0.07249... Test loss: 0.02082\n",
      "Epoch: 1... Training loss: 0.06575... Test loss: 0.0141\n",
      "Epoch: 1... Training loss: 0.06018... Test loss: 0.02292\n",
      "Epoch: 1... Training loss: 0.05488... Test loss: 0.01308\n",
      "Epoch: 1... Training loss: 0.05061... Test loss: 0.02415\n",
      "Epoch: 1... Training loss: 0.04427... Test loss: 0.01331\n",
      "Epoch: 1... Training loss: 0.0419... Test loss: 0.02347\n",
      "Epoch: 1... Training loss: 0.03892... Test loss: 0.01176\n",
      "Epoch: 1... Training loss: 0.03699... Test loss: 0.02486\n",
      "Epoch: 1... Training loss: 0.03383... Test loss: 0.01075\n",
      "Epoch: 1... Training loss: 0.03214... Test loss: 0.02757\n",
      "Epoch: 1... Training loss: 0.03009... Test loss: 0.02098\n",
      "Epoch: 1... Training loss: 0.02688... Test loss: 0.01478\n",
      "Epoch: 1... Training loss: 0.02675... Test loss: 0.02589\n",
      "Epoch: 1... Training loss: 0.02416... Test loss: 0.01353\n",
      "Epoch: 1... Training loss: 0.0242... Test loss: 0.02883\n",
      "Epoch: 1... Training loss: 0.02164... Test loss: 0.01272\n",
      "Epoch: 1... Training loss: 0.02152... Test loss: 0.02894\n",
      "Epoch: 1... Training loss: 0.01978... Test loss: 0.01199\n",
      "Epoch: 1... Training loss: 0.0184... Test loss: 0.02705\n",
      "Epoch: 1... Training loss: 0.01748... Test loss: 0.0157\n",
      "Epoch: 1... Training loss: 0.01692... Test loss: 0.02169\n",
      "Epoch: 1... Training loss: 0.01644... Test loss: 0.01372\n",
      "Epoch: 1... Training loss: 0.01563... Test loss: 0.02266\n",
      "Epoch: 1... Training loss: 0.01478... Test loss: 0.01729\n",
      "Epoch: 1... Training loss: 0.0142... Test loss: 0.01539\n",
      "Epoch: 1... Training loss: 0.01368... Test loss: 0.01823\n",
      "Epoch: 1... Training loss: 0.01327... Test loss: 0.01271\n",
      "Epoch: 1... Training loss: 0.01295... Test loss: 0.01623\n",
      "Epoch: 1... Training loss: 0.01246... Test loss: 0.01322\n",
      "Epoch: 1... Training loss: 0.01176... Test loss: 0.01339\n",
      "Epoch: 1... Training loss: 0.0114... Test loss: 0.01085\n",
      "Epoch: 1... Training loss: 0.0111... Test loss: 0.00785\n",
      "Epoch: 1... Training loss: 0.01076... Test loss: 0.01397\n",
      "Epoch: 1... Training loss: 0.01033... Test loss: 0.00548\n",
      "Epoch: 1... Training loss: 0.01017... Test loss: 0.01441\n",
      "Epoch: 1... Training loss: 0.00967... Test loss: 0.00714\n",
      "Epoch: 1... Training loss: 0.00946... Test loss: 0.01193\n",
      "Epoch: 1... Training loss: 0.00909... Test loss: 0.01013\n",
      "Epoch: 1... Training loss: 0.00898... Test loss: 0.01043\n",
      "Epoch: 1... Training loss: 0.00871... Test loss: 0.00934\n",
      "Epoch: 1... Training loss: 0.00846... Test loss: 0.00935\n",
      "Epoch: 1... Training loss: 0.00816... Test loss: 0.00941\n",
      "Epoch: 1... Training loss: 0.00789... Test loss: 0.00896\n",
      "Epoch: 1... Training loss: 0.00761... Test loss: 0.00711\n",
      "Epoch: 1... Training loss: 0.00755... Test loss: 0.00813\n",
      "Epoch: 1... Training loss: 0.00719... Test loss: 0.00631\n",
      "Epoch: 1... Training loss: 0.00712... Test loss: 0.00776\n",
      "Epoch: 1... Training loss: 0.00698... Test loss: 0.00636\n",
      "Epoch: 1... Training loss: 0.00667... Test loss: 0.00792\n",
      "Epoch: 1... Training loss: 0.00664... Test loss: 0.0064\n",
      "Epoch: 1... Training loss: 0.00639... Test loss: 0.00685\n",
      "Epoch: 1... Training loss: 0.00633... Test loss: 0.00604\n",
      "Epoch: 1... Training loss: 0.00605... Test loss: 0.008\n",
      "Epoch: 1... Training loss: 0.00593... Test loss: 0.00659\n",
      "Epoch: 1... Training loss: 0.00578... Test loss: 0.00628\n",
      "Epoch: 1... Training loss: 0.01162... Test loss: 0.01023\n",
      "Epoch: 1... Training loss: 0.00995... Test loss: 0.00856\n",
      "Epoch: 1... Training loss: 0.01054... Test loss: 0.00974\n",
      "Epoch: 1... Training loss: 0.01198... Test loss: 0.01029\n",
      "Epoch: 1... Training loss: 0.0096... Test loss: 0.01039\n",
      "Epoch: 1... Training loss: 0.01034... Test loss: 0.01272\n",
      "Epoch: 1... Training loss: 0.00956... Test loss: 0.01156\n",
      "Epoch: 1... Training loss: 0.00928... Test loss: 0.01002\n",
      "Epoch: 1... Training loss: 0.00904... Test loss: 0.01104\n",
      "Epoch: 1... Training loss: 0.00847... Test loss: 0.01014\n",
      "Epoch: 1... Training loss: 0.00845... Test loss: 0.00903\n",
      "Epoch: 1... Training loss: 0.00787... Test loss: 0.00924\n",
      "Epoch: 1... Training loss: 0.00763... Test loss: 0.01025\n",
      "Epoch: 1... Training loss: 0.00794... Test loss: 0.00893\n",
      "Epoch: 1... Training loss: 0.00756... Test loss: 0.01006\n",
      "Epoch: 1... Training loss: 0.0073... Test loss: 0.00933\n",
      "Epoch: 1... Training loss: 0.00714... Test loss: 0.00749\n",
      "Epoch: 1... Training loss: 0.00688... Test loss: 0.01059\n",
      "Epoch: 1... Training loss: 0.0067... Test loss: 0.00662\n",
      "Epoch: 1... Training loss: 0.00684... Test loss: 0.00973\n",
      "Epoch: 1... Training loss: 0.00658... Test loss: 0.00654\n",
      "Epoch: 1... Training loss: 0.00599... Test loss: 0.0095\n",
      "Epoch: 1... Training loss: 0.00586... Test loss: 0.00664\n",
      "Epoch: 1... Training loss: 0.00614... Test loss: 0.00649\n",
      "Epoch: 1... Training loss: 0.00601... Test loss: 0.00684\n",
      "Epoch: 1... Training loss: 0.00546... Test loss: 0.00574\n",
      "Epoch: 1... Training loss: 0.00537... Test loss: 0.00507\n",
      "Epoch: 1... Training loss: 0.00538... Test loss: 0.00574\n",
      "Epoch: 1... Training loss: 0.00489... Test loss: 0.00594\n",
      "Epoch: 1... Training loss: 0.00503... Test loss: 0.00534\n",
      "Epoch: 1... Training loss: 0.00499... Test loss: 0.00576\n",
      "Epoch: 1... Training loss: 0.00465... Test loss: 0.005\n",
      "Epoch: 1... Training loss: 0.00437... Test loss: 0.00471\n",
      "Epoch: 1... Training loss: 0.00428... Test loss: 0.00464\n",
      "Epoch: 1... Training loss: 0.00416... Test loss: 0.00432\n",
      "Epoch: 1... Training loss: 0.00402... Test loss: 0.00448\n",
      "Epoch: 1... Training loss: 0.00389... Test loss: 0.00458\n",
      "Epoch: 1... Training loss: 0.00389... Test loss: 0.00402\n",
      "Epoch: 1... Training loss: 0.00399... Test loss: 0.0038\n",
      "Epoch: 1... Training loss: 0.00396... Test loss: 0.00461\n",
      "Epoch: 1... Training loss: 0.00389... Test loss: 0.00343\n",
      "Epoch: 1... Training loss: 0.00366... Test loss: 0.00487\n",
      "Epoch: 1... Training loss: 0.0035... Test loss: 0.00395\n",
      "Epoch: 1... Training loss: 0.0035... Test loss: 0.00411\n",
      "Epoch: 1... Training loss: 0.00342... Test loss: 0.00406\n",
      "Epoch: 1... Training loss: 0.00337... Test loss: 0.00344\n",
      "Epoch: 1... Training loss: 0.00336... Test loss: 0.00409\n",
      "Epoch: 1... Training loss: 0.0032... Test loss: 0.00324\n",
      "Epoch: 1... Training loss: 0.00321... Test loss: 0.00354\n",
      "Epoch: 1... Training loss: 0.00315... Test loss: 0.00278\n",
      "Epoch: 1... Training loss: 0.00295... Test loss: 0.0037\n",
      "Epoch: 1... Training loss: 0.00291... Test loss: 0.00274\n",
      "Epoch: 1... Training loss: 0.0029... Test loss: 0.00356\n",
      "Epoch: 1... Training loss: 0.00288... Test loss: 0.00222\n",
      "Epoch: 1... Training loss: 0.00282... Test loss: 0.00369\n",
      "Epoch: 1... Training loss: 0.00266... Test loss: 0.00238\n",
      "Epoch: 1... Training loss: 0.00268... Test loss: 0.0033\n",
      "Epoch: 1... Training loss: 0.00252... Test loss: 0.00241\n",
      "Epoch: 1... Training loss: 0.00247... Test loss: 0.00309\n",
      "Epoch: 1... Training loss: 0.00241... Test loss: 0.00235\n",
      "Epoch: 1... Training loss: 0.00235... Test loss: 0.00307\n",
      "Epoch: 1... Training loss: 0.00234... Test loss: 0.00233\n",
      "Epoch: 1... Training loss: 0.00226... Test loss: 0.00289\n",
      "Epoch: 1... Training loss: 0.00231... Test loss: 0.00209\n",
      "Epoch: 1... Training loss: 0.0022... Test loss: 0.00243\n",
      "Epoch: 1... Training loss: 0.00222... Test loss: 0.00222\n",
      "Epoch: 1... Training loss: 0.00215... Test loss: 0.00259\n",
      "Epoch: 1... Training loss: 0.00209... Test loss: 0.00222\n",
      "Epoch: 1... Training loss: 0.00216... Test loss: 0.00198\n",
      "Epoch: 1... Training loss: 0.00201... Test loss: 0.00206\n",
      "Epoch: 1... Training loss: 0.00203... Test loss: 0.00186\n",
      "Epoch: 1... Training loss: 0.00195... Test loss: 0.00186\n",
      "Epoch: 1... Training loss: 0.00184... Test loss: 0.00199\n",
      "Epoch: 1... Training loss: 0.00194... Test loss: 0.00184\n",
      "Epoch: 1... Training loss: 0.00177... Test loss: 0.00172\n",
      "Epoch: 1... Training loss: 0.00179... Test loss: 0.00171\n",
      "Epoch: 1... Training loss: 0.00175... Test loss: 0.00188\n",
      "Epoch: 1... Training loss: 0.00172... Test loss: 0.00153\n",
      "Epoch: 1... Training loss: 0.00161... Test loss: 0.00169\n",
      "Epoch: 1... Training loss: 0.00163... Test loss: 0.00167\n",
      "Epoch: 1... Training loss: 0.00164... Test loss: 0.00159\n",
      "Epoch: 1... Training loss: 0.00153... Test loss: 0.00173\n",
      "Epoch: 1... Training loss: 0.00151... Test loss: 0.00159\n",
      "Epoch: 1... Training loss: 0.00145... Test loss: 0.00151\n",
      "Epoch: 1... Training loss: 0.00138... Test loss: 0.00153\n",
      "Epoch: 1... Training loss: 0.00137... Test loss: 0.00131\n",
      "Epoch: 1... Training loss: 0.00133... Test loss: 0.00147\n",
      "Epoch: 1... Training loss: 0.0013... Test loss: 0.00141\n",
      "Epoch: 1... Training loss: 0.00132... Test loss: 0.00155\n",
      "Epoch: 1... Training loss: 0.00134... Test loss: 0.00129\n",
      "Epoch: 1... Training loss: 0.00128... Test loss: 0.00148\n",
      "Epoch: 1... Training loss: 0.00123... Test loss: 0.00126\n",
      "Epoch: 1... Training loss: 0.00118... Test loss: 0.00121\n",
      "Epoch: 1... Training loss: 0.0011... Test loss: 0.00107\n",
      "Epoch: 1... Training loss: 0.00117... Test loss: 0.00134\n",
      "Epoch: 1... Training loss: 0.00112... Test loss: 0.00113\n",
      "Epoch: 1... Training loss: 0.00108... Test loss: 0.00127\n",
      "Epoch: 1... Training loss: 0.00101... Test loss: 0.00104\n",
      "Epoch: 1... Training loss: 0.001... Test loss: 0.00122\n",
      "Epoch: 1... Training loss: 0.00103... Test loss: 0.00109\n",
      "Epoch: 1... Training loss: 0.0009... Test loss: 0.00111\n",
      "Epoch: 1... Training loss: 0.0009... Test loss: 0.0009\n",
      "Epoch: 1... Training loss: 0.00087... Test loss: 0.00093\n",
      "Epoch: 1... Training loss: 0.00082... Test loss: 0.00079\n",
      "Epoch: 1... Training loss: 0.0009... Test loss: 0.00097\n",
      "Epoch: 1... Training loss: 0.00081... Test loss: 0.00083\n",
      "Epoch: 1... Training loss: 0.0008... Test loss: 0.0009\n",
      "Epoch: 1... Training loss: 0.00072... Test loss: 0.0008\n",
      "Epoch: 1... Training loss: 0.00066... Test loss: 0.00079\n",
      "Epoch: 1... Training loss: 0.00067... Test loss: 0.00066\n",
      "Epoch: 1... Training loss: 0.00064... Test loss: 0.00065\n",
      "Epoch: 1... Training loss: 0.00061... Test loss: 0.00061\n",
      "Epoch: 1... Training loss: 0.00063... Test loss: 0.00062\n",
      "Epoch: 1... Training loss: 0.00065... Test loss: 0.00064\n",
      "Epoch: 1... Training loss: 0.00059... Test loss: 0.00059\n",
      "Epoch: 1... Training loss: 0.00055... Test loss: 0.0006\n",
      "Epoch: 1... Training loss: 0.0005... Test loss: 0.00057\n",
      "Epoch: 1... Training loss: 0.00048... Test loss: 0.00056\n",
      "Epoch: 1... Training loss: 0.00048... Test loss: 0.00042\n",
      "Epoch: 1... Training loss: 0.00043... Test loss: 0.00044\n",
      "Epoch: 1... Training loss: 0.00042... Test loss: 0.00054\n",
      "Epoch: 1... Training loss: 0.00038... Test loss: 0.00046\n",
      "Epoch: 1... Training loss: 0.00036... Test loss: 0.00044\n",
      "Epoch: 1... Training loss: 0.00035... Test loss: 0.00039\n",
      "Epoch: 1... Training loss: 0.00032... Test loss: 0.00046\n",
      "Epoch: 1... Training loss: 0.00033... Test loss: 0.00038\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00034\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.00036\n",
      "Epoch: 1... Training loss: 0.00026... Test loss: 0.00028\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00024\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00017\n",
      "254.76415075419936\n",
      "Epoch: 1... Training loss: 0.9775... Test loss: 0.2926\n",
      "Epoch: 1... Training loss: 0.39722... Test loss: 0.08711\n",
      "Epoch: 1... Training loss: 0.25477... Test loss: 0.0811\n",
      "Epoch: 1... Training loss: 0.18613... Test loss: 0.06071\n",
      "Epoch: 1... Training loss: 0.14522... Test loss: 0.04271\n",
      "Epoch: 1... Training loss: 0.12381... Test loss: 0.03612\n",
      "Epoch: 1... Training loss: 0.10833... Test loss: 0.03074\n",
      "Epoch: 1... Training loss: 0.09806... Test loss: 0.02972\n",
      "Epoch: 1... Training loss: 0.08545... Test loss: 0.02433\n",
      "Epoch: 1... Training loss: 0.07544... Test loss: 0.0224\n",
      "Epoch: 1... Training loss: 0.06401... Test loss: 0.0242\n",
      "Epoch: 1... Training loss: 0.06275... Test loss: 0.01655\n",
      "Epoch: 1... Training loss: 0.04869... Test loss: 0.01355\n",
      "Epoch: 1... Training loss: 0.04627... Test loss: 0.01732\n",
      "Epoch: 1... Training loss: 0.04351... Test loss: 0.00929\n",
      "Epoch: 1... Training loss: 0.03658... Test loss: 0.01667\n",
      "Epoch: 1... Training loss: 0.03651... Test loss: 0.00791\n",
      "Epoch: 1... Training loss: 0.03243... Test loss: 0.01575\n",
      "Epoch: 1... Training loss: 0.03054... Test loss: 0.00789\n",
      "Epoch: 1... Training loss: 0.02761... Test loss: 0.01431\n",
      "Epoch: 1... Training loss: 0.02674... Test loss: 0.01281\n",
      "Epoch: 1... Training loss: 0.02543... Test loss: 0.01217\n",
      "Epoch: 1... Training loss: 0.02397... Test loss: 0.02209\n",
      "Epoch: 1... Training loss: 0.0227... Test loss: 0.01215\n",
      "Epoch: 1... Training loss: 0.02178... Test loss: 0.02178\n",
      "Epoch: 1... Training loss: 0.02088... Test loss: 0.01499\n",
      "Epoch: 1... Training loss: 0.01984... Test loss: 0.02185\n",
      "Epoch: 1... Training loss: 0.01899... Test loss: 0.01859\n",
      "Epoch: 1... Training loss: 0.01831... Test loss: 0.01254\n",
      "Epoch: 1... Training loss: 0.01676... Test loss: 0.01713\n",
      "Epoch: 1... Training loss: 0.01552... Test loss: 0.01602\n",
      "Epoch: 1... Training loss: 0.01489... Test loss: 0.01573\n",
      "Epoch: 1... Training loss: 0.01446... Test loss: 0.01895\n",
      "Epoch: 1... Training loss: 0.01422... Test loss: 0.00891\n",
      "Epoch: 1... Training loss: 0.01368... Test loss: 0.01532\n",
      "Epoch: 1... Training loss: 0.01304... Test loss: 0.0105\n",
      "Epoch: 1... Training loss: 0.01264... Test loss: 0.01523\n",
      "Epoch: 1... Training loss: 0.01224... Test loss: 0.00864\n",
      "Epoch: 1... Training loss: 0.01165... Test loss: 0.01516\n",
      "Epoch: 1... Training loss: 0.01128... Test loss: 0.00853\n",
      "Epoch: 1... Training loss: 0.01083... Test loss: 0.01311\n",
      "Epoch: 1... Training loss: 0.01036... Test loss: 0.00949\n",
      "Epoch: 1... Training loss: 0.01028... Test loss: 0.01149\n",
      "Epoch: 1... Training loss: 0.00987... Test loss: 0.01009\n",
      "Epoch: 1... Training loss: 0.00968... Test loss: 0.01132\n",
      "Epoch: 1... Training loss: 0.00929... Test loss: 0.00857\n",
      "Epoch: 1... Training loss: 0.0093... Test loss: 0.00905\n",
      "Epoch: 1... Training loss: 0.00889... Test loss: 0.00898\n",
      "Epoch: 1... Training loss: 0.00867... Test loss: 0.00887\n",
      "Epoch: 1... Training loss: 0.00846... Test loss: 0.00867\n",
      "Epoch: 1... Training loss: 0.00828... Test loss: 0.00779\n",
      "Epoch: 1... Training loss: 0.00816... Test loss: 0.00831\n",
      "Epoch: 1... Training loss: 0.00783... Test loss: 0.00874\n",
      "Epoch: 1... Training loss: 0.00769... Test loss: 0.0074\n",
      "Epoch: 1... Training loss: 0.00725... Test loss: 0.00755\n",
      "Epoch: 1... Training loss: 0.00716... Test loss: 0.00702\n",
      "Epoch: 1... Training loss: 0.00693... Test loss: 0.00611\n",
      "Epoch: 1... Training loss: 0.00682... Test loss: 0.0067\n",
      "Epoch: 1... Training loss: 0.00662... Test loss: 0.00591\n",
      "Epoch: 1... Training loss: 0.00648... Test loss: 0.00621\n",
      "Epoch: 1... Training loss: 0.00629... Test loss: 0.0066\n",
      "Epoch: 1... Training loss: 0.00616... Test loss: 0.00578\n",
      "Epoch: 1... Training loss: 0.00607... Test loss: 0.00594\n",
      "Epoch: 1... Training loss: 0.00588... Test loss: 0.00564\n",
      "Epoch: 1... Training loss: 0.01505... Test loss: 0.01659\n",
      "Epoch: 1... Training loss: 0.01189... Test loss: 0.00979\n",
      "Epoch: 1... Training loss: 0.01215... Test loss: 0.0218\n",
      "Epoch: 1... Training loss: 0.00971... Test loss: 0.01355\n",
      "Epoch: 1... Training loss: 0.00876... Test loss: 0.01935\n",
      "Epoch: 1... Training loss: 0.01011... Test loss: 0.0156\n",
      "Epoch: 1... Training loss: 0.00913... Test loss: 0.01324\n",
      "Epoch: 1... Training loss: 0.00984... Test loss: 0.01105\n",
      "Epoch: 1... Training loss: 0.00977... Test loss: 0.01655\n",
      "Epoch: 1... Training loss: 0.00866... Test loss: 0.01069\n",
      "Epoch: 1... Training loss: 0.00809... Test loss: 0.01259\n",
      "Epoch: 1... Training loss: 0.00849... Test loss: 0.01103\n",
      "Epoch: 1... Training loss: 0.00729... Test loss: 0.00916\n",
      "Epoch: 1... Training loss: 0.00739... Test loss: 0.01\n",
      "Epoch: 1... Training loss: 0.0072... Test loss: 0.00736\n",
      "Epoch: 1... Training loss: 0.00735... Test loss: 0.00816\n",
      "Epoch: 1... Training loss: 0.00726... Test loss: 0.00831\n",
      "Epoch: 1... Training loss: 0.0069... Test loss: 0.00679\n",
      "Epoch: 1... Training loss: 0.00622... Test loss: 0.00852\n",
      "Epoch: 1... Training loss: 0.00643... Test loss: 0.00636\n",
      "Epoch: 1... Training loss: 0.00611... Test loss: 0.00983\n",
      "Epoch: 1... Training loss: 0.00585... Test loss: 0.00712\n",
      "Epoch: 1... Training loss: 0.00553... Test loss: 0.00797\n",
      "Epoch: 1... Training loss: 0.00556... Test loss: 0.00678\n",
      "Epoch: 1... Training loss: 0.00528... Test loss: 0.0079\n",
      "Epoch: 1... Training loss: 0.00566... Test loss: 0.00562\n",
      "Epoch: 1... Training loss: 0.00548... Test loss: 0.00702\n",
      "Epoch: 1... Training loss: 0.00484... Test loss: 0.00578\n",
      "Epoch: 1... Training loss: 0.00475... Test loss: 0.00596\n",
      "Epoch: 1... Training loss: 0.00469... Test loss: 0.00541\n",
      "Epoch: 1... Training loss: 0.00451... Test loss: 0.0056\n",
      "Epoch: 1... Training loss: 0.00456... Test loss: 0.00482\n",
      "Epoch: 1... Training loss: 0.00426... Test loss: 0.00586\n",
      "Epoch: 1... Training loss: 0.00424... Test loss: 0.00393\n",
      "Epoch: 1... Training loss: 0.00417... Test loss: 0.0049\n",
      "Epoch: 1... Training loss: 0.00395... Test loss: 0.00372\n",
      "Epoch: 1... Training loss: 0.00393... Test loss: 0.00476\n",
      "Epoch: 1... Training loss: 0.00389... Test loss: 0.00356\n",
      "Epoch: 1... Training loss: 0.00373... Test loss: 0.0047\n",
      "Epoch: 1... Training loss: 0.00365... Test loss: 0.00363\n",
      "Epoch: 1... Training loss: 0.0037... Test loss: 0.00366\n",
      "Epoch: 1... Training loss: 0.00365... Test loss: 0.00383\n",
      "Epoch: 1... Training loss: 0.00347... Test loss: 0.00348\n",
      "Epoch: 1... Training loss: 0.00342... Test loss: 0.00415\n",
      "Epoch: 1... Training loss: 0.00332... Test loss: 0.0037\n",
      "Epoch: 1... Training loss: 0.00315... Test loss: 0.00334\n",
      "Epoch: 1... Training loss: 0.00309... Test loss: 0.00348\n",
      "Epoch: 1... Training loss: 0.00315... Test loss: 0.0033\n",
      "Epoch: 1... Training loss: 0.00301... Test loss: 0.0029\n",
      "Epoch: 1... Training loss: 0.00292... Test loss: 0.00352\n",
      "Epoch: 1... Training loss: 0.00281... Test loss: 0.00278\n",
      "Epoch: 1... Training loss: 0.00291... Test loss: 0.00337\n",
      "Epoch: 1... Training loss: 0.00271... Test loss: 0.00264\n",
      "Epoch: 1... Training loss: 0.00263... Test loss: 0.00311\n",
      "Epoch: 1... Training loss: 0.00258... Test loss: 0.00246\n",
      "Epoch: 1... Training loss: 0.00264... Test loss: 0.00303\n",
      "Epoch: 1... Training loss: 0.00251... Test loss: 0.00235\n",
      "Epoch: 1... Training loss: 0.00256... Test loss: 0.00289\n",
      "Epoch: 1... Training loss: 0.00231... Test loss: 0.00229\n",
      "Epoch: 1... Training loss: 0.00232... Test loss: 0.00239\n",
      "Epoch: 1... Training loss: 0.0022... Test loss: 0.00276\n",
      "Epoch: 1... Training loss: 0.00219... Test loss: 0.00213\n",
      "Epoch: 1... Training loss: 0.00215... Test loss: 0.00199\n",
      "Epoch: 1... Training loss: 0.00203... Test loss: 0.00198\n",
      "Epoch: 1... Training loss: 0.00193... Test loss: 0.00203\n",
      "Epoch: 1... Training loss: 0.00204... Test loss: 0.00207\n",
      "Epoch: 1... Training loss: 0.00202... Test loss: 0.00202\n",
      "Epoch: 1... Training loss: 0.00187... Test loss: 0.00216\n",
      "Epoch: 1... Training loss: 0.00179... Test loss: 0.00227\n",
      "Epoch: 1... Training loss: 0.00171... Test loss: 0.00206\n",
      "Epoch: 1... Training loss: 0.00165... Test loss: 0.00194\n",
      "Epoch: 1... Training loss: 0.00161... Test loss: 0.00199\n",
      "Epoch: 1... Training loss: 0.00158... Test loss: 0.00165\n",
      "Epoch: 1... Training loss: 0.00157... Test loss: 0.0018\n",
      "Epoch: 1... Training loss: 0.00152... Test loss: 0.00143\n",
      "Epoch: 1... Training loss: 0.00144... Test loss: 0.00168\n",
      "Epoch: 1... Training loss: 0.00139... Test loss: 0.0017\n",
      "Epoch: 1... Training loss: 0.00143... Test loss: 0.00144\n",
      "Epoch: 1... Training loss: 0.00134... Test loss: 0.00149\n",
      "Epoch: 1... Training loss: 0.00129... Test loss: 0.00129\n",
      "Epoch: 1... Training loss: 0.00148... Test loss: 0.00139\n",
      "Epoch: 1... Training loss: 0.00133... Test loss: 0.00128\n",
      "Epoch: 1... Training loss: 0.00124... Test loss: 0.00136\n",
      "Epoch: 1... Training loss: 0.00117... Test loss: 0.00125\n",
      "Epoch: 1... Training loss: 0.00109... Test loss: 0.00142\n",
      "Epoch: 1... Training loss: 0.00109... Test loss: 0.00134\n",
      "Epoch: 1... Training loss: 0.00106... Test loss: 0.00122\n",
      "Epoch: 1... Training loss: 0.00109... Test loss: 0.00131\n",
      "Epoch: 1... Training loss: 0.00105... Test loss: 0.0011\n",
      "Epoch: 1... Training loss: 0.00104... Test loss: 0.00127\n",
      "Epoch: 1... Training loss: 0.00098... Test loss: 0.00103\n",
      "Epoch: 1... Training loss: 0.00095... Test loss: 0.00097\n",
      "Epoch: 1... Training loss: 0.0009... Test loss: 0.00095\n",
      "Epoch: 1... Training loss: 0.00088... Test loss: 0.00096\n",
      "Epoch: 1... Training loss: 0.00089... Test loss: 0.001\n",
      "Epoch: 1... Training loss: 0.0009... Test loss: 0.00078\n",
      "Epoch: 1... Training loss: 0.00078... Test loss: 0.00084\n",
      "Epoch: 1... Training loss: 0.00086... Test loss: 0.00072\n",
      "Epoch: 1... Training loss: 0.00073... Test loss: 0.00092\n",
      "Epoch: 1... Training loss: 0.00072... Test loss: 0.00063\n",
      "Epoch: 1... Training loss: 0.00069... Test loss: 0.00092\n",
      "Epoch: 1... Training loss: 0.0007... Test loss: 0.00065\n",
      "Epoch: 1... Training loss: 0.00065... Test loss: 0.00074\n",
      "Epoch: 1... Training loss: 0.00066... Test loss: 0.00069\n",
      "Epoch: 1... Training loss: 0.00069... Test loss: 0.00071\n",
      "Epoch: 1... Training loss: 0.00065... Test loss: 0.00071\n",
      "Epoch: 1... Training loss: 0.00057... Test loss: 0.00059\n",
      "Epoch: 1... Training loss: 0.00055... Test loss: 0.00052\n",
      "Epoch: 1... Training loss: 0.00052... Test loss: 0.00058\n",
      "Epoch: 1... Training loss: 0.0005... Test loss: 0.00055\n",
      "Epoch: 1... Training loss: 0.00048... Test loss: 0.00058\n",
      "Epoch: 1... Training loss: 0.00056... Test loss: 0.00055\n",
      "Epoch: 1... Training loss: 0.00047... Test loss: 0.00043\n",
      "Epoch: 1... Training loss: 0.00046... Test loss: 0.00057\n",
      "Epoch: 1... Training loss: 0.00047... Test loss: 0.00033\n",
      "Epoch: 1... Training loss: 0.00039... Test loss: 0.00055\n",
      "Epoch: 1... Training loss: 0.00039... Test loss: 0.00037\n",
      "Epoch: 1... Training loss: 0.00034... Test loss: 0.0005\n",
      "Epoch: 1... Training loss: 0.00034... Test loss: 0.00028\n",
      "Epoch: 1... Training loss: 0.00036... Test loss: 0.00043\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00043\n",
      "Epoch: 1... Training loss: 0.00029... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00036\n",
      "Epoch: 1... Training loss: 0.00026... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00035\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00016\n",
      "258.0230169821298\n",
      "Epoch: 1... Training loss: 0.89098... Test loss: 0.2395\n",
      "Epoch: 1... Training loss: 0.4712... Test loss: 0.14182\n",
      "Epoch: 1... Training loss: 0.27239... Test loss: 0.06904\n",
      "Epoch: 1... Training loss: 0.18592... Test loss: 0.04602\n",
      "Epoch: 1... Training loss: 0.14753... Test loss: 0.0385\n",
      "Epoch: 1... Training loss: 0.12613... Test loss: 0.04874\n",
      "Epoch: 1... Training loss: 0.10137... Test loss: 0.02941\n",
      "Epoch: 1... Training loss: 0.08016... Test loss: 0.03221\n",
      "Epoch: 1... Training loss: 0.0649... Test loss: 0.01665\n",
      "Epoch: 1... Training loss: 0.05543... Test loss: 0.0181\n",
      "Epoch: 1... Training loss: 0.04903... Test loss: 0.01796\n",
      "Epoch: 1... Training loss: 0.04522... Test loss: 0.00847\n",
      "Epoch: 1... Training loss: 0.04138... Test loss: 0.01773\n",
      "Epoch: 1... Training loss: 0.04018... Test loss: 0.01181\n",
      "Epoch: 1... Training loss: 0.03628... Test loss: 0.00669\n",
      "Epoch: 1... Training loss: 0.03536... Test loss: 0.00999\n",
      "Epoch: 1... Training loss: 0.03234... Test loss: 0.00736\n",
      "Epoch: 1... Training loss: 0.03143... Test loss: 0.01496\n",
      "Epoch: 1... Training loss: 0.02972... Test loss: 0.0053\n",
      "Epoch: 1... Training loss: 0.02788... Test loss: 0.01527\n",
      "Epoch: 1... Training loss: 0.02692... Test loss: 0.0096\n",
      "Epoch: 1... Training loss: 0.02451... Test loss: 0.01325\n",
      "Epoch: 1... Training loss: 0.02374... Test loss: 0.01556\n",
      "Epoch: 1... Training loss: 0.02181... Test loss: 0.00822\n",
      "Epoch: 1... Training loss: 0.02045... Test loss: 0.01201\n",
      "Epoch: 1... Training loss: 0.01904... Test loss: 0.00916\n",
      "Epoch: 1... Training loss: 0.01789... Test loss: 0.01138\n",
      "Epoch: 1... Training loss: 0.01698... Test loss: 0.00749\n",
      "Epoch: 1... Training loss: 0.01622... Test loss: 0.01183\n",
      "Epoch: 1... Training loss: 0.01561... Test loss: 0.00929\n",
      "Epoch: 1... Training loss: 0.0152... Test loss: 0.01161\n",
      "Epoch: 1... Training loss: 0.01462... Test loss: 0.01216\n",
      "Epoch: 1... Training loss: 0.01411... Test loss: 0.00829\n",
      "Epoch: 1... Training loss: 0.01335... Test loss: 0.01387\n",
      "Epoch: 1... Training loss: 0.0129... Test loss: 0.00652\n",
      "Epoch: 1... Training loss: 0.01262... Test loss: 0.01154\n",
      "Epoch: 1... Training loss: 0.01215... Test loss: 0.00599\n",
      "Epoch: 1... Training loss: 0.01206... Test loss: 0.01057\n",
      "Epoch: 1... Training loss: 0.01157... Test loss: 0.00662\n",
      "Epoch: 1... Training loss: 0.01124... Test loss: 0.0094\n",
      "Epoch: 1... Training loss: 0.01093... Test loss: 0.00703\n",
      "Epoch: 1... Training loss: 0.0106... Test loss: 0.00892\n",
      "Epoch: 1... Training loss: 0.01014... Test loss: 0.00686\n",
      "Epoch: 1... Training loss: 0.00994... Test loss: 0.00901\n",
      "Epoch: 1... Training loss: 0.00959... Test loss: 0.00646\n",
      "Epoch: 1... Training loss: 0.00933... Test loss: 0.00833\n",
      "Epoch: 1... Training loss: 0.0091... Test loss: 0.00661\n",
      "Epoch: 1... Training loss: 0.00883... Test loss: 0.00865\n",
      "Epoch: 1... Training loss: 0.00864... Test loss: 0.00541\n",
      "Epoch: 1... Training loss: 0.00842... Test loss: 0.0078\n",
      "Epoch: 1... Training loss: 0.00823... Test loss: 0.00567\n",
      "Epoch: 1... Training loss: 0.00813... Test loss: 0.00733\n",
      "Epoch: 1... Training loss: 0.00797... Test loss: 0.00591\n",
      "Epoch: 1... Training loss: 0.0078... Test loss: 0.00748\n",
      "Epoch: 1... Training loss: 0.00754... Test loss: 0.00594\n",
      "Epoch: 1... Training loss: 0.00743... Test loss: 0.00708\n",
      "Epoch: 1... Training loss: 0.00713... Test loss: 0.00577\n",
      "Epoch: 1... Training loss: 0.00707... Test loss: 0.00709\n",
      "Epoch: 1... Training loss: 0.00669... Test loss: 0.00513\n",
      "Epoch: 1... Training loss: 0.00663... Test loss: 0.00661\n",
      "Epoch: 1... Training loss: 0.00641... Test loss: 0.00486\n",
      "Epoch: 1... Training loss: 0.00624... Test loss: 0.00647\n",
      "Epoch: 1... Training loss: 0.00602... Test loss: 0.00476\n",
      "Epoch: 1... Training loss: 0.00581... Test loss: 0.00639\n",
      "Epoch: 1... Training loss: 0.01871... Test loss: 0.007\n",
      "Epoch: 1... Training loss: 0.01435... Test loss: 0.01248\n",
      "Epoch: 1... Training loss: 0.01198... Test loss: 0.01091\n",
      "Epoch: 1... Training loss: 0.01252... Test loss: 0.01279\n",
      "Epoch: 1... Training loss: 0.00932... Test loss: 0.01705\n",
      "Epoch: 1... Training loss: 0.00876... Test loss: 0.01592\n",
      "Epoch: 1... Training loss: 0.00912... Test loss: 0.0134\n",
      "Epoch: 1... Training loss: 0.00923... Test loss: 0.00977\n",
      "Epoch: 1... Training loss: 0.00902... Test loss: 0.01076\n",
      "Epoch: 1... Training loss: 0.00893... Test loss: 0.01181\n",
      "Epoch: 1... Training loss: 0.00854... Test loss: 0.01063\n",
      "Epoch: 1... Training loss: 0.00856... Test loss: 0.00605\n",
      "Epoch: 1... Training loss: 0.00795... Test loss: 0.01168\n",
      "Epoch: 1... Training loss: 0.00743... Test loss: 0.0085\n",
      "Epoch: 1... Training loss: 0.00726... Test loss: 0.01028\n",
      "Epoch: 1... Training loss: 0.00747... Test loss: 0.0076\n",
      "Epoch: 1... Training loss: 0.00633... Test loss: 0.01123\n",
      "Epoch: 1... Training loss: 0.00698... Test loss: 0.00692\n",
      "Epoch: 1... Training loss: 0.00649... Test loss: 0.0085\n",
      "Epoch: 1... Training loss: 0.00625... Test loss: 0.00714\n",
      "Epoch: 1... Training loss: 0.00574... Test loss: 0.00892\n",
      "Epoch: 1... Training loss: 0.00572... Test loss: 0.00643\n",
      "Epoch: 1... Training loss: 0.0055... Test loss: 0.00697\n",
      "Epoch: 1... Training loss: 0.00561... Test loss: 0.00644\n",
      "Epoch: 1... Training loss: 0.00532... Test loss: 0.00673\n",
      "Epoch: 1... Training loss: 0.00531... Test loss: 0.00603\n",
      "Epoch: 1... Training loss: 0.00496... Test loss: 0.00562\n",
      "Epoch: 1... Training loss: 0.00489... Test loss: 0.00553\n",
      "Epoch: 1... Training loss: 0.00491... Test loss: 0.00423\n",
      "Epoch: 1... Training loss: 0.00477... Test loss: 0.00627\n",
      "Epoch: 1... Training loss: 0.00456... Test loss: 0.00575\n",
      "Epoch: 1... Training loss: 0.00436... Test loss: 0.00563\n",
      "Epoch: 1... Training loss: 0.00425... Test loss: 0.00496\n",
      "Epoch: 1... Training loss: 0.00414... Test loss: 0.00474\n",
      "Epoch: 1... Training loss: 0.00396... Test loss: 0.00371\n",
      "Epoch: 1... Training loss: 0.004... Test loss: 0.00495\n",
      "Epoch: 1... Training loss: 0.00402... Test loss: 0.00363\n",
      "Epoch: 1... Training loss: 0.00388... Test loss: 0.00526\n",
      "Epoch: 1... Training loss: 0.00381... Test loss: 0.00428\n",
      "Epoch: 1... Training loss: 0.00359... Test loss: 0.00467\n",
      "Epoch: 1... Training loss: 0.00355... Test loss: 0.00385\n",
      "Epoch: 1... Training loss: 0.00342... Test loss: 0.00452\n",
      "Epoch: 1... Training loss: 0.00336... Test loss: 0.00363\n",
      "Epoch: 1... Training loss: 0.00337... Test loss: 0.00349\n",
      "Epoch: 1... Training loss: 0.00333... Test loss: 0.00314\n",
      "Epoch: 1... Training loss: 0.00336... Test loss: 0.0032\n",
      "Epoch: 1... Training loss: 0.00319... Test loss: 0.00299\n",
      "Epoch: 1... Training loss: 0.00322... Test loss: 0.00389\n",
      "Epoch: 1... Training loss: 0.00298... Test loss: 0.00344\n",
      "Epoch: 1... Training loss: 0.00292... Test loss: 0.00354\n",
      "Epoch: 1... Training loss: 0.00292... Test loss: 0.00299\n",
      "Epoch: 1... Training loss: 0.00282... Test loss: 0.00361\n",
      "Epoch: 1... Training loss: 0.00274... Test loss: 0.00269\n",
      "Epoch: 1... Training loss: 0.00286... Test loss: 0.0032\n",
      "Epoch: 1... Training loss: 0.00258... Test loss: 0.00294\n",
      "Epoch: 1... Training loss: 0.00263... Test loss: 0.00293\n",
      "Epoch: 1... Training loss: 0.00252... Test loss: 0.00246\n",
      "Epoch: 1... Training loss: 0.00248... Test loss: 0.00304\n",
      "Epoch: 1... Training loss: 0.00237... Test loss: 0.00246\n",
      "Epoch: 1... Training loss: 0.00229... Test loss: 0.00269\n",
      "Epoch: 1... Training loss: 0.00245... Test loss: 0.00267\n",
      "Epoch: 1... Training loss: 0.0023... Test loss: 0.00241\n",
      "Epoch: 1... Training loss: 0.00217... Test loss: 0.00238\n",
      "Epoch: 1... Training loss: 0.0022... Test loss: 0.0023\n",
      "Epoch: 1... Training loss: 0.00217... Test loss: 0.00202\n",
      "Epoch: 1... Training loss: 0.00213... Test loss: 0.00231\n",
      "Epoch: 1... Training loss: 0.00216... Test loss: 0.00205\n",
      "Epoch: 1... Training loss: 0.002... Test loss: 0.0021\n",
      "Epoch: 1... Training loss: 0.002... Test loss: 0.00202\n",
      "Epoch: 1... Training loss: 0.00195... Test loss: 0.00207\n",
      "Epoch: 1... Training loss: 0.00197... Test loss: 0.00203\n",
      "Epoch: 1... Training loss: 0.00183... Test loss: 0.00187\n",
      "Epoch: 1... Training loss: 0.00178... Test loss: 0.00213\n",
      "Epoch: 1... Training loss: 0.00178... Test loss: 0.00184\n",
      "Epoch: 1... Training loss: 0.00177... Test loss: 0.00174\n",
      "Epoch: 1... Training loss: 0.00172... Test loss: 0.00151\n",
      "Epoch: 1... Training loss: 0.00164... Test loss: 0.00198\n",
      "Epoch: 1... Training loss: 0.00156... Test loss: 0.00141\n",
      "Epoch: 1... Training loss: 0.00144... Test loss: 0.00196\n",
      "Epoch: 1... Training loss: 0.00154... Test loss: 0.00137\n",
      "Epoch: 1... Training loss: 0.00152... Test loss: 0.00143\n",
      "Epoch: 1... Training loss: 0.00133... Test loss: 0.0013\n",
      "Epoch: 1... Training loss: 0.00132... Test loss: 0.00112\n",
      "Epoch: 1... Training loss: 0.00125... Test loss: 0.00121\n",
      "Epoch: 1... Training loss: 0.00123... Test loss: 0.00108\n",
      "Epoch: 1... Training loss: 0.00114... Test loss: 0.00116\n",
      "Epoch: 1... Training loss: 0.00106... Test loss: 0.00109\n",
      "Epoch: 1... Training loss: 0.00104... Test loss: 0.00119\n",
      "Epoch: 1... Training loss: 0.00102... Test loss: 0.00114\n",
      "Epoch: 1... Training loss: 0.00105... Test loss: 0.00092\n",
      "Epoch: 1... Training loss: 0.00108... Test loss: 0.00115\n",
      "Epoch: 1... Training loss: 0.00099... Test loss: 0.00078\n",
      "Epoch: 1... Training loss: 0.00094... Test loss: 0.00112\n",
      "Epoch: 1... Training loss: 0.0009... Test loss: 0.00099\n",
      "Epoch: 1... Training loss: 0.00092... Test loss: 0.00098\n",
      "Epoch: 1... Training loss: 0.00082... Test loss: 0.00081\n",
      "Epoch: 1... Training loss: 0.00079... Test loss: 0.00077\n",
      "Epoch: 1... Training loss: 0.00081... Test loss: 0.00094\n",
      "Epoch: 1... Training loss: 0.00081... Test loss: 0.00074\n",
      "Epoch: 1... Training loss: 0.00074... Test loss: 0.00063\n",
      "Epoch: 1... Training loss: 0.00073... Test loss: 0.00087\n",
      "Epoch: 1... Training loss: 0.00068... Test loss: 0.00067\n",
      "Epoch: 1... Training loss: 0.0007... Test loss: 0.00077\n",
      "Epoch: 1... Training loss: 0.00066... Test loss: 0.00067\n",
      "Epoch: 1... Training loss: 0.00065... Test loss: 0.00063\n",
      "Epoch: 1... Training loss: 0.00062... Test loss: 0.00076\n",
      "Epoch: 1... Training loss: 0.0006... Test loss: 0.00059\n",
      "Epoch: 1... Training loss: 0.00055... Test loss: 0.00081\n",
      "Epoch: 1... Training loss: 0.00053... Test loss: 0.00052\n",
      "Epoch: 1... Training loss: 0.00051... Test loss: 0.0007\n",
      "Epoch: 1... Training loss: 0.00054... Test loss: 0.00053\n",
      "Epoch: 1... Training loss: 0.00049... Test loss: 0.00064\n",
      "Epoch: 1... Training loss: 0.00053... Test loss: 0.00048\n",
      "Epoch: 1... Training loss: 0.00046... Test loss: 0.00049\n",
      "Epoch: 1... Training loss: 0.00043... Test loss: 0.00039\n",
      "Epoch: 1... Training loss: 0.00045... Test loss: 0.00054\n",
      "Epoch: 1... Training loss: 0.00047... Test loss: 0.00041\n",
      "Epoch: 1... Training loss: 0.0004... Test loss: 0.00053\n",
      "Epoch: 1... Training loss: 0.00042... Test loss: 0.00057\n",
      "Epoch: 1... Training loss: 0.00038... Test loss: 0.00037\n",
      "Epoch: 1... Training loss: 0.00037... Test loss: 0.00056\n",
      "Epoch: 1... Training loss: 0.00036... Test loss: 0.00036\n",
      "Epoch: 1... Training loss: 0.00036... Test loss: 0.00043\n",
      "Epoch: 1... Training loss: 0.00035... Test loss: 0.00032\n",
      "Epoch: 1... Training loss: 0.00032... Test loss: 0.00038\n",
      "Epoch: 1... Training loss: 0.00033... Test loss: 0.00028\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00037\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.0003\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.00029... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00019\n",
      "328.21004222193733\n",
      "Epoch: 1... Training loss: 1.05807... Test loss: 0.41825\n",
      "Epoch: 1... Training loss: 0.4554... Test loss: 0.15239\n",
      "Epoch: 1... Training loss: 0.21742... Test loss: 0.09609\n",
      "Epoch: 1... Training loss: 0.24328... Test loss: 0.08701\n",
      "Epoch: 1... Training loss: 0.14633... Test loss: 0.09283\n",
      "Epoch: 1... Training loss: 0.1126... Test loss: 0.08347\n",
      "Epoch: 1... Training loss: 0.09408... Test loss: 0.0526\n",
      "Epoch: 1... Training loss: 0.07788... Test loss: 0.07975\n",
      "Epoch: 1... Training loss: 0.07008... Test loss: 0.0288\n",
      "Epoch: 1... Training loss: 0.06481... Test loss: 0.07205\n",
      "Epoch: 1... Training loss: 0.05771... Test loss: 0.03213\n",
      "Epoch: 1... Training loss: 0.05031... Test loss: 0.06448\n",
      "Epoch: 1... Training loss: 0.04899... Test loss: 0.02285\n",
      "Epoch: 1... Training loss: 0.04384... Test loss: 0.06024\n",
      "Epoch: 1... Training loss: 0.04082... Test loss: 0.02165\n",
      "Epoch: 1... Training loss: 0.03693... Test loss: 0.06135\n",
      "Epoch: 1... Training loss: 0.03585... Test loss: 0.03531\n",
      "Epoch: 1... Training loss: 0.03299... Test loss: 0.01282\n",
      "Epoch: 1... Training loss: 0.03126... Test loss: 0.04116\n",
      "Epoch: 1... Training loss: 0.03066... Test loss: 0.01995\n",
      "Epoch: 1... Training loss: 0.0282... Test loss: 0.02797\n",
      "Epoch: 1... Training loss: 0.02771... Test loss: 0.02393\n",
      "Epoch: 1... Training loss: 0.02509... Test loss: 0.02085\n",
      "Epoch: 1... Training loss: 0.02442... Test loss: 0.03754\n",
      "Epoch: 1... Training loss: 0.02324... Test loss: 0.01216\n",
      "Epoch: 1... Training loss: 0.02246... Test loss: 0.03806\n",
      "Epoch: 1... Training loss: 0.02165... Test loss: 0.01326\n",
      "Epoch: 1... Training loss: 0.02058... Test loss: 0.03272\n",
      "Epoch: 1... Training loss: 0.01969... Test loss: 0.01853\n",
      "Epoch: 1... Training loss: 0.01869... Test loss: 0.03023\n",
      "Epoch: 1... Training loss: 0.01801... Test loss: 0.01584\n",
      "Epoch: 1... Training loss: 0.01753... Test loss: 0.02505\n",
      "Epoch: 1... Training loss: 0.01609... Test loss: 0.01634\n",
      "Epoch: 1... Training loss: 0.01565... Test loss: 0.01896\n",
      "Epoch: 1... Training loss: 0.0149... Test loss: 0.02111\n",
      "Epoch: 1... Training loss: 0.01444... Test loss: 0.01357\n",
      "Epoch: 1... Training loss: 0.01375... Test loss: 0.02302\n",
      "Epoch: 1... Training loss: 0.0134... Test loss: 0.01333\n",
      "Epoch: 1... Training loss: 0.01294... Test loss: 0.01939\n",
      "Epoch: 1... Training loss: 0.01275... Test loss: 0.01355\n",
      "Epoch: 1... Training loss: 0.01218... Test loss: 0.02068\n",
      "Epoch: 1... Training loss: 0.01188... Test loss: 0.01119\n",
      "Epoch: 1... Training loss: 0.01137... Test loss: 0.02016\n",
      "Epoch: 1... Training loss: 0.01125... Test loss: 0.01073\n",
      "Epoch: 1... Training loss: 0.01077... Test loss: 0.01811\n",
      "Epoch: 1... Training loss: 0.01043... Test loss: 0.01\n",
      "Epoch: 1... Training loss: 0.01019... Test loss: 0.01501\n",
      "Epoch: 1... Training loss: 0.00994... Test loss: 0.00841\n",
      "Epoch: 1... Training loss: 0.00967... Test loss: 0.01391\n",
      "Epoch: 1... Training loss: 0.00936... Test loss: 0.00852\n",
      "Epoch: 1... Training loss: 0.00905... Test loss: 0.01349\n",
      "Epoch: 1... Training loss: 0.00905... Test loss: 0.00704\n",
      "Epoch: 1... Training loss: 0.00873... Test loss: 0.01173\n",
      "Epoch: 1... Training loss: 0.00856... Test loss: 0.00972\n",
      "Epoch: 1... Training loss: 0.00817... Test loss: 0.0071\n",
      "Epoch: 1... Training loss: 0.00794... Test loss: 0.01194\n",
      "Epoch: 1... Training loss: 0.0077... Test loss: 0.00614\n",
      "Epoch: 1... Training loss: 0.0075... Test loss: 0.01064\n",
      "Epoch: 1... Training loss: 0.00718... Test loss: 0.0065\n",
      "Epoch: 1... Training loss: 0.00704... Test loss: 0.00915\n",
      "Epoch: 1... Training loss: 0.00683... Test loss: 0.00648\n",
      "Epoch: 1... Training loss: 0.00669... Test loss: 0.00782\n",
      "Epoch: 1... Training loss: 0.00649... Test loss: 0.00762\n",
      "Epoch: 1... Training loss: 0.00645... Test loss: 0.00636\n",
      "Epoch: 1... Training loss: 0.01178... Test loss: 0.00989\n",
      "Epoch: 1... Training loss: 0.01281... Test loss: 0.00964\n",
      "Epoch: 1... Training loss: 0.01176... Test loss: 0.00934\n",
      "Epoch: 1... Training loss: 0.012... Test loss: 0.01206\n",
      "Epoch: 1... Training loss: 0.01044... Test loss: 0.01268\n",
      "Epoch: 1... Training loss: 0.01004... Test loss: 0.01118\n",
      "Epoch: 1... Training loss: 0.0106... Test loss: 0.01326\n",
      "Epoch: 1... Training loss: 0.01086... Test loss: 0.01102\n",
      "Epoch: 1... Training loss: 0.01031... Test loss: 0.01235\n",
      "Epoch: 1... Training loss: 0.009... Test loss: 0.01423\n",
      "Epoch: 1... Training loss: 0.00888... Test loss: 0.00871\n",
      "Epoch: 1... Training loss: 0.00912... Test loss: 0.01274\n",
      "Epoch: 1... Training loss: 0.00884... Test loss: 0.0098\n",
      "Epoch: 1... Training loss: 0.00813... Test loss: 0.01076\n",
      "Epoch: 1... Training loss: 0.00765... Test loss: 0.01053\n",
      "Epoch: 1... Training loss: 0.00806... Test loss: 0.00775\n",
      "Epoch: 1... Training loss: 0.00772... Test loss: 0.01332\n",
      "Epoch: 1... Training loss: 0.00716... Test loss: 0.00881\n",
      "Epoch: 1... Training loss: 0.00712... Test loss: 0.01004\n",
      "Epoch: 1... Training loss: 0.00682... Test loss: 0.00949\n",
      "Epoch: 1... Training loss: 0.0068... Test loss: 0.00847\n",
      "Epoch: 1... Training loss: 0.00616... Test loss: 0.00883\n",
      "Epoch: 1... Training loss: 0.00632... Test loss: 0.00662\n",
      "Epoch: 1... Training loss: 0.00599... Test loss: 0.00758\n",
      "Epoch: 1... Training loss: 0.00632... Test loss: 0.00658\n",
      "Epoch: 1... Training loss: 0.00567... Test loss: 0.00717\n",
      "Epoch: 1... Training loss: 0.00553... Test loss: 0.00546\n",
      "Epoch: 1... Training loss: 0.00566... Test loss: 0.0067\n",
      "Epoch: 1... Training loss: 0.00524... Test loss: 0.00551\n",
      "Epoch: 1... Training loss: 0.00517... Test loss: 0.00547\n",
      "Epoch: 1... Training loss: 0.00497... Test loss: 0.00449\n",
      "Epoch: 1... Training loss: 0.00476... Test loss: 0.00615\n",
      "Epoch: 1... Training loss: 0.00461... Test loss: 0.00522\n",
      "Epoch: 1... Training loss: 0.00464... Test loss: 0.00528\n",
      "Epoch: 1... Training loss: 0.00474... Test loss: 0.00565\n",
      "Epoch: 1... Training loss: 0.00444... Test loss: 0.00507\n",
      "Epoch: 1... Training loss: 0.00434... Test loss: 0.00521\n",
      "Epoch: 1... Training loss: 0.00417... Test loss: 0.00365\n",
      "Epoch: 1... Training loss: 0.00428... Test loss: 0.0047\n",
      "Epoch: 1... Training loss: 0.00427... Test loss: 0.00462\n",
      "Epoch: 1... Training loss: 0.00409... Test loss: 0.00485\n",
      "Epoch: 1... Training loss: 0.00394... Test loss: 0.00433\n",
      "Epoch: 1... Training loss: 0.00401... Test loss: 0.005\n",
      "Epoch: 1... Training loss: 0.00374... Test loss: 0.00482\n",
      "Epoch: 1... Training loss: 0.00369... Test loss: 0.00487\n",
      "Epoch: 1... Training loss: 0.00355... Test loss: 0.00427\n",
      "Epoch: 1... Training loss: 0.0036... Test loss: 0.00452\n",
      "Epoch: 1... Training loss: 0.00347... Test loss: 0.00402\n",
      "Epoch: 1... Training loss: 0.00351... Test loss: 0.00374\n",
      "Epoch: 1... Training loss: 0.0035... Test loss: 0.00399\n",
      "Epoch: 1... Training loss: 0.00333... Test loss: 0.00346\n",
      "Epoch: 1... Training loss: 0.00317... Test loss: 0.00341\n",
      "Epoch: 1... Training loss: 0.00304... Test loss: 0.00306\n",
      "Epoch: 1... Training loss: 0.00301... Test loss: 0.00339\n",
      "Epoch: 1... Training loss: 0.00284... Test loss: 0.00291\n",
      "Epoch: 1... Training loss: 0.00271... Test loss: 0.00337\n",
      "Epoch: 1... Training loss: 0.00276... Test loss: 0.00309\n",
      "Epoch: 1... Training loss: 0.0027... Test loss: 0.00334\n",
      "Epoch: 1... Training loss: 0.0026... Test loss: 0.00324\n",
      "Epoch: 1... Training loss: 0.00245... Test loss: 0.00292\n",
      "Epoch: 1... Training loss: 0.0025... Test loss: 0.00304\n",
      "Epoch: 1... Training loss: 0.00242... Test loss: 0.00297\n",
      "Epoch: 1... Training loss: 0.00228... Test loss: 0.00267\n",
      "Epoch: 1... Training loss: 0.00219... Test loss: 0.00241\n",
      "Epoch: 1... Training loss: 0.00217... Test loss: 0.00254\n",
      "Epoch: 1... Training loss: 0.00214... Test loss: 0.00208\n",
      "Epoch: 1... Training loss: 0.00199... Test loss: 0.00295\n",
      "Epoch: 1... Training loss: 0.00191... Test loss: 0.00212\n",
      "Epoch: 1... Training loss: 0.00189... Test loss: 0.00234\n",
      "Epoch: 1... Training loss: 0.00184... Test loss: 0.00204\n",
      "Epoch: 1... Training loss: 0.00189... Test loss: 0.00234\n",
      "Epoch: 1... Training loss: 0.00187... Test loss: 0.00209\n",
      "Epoch: 1... Training loss: 0.00192... Test loss: 0.00166\n",
      "Epoch: 1... Training loss: 0.00176... Test loss: 0.00215\n",
      "Epoch: 1... Training loss: 0.0017... Test loss: 0.00189\n",
      "Epoch: 1... Training loss: 0.00168... Test loss: 0.00199\n",
      "Epoch: 1... Training loss: 0.00151... Test loss: 0.00177\n",
      "Epoch: 1... Training loss: 0.00145... Test loss: 0.0016\n",
      "Epoch: 1... Training loss: 0.00144... Test loss: 0.00173\n",
      "Epoch: 1... Training loss: 0.00146... Test loss: 0.00132\n",
      "Epoch: 1... Training loss: 0.0014... Test loss: 0.00158\n",
      "Epoch: 1... Training loss: 0.00134... Test loss: 0.0013\n",
      "Epoch: 1... Training loss: 0.00138... Test loss: 0.00161\n",
      "Epoch: 1... Training loss: 0.00127... Test loss: 0.00106\n",
      "Epoch: 1... Training loss: 0.00122... Test loss: 0.00167\n",
      "Epoch: 1... Training loss: 0.00123... Test loss: 0.0011\n",
      "Epoch: 1... Training loss: 0.00128... Test loss: 0.00165\n",
      "Epoch: 1... Training loss: 0.00123... Test loss: 0.00097\n",
      "Epoch: 1... Training loss: 0.00113... Test loss: 0.00142\n",
      "Epoch: 1... Training loss: 0.00111... Test loss: 0.00087\n",
      "Epoch: 1... Training loss: 0.00107... Test loss: 0.00104\n",
      "Epoch: 1... Training loss: 0.00106... Test loss: 0.0009\n",
      "Epoch: 1... Training loss: 0.00101... Test loss: 0.00132\n",
      "Epoch: 1... Training loss: 0.00103... Test loss: 0.00091\n",
      "Epoch: 1... Training loss: 0.00105... Test loss: 0.00135\n",
      "Epoch: 1... Training loss: 0.00102... Test loss: 0.00081\n",
      "Epoch: 1... Training loss: 0.00086... Test loss: 0.00107\n",
      "Epoch: 1... Training loss: 0.00095... Test loss: 0.00077\n",
      "Epoch: 1... Training loss: 0.00079... Test loss: 0.00083\n",
      "Epoch: 1... Training loss: 0.00076... Test loss: 0.00079\n",
      "Epoch: 1... Training loss: 0.00075... Test loss: 0.00072\n",
      "Epoch: 1... Training loss: 0.0008... Test loss: 0.0007\n",
      "Epoch: 1... Training loss: 0.0007... Test loss: 0.00082\n",
      "Epoch: 1... Training loss: 0.00073... Test loss: 0.00089\n",
      "Epoch: 1... Training loss: 0.00069... Test loss: 0.00091\n",
      "Epoch: 1... Training loss: 0.00069... Test loss: 0.00075\n",
      "Epoch: 1... Training loss: 0.00062... Test loss: 0.00086\n",
      "Epoch: 1... Training loss: 0.00059... Test loss: 0.0007\n",
      "Epoch: 1... Training loss: 0.00059... Test loss: 0.00084\n",
      "Epoch: 1... Training loss: 0.00057... Test loss: 0.00062\n",
      "Epoch: 1... Training loss: 0.00057... Test loss: 0.00074\n",
      "Epoch: 1... Training loss: 0.00055... Test loss: 0.00049\n",
      "Epoch: 1... Training loss: 0.00053... Test loss: 0.00062\n",
      "Epoch: 1... Training loss: 0.00048... Test loss: 0.00044\n",
      "Epoch: 1... Training loss: 0.00047... Test loss: 0.00045\n",
      "Epoch: 1... Training loss: 0.00047... Test loss: 0.00032\n",
      "Epoch: 1... Training loss: 0.00048... Test loss: 0.0006\n",
      "Epoch: 1... Training loss: 0.00043... Test loss: 0.00033\n",
      "Epoch: 1... Training loss: 0.00042... Test loss: 0.00045\n",
      "Epoch: 1... Training loss: 0.00042... Test loss: 0.00033\n",
      "Epoch: 1... Training loss: 0.0004... Test loss: 0.00044\n",
      "Epoch: 1... Training loss: 0.00037... Test loss: 0.00038\n",
      "Epoch: 1... Training loss: 0.00041... Test loss: 0.00034\n",
      "Epoch: 1... Training loss: 0.00035... Test loss: 0.0004\n",
      "Epoch: 1... Training loss: 0.00032... Test loss: 0.00037\n",
      "Epoch: 1... Training loss: 0.00031... Test loss: 0.00032\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.00033\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.00028\n",
      "Epoch: 1... Training loss: 0.00026... Test loss: 0.00032\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00028\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00019\n",
      "301.886411691783\n",
      "Epoch: 1... Training loss: 0.87187... Test loss: 0.2656\n",
      "Epoch: 1... Training loss: 0.39974... Test loss: 0.11938\n",
      "Epoch: 1... Training loss: 0.21782... Test loss: 0.06087\n",
      "Epoch: 1... Training loss: 0.15376... Test loss: 0.04262\n",
      "Epoch: 1... Training loss: 0.12164... Test loss: 0.03065\n",
      "Epoch: 1... Training loss: 0.09528... Test loss: 0.02214\n",
      "Epoch: 1... Training loss: 0.07429... Test loss: 0.01888\n",
      "Epoch: 1... Training loss: 0.0657... Test loss: 0.01555\n",
      "Epoch: 1... Training loss: 0.06001... Test loss: 0.01526\n",
      "Epoch: 1... Training loss: 0.05116... Test loss: 0.01255\n",
      "Epoch: 1... Training loss: 0.04506... Test loss: 0.01482\n",
      "Epoch: 1... Training loss: 0.04117... Test loss: 0.00774\n",
      "Epoch: 1... Training loss: 0.03816... Test loss: 0.01028\n",
      "Epoch: 1... Training loss: 0.03616... Test loss: 0.00661\n",
      "Epoch: 1... Training loss: 0.03324... Test loss: 0.00401\n",
      "Epoch: 1... Training loss: 0.03154... Test loss: 0.00953\n",
      "Epoch: 1... Training loss: 0.03014... Test loss: 0.00332\n",
      "Epoch: 1... Training loss: 0.02819... Test loss: 0.00998\n",
      "Epoch: 1... Training loss: 0.02664... Test loss: 0.00362\n",
      "Epoch: 1... Training loss: 0.02497... Test loss: 0.00875\n",
      "Epoch: 1... Training loss: 0.0235... Test loss: 0.00387\n",
      "Epoch: 1... Training loss: 0.02267... Test loss: 0.00971\n",
      "Epoch: 1... Training loss: 0.02145... Test loss: 0.00376\n",
      "Epoch: 1... Training loss: 0.02042... Test loss: 0.01101\n",
      "Epoch: 1... Training loss: 0.0193... Test loss: 0.00343\n",
      "Epoch: 1... Training loss: 0.01841... Test loss: 0.01108\n",
      "Epoch: 1... Training loss: 0.0174... Test loss: 0.00707\n",
      "Epoch: 1... Training loss: 0.0165... Test loss: 0.01204\n",
      "Epoch: 1... Training loss: 0.01609... Test loss: 0.00815\n",
      "Epoch: 1... Training loss: 0.01575... Test loss: 0.00788\n",
      "Epoch: 1... Training loss: 0.01489... Test loss: 0.01519\n",
      "Epoch: 1... Training loss: 0.01475... Test loss: 0.00506\n",
      "Epoch: 1... Training loss: 0.01413... Test loss: 0.01423\n",
      "Epoch: 1... Training loss: 0.01367... Test loss: 0.00661\n",
      "Epoch: 1... Training loss: 0.01306... Test loss: 0.01531\n",
      "Epoch: 1... Training loss: 0.01282... Test loss: 0.00635\n",
      "Epoch: 1... Training loss: 0.0121... Test loss: 0.01419\n",
      "Epoch: 1... Training loss: 0.01181... Test loss: 0.0056\n",
      "Epoch: 1... Training loss: 0.01155... Test loss: 0.01211\n",
      "Epoch: 1... Training loss: 0.0112... Test loss: 0.00475\n",
      "Epoch: 1... Training loss: 0.01084... Test loss: 0.0111\n",
      "Epoch: 1... Training loss: 0.01046... Test loss: 0.00535\n",
      "Epoch: 1... Training loss: 0.01018... Test loss: 0.01085\n",
      "Epoch: 1... Training loss: 0.00995... Test loss: 0.00522\n",
      "Epoch: 1... Training loss: 0.00969... Test loss: 0.00976\n",
      "Epoch: 1... Training loss: 0.00925... Test loss: 0.00542\n",
      "Epoch: 1... Training loss: 0.00909... Test loss: 0.00892\n",
      "Epoch: 1... Training loss: 0.00879... Test loss: 0.00616\n",
      "Epoch: 1... Training loss: 0.00837... Test loss: 0.0079\n",
      "Epoch: 1... Training loss: 0.00824... Test loss: 0.00658\n",
      "Epoch: 1... Training loss: 0.00787... Test loss: 0.00577\n",
      "Epoch: 1... Training loss: 0.0077... Test loss: 0.00898\n",
      "Epoch: 1... Training loss: 0.00739... Test loss: 0.00491\n",
      "Epoch: 1... Training loss: 0.00728... Test loss: 0.00816\n",
      "Epoch: 1... Training loss: 0.00701... Test loss: 0.00518\n",
      "Epoch: 1... Training loss: 0.00695... Test loss: 0.00667\n",
      "Epoch: 1... Training loss: 0.0067... Test loss: 0.00448\n",
      "Epoch: 1... Training loss: 0.00654... Test loss: 0.00599\n",
      "Epoch: 1... Training loss: 0.00638... Test loss: 0.00497\n",
      "Epoch: 1... Training loss: 0.00618... Test loss: 0.00497\n",
      "Epoch: 1... Training loss: 0.00598... Test loss: 0.00595\n",
      "Epoch: 1... Training loss: 0.00583... Test loss: 0.00457\n",
      "Epoch: 1... Training loss: 0.00568... Test loss: 0.00625\n",
      "Epoch: 1... Training loss: 0.00558... Test loss: 0.00464\n",
      "Epoch: 1... Training loss: 0.00969... Test loss: 0.00859\n",
      "Epoch: 1... Training loss: 0.00955... Test loss: 0.01169\n",
      "Epoch: 1... Training loss: 0.011... Test loss: 0.0116\n",
      "Epoch: 1... Training loss: 0.00975... Test loss: 0.00895\n",
      "Epoch: 1... Training loss: 0.00998... Test loss: 0.01202\n",
      "Epoch: 1... Training loss: 0.00898... Test loss: 0.01251\n",
      "Epoch: 1... Training loss: 0.00889... Test loss: 0.00922\n",
      "Epoch: 1... Training loss: 0.00915... Test loss: 0.01133\n",
      "Epoch: 1... Training loss: 0.00878... Test loss: 0.01079\n",
      "Epoch: 1... Training loss: 0.00802... Test loss: 0.01106\n",
      "Epoch: 1... Training loss: 0.00812... Test loss: 0.00893\n",
      "Epoch: 1... Training loss: 0.00731... Test loss: 0.00876\n",
      "Epoch: 1... Training loss: 0.00706... Test loss: 0.00882\n",
      "Epoch: 1... Training loss: 0.00741... Test loss: 0.01058\n",
      "Epoch: 1... Training loss: 0.0068... Test loss: 0.00823\n",
      "Epoch: 1... Training loss: 0.00682... Test loss: 0.01029\n",
      "Epoch: 1... Training loss: 0.00637... Test loss: 0.00651\n",
      "Epoch: 1... Training loss: 0.00597... Test loss: 0.00886\n",
      "Epoch: 1... Training loss: 0.00642... Test loss: 0.00644\n",
      "Epoch: 1... Training loss: 0.00551... Test loss: 0.00662\n",
      "Epoch: 1... Training loss: 0.00593... Test loss: 0.00531\n",
      "Epoch: 1... Training loss: 0.00558... Test loss: 0.00714\n",
      "Epoch: 1... Training loss: 0.00537... Test loss: 0.00523\n",
      "Epoch: 1... Training loss: 0.00519... Test loss: 0.00654\n",
      "Epoch: 1... Training loss: 0.00519... Test loss: 0.00481\n",
      "Epoch: 1... Training loss: 0.00483... Test loss: 0.00467\n",
      "Epoch: 1... Training loss: 0.0046... Test loss: 0.00392\n",
      "Epoch: 1... Training loss: 0.00471... Test loss: 0.0048\n",
      "Epoch: 1... Training loss: 0.00438... Test loss: 0.00504\n",
      "Epoch: 1... Training loss: 0.00434... Test loss: 0.00528\n",
      "Epoch: 1... Training loss: 0.00425... Test loss: 0.00435\n",
      "Epoch: 1... Training loss: 0.00418... Test loss: 0.00477\n",
      "Epoch: 1... Training loss: 0.00397... Test loss: 0.00459\n",
      "Epoch: 1... Training loss: 0.00405... Test loss: 0.00455\n",
      "Epoch: 1... Training loss: 0.00377... Test loss: 0.0045\n",
      "Epoch: 1... Training loss: 0.00373... Test loss: 0.00415\n",
      "Epoch: 1... Training loss: 0.00375... Test loss: 0.00376\n",
      "Epoch: 1... Training loss: 0.00382... Test loss: 0.00448\n",
      "Epoch: 1... Training loss: 0.00361... Test loss: 0.00359\n",
      "Epoch: 1... Training loss: 0.00359... Test loss: 0.00384\n",
      "Epoch: 1... Training loss: 0.0035... Test loss: 0.00347\n",
      "Epoch: 1... Training loss: 0.00324... Test loss: 0.00426\n",
      "Epoch: 1... Training loss: 0.00333... Test loss: 0.00307\n",
      "Epoch: 1... Training loss: 0.00326... Test loss: 0.00421\n",
      "Epoch: 1... Training loss: 0.00318... Test loss: 0.003\n",
      "Epoch: 1... Training loss: 0.00319... Test loss: 0.00352\n",
      "Epoch: 1... Training loss: 0.00313... Test loss: 0.0028\n",
      "Epoch: 1... Training loss: 0.00307... Test loss: 0.00311\n",
      "Epoch: 1... Training loss: 0.00296... Test loss: 0.00292\n",
      "Epoch: 1... Training loss: 0.00284... Test loss: 0.00316\n",
      "Epoch: 1... Training loss: 0.0028... Test loss: 0.00278\n",
      "Epoch: 1... Training loss: 0.00268... Test loss: 0.00309\n",
      "Epoch: 1... Training loss: 0.00271... Test loss: 0.00299\n",
      "Epoch: 1... Training loss: 0.00263... Test loss: 0.00301\n",
      "Epoch: 1... Training loss: 0.00257... Test loss: 0.0029\n",
      "Epoch: 1... Training loss: 0.00259... Test loss: 0.00263\n",
      "Epoch: 1... Training loss: 0.0025... Test loss: 0.0028\n",
      "Epoch: 1... Training loss: 0.00246... Test loss: 0.00262\n",
      "Epoch: 1... Training loss: 0.00238... Test loss: 0.00294\n",
      "Epoch: 1... Training loss: 0.0024... Test loss: 0.00217\n",
      "Epoch: 1... Training loss: 0.00224... Test loss: 0.00226\n",
      "Epoch: 1... Training loss: 0.0022... Test loss: 0.00217\n",
      "Epoch: 1... Training loss: 0.00227... Test loss: 0.00222\n",
      "Epoch: 1... Training loss: 0.00218... Test loss: 0.00223\n",
      "Epoch: 1... Training loss: 0.00208... Test loss: 0.0022\n",
      "Epoch: 1... Training loss: 0.00204... Test loss: 0.00189\n",
      "Epoch: 1... Training loss: 0.00194... Test loss: 0.00205\n",
      "Epoch: 1... Training loss: 0.0019... Test loss: 0.00204\n",
      "Epoch: 1... Training loss: 0.00178... Test loss: 0.00177\n",
      "Epoch: 1... Training loss: 0.00186... Test loss: 0.00199\n",
      "Epoch: 1... Training loss: 0.00171... Test loss: 0.00181\n",
      "Epoch: 1... Training loss: 0.00169... Test loss: 0.00177\n",
      "Epoch: 1... Training loss: 0.00163... Test loss: 0.00175\n",
      "Epoch: 1... Training loss: 0.00168... Test loss: 0.0017\n",
      "Epoch: 1... Training loss: 0.00155... Test loss: 0.00179\n",
      "Epoch: 1... Training loss: 0.00153... Test loss: 0.0015\n",
      "Epoch: 1... Training loss: 0.00145... Test loss: 0.00192\n",
      "Epoch: 1... Training loss: 0.00139... Test loss: 0.0015\n",
      "Epoch: 1... Training loss: 0.00136... Test loss: 0.00176\n",
      "Epoch: 1... Training loss: 0.00134... Test loss: 0.00143\n",
      "Epoch: 1... Training loss: 0.00128... Test loss: 0.0016\n",
      "Epoch: 1... Training loss: 0.00122... Test loss: 0.00138\n",
      "Epoch: 1... Training loss: 0.00118... Test loss: 0.00136\n",
      "Epoch: 1... Training loss: 0.00123... Test loss: 0.00125\n",
      "Epoch: 1... Training loss: 0.00118... Test loss: 0.00131\n",
      "Epoch: 1... Training loss: 0.00111... Test loss: 0.00116\n",
      "Epoch: 1... Training loss: 0.00116... Test loss: 0.00124\n",
      "Epoch: 1... Training loss: 0.00108... Test loss: 0.00116\n",
      "Epoch: 1... Training loss: 0.00109... Test loss: 0.00105\n",
      "Epoch: 1... Training loss: 0.00109... Test loss: 0.00111\n",
      "Epoch: 1... Training loss: 0.00102... Test loss: 0.00106\n",
      "Epoch: 1... Training loss: 0.00096... Test loss: 0.00101\n",
      "Epoch: 1... Training loss: 0.00101... Test loss: 0.00099\n",
      "Epoch: 1... Training loss: 0.00088... Test loss: 0.00104\n",
      "Epoch: 1... Training loss: 0.00092... Test loss: 0.00084\n",
      "Epoch: 1... Training loss: 0.00087... Test loss: 0.00083\n",
      "Epoch: 1... Training loss: 0.00087... Test loss: 0.0008\n",
      "Epoch: 1... Training loss: 0.00086... Test loss: 0.00078\n",
      "Epoch: 1... Training loss: 0.0008... Test loss: 0.00082\n",
      "Epoch: 1... Training loss: 0.00085... Test loss: 0.00079\n",
      "Epoch: 1... Training loss: 0.00076... Test loss: 0.00083\n",
      "Epoch: 1... Training loss: 0.00068... Test loss: 0.00083\n",
      "Epoch: 1... Training loss: 0.00076... Test loss: 0.00078\n",
      "Epoch: 1... Training loss: 0.00074... Test loss: 0.00087\n",
      "Epoch: 1... Training loss: 0.00066... Test loss: 0.00069\n",
      "Epoch: 1... Training loss: 0.00063... Test loss: 0.00069\n",
      "Epoch: 1... Training loss: 0.0006... Test loss: 0.00067\n",
      "Epoch: 1... Training loss: 0.00061... Test loss: 0.00072\n",
      "Epoch: 1... Training loss: 0.00061... Test loss: 0.00056\n",
      "Epoch: 1... Training loss: 0.00057... Test loss: 0.00056\n",
      "Epoch: 1... Training loss: 0.0006... Test loss: 0.00051\n",
      "Epoch: 1... Training loss: 0.00053... Test loss: 0.00057\n",
      "Epoch: 1... Training loss: 0.00052... Test loss: 0.00051\n",
      "Epoch: 1... Training loss: 0.00055... Test loss: 0.00061\n",
      "Epoch: 1... Training loss: 0.00045... Test loss: 0.00047\n",
      "Epoch: 1... Training loss: 0.00044... Test loss: 0.00053\n",
      "Epoch: 1... Training loss: 0.00042... Test loss: 0.00042\n",
      "Epoch: 1... Training loss: 0.0004... Test loss: 0.00042\n",
      "Epoch: 1... Training loss: 0.0004... Test loss: 0.00044\n",
      "Epoch: 1... Training loss: 0.00042... Test loss: 0.00045\n",
      "Epoch: 1... Training loss: 0.00035... Test loss: 0.00042\n",
      "Epoch: 1... Training loss: 0.00039... Test loss: 0.00038\n",
      "Epoch: 1... Training loss: 0.00036... Test loss: 0.00038\n",
      "Epoch: 1... Training loss: 0.00031... Test loss: 0.00034\n",
      "Epoch: 1... Training loss: 0.00033... Test loss: 0.00036\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00028\n",
      "Epoch: 1... Training loss: 0.00029... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.00034... Test loss: 0.00028\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00024\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00019\n",
      "268.2827505079331\n",
      "Epoch: 1... Training loss: 0.83169... Test loss: 0.21232\n",
      "Epoch: 1... Training loss: 0.44912... Test loss: 0.11635\n",
      "Epoch: 1... Training loss: 0.26976... Test loss: 0.08364\n",
      "Epoch: 1... Training loss: 0.18578... Test loss: 0.04827\n",
      "Epoch: 1... Training loss: 0.14584... Test loss: 0.0411\n",
      "Epoch: 1... Training loss: 0.12047... Test loss: 0.03264\n",
      "Epoch: 1... Training loss: 0.09497... Test loss: 0.03152\n",
      "Epoch: 1... Training loss: 0.07933... Test loss: 0.01802\n",
      "Epoch: 1... Training loss: 0.07227... Test loss: 0.02514\n",
      "Epoch: 1... Training loss: 0.06033... Test loss: 0.01776\n",
      "Epoch: 1... Training loss: 0.05536... Test loss: 0.02395\n",
      "Epoch: 1... Training loss: 0.04736... Test loss: 0.02057\n",
      "Epoch: 1... Training loss: 0.04309... Test loss: 0.02012\n",
      "Epoch: 1... Training loss: 0.03941... Test loss: 0.01534\n",
      "Epoch: 1... Training loss: 0.03736... Test loss: 0.0159\n",
      "Epoch: 1... Training loss: 0.03378... Test loss: 0.02413\n",
      "Epoch: 1... Training loss: 0.03132... Test loss: 0.01626\n",
      "Epoch: 1... Training loss: 0.02989... Test loss: 0.01277\n",
      "Epoch: 1... Training loss: 0.02836... Test loss: 0.02442\n",
      "Epoch: 1... Training loss: 0.02577... Test loss: 0.0141\n",
      "Epoch: 1... Training loss: 0.024... Test loss: 0.01345\n",
      "Epoch: 1... Training loss: 0.02226... Test loss: 0.02207\n",
      "Epoch: 1... Training loss: 0.02124... Test loss: 0.01033\n",
      "Epoch: 1... Training loss: 0.02026... Test loss: 0.01933\n",
      "Epoch: 1... Training loss: 0.01973... Test loss: 0.01173\n",
      "Epoch: 1... Training loss: 0.0189... Test loss: 0.01284\n",
      "Epoch: 1... Training loss: 0.01796... Test loss: 0.0145\n",
      "Epoch: 1... Training loss: 0.0169... Test loss: 0.01019\n",
      "Epoch: 1... Training loss: 0.01651... Test loss: 0.01377\n",
      "Epoch: 1... Training loss: 0.01595... Test loss: 0.00764\n",
      "Epoch: 1... Training loss: 0.01512... Test loss: 0.01714\n",
      "Epoch: 1... Training loss: 0.01495... Test loss: 0.00909\n",
      "Epoch: 1... Training loss: 0.01404... Test loss: 0.01434\n",
      "Epoch: 1... Training loss: 0.01365... Test loss: 0.00791\n",
      "Epoch: 1... Training loss: 0.01292... Test loss: 0.01367\n",
      "Epoch: 1... Training loss: 0.01266... Test loss: 0.00753\n",
      "Epoch: 1... Training loss: 0.01181... Test loss: 0.01184\n",
      "Epoch: 1... Training loss: 0.01149... Test loss: 0.00754\n",
      "Epoch: 1... Training loss: 0.01105... Test loss: 0.01054\n",
      "Epoch: 1... Training loss: 0.01075... Test loss: 0.00793\n",
      "Epoch: 1... Training loss: 0.01033... Test loss: 0.00857\n",
      "Epoch: 1... Training loss: 0.00999... Test loss: 0.00838\n",
      "Epoch: 1... Training loss: 0.00977... Test loss: 0.00688\n",
      "Epoch: 1... Training loss: 0.00948... Test loss: 0.00857\n",
      "Epoch: 1... Training loss: 0.00947... Test loss: 0.00663\n",
      "Epoch: 1... Training loss: 0.00893... Test loss: 0.00901\n",
      "Epoch: 1... Training loss: 0.00875... Test loss: 0.00713\n",
      "Epoch: 1... Training loss: 0.00843... Test loss: 0.00689\n",
      "Epoch: 1... Training loss: 0.00827... Test loss: 0.00728\n",
      "Epoch: 1... Training loss: 0.00791... Test loss: 0.00585\n",
      "Epoch: 1... Training loss: 0.00789... Test loss: 0.00789\n",
      "Epoch: 1... Training loss: 0.00764... Test loss: 0.00443\n",
      "Epoch: 1... Training loss: 0.00744... Test loss: 0.00757\n",
      "Epoch: 1... Training loss: 0.00722... Test loss: 0.00504\n",
      "Epoch: 1... Training loss: 0.00714... Test loss: 0.00786\n",
      "Epoch: 1... Training loss: 0.007... Test loss: 0.0051\n",
      "Epoch: 1... Training loss: 0.00686... Test loss: 0.0068\n",
      "Epoch: 1... Training loss: 0.0067... Test loss: 0.00543\n",
      "Epoch: 1... Training loss: 0.00667... Test loss: 0.00676\n",
      "Epoch: 1... Training loss: 0.00657... Test loss: 0.00537\n",
      "Epoch: 1... Training loss: 0.00639... Test loss: 0.00549\n",
      "Epoch: 1... Training loss: 0.00631... Test loss: 0.0053\n",
      "Epoch: 1... Training loss: 0.00608... Test loss: 0.00559\n",
      "Epoch: 1... Training loss: 0.00599... Test loss: 0.00538\n",
      "Epoch: 1... Training loss: 0.00851... Test loss: 0.00946\n",
      "Epoch: 1... Training loss: 0.01404... Test loss: 0.00906\n",
      "Epoch: 1... Training loss: 0.01018... Test loss: 0.00844\n",
      "Epoch: 1... Training loss: 0.00973... Test loss: 0.01177\n",
      "Epoch: 1... Training loss: 0.01074... Test loss: 0.00897\n",
      "Epoch: 1... Training loss: 0.01096... Test loss: 0.01303\n",
      "Epoch: 1... Training loss: 0.0093... Test loss: 0.00843\n",
      "Epoch: 1... Training loss: 0.00923... Test loss: 0.01127\n",
      "Epoch: 1... Training loss: 0.00954... Test loss: 0.00797\n",
      "Epoch: 1... Training loss: 0.00861... Test loss: 0.00961\n",
      "Epoch: 1... Training loss: 0.00848... Test loss: 0.00739\n",
      "Epoch: 1... Training loss: 0.0079... Test loss: 0.01005\n",
      "Epoch: 1... Training loss: 0.00837... Test loss: 0.00814\n",
      "Epoch: 1... Training loss: 0.00763... Test loss: 0.00845\n",
      "Epoch: 1... Training loss: 0.00778... Test loss: 0.00909\n",
      "Epoch: 1... Training loss: 0.00753... Test loss: 0.00814\n",
      "Epoch: 1... Training loss: 0.00754... Test loss: 0.00821\n",
      "Epoch: 1... Training loss: 0.00674... Test loss: 0.00856\n",
      "Epoch: 1... Training loss: 0.0068... Test loss: 0.00815\n",
      "Epoch: 1... Training loss: 0.00674... Test loss: 0.01019\n",
      "Epoch: 1... Training loss: 0.00657... Test loss: 0.00635\n",
      "Epoch: 1... Training loss: 0.00646... Test loss: 0.00689\n",
      "Epoch: 1... Training loss: 0.00614... Test loss: 0.00613\n",
      "Epoch: 1... Training loss: 0.00597... Test loss: 0.00806\n",
      "Epoch: 1... Training loss: 0.00574... Test loss: 0.00665\n",
      "Epoch: 1... Training loss: 0.00539... Test loss: 0.00715\n",
      "Epoch: 1... Training loss: 0.00548... Test loss: 0.00624\n",
      "Epoch: 1... Training loss: 0.00506... Test loss: 0.0058\n",
      "Epoch: 1... Training loss: 0.00506... Test loss: 0.0066\n",
      "Epoch: 1... Training loss: 0.00492... Test loss: 0.0053\n",
      "Epoch: 1... Training loss: 0.00458... Test loss: 0.00499\n",
      "Epoch: 1... Training loss: 0.00448... Test loss: 0.00445\n",
      "Epoch: 1... Training loss: 0.0043... Test loss: 0.00456\n",
      "Epoch: 1... Training loss: 0.00416... Test loss: 0.00516\n",
      "Epoch: 1... Training loss: 0.00409... Test loss: 0.00454\n",
      "Epoch: 1... Training loss: 0.00403... Test loss: 0.00497\n",
      "Epoch: 1... Training loss: 0.00388... Test loss: 0.00421\n",
      "Epoch: 1... Training loss: 0.00385... Test loss: 0.00478\n",
      "Epoch: 1... Training loss: 0.00373... Test loss: 0.00444\n",
      "Epoch: 1... Training loss: 0.00368... Test loss: 0.0049\n",
      "Epoch: 1... Training loss: 0.00345... Test loss: 0.00375\n",
      "Epoch: 1... Training loss: 0.00341... Test loss: 0.00466\n",
      "Epoch: 1... Training loss: 0.00332... Test loss: 0.00381\n",
      "Epoch: 1... Training loss: 0.00324... Test loss: 0.00465\n",
      "Epoch: 1... Training loss: 0.00321... Test loss: 0.00333\n",
      "Epoch: 1... Training loss: 0.00318... Test loss: 0.00388\n",
      "Epoch: 1... Training loss: 0.00311... Test loss: 0.0031\n",
      "Epoch: 1... Training loss: 0.00318... Test loss: 0.00343\n",
      "Epoch: 1... Training loss: 0.00315... Test loss: 0.00328\n",
      "Epoch: 1... Training loss: 0.0029... Test loss: 0.00311\n",
      "Epoch: 1... Training loss: 0.00282... Test loss: 0.00376\n",
      "Epoch: 1... Training loss: 0.00279... Test loss: 0.00304\n",
      "Epoch: 1... Training loss: 0.00276... Test loss: 0.00341\n",
      "Epoch: 1... Training loss: 0.00267... Test loss: 0.00284\n",
      "Epoch: 1... Training loss: 0.00263... Test loss: 0.00275\n",
      "Epoch: 1... Training loss: 0.00273... Test loss: 0.0031\n",
      "Epoch: 1... Training loss: 0.00256... Test loss: 0.00274\n",
      "Epoch: 1... Training loss: 0.00252... Test loss: 0.00257\n",
      "Epoch: 1... Training loss: 0.00248... Test loss: 0.00264\n",
      "Epoch: 1... Training loss: 0.00241... Test loss: 0.00288\n",
      "Epoch: 1... Training loss: 0.00233... Test loss: 0.00273\n",
      "Epoch: 1... Training loss: 0.00231... Test loss: 0.00252\n",
      "Epoch: 1... Training loss: 0.00232... Test loss: 0.00247\n",
      "Epoch: 1... Training loss: 0.00218... Test loss: 0.00279\n",
      "Epoch: 1... Training loss: 0.00219... Test loss: 0.00208\n",
      "Epoch: 1... Training loss: 0.00208... Test loss: 0.00248\n",
      "Epoch: 1... Training loss: 0.00197... Test loss: 0.00175\n",
      "Epoch: 1... Training loss: 0.00206... Test loss: 0.00263\n",
      "Epoch: 1... Training loss: 0.00192... Test loss: 0.00169\n",
      "Epoch: 1... Training loss: 0.00189... Test loss: 0.00218\n",
      "Epoch: 1... Training loss: 0.00185... Test loss: 0.00186\n",
      "Epoch: 1... Training loss: 0.00187... Test loss: 0.00215\n",
      "Epoch: 1... Training loss: 0.00178... Test loss: 0.00175\n",
      "Epoch: 1... Training loss: 0.00172... Test loss: 0.00172\n",
      "Epoch: 1... Training loss: 0.0018... Test loss: 0.00175\n",
      "Epoch: 1... Training loss: 0.00168... Test loss: 0.00174\n",
      "Epoch: 1... Training loss: 0.00157... Test loss: 0.00197\n",
      "Epoch: 1... Training loss: 0.00159... Test loss: 0.00165\n",
      "Epoch: 1... Training loss: 0.00159... Test loss: 0.00173\n",
      "Epoch: 1... Training loss: 0.00145... Test loss: 0.00185\n",
      "Epoch: 1... Training loss: 0.0015... Test loss: 0.00161\n",
      "Epoch: 1... Training loss: 0.00144... Test loss: 0.00175\n",
      "Epoch: 1... Training loss: 0.00136... Test loss: 0.00133\n",
      "Epoch: 1... Training loss: 0.00128... Test loss: 0.00146\n",
      "Epoch: 1... Training loss: 0.00128... Test loss: 0.00128\n",
      "Epoch: 1... Training loss: 0.00122... Test loss: 0.00155\n",
      "Epoch: 1... Training loss: 0.00116... Test loss: 0.00142\n",
      "Epoch: 1... Training loss: 0.00116... Test loss: 0.00117\n",
      "Epoch: 1... Training loss: 0.00114... Test loss: 0.00133\n",
      "Epoch: 1... Training loss: 0.00109... Test loss: 0.00115\n",
      "Epoch: 1... Training loss: 0.00101... Test loss: 0.00123\n",
      "Epoch: 1... Training loss: 0.00102... Test loss: 0.00107\n",
      "Epoch: 1... Training loss: 0.00098... Test loss: 0.00116\n",
      "Epoch: 1... Training loss: 0.00105... Test loss: 0.00094\n",
      "Epoch: 1... Training loss: 0.00096... Test loss: 0.00108\n",
      "Epoch: 1... Training loss: 0.00087... Test loss: 0.0009\n",
      "Epoch: 1... Training loss: 0.00085... Test loss: 0.00098\n",
      "Epoch: 1... Training loss: 0.00082... Test loss: 0.00079\n",
      "Epoch: 1... Training loss: 0.00072... Test loss: 0.00082\n",
      "Epoch: 1... Training loss: 0.00068... Test loss: 0.00077\n",
      "Epoch: 1... Training loss: 0.00066... Test loss: 0.00075\n",
      "Epoch: 1... Training loss: 0.00071... Test loss: 0.00071\n",
      "Epoch: 1... Training loss: 0.00063... Test loss: 0.00065\n",
      "Epoch: 1... Training loss: 0.00062... Test loss: 0.0006\n",
      "Epoch: 1... Training loss: 0.00058... Test loss: 0.00068\n",
      "Epoch: 1... Training loss: 0.00049... Test loss: 0.00079\n",
      "Epoch: 1... Training loss: 0.00054... Test loss: 0.00056\n",
      "Epoch: 1... Training loss: 0.00048... Test loss: 0.00055\n",
      "Epoch: 1... Training loss: 0.00045... Test loss: 0.00053\n",
      "Epoch: 1... Training loss: 0.0004... Test loss: 0.00049\n",
      "Epoch: 1... Training loss: 0.00039... Test loss: 0.00054\n",
      "Epoch: 1... Training loss: 0.00038... Test loss: 0.00045\n",
      "Epoch: 1... Training loss: 0.00036... Test loss: 0.00046\n",
      "Epoch: 1... Training loss: 0.00036... Test loss: 0.00041\n",
      "Epoch: 1... Training loss: 0.00036... Test loss: 0.00047\n",
      "Epoch: 1... Training loss: 0.00034... Test loss: 0.00032\n",
      "Epoch: 1... Training loss: 0.00034... Test loss: 0.00038\n",
      "Epoch: 1... Training loss: 0.00039... Test loss: 0.0003\n",
      "Epoch: 1... Training loss: 0.00033... Test loss: 0.0005\n",
      "Epoch: 1... Training loss: 0.00032... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00029... Test loss: 0.00046\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00044\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00024\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00014\n",
      "246.54167244798737\n",
      "Epoch: 1... Training loss: 0.93044... Test loss: 0.29468\n",
      "Epoch: 1... Training loss: 0.48474... Test loss: 0.1435\n",
      "Epoch: 1... Training loss: 0.28461... Test loss: 0.07984\n",
      "Epoch: 1... Training loss: 0.19845... Test loss: 0.0585\n",
      "Epoch: 1... Training loss: 0.15852... Test loss: 0.04853\n",
      "Epoch: 1... Training loss: 0.12235... Test loss: 0.0538\n",
      "Epoch: 1... Training loss: 0.1022... Test loss: 0.03068\n",
      "Epoch: 1... Training loss: 0.09254... Test loss: 0.04173\n",
      "Epoch: 1... Training loss: 0.07698... Test loss: 0.03038\n",
      "Epoch: 1... Training loss: 0.07045... Test loss: 0.04117\n",
      "Epoch: 1... Training loss: 0.06425... Test loss: 0.02322\n",
      "Epoch: 1... Training loss: 0.05814... Test loss: 0.04331\n",
      "Epoch: 1... Training loss: 0.05209... Test loss: 0.02284\n",
      "Epoch: 1... Training loss: 0.04758... Test loss: 0.03714\n",
      "Epoch: 1... Training loss: 0.04624... Test loss: 0.02184\n",
      "Epoch: 1... Training loss: 0.04097... Test loss: 0.04293\n",
      "Epoch: 1... Training loss: 0.03809... Test loss: 0.01853\n",
      "Epoch: 1... Training loss: 0.03478... Test loss: 0.03125\n",
      "Epoch: 1... Training loss: 0.03214... Test loss: 0.02186\n",
      "Epoch: 1... Training loss: 0.02928... Test loss: 0.03051\n",
      "Epoch: 1... Training loss: 0.02777... Test loss: 0.02017\n",
      "Epoch: 1... Training loss: 0.02616... Test loss: 0.02507\n",
      "Epoch: 1... Training loss: 0.02445... Test loss: 0.01528\n",
      "Epoch: 1... Training loss: 0.02399... Test loss: 0.02533\n",
      "Epoch: 1... Training loss: 0.02176... Test loss: 0.01393\n",
      "Epoch: 1... Training loss: 0.02096... Test loss: 0.02033\n",
      "Epoch: 1... Training loss: 0.02039... Test loss: 0.01746\n",
      "Epoch: 1... Training loss: 0.01903... Test loss: 0.02332\n",
      "Epoch: 1... Training loss: 0.01789... Test loss: 0.01124\n",
      "Epoch: 1... Training loss: 0.01713... Test loss: 0.02045\n",
      "Epoch: 1... Training loss: 0.01613... Test loss: 0.00965\n",
      "Epoch: 1... Training loss: 0.0152... Test loss: 0.01911\n",
      "Epoch: 1... Training loss: 0.01509... Test loss: 0.0089\n",
      "Epoch: 1... Training loss: 0.01433... Test loss: 0.01705\n",
      "Epoch: 1... Training loss: 0.01406... Test loss: 0.0121\n",
      "Epoch: 1... Training loss: 0.01334... Test loss: 0.01149\n",
      "Epoch: 1... Training loss: 0.01305... Test loss: 0.01397\n",
      "Epoch: 1... Training loss: 0.01214... Test loss: 0.00677\n",
      "Epoch: 1... Training loss: 0.01177... Test loss: 0.01363\n",
      "Epoch: 1... Training loss: 0.01127... Test loss: 0.00743\n",
      "Epoch: 1... Training loss: 0.01104... Test loss: 0.01106\n",
      "Epoch: 1... Training loss: 0.01067... Test loss: 0.00844\n",
      "Epoch: 1... Training loss: 0.0106... Test loss: 0.01207\n",
      "Epoch: 1... Training loss: 0.01005... Test loss: 0.00948\n",
      "Epoch: 1... Training loss: 0.0098... Test loss: 0.00968\n",
      "Epoch: 1... Training loss: 0.00936... Test loss: 0.01075\n",
      "Epoch: 1... Training loss: 0.00912... Test loss: 0.00663\n",
      "Epoch: 1... Training loss: 0.0089... Test loss: 0.01171\n",
      "Epoch: 1... Training loss: 0.00865... Test loss: 0.00631\n",
      "Epoch: 1... Training loss: 0.00834... Test loss: 0.00974\n",
      "Epoch: 1... Training loss: 0.00811... Test loss: 0.00578\n",
      "Epoch: 1... Training loss: 0.00774... Test loss: 0.00843\n",
      "Epoch: 1... Training loss: 0.00744... Test loss: 0.00677\n",
      "Epoch: 1... Training loss: 0.00731... Test loss: 0.00772\n",
      "Epoch: 1... Training loss: 0.00721... Test loss: 0.00529\n",
      "Epoch: 1... Training loss: 0.00697... Test loss: 0.00624\n",
      "Epoch: 1... Training loss: 0.00676... Test loss: 0.00591\n",
      "Epoch: 1... Training loss: 0.00667... Test loss: 0.00463\n",
      "Epoch: 1... Training loss: 0.00647... Test loss: 0.00598\n",
      "Epoch: 1... Training loss: 0.00633... Test loss: 0.00466\n",
      "Epoch: 1... Training loss: 0.00619... Test loss: 0.00567\n",
      "Epoch: 1... Training loss: 0.00608... Test loss: 0.00516\n",
      "Epoch: 1... Training loss: 0.00596... Test loss: 0.00598\n",
      "Epoch: 1... Training loss: 0.00578... Test loss: 0.00482\n",
      "Epoch: 1... Training loss: 0.01367... Test loss: 0.01379\n",
      "Epoch: 1... Training loss: 0.00943... Test loss: 0.00723\n",
      "Epoch: 1... Training loss: 0.01254... Test loss: 0.01388\n",
      "Epoch: 1... Training loss: 0.01196... Test loss: 0.01347\n",
      "Epoch: 1... Training loss: 0.00892... Test loss: 0.01593\n",
      "Epoch: 1... Training loss: 0.0111... Test loss: 0.0118\n",
      "Epoch: 1... Training loss: 0.01044... Test loss: 0.00979\n",
      "Epoch: 1... Training loss: 0.00858... Test loss: 0.01007\n",
      "Epoch: 1... Training loss: 0.01133... Test loss: 0.01136\n",
      "Epoch: 1... Training loss: 0.00957... Test loss: 0.01055\n",
      "Epoch: 1... Training loss: 0.00835... Test loss: 0.01267\n",
      "Epoch: 1... Training loss: 0.00806... Test loss: 0.00955\n",
      "Epoch: 1... Training loss: 0.00757... Test loss: 0.00964\n",
      "Epoch: 1... Training loss: 0.00745... Test loss: 0.00826\n",
      "Epoch: 1... Training loss: 0.00747... Test loss: 0.00889\n",
      "Epoch: 1... Training loss: 0.0071... Test loss: 0.00893\n",
      "Epoch: 1... Training loss: 0.00763... Test loss: 0.00856\n",
      "Epoch: 1... Training loss: 0.00674... Test loss: 0.00713\n",
      "Epoch: 1... Training loss: 0.00672... Test loss: 0.00659\n",
      "Epoch: 1... Training loss: 0.00694... Test loss: 0.00736\n",
      "Epoch: 1... Training loss: 0.00656... Test loss: 0.00627\n",
      "Epoch: 1... Training loss: 0.00608... Test loss: 0.00725\n",
      "Epoch: 1... Training loss: 0.00596... Test loss: 0.0069\n",
      "Epoch: 1... Training loss: 0.00564... Test loss: 0.0061\n",
      "Epoch: 1... Training loss: 0.00566... Test loss: 0.00592\n",
      "Epoch: 1... Training loss: 0.0053... Test loss: 0.00695\n",
      "Epoch: 1... Training loss: 0.00523... Test loss: 0.00581\n",
      "Epoch: 1... Training loss: 0.00492... Test loss: 0.006\n",
      "Epoch: 1... Training loss: 0.00466... Test loss: 0.00546\n",
      "Epoch: 1... Training loss: 0.00472... Test loss: 0.00488\n",
      "Epoch: 1... Training loss: 0.0045... Test loss: 0.00478\n",
      "Epoch: 1... Training loss: 0.00443... Test loss: 0.00467\n",
      "Epoch: 1... Training loss: 0.00441... Test loss: 0.00439\n",
      "Epoch: 1... Training loss: 0.00404... Test loss: 0.00476\n",
      "Epoch: 1... Training loss: 0.00403... Test loss: 0.00447\n",
      "Epoch: 1... Training loss: 0.00379... Test loss: 0.00521\n",
      "Epoch: 1... Training loss: 0.00382... Test loss: 0.00425\n",
      "Epoch: 1... Training loss: 0.00371... Test loss: 0.00523\n",
      "Epoch: 1... Training loss: 0.00366... Test loss: 0.00391\n",
      "Epoch: 1... Training loss: 0.00354... Test loss: 0.00455\n",
      "Epoch: 1... Training loss: 0.00347... Test loss: 0.0037\n",
      "Epoch: 1... Training loss: 0.00354... Test loss: 0.0039\n",
      "Epoch: 1... Training loss: 0.00327... Test loss: 0.00366\n",
      "Epoch: 1... Training loss: 0.0033... Test loss: 0.00416\n",
      "Epoch: 1... Training loss: 0.00318... Test loss: 0.0038\n",
      "Epoch: 1... Training loss: 0.0031... Test loss: 0.00378\n",
      "Epoch: 1... Training loss: 0.00301... Test loss: 0.00363\n",
      "Epoch: 1... Training loss: 0.00294... Test loss: 0.0032\n",
      "Epoch: 1... Training loss: 0.00281... Test loss: 0.00335\n",
      "Epoch: 1... Training loss: 0.00289... Test loss: 0.00278\n",
      "Epoch: 1... Training loss: 0.00283... Test loss: 0.00278\n",
      "Epoch: 1... Training loss: 0.00281... Test loss: 0.00274\n",
      "Epoch: 1... Training loss: 0.00277... Test loss: 0.0028\n",
      "Epoch: 1... Training loss: 0.00265... Test loss: 0.00258\n",
      "Epoch: 1... Training loss: 0.0026... Test loss: 0.00285\n",
      "Epoch: 1... Training loss: 0.0026... Test loss: 0.0023\n",
      "Epoch: 1... Training loss: 0.00255... Test loss: 0.00259\n",
      "Epoch: 1... Training loss: 0.00252... Test loss: 0.00249\n",
      "Epoch: 1... Training loss: 0.00241... Test loss: 0.00248\n",
      "Epoch: 1... Training loss: 0.00244... Test loss: 0.00237\n",
      "Epoch: 1... Training loss: 0.00237... Test loss: 0.0025\n",
      "Epoch: 1... Training loss: 0.0022... Test loss: 0.00257\n",
      "Epoch: 1... Training loss: 0.00217... Test loss: 0.00249\n",
      "Epoch: 1... Training loss: 0.00218... Test loss: 0.00216\n",
      "Epoch: 1... Training loss: 0.00202... Test loss: 0.00246\n",
      "Epoch: 1... Training loss: 0.00208... Test loss: 0.00223\n",
      "Epoch: 1... Training loss: 0.00214... Test loss: 0.00237\n",
      "Epoch: 1... Training loss: 0.00197... Test loss: 0.00202\n",
      "Epoch: 1... Training loss: 0.00189... Test loss: 0.00246\n",
      "Epoch: 1... Training loss: 0.00175... Test loss: 0.00188\n",
      "Epoch: 1... Training loss: 0.00175... Test loss: 0.00208\n",
      "Epoch: 1... Training loss: 0.0016... Test loss: 0.0019\n",
      "Epoch: 1... Training loss: 0.00153... Test loss: 0.00183\n",
      "Epoch: 1... Training loss: 0.00162... Test loss: 0.00151\n",
      "Epoch: 1... Training loss: 0.00152... Test loss: 0.00186\n",
      "Epoch: 1... Training loss: 0.00149... Test loss: 0.00152\n",
      "Epoch: 1... Training loss: 0.00156... Test loss: 0.00163\n",
      "Epoch: 1... Training loss: 0.00139... Test loss: 0.0015\n",
      "Epoch: 1... Training loss: 0.00137... Test loss: 0.00142\n",
      "Epoch: 1... Training loss: 0.00129... Test loss: 0.00134\n",
      "Epoch: 1... Training loss: 0.00125... Test loss: 0.00155\n",
      "Epoch: 1... Training loss: 0.0013... Test loss: 0.00137\n",
      "Epoch: 1... Training loss: 0.00117... Test loss: 0.00123\n",
      "Epoch: 1... Training loss: 0.00118... Test loss: 0.00139\n",
      "Epoch: 1... Training loss: 0.00109... Test loss: 0.00129\n",
      "Epoch: 1... Training loss: 0.00108... Test loss: 0.00122\n",
      "Epoch: 1... Training loss: 0.00099... Test loss: 0.0013\n",
      "Epoch: 1... Training loss: 0.00098... Test loss: 0.00117\n",
      "Epoch: 1... Training loss: 0.00095... Test loss: 0.0013\n",
      "Epoch: 1... Training loss: 0.00099... Test loss: 0.00122\n",
      "Epoch: 1... Training loss: 0.00092... Test loss: 0.0011\n",
      "Epoch: 1... Training loss: 0.00089... Test loss: 0.00113\n",
      "Epoch: 1... Training loss: 0.00088... Test loss: 0.00101\n",
      "Epoch: 1... Training loss: 0.00087... Test loss: 0.0011\n",
      "Epoch: 1... Training loss: 0.00079... Test loss: 0.00096\n",
      "Epoch: 1... Training loss: 0.00083... Test loss: 0.00081\n",
      "Epoch: 1... Training loss: 0.00076... Test loss: 0.00078\n",
      "Epoch: 1... Training loss: 0.00077... Test loss: 0.00062\n",
      "Epoch: 1... Training loss: 0.00073... Test loss: 0.00085\n",
      "Epoch: 1... Training loss: 0.00069... Test loss: 0.00066\n",
      "Epoch: 1... Training loss: 0.00067... Test loss: 0.0006\n",
      "Epoch: 1... Training loss: 0.00067... Test loss: 0.00065\n",
      "Epoch: 1... Training loss: 0.00068... Test loss: 0.00074\n",
      "Epoch: 1... Training loss: 0.00062... Test loss: 0.00067\n",
      "Epoch: 1... Training loss: 0.00057... Test loss: 0.00063\n",
      "Epoch: 1... Training loss: 0.00054... Test loss: 0.00052\n",
      "Epoch: 1... Training loss: 0.00059... Test loss: 0.00059\n",
      "Epoch: 1... Training loss: 0.00046... Test loss: 0.00052\n",
      "Epoch: 1... Training loss: 0.00044... Test loss: 0.00051\n",
      "Epoch: 1... Training loss: 0.00047... Test loss: 0.00049\n",
      "Epoch: 1... Training loss: 0.00042... Test loss: 0.00054\n",
      "Epoch: 1... Training loss: 0.00042... Test loss: 0.00045\n",
      "Epoch: 1... Training loss: 0.00039... Test loss: 0.00052\n",
      "Epoch: 1... Training loss: 0.00031... Test loss: 0.0005\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00039\n",
      "Epoch: 1... Training loss: 0.00031... Test loss: 0.00037\n",
      "Epoch: 1... Training loss: 0.00031... Test loss: 0.00034\n",
      "Epoch: 1... Training loss: 0.00029... Test loss: 0.00041\n",
      "Epoch: 1... Training loss: 0.00031... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00036\n",
      "Epoch: 1... Training loss: 0.00029... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.00026... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00016\n",
      "267.8527257575479\n",
      "Epoch: 1... Training loss: 1.05354... Test loss: 0.42633\n",
      "Epoch: 1... Training loss: 0.54184... Test loss: 0.1857\n",
      "Epoch: 1... Training loss: 0.31623... Test loss: 0.12497\n",
      "Epoch: 1... Training loss: 0.20415... Test loss: 0.0953\n",
      "Epoch: 1... Training loss: 0.18033... Test loss: 0.05675\n",
      "Epoch: 1... Training loss: 0.13016... Test loss: 0.0683\n",
      "Epoch: 1... Training loss: 0.10129... Test loss: 0.05285\n",
      "Epoch: 1... Training loss: 0.08341... Test loss: 0.04604\n",
      "Epoch: 1... Training loss: 0.07337... Test loss: 0.02695\n",
      "Epoch: 1... Training loss: 0.06696... Test loss: 0.04599\n",
      "Epoch: 1... Training loss: 0.05967... Test loss: 0.02427\n",
      "Epoch: 1... Training loss: 0.05133... Test loss: 0.03602\n",
      "Epoch: 1... Training loss: 0.0443... Test loss: 0.02186\n",
      "Epoch: 1... Training loss: 0.04149... Test loss: 0.02069\n",
      "Epoch: 1... Training loss: 0.03719... Test loss: 0.04332\n",
      "Epoch: 1... Training loss: 0.03531... Test loss: 0.01735\n",
      "Epoch: 1... Training loss: 0.03262... Test loss: 0.03318\n",
      "Epoch: 1... Training loss: 0.02981... Test loss: 0.02473\n",
      "Epoch: 1... Training loss: 0.02771... Test loss: 0.01912\n",
      "Epoch: 1... Training loss: 0.02648... Test loss: 0.0288\n",
      "Epoch: 1... Training loss: 0.02459... Test loss: 0.01627\n",
      "Epoch: 1... Training loss: 0.02237... Test loss: 0.02771\n",
      "Epoch: 1... Training loss: 0.02195... Test loss: 0.01203\n",
      "Epoch: 1... Training loss: 0.02094... Test loss: 0.02015\n",
      "Epoch: 1... Training loss: 0.02... Test loss: 0.013\n",
      "Epoch: 1... Training loss: 0.01891... Test loss: 0.01728\n",
      "Epoch: 1... Training loss: 0.01857... Test loss: 0.01118\n",
      "Epoch: 1... Training loss: 0.01692... Test loss: 0.01335\n",
      "Epoch: 1... Training loss: 0.01666... Test loss: 0.00925\n",
      "Epoch: 1... Training loss: 0.01607... Test loss: 0.01304\n",
      "Epoch: 1... Training loss: 0.01574... Test loss: 0.00784\n",
      "Epoch: 1... Training loss: 0.01526... Test loss: 0.00943\n",
      "Epoch: 1... Training loss: 0.0145... Test loss: 0.00813\n",
      "Epoch: 1... Training loss: 0.01412... Test loss: 0.01084\n",
      "Epoch: 1... Training loss: 0.01381... Test loss: 0.00912\n",
      "Epoch: 1... Training loss: 0.01301... Test loss: 0.01432\n",
      "Epoch: 1... Training loss: 0.01277... Test loss: 0.0068\n",
      "Epoch: 1... Training loss: 0.01183... Test loss: 0.01161\n",
      "Epoch: 1... Training loss: 0.01163... Test loss: 0.00607\n",
      "Epoch: 1... Training loss: 0.0111... Test loss: 0.0106\n",
      "Epoch: 1... Training loss: 0.01091... Test loss: 0.00614\n",
      "Epoch: 1... Training loss: 0.01025... Test loss: 0.0105\n",
      "Epoch: 1... Training loss: 0.01008... Test loss: 0.00627\n",
      "Epoch: 1... Training loss: 0.00982... Test loss: 0.01004\n",
      "Epoch: 1... Training loss: 0.00963... Test loss: 0.00683\n",
      "Epoch: 1... Training loss: 0.00932... Test loss: 0.00898\n",
      "Epoch: 1... Training loss: 0.00913... Test loss: 0.00793\n",
      "Epoch: 1... Training loss: 0.00891... Test loss: 0.0075\n",
      "Epoch: 1... Training loss: 0.00871... Test loss: 0.00884\n",
      "Epoch: 1... Training loss: 0.00844... Test loss: 0.00666\n",
      "Epoch: 1... Training loss: 0.00829... Test loss: 0.00758\n",
      "Epoch: 1... Training loss: 0.008... Test loss: 0.00559\n",
      "Epoch: 1... Training loss: 0.00781... Test loss: 0.00712\n",
      "Epoch: 1... Training loss: 0.00764... Test loss: 0.00588\n",
      "Epoch: 1... Training loss: 0.00746... Test loss: 0.00726\n",
      "Epoch: 1... Training loss: 0.00717... Test loss: 0.00544\n",
      "Epoch: 1... Training loss: 0.00709... Test loss: 0.00678\n",
      "Epoch: 1... Training loss: 0.00682... Test loss: 0.00498\n",
      "Epoch: 1... Training loss: 0.00661... Test loss: 0.00656\n",
      "Epoch: 1... Training loss: 0.00631... Test loss: 0.00497\n",
      "Epoch: 1... Training loss: 0.00619... Test loss: 0.00573\n",
      "Epoch: 1... Training loss: 0.00606... Test loss: 0.0057\n",
      "Epoch: 1... Training loss: 0.00594... Test loss: 0.00537\n",
      "Epoch: 1... Training loss: 0.00572... Test loss: 0.00587\n",
      "Epoch: 1... Training loss: 0.01327... Test loss: 0.01246\n",
      "Epoch: 1... Training loss: 0.01176... Test loss: 0.00952\n",
      "Epoch: 1... Training loss: 0.01338... Test loss: 0.01781\n",
      "Epoch: 1... Training loss: 0.01062... Test loss: 0.01087\n",
      "Epoch: 1... Training loss: 0.01047... Test loss: 0.01706\n",
      "Epoch: 1... Training loss: 0.0098... Test loss: 0.01095\n",
      "Epoch: 1... Training loss: 0.00981... Test loss: 0.0142\n",
      "Epoch: 1... Training loss: 0.00926... Test loss: 0.01098\n",
      "Epoch: 1... Training loss: 0.00905... Test loss: 0.01173\n",
      "Epoch: 1... Training loss: 0.00878... Test loss: 0.01002\n",
      "Epoch: 1... Training loss: 0.0088... Test loss: 0.01003\n",
      "Epoch: 1... Training loss: 0.00778... Test loss: 0.01044\n",
      "Epoch: 1... Training loss: 0.00805... Test loss: 0.00962\n",
      "Epoch: 1... Training loss: 0.00772... Test loss: 0.01024\n",
      "Epoch: 1... Training loss: 0.00716... Test loss: 0.0098\n",
      "Epoch: 1... Training loss: 0.00672... Test loss: 0.0106\n",
      "Epoch: 1... Training loss: 0.00717... Test loss: 0.00849\n",
      "Epoch: 1... Training loss: 0.00675... Test loss: 0.01013\n",
      "Epoch: 1... Training loss: 0.00625... Test loss: 0.00727\n",
      "Epoch: 1... Training loss: 0.00612... Test loss: 0.00979\n",
      "Epoch: 1... Training loss: 0.00595... Test loss: 0.00725\n",
      "Epoch: 1... Training loss: 0.00599... Test loss: 0.00655\n",
      "Epoch: 1... Training loss: 0.00573... Test loss: 0.00598\n",
      "Epoch: 1... Training loss: 0.00557... Test loss: 0.00674\n",
      "Epoch: 1... Training loss: 0.00548... Test loss: 0.00633\n",
      "Epoch: 1... Training loss: 0.005... Test loss: 0.00622\n",
      "Epoch: 1... Training loss: 0.00504... Test loss: 0.00564\n",
      "Epoch: 1... Training loss: 0.00507... Test loss: 0.00681\n",
      "Epoch: 1... Training loss: 0.00474... Test loss: 0.00545\n",
      "Epoch: 1... Training loss: 0.0046... Test loss: 0.00646\n",
      "Epoch: 1... Training loss: 0.00458... Test loss: 0.00531\n",
      "Epoch: 1... Training loss: 0.00439... Test loss: 0.00503\n",
      "Epoch: 1... Training loss: 0.00412... Test loss: 0.00499\n",
      "Epoch: 1... Training loss: 0.00406... Test loss: 0.0052\n",
      "Epoch: 1... Training loss: 0.00399... Test loss: 0.00489\n",
      "Epoch: 1... Training loss: 0.00381... Test loss: 0.00488\n",
      "Epoch: 1... Training loss: 0.00369... Test loss: 0.00379\n",
      "Epoch: 1... Training loss: 0.00362... Test loss: 0.00385\n",
      "Epoch: 1... Training loss: 0.00358... Test loss: 0.00347\n",
      "Epoch: 1... Training loss: 0.00369... Test loss: 0.00394\n",
      "Epoch: 1... Training loss: 0.00341... Test loss: 0.00377\n",
      "Epoch: 1... Training loss: 0.0033... Test loss: 0.00373\n",
      "Epoch: 1... Training loss: 0.00319... Test loss: 0.00348\n",
      "Epoch: 1... Training loss: 0.00323... Test loss: 0.00352\n",
      "Epoch: 1... Training loss: 0.00316... Test loss: 0.00342\n",
      "Epoch: 1... Training loss: 0.00301... Test loss: 0.00327\n",
      "Epoch: 1... Training loss: 0.00308... Test loss: 0.00276\n",
      "Epoch: 1... Training loss: 0.00298... Test loss: 0.00301\n",
      "Epoch: 1... Training loss: 0.00304... Test loss: 0.00251\n",
      "Epoch: 1... Training loss: 0.00301... Test loss: 0.00351\n",
      "Epoch: 1... Training loss: 0.00268... Test loss: 0.00284\n",
      "Epoch: 1... Training loss: 0.00273... Test loss: 0.00338\n",
      "Epoch: 1... Training loss: 0.00276... Test loss: 0.00271\n",
      "Epoch: 1... Training loss: 0.00265... Test loss: 0.00284\n",
      "Epoch: 1... Training loss: 0.00272... Test loss: 0.00268\n",
      "Epoch: 1... Training loss: 0.00248... Test loss: 0.00231\n",
      "Epoch: 1... Training loss: 0.00269... Test loss: 0.0024\n",
      "Epoch: 1... Training loss: 0.00237... Test loss: 0.00248\n",
      "Epoch: 1... Training loss: 0.00246... Test loss: 0.00237\n",
      "Epoch: 1... Training loss: 0.00225... Test loss: 0.00273\n",
      "Epoch: 1... Training loss: 0.0023... Test loss: 0.00243\n",
      "Epoch: 1... Training loss: 0.00216... Test loss: 0.00233\n",
      "Epoch: 1... Training loss: 0.00213... Test loss: 0.00189\n",
      "Epoch: 1... Training loss: 0.00214... Test loss: 0.00195\n",
      "Epoch: 1... Training loss: 0.00204... Test loss: 0.00192\n",
      "Epoch: 1... Training loss: 0.00202... Test loss: 0.00229\n",
      "Epoch: 1... Training loss: 0.00205... Test loss: 0.00203\n",
      "Epoch: 1... Training loss: 0.0019... Test loss: 0.002\n",
      "Epoch: 1... Training loss: 0.00194... Test loss: 0.00205\n",
      "Epoch: 1... Training loss: 0.00185... Test loss: 0.00169\n",
      "Epoch: 1... Training loss: 0.00189... Test loss: 0.0018\n",
      "Epoch: 1... Training loss: 0.00183... Test loss: 0.00168\n",
      "Epoch: 1... Training loss: 0.00171... Test loss: 0.00193\n",
      "Epoch: 1... Training loss: 0.00177... Test loss: 0.00145\n",
      "Epoch: 1... Training loss: 0.0017... Test loss: 0.00177\n",
      "Epoch: 1... Training loss: 0.00168... Test loss: 0.00177\n",
      "Epoch: 1... Training loss: 0.00165... Test loss: 0.00174\n",
      "Epoch: 1... Training loss: 0.00161... Test loss: 0.00143\n",
      "Epoch: 1... Training loss: 0.00152... Test loss: 0.0016\n",
      "Epoch: 1... Training loss: 0.00157... Test loss: 0.00152\n",
      "Epoch: 1... Training loss: 0.00146... Test loss: 0.00157\n",
      "Epoch: 1... Training loss: 0.00142... Test loss: 0.00147\n",
      "Epoch: 1... Training loss: 0.00133... Test loss: 0.00161\n",
      "Epoch: 1... Training loss: 0.0013... Test loss: 0.0015\n",
      "Epoch: 1... Training loss: 0.00122... Test loss: 0.00148\n",
      "Epoch: 1... Training loss: 0.0013... Test loss: 0.00143\n",
      "Epoch: 1... Training loss: 0.00112... Test loss: 0.00146\n",
      "Epoch: 1... Training loss: 0.00115... Test loss: 0.00116\n",
      "Epoch: 1... Training loss: 0.00116... Test loss: 0.00128\n",
      "Epoch: 1... Training loss: 0.00115... Test loss: 0.00106\n",
      "Epoch: 1... Training loss: 0.00107... Test loss: 0.00099\n",
      "Epoch: 1... Training loss: 0.00102... Test loss: 0.0012\n",
      "Epoch: 1... Training loss: 0.00095... Test loss: 0.00109\n",
      "Epoch: 1... Training loss: 0.00096... Test loss: 0.00103\n",
      "Epoch: 1... Training loss: 0.00095... Test loss: 0.001\n",
      "Epoch: 1... Training loss: 0.00094... Test loss: 0.0009\n",
      "Epoch: 1... Training loss: 0.00093... Test loss: 0.00081\n",
      "Epoch: 1... Training loss: 0.00086... Test loss: 0.00084\n",
      "Epoch: 1... Training loss: 0.0009... Test loss: 0.00079\n",
      "Epoch: 1... Training loss: 0.00085... Test loss: 0.00094\n",
      "Epoch: 1... Training loss: 0.00079... Test loss: 0.00076\n",
      "Epoch: 1... Training loss: 0.00079... Test loss: 0.0007\n",
      "Epoch: 1... Training loss: 0.00078... Test loss: 0.00076\n",
      "Epoch: 1... Training loss: 0.00074... Test loss: 0.00068\n",
      "Epoch: 1... Training loss: 0.00077... Test loss: 0.00068\n",
      "Epoch: 1... Training loss: 0.00063... Test loss: 0.00064\n",
      "Epoch: 1... Training loss: 0.00069... Test loss: 0.00061\n",
      "Epoch: 1... Training loss: 0.00062... Test loss: 0.00071\n",
      "Epoch: 1... Training loss: 0.00063... Test loss: 0.00062\n",
      "Epoch: 1... Training loss: 0.00063... Test loss: 0.00067\n",
      "Epoch: 1... Training loss: 0.00058... Test loss: 0.00069\n",
      "Epoch: 1... Training loss: 0.00057... Test loss: 0.00057\n",
      "Epoch: 1... Training loss: 0.00056... Test loss: 0.00066\n",
      "Epoch: 1... Training loss: 0.00056... Test loss: 0.00056\n",
      "Epoch: 1... Training loss: 0.00051... Test loss: 0.00054\n",
      "Epoch: 1... Training loss: 0.00052... Test loss: 0.0005\n",
      "Epoch: 1... Training loss: 0.00051... Test loss: 0.00052\n",
      "Epoch: 1... Training loss: 0.00049... Test loss: 0.00044\n",
      "Epoch: 1... Training loss: 0.0005... Test loss: 0.00038\n",
      "Epoch: 1... Training loss: 0.00042... Test loss: 0.00048\n",
      "Epoch: 1... Training loss: 0.00044... Test loss: 0.00043\n",
      "Epoch: 1... Training loss: 0.00041... Test loss: 0.00047\n",
      "Epoch: 1... Training loss: 0.00035... Test loss: 0.00036\n",
      "Epoch: 1... Training loss: 0.0004... Test loss: 0.0004\n",
      "Epoch: 1... Training loss: 0.00036... Test loss: 0.00039\n",
      "Epoch: 1... Training loss: 0.00039... Test loss: 0.00039\n",
      "Epoch: 1... Training loss: 0.00038... Test loss: 0.00033\n",
      "Epoch: 1... Training loss: 0.00033... Test loss: 0.00036\n",
      "Epoch: 1... Training loss: 0.00032... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.00031... Test loss: 0.00034\n",
      "Epoch: 1... Training loss: 0.00026... Test loss: 0.00031\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.0003\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00023\n",
      "272.5493637531763\n",
      "Epoch: 1... Training loss: 0.91492... Test loss: 0.23753\n",
      "Epoch: 1... Training loss: 0.43097... Test loss: 0.11129\n",
      "Epoch: 1... Training loss: 0.23323... Test loss: 0.07243\n",
      "Epoch: 1... Training loss: 0.1581... Test loss: 0.04407\n",
      "Epoch: 1... Training loss: 0.10837... Test loss: 0.02826\n",
      "Epoch: 1... Training loss: 0.09405... Test loss: 0.02402\n",
      "Epoch: 1... Training loss: 0.07688... Test loss: 0.01705\n",
      "Epoch: 1... Training loss: 0.07042... Test loss: 0.01549\n",
      "Epoch: 1... Training loss: 0.06126... Test loss: 0.01366\n",
      "Epoch: 1... Training loss: 0.05618... Test loss: 0.01248\n",
      "Epoch: 1... Training loss: 0.04918... Test loss: 0.00995\n",
      "Epoch: 1... Training loss: 0.04449... Test loss: 0.00781\n",
      "Epoch: 1... Training loss: 0.03983... Test loss: 0.00946\n",
      "Epoch: 1... Training loss: 0.037... Test loss: 0.00664\n",
      "Epoch: 1... Training loss: 0.03481... Test loss: 0.00931\n",
      "Epoch: 1... Training loss: 0.03293... Test loss: 0.00485\n",
      "Epoch: 1... Training loss: 0.03058... Test loss: 0.00963\n",
      "Epoch: 1... Training loss: 0.02808... Test loss: 0.00363\n",
      "Epoch: 1... Training loss: 0.02739... Test loss: 0.00872\n",
      "Epoch: 1... Training loss: 0.02547... Test loss: 0.00589\n",
      "Epoch: 1... Training loss: 0.02507... Test loss: 0.00597\n",
      "Epoch: 1... Training loss: 0.02306... Test loss: 0.0118\n",
      "Epoch: 1... Training loss: 0.02297... Test loss: 0.005\n",
      "Epoch: 1... Training loss: 0.02071... Test loss: 0.01079\n",
      "Epoch: 1... Training loss: 0.02026... Test loss: 0.00496\n",
      "Epoch: 1... Training loss: 0.01913... Test loss: 0.00904\n",
      "Epoch: 1... Training loss: 0.0181... Test loss: 0.00546\n",
      "Epoch: 1... Training loss: 0.01729... Test loss: 0.00849\n",
      "Epoch: 1... Training loss: 0.01656... Test loss: 0.0058\n",
      "Epoch: 1... Training loss: 0.01584... Test loss: 0.00756\n",
      "Epoch: 1... Training loss: 0.01494... Test loss: 0.00661\n",
      "Epoch: 1... Training loss: 0.0144... Test loss: 0.00457\n",
      "Epoch: 1... Training loss: 0.01381... Test loss: 0.00937\n",
      "Epoch: 1... Training loss: 0.01347... Test loss: 0.0041\n",
      "Epoch: 1... Training loss: 0.01304... Test loss: 0.00884\n",
      "Epoch: 1... Training loss: 0.01261... Test loss: 0.00553\n",
      "Epoch: 1... Training loss: 0.01233... Test loss: 0.00903\n",
      "Epoch: 1... Training loss: 0.01185... Test loss: 0.00523\n",
      "Epoch: 1... Training loss: 0.01119... Test loss: 0.00818\n",
      "Epoch: 1... Training loss: 0.01084... Test loss: 0.00495\n",
      "Epoch: 1... Training loss: 0.01052... Test loss: 0.00831\n",
      "Epoch: 1... Training loss: 0.01029... Test loss: 0.0045\n",
      "Epoch: 1... Training loss: 0.01002... Test loss: 0.00671\n",
      "Epoch: 1... Training loss: 0.00984... Test loss: 0.00732\n",
      "Epoch: 1... Training loss: 0.00948... Test loss: 0.00691\n",
      "Epoch: 1... Training loss: 0.00927... Test loss: 0.00766\n",
      "Epoch: 1... Training loss: 0.0089... Test loss: 0.00665\n",
      "Epoch: 1... Training loss: 0.00875... Test loss: 0.00768\n",
      "Epoch: 1... Training loss: 0.00849... Test loss: 0.00611\n",
      "Epoch: 1... Training loss: 0.00822... Test loss: 0.00833\n",
      "Epoch: 1... Training loss: 0.00793... Test loss: 0.00538\n",
      "Epoch: 1... Training loss: 0.00779... Test loss: 0.00856\n",
      "Epoch: 1... Training loss: 0.0077... Test loss: 0.00511\n",
      "Epoch: 1... Training loss: 0.00735... Test loss: 0.00695\n",
      "Epoch: 1... Training loss: 0.00707... Test loss: 0.00547\n",
      "Epoch: 1... Training loss: 0.00696... Test loss: 0.00723\n",
      "Epoch: 1... Training loss: 0.00683... Test loss: 0.00639\n",
      "Epoch: 1... Training loss: 0.00655... Test loss: 0.00756\n",
      "Epoch: 1... Training loss: 0.00653... Test loss: 0.00614\n",
      "Epoch: 1... Training loss: 0.00624... Test loss: 0.00691\n",
      "Epoch: 1... Training loss: 0.00615... Test loss: 0.00541\n",
      "Epoch: 1... Training loss: 0.00605... Test loss: 0.00643\n",
      "Epoch: 1... Training loss: 0.00591... Test loss: 0.00536\n",
      "Epoch: 1... Training loss: 0.00584... Test loss: 0.00529\n",
      "Epoch: 1... Training loss: 0.01148... Test loss: 0.01471\n",
      "Epoch: 1... Training loss: 0.01189... Test loss: 0.01042\n",
      "Epoch: 1... Training loss: 0.00915... Test loss: 0.01128\n",
      "Epoch: 1... Training loss: 0.00992... Test loss: 0.00872\n",
      "Epoch: 1... Training loss: 0.01356... Test loss: 0.01169\n",
      "Epoch: 1... Training loss: 0.01046... Test loss: 0.00857\n",
      "Epoch: 1... Training loss: 0.00945... Test loss: 0.01063\n",
      "Epoch: 1... Training loss: 0.00887... Test loss: 0.00812\n",
      "Epoch: 1... Training loss: 0.0097... Test loss: 0.01104\n",
      "Epoch: 1... Training loss: 0.00862... Test loss: 0.01057\n",
      "Epoch: 1... Training loss: 0.0084... Test loss: 0.00968\n",
      "Epoch: 1... Training loss: 0.00899... Test loss: 0.0109\n",
      "Epoch: 1... Training loss: 0.00809... Test loss: 0.01137\n",
      "Epoch: 1... Training loss: 0.00835... Test loss: 0.00856\n",
      "Epoch: 1... Training loss: 0.00811... Test loss: 0.01212\n",
      "Epoch: 1... Training loss: 0.00777... Test loss: 0.00864\n",
      "Epoch: 1... Training loss: 0.00718... Test loss: 0.00961\n",
      "Epoch: 1... Training loss: 0.00657... Test loss: 0.00834\n",
      "Epoch: 1... Training loss: 0.00695... Test loss: 0.00902\n",
      "Epoch: 1... Training loss: 0.00643... Test loss: 0.00745\n",
      "Epoch: 1... Training loss: 0.0065... Test loss: 0.00814\n",
      "Epoch: 1... Training loss: 0.00644... Test loss: 0.00707\n",
      "Epoch: 1... Training loss: 0.00586... Test loss: 0.00793\n",
      "Epoch: 1... Training loss: 0.00589... Test loss: 0.0065\n",
      "Epoch: 1... Training loss: 0.0057... Test loss: 0.00687\n",
      "Epoch: 1... Training loss: 0.00546... Test loss: 0.00582\n",
      "Epoch: 1... Training loss: 0.0053... Test loss: 0.00693\n",
      "Epoch: 1... Training loss: 0.00541... Test loss: 0.00509\n",
      "Epoch: 1... Training loss: 0.00496... Test loss: 0.00753\n",
      "Epoch: 1... Training loss: 0.00496... Test loss: 0.00515\n",
      "Epoch: 1... Training loss: 0.00479... Test loss: 0.00556\n",
      "Epoch: 1... Training loss: 0.00463... Test loss: 0.00547\n",
      "Epoch: 1... Training loss: 0.00438... Test loss: 0.00541\n",
      "Epoch: 1... Training loss: 0.00429... Test loss: 0.00472\n",
      "Epoch: 1... Training loss: 0.00427... Test loss: 0.00461\n",
      "Epoch: 1... Training loss: 0.0041... Test loss: 0.00393\n",
      "Epoch: 1... Training loss: 0.00402... Test loss: 0.00477\n",
      "Epoch: 1... Training loss: 0.00414... Test loss: 0.00381\n",
      "Epoch: 1... Training loss: 0.00389... Test loss: 0.00472\n",
      "Epoch: 1... Training loss: 0.00389... Test loss: 0.00402\n",
      "Epoch: 1... Training loss: 0.00384... Test loss: 0.00433\n",
      "Epoch: 1... Training loss: 0.00371... Test loss: 0.00379\n",
      "Epoch: 1... Training loss: 0.00366... Test loss: 0.00434\n",
      "Epoch: 1... Training loss: 0.00369... Test loss: 0.00316\n",
      "Epoch: 1... Training loss: 0.00363... Test loss: 0.00389\n",
      "Epoch: 1... Training loss: 0.00352... Test loss: 0.00352\n",
      "Epoch: 1... Training loss: 0.00334... Test loss: 0.00369\n",
      "Epoch: 1... Training loss: 0.00333... Test loss: 0.00354\n",
      "Epoch: 1... Training loss: 0.00324... Test loss: 0.00307\n",
      "Epoch: 1... Training loss: 0.00322... Test loss: 0.00337\n",
      "Epoch: 1... Training loss: 0.00307... Test loss: 0.00344\n",
      "Epoch: 1... Training loss: 0.00318... Test loss: 0.00305\n",
      "Epoch: 1... Training loss: 0.00306... Test loss: 0.00325\n",
      "Epoch: 1... Training loss: 0.0029... Test loss: 0.00289\n",
      "Epoch: 1... Training loss: 0.00277... Test loss: 0.00325\n",
      "Epoch: 1... Training loss: 0.00277... Test loss: 0.00277\n",
      "Epoch: 1... Training loss: 0.0027... Test loss: 0.00283\n",
      "Epoch: 1... Training loss: 0.00259... Test loss: 0.00275\n",
      "Epoch: 1... Training loss: 0.0025... Test loss: 0.00328\n",
      "Epoch: 1... Training loss: 0.0026... Test loss: 0.0025\n",
      "Epoch: 1... Training loss: 0.00248... Test loss: 0.00297\n",
      "Epoch: 1... Training loss: 0.0023... Test loss: 0.00277\n",
      "Epoch: 1... Training loss: 0.00234... Test loss: 0.00301\n",
      "Epoch: 1... Training loss: 0.00224... Test loss: 0.00276\n",
      "Epoch: 1... Training loss: 0.00222... Test loss: 0.00317\n",
      "Epoch: 1... Training loss: 0.00221... Test loss: 0.00238\n",
      "Epoch: 1... Training loss: 0.00218... Test loss: 0.00276\n",
      "Epoch: 1... Training loss: 0.00213... Test loss: 0.00222\n",
      "Epoch: 1... Training loss: 0.0021... Test loss: 0.00226\n",
      "Epoch: 1... Training loss: 0.00197... Test loss: 0.00197\n",
      "Epoch: 1... Training loss: 0.00202... Test loss: 0.00238\n",
      "Epoch: 1... Training loss: 0.00195... Test loss: 0.00204\n",
      "Epoch: 1... Training loss: 0.00182... Test loss: 0.00221\n",
      "Epoch: 1... Training loss: 0.00188... Test loss: 0.00185\n",
      "Epoch: 1... Training loss: 0.00177... Test loss: 0.00201\n",
      "Epoch: 1... Training loss: 0.00171... Test loss: 0.00183\n",
      "Epoch: 1... Training loss: 0.00168... Test loss: 0.00184\n",
      "Epoch: 1... Training loss: 0.00162... Test loss: 0.00155\n",
      "Epoch: 1... Training loss: 0.00161... Test loss: 0.00147\n",
      "Epoch: 1... Training loss: 0.00154... Test loss: 0.00154\n",
      "Epoch: 1... Training loss: 0.00147... Test loss: 0.00161\n",
      "Epoch: 1... Training loss: 0.00153... Test loss: 0.00162\n",
      "Epoch: 1... Training loss: 0.00134... Test loss: 0.00153\n",
      "Epoch: 1... Training loss: 0.00133... Test loss: 0.00156\n",
      "Epoch: 1... Training loss: 0.00124... Test loss: 0.00145\n",
      "Epoch: 1... Training loss: 0.00126... Test loss: 0.00126\n",
      "Epoch: 1... Training loss: 0.00125... Test loss: 0.00138\n",
      "Epoch: 1... Training loss: 0.00119... Test loss: 0.00117\n",
      "Epoch: 1... Training loss: 0.00116... Test loss: 0.00138\n",
      "Epoch: 1... Training loss: 0.00111... Test loss: 0.00124\n",
      "Epoch: 1... Training loss: 0.00112... Test loss: 0.00113\n",
      "Epoch: 1... Training loss: 0.00099... Test loss: 0.00105\n",
      "Epoch: 1... Training loss: 0.00107... Test loss: 0.00096\n",
      "Epoch: 1... Training loss: 0.001... Test loss: 0.00102\n",
      "Epoch: 1... Training loss: 0.00092... Test loss: 0.00091\n",
      "Epoch: 1... Training loss: 0.00093... Test loss: 0.00104\n",
      "Epoch: 1... Training loss: 0.00088... Test loss: 0.00085\n",
      "Epoch: 1... Training loss: 0.00081... Test loss: 0.00102\n",
      "Epoch: 1... Training loss: 0.0008... Test loss: 0.00074\n",
      "Epoch: 1... Training loss: 0.00075... Test loss: 0.00076\n",
      "Epoch: 1... Training loss: 0.00082... Test loss: 0.00069\n",
      "Epoch: 1... Training loss: 0.00068... Test loss: 0.00081\n",
      "Epoch: 1... Training loss: 0.00067... Test loss: 0.00059\n",
      "Epoch: 1... Training loss: 0.00065... Test loss: 0.00081\n",
      "Epoch: 1... Training loss: 0.0006... Test loss: 0.0006\n",
      "Epoch: 1... Training loss: 0.00061... Test loss: 0.00074\n",
      "Epoch: 1... Training loss: 0.00057... Test loss: 0.00063\n",
      "Epoch: 1... Training loss: 0.00059... Test loss: 0.00068\n",
      "Epoch: 1... Training loss: 0.00059... Test loss: 0.00061\n",
      "Epoch: 1... Training loss: 0.00053... Test loss: 0.00066\n",
      "Epoch: 1... Training loss: 0.00052... Test loss: 0.00056\n",
      "Epoch: 1... Training loss: 0.00049... Test loss: 0.00069\n",
      "Epoch: 1... Training loss: 0.00046... Test loss: 0.00058\n",
      "Epoch: 1... Training loss: 0.00043... Test loss: 0.00045\n",
      "Epoch: 1... Training loss: 0.00046... Test loss: 0.00043\n",
      "Epoch: 1... Training loss: 0.00052... Test loss: 0.00046\n",
      "Epoch: 1... Training loss: 0.00045... Test loss: 0.00041\n",
      "Epoch: 1... Training loss: 0.00043... Test loss: 0.00036\n",
      "Epoch: 1... Training loss: 0.00039... Test loss: 0.00044\n",
      "Epoch: 1... Training loss: 0.00039... Test loss: 0.00037\n",
      "Epoch: 1... Training loss: 0.00033... Test loss: 0.00049\n",
      "Epoch: 1... Training loss: 0.00034... Test loss: 0.00033\n",
      "Epoch: 1... Training loss: 0.00032... Test loss: 0.00039\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00026... Test loss: 0.00036\n",
      "Epoch: 1... Training loss: 0.00029... Test loss: 0.00028\n",
      "Epoch: 1... Training loss: 0.00026... Test loss: 0.0003\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00024\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00018\n",
      "287.7844328917563\n",
      "Epoch: 1... Training loss: 0.84528... Test loss: 0.22633\n",
      "Epoch: 1... Training loss: 0.50947... Test loss: 0.17902\n",
      "Epoch: 1... Training loss: 0.32123... Test loss: 0.10198\n",
      "Epoch: 1... Training loss: 0.22478... Test loss: 0.06043\n",
      "Epoch: 1... Training loss: 0.1792... Test loss: 0.04605\n",
      "Epoch: 1... Training loss: 0.14801... Test loss: 0.03859\n",
      "Epoch: 1... Training loss: 0.11756... Test loss: 0.03483\n",
      "Epoch: 1... Training loss: 0.08326... Test loss: 0.02206\n",
      "Epoch: 1... Training loss: 0.06585... Test loss: 0.01776\n",
      "Epoch: 1... Training loss: 0.05349... Test loss: 0.01556\n",
      "Epoch: 1... Training loss: 0.05066... Test loss: 0.01213\n",
      "Epoch: 1... Training loss: 0.04408... Test loss: 0.01209\n",
      "Epoch: 1... Training loss: 0.0499... Test loss: 0.01016\n",
      "Epoch: 1... Training loss: 0.03711... Test loss: 0.01502\n",
      "Epoch: 1... Training loss: 0.03824... Test loss: 0.00806\n",
      "Epoch: 1... Training loss: 0.03235... Test loss: 0.013\n",
      "Epoch: 1... Training loss: 0.03189... Test loss: 0.00595\n",
      "Epoch: 1... Training loss: 0.02848... Test loss: 0.0135\n",
      "Epoch: 1... Training loss: 0.02862... Test loss: 0.00577\n",
      "Epoch: 1... Training loss: 0.02551... Test loss: 0.01269\n",
      "Epoch: 1... Training loss: 0.02462... Test loss: 0.0055\n",
      "Epoch: 1... Training loss: 0.02351... Test loss: 0.01289\n",
      "Epoch: 1... Training loss: 0.02232... Test loss: 0.005\n",
      "Epoch: 1... Training loss: 0.02039... Test loss: 0.01132\n",
      "Epoch: 1... Training loss: 0.01961... Test loss: 0.0064\n",
      "Epoch: 1... Training loss: 0.01855... Test loss: 0.00983\n",
      "Epoch: 1... Training loss: 0.01859... Test loss: 0.00861\n",
      "Epoch: 1... Training loss: 0.01744... Test loss: 0.00683\n",
      "Epoch: 1... Training loss: 0.0167... Test loss: 0.01099\n",
      "Epoch: 1... Training loss: 0.01587... Test loss: 0.00679\n",
      "Epoch: 1... Training loss: 0.01538... Test loss: 0.01186\n",
      "Epoch: 1... Training loss: 0.01449... Test loss: 0.00592\n",
      "Epoch: 1... Training loss: 0.01414... Test loss: 0.01172\n",
      "Epoch: 1... Training loss: 0.01343... Test loss: 0.0071\n",
      "Epoch: 1... Training loss: 0.01302... Test loss: 0.01192\n",
      "Epoch: 1... Training loss: 0.01284... Test loss: 0.00705\n",
      "Epoch: 1... Training loss: 0.0123... Test loss: 0.01028\n",
      "Epoch: 1... Training loss: 0.01191... Test loss: 0.01132\n",
      "Epoch: 1... Training loss: 0.01142... Test loss: 0.00706\n",
      "Epoch: 1... Training loss: 0.01105... Test loss: 0.01004\n",
      "Epoch: 1... Training loss: 0.01048... Test loss: 0.00628\n",
      "Epoch: 1... Training loss: 0.01018... Test loss: 0.00862\n",
      "Epoch: 1... Training loss: 0.01005... Test loss: 0.00725\n",
      "Epoch: 1... Training loss: 0.0095... Test loss: 0.00716\n",
      "Epoch: 1... Training loss: 0.00945... Test loss: 0.00886\n",
      "Epoch: 1... Training loss: 0.0092... Test loss: 0.00528\n",
      "Epoch: 1... Training loss: 0.00905... Test loss: 0.00938\n",
      "Epoch: 1... Training loss: 0.00862... Test loss: 0.00488\n",
      "Epoch: 1... Training loss: 0.0085... Test loss: 0.0082\n",
      "Epoch: 1... Training loss: 0.00826... Test loss: 0.00471\n",
      "Epoch: 1... Training loss: 0.00804... Test loss: 0.00791\n",
      "Epoch: 1... Training loss: 0.00776... Test loss: 0.0051\n",
      "Epoch: 1... Training loss: 0.00767... Test loss: 0.00811\n",
      "Epoch: 1... Training loss: 0.00737... Test loss: 0.005\n",
      "Epoch: 1... Training loss: 0.0073... Test loss: 0.00782\n",
      "Epoch: 1... Training loss: 0.00717... Test loss: 0.00509\n",
      "Epoch: 1... Training loss: 0.00702... Test loss: 0.00777\n",
      "Epoch: 1... Training loss: 0.00684... Test loss: 0.00555\n",
      "Epoch: 1... Training loss: 0.00661... Test loss: 0.00758\n",
      "Epoch: 1... Training loss: 0.00644... Test loss: 0.00528\n",
      "Epoch: 1... Training loss: 0.00628... Test loss: 0.00729\n",
      "Epoch: 1... Training loss: 0.00613... Test loss: 0.0049\n",
      "Epoch: 1... Training loss: 0.00588... Test loss: 0.00662\n",
      "Epoch: 1... Training loss: 0.00567... Test loss: 0.00498\n",
      "Epoch: 1... Training loss: 0.01345... Test loss: 0.01818\n",
      "Epoch: 1... Training loss: 0.01217... Test loss: 0.01009\n",
      "Epoch: 1... Training loss: 0.01218... Test loss: 0.01653\n",
      "Epoch: 1... Training loss: 0.01076... Test loss: 0.01098\n",
      "Epoch: 1... Training loss: 0.0088... Test loss: 0.01368\n",
      "Epoch: 1... Training loss: 0.00977... Test loss: 0.00921\n",
      "Epoch: 1... Training loss: 0.00946... Test loss: 0.01218\n",
      "Epoch: 1... Training loss: 0.00906... Test loss: 0.01035\n",
      "Epoch: 1... Training loss: 0.00921... Test loss: 0.01027\n",
      "Epoch: 1... Training loss: 0.00961... Test loss: 0.00984\n",
      "Epoch: 1... Training loss: 0.00893... Test loss: 0.00959\n",
      "Epoch: 1... Training loss: 0.00802... Test loss: 0.01029\n",
      "Epoch: 1... Training loss: 0.008... Test loss: 0.00961\n",
      "Epoch: 1... Training loss: 0.00816... Test loss: 0.00867\n",
      "Epoch: 1... Training loss: 0.007... Test loss: 0.0101\n",
      "Epoch: 1... Training loss: 0.00722... Test loss: 0.00754\n",
      "Epoch: 1... Training loss: 0.00679... Test loss: 0.00934\n",
      "Epoch: 1... Training loss: 0.00674... Test loss: 0.00811\n",
      "Epoch: 1... Training loss: 0.00663... Test loss: 0.00849\n",
      "Epoch: 1... Training loss: 0.00645... Test loss: 0.0068\n",
      "Epoch: 1... Training loss: 0.00582... Test loss: 0.00763\n",
      "Epoch: 1... Training loss: 0.00602... Test loss: 0.00644\n",
      "Epoch: 1... Training loss: 0.00605... Test loss: 0.00795\n",
      "Epoch: 1... Training loss: 0.00541... Test loss: 0.00698\n",
      "Epoch: 1... Training loss: 0.00531... Test loss: 0.00638\n",
      "Epoch: 1... Training loss: 0.00532... Test loss: 0.00733\n",
      "Epoch: 1... Training loss: 0.00518... Test loss: 0.00594\n",
      "Epoch: 1... Training loss: 0.00476... Test loss: 0.00577\n",
      "Epoch: 1... Training loss: 0.0049... Test loss: 0.00534\n",
      "Epoch: 1... Training loss: 0.0048... Test loss: 0.00485\n",
      "Epoch: 1... Training loss: 0.0045... Test loss: 0.00467\n",
      "Epoch: 1... Training loss: 0.00436... Test loss: 0.00552\n",
      "Epoch: 1... Training loss: 0.00427... Test loss: 0.00457\n",
      "Epoch: 1... Training loss: 0.00435... Test loss: 0.00431\n",
      "Epoch: 1... Training loss: 0.00404... Test loss: 0.00472\n",
      "Epoch: 1... Training loss: 0.00401... Test loss: 0.00405\n",
      "Epoch: 1... Training loss: 0.00395... Test loss: 0.00509\n",
      "Epoch: 1... Training loss: 0.00378... Test loss: 0.00427\n",
      "Epoch: 1... Training loss: 0.00359... Test loss: 0.00495\n",
      "Epoch: 1... Training loss: 0.00358... Test loss: 0.00403\n",
      "Epoch: 1... Training loss: 0.0036... Test loss: 0.00344\n",
      "Epoch: 1... Training loss: 0.00336... Test loss: 0.00387\n",
      "Epoch: 1... Training loss: 0.00341... Test loss: 0.00325\n",
      "Epoch: 1... Training loss: 0.00335... Test loss: 0.00419\n",
      "Epoch: 1... Training loss: 0.00328... Test loss: 0.00316\n",
      "Epoch: 1... Training loss: 0.00326... Test loss: 0.00389\n",
      "Epoch: 1... Training loss: 0.00317... Test loss: 0.00348\n",
      "Epoch: 1... Training loss: 0.00307... Test loss: 0.00369\n",
      "Epoch: 1... Training loss: 0.00306... Test loss: 0.00333\n",
      "Epoch: 1... Training loss: 0.00294... Test loss: 0.00329\n",
      "Epoch: 1... Training loss: 0.0032... Test loss: 0.00327\n",
      "Epoch: 1... Training loss: 0.00296... Test loss: 0.00292\n",
      "Epoch: 1... Training loss: 0.00295... Test loss: 0.00303\n",
      "Epoch: 1... Training loss: 0.0027... Test loss: 0.00314\n",
      "Epoch: 1... Training loss: 0.00267... Test loss: 0.00278\n",
      "Epoch: 1... Training loss: 0.00258... Test loss: 0.00309\n",
      "Epoch: 1... Training loss: 0.00248... Test loss: 0.00248\n",
      "Epoch: 1... Training loss: 0.00252... Test loss: 0.00275\n",
      "Epoch: 1... Training loss: 0.00254... Test loss: 0.00264\n",
      "Epoch: 1... Training loss: 0.00241... Test loss: 0.00258\n",
      "Epoch: 1... Training loss: 0.00239... Test loss: 0.00241\n",
      "Epoch: 1... Training loss: 0.00233... Test loss: 0.00264\n",
      "Epoch: 1... Training loss: 0.00233... Test loss: 0.00239\n",
      "Epoch: 1... Training loss: 0.00212... Test loss: 0.00233\n",
      "Epoch: 1... Training loss: 0.00213... Test loss: 0.00242\n",
      "Epoch: 1... Training loss: 0.00214... Test loss: 0.00258\n",
      "Epoch: 1... Training loss: 0.00202... Test loss: 0.00212\n",
      "Epoch: 1... Training loss: 0.00195... Test loss: 0.00238\n",
      "Epoch: 1... Training loss: 0.00189... Test loss: 0.00197\n",
      "Epoch: 1... Training loss: 0.00185... Test loss: 0.00231\n",
      "Epoch: 1... Training loss: 0.00187... Test loss: 0.00177\n",
      "Epoch: 1... Training loss: 0.00175... Test loss: 0.0021\n",
      "Epoch: 1... Training loss: 0.00173... Test loss: 0.00162\n",
      "Epoch: 1... Training loss: 0.00173... Test loss: 0.00194\n",
      "Epoch: 1... Training loss: 0.00166... Test loss: 0.00169\n",
      "Epoch: 1... Training loss: 0.00158... Test loss: 0.00172\n",
      "Epoch: 1... Training loss: 0.00157... Test loss: 0.00156\n",
      "Epoch: 1... Training loss: 0.00152... Test loss: 0.0019\n",
      "Epoch: 1... Training loss: 0.00139... Test loss: 0.00161\n",
      "Epoch: 1... Training loss: 0.00145... Test loss: 0.00163\n",
      "Epoch: 1... Training loss: 0.00142... Test loss: 0.00147\n",
      "Epoch: 1... Training loss: 0.00128... Test loss: 0.00137\n",
      "Epoch: 1... Training loss: 0.00124... Test loss: 0.00131\n",
      "Epoch: 1... Training loss: 0.0012... Test loss: 0.00111\n",
      "Epoch: 1... Training loss: 0.00127... Test loss: 0.00143\n",
      "Epoch: 1... Training loss: 0.00113... Test loss: 0.00119\n",
      "Epoch: 1... Training loss: 0.0011... Test loss: 0.00135\n",
      "Epoch: 1... Training loss: 0.00108... Test loss: 0.00128\n",
      "Epoch: 1... Training loss: 0.00103... Test loss: 0.0013\n",
      "Epoch: 1... Training loss: 0.00101... Test loss: 0.00117\n",
      "Epoch: 1... Training loss: 0.00095... Test loss: 0.00103\n",
      "Epoch: 1... Training loss: 0.00092... Test loss: 0.00113\n",
      "Epoch: 1... Training loss: 0.00094... Test loss: 0.00104\n",
      "Epoch: 1... Training loss: 0.00087... Test loss: 0.00103\n",
      "Epoch: 1... Training loss: 0.00086... Test loss: 0.00105\n",
      "Epoch: 1... Training loss: 0.00084... Test loss: 0.00097\n",
      "Epoch: 1... Training loss: 0.00081... Test loss: 0.00095\n",
      "Epoch: 1... Training loss: 0.00075... Test loss: 0.00093\n",
      "Epoch: 1... Training loss: 0.00078... Test loss: 0.00075\n",
      "Epoch: 1... Training loss: 0.00075... Test loss: 0.00091\n",
      "Epoch: 1... Training loss: 0.00069... Test loss: 0.00065\n",
      "Epoch: 1... Training loss: 0.00067... Test loss: 0.00084\n",
      "Epoch: 1... Training loss: 0.00066... Test loss: 0.00062\n",
      "Epoch: 1... Training loss: 0.00068... Test loss: 0.00073\n",
      "Epoch: 1... Training loss: 0.00063... Test loss: 0.00056\n",
      "Epoch: 1... Training loss: 0.00057... Test loss: 0.00066\n",
      "Epoch: 1... Training loss: 0.00054... Test loss: 0.00055\n",
      "Epoch: 1... Training loss: 0.00054... Test loss: 0.00073\n",
      "Epoch: 1... Training loss: 0.00048... Test loss: 0.00056\n",
      "Epoch: 1... Training loss: 0.0005... Test loss: 0.00054\n",
      "Epoch: 1... Training loss: 0.00044... Test loss: 0.00053\n",
      "Epoch: 1... Training loss: 0.00046... Test loss: 0.0005\n",
      "Epoch: 1... Training loss: 0.00041... Test loss: 0.00057\n",
      "Epoch: 1... Training loss: 0.00047... Test loss: 0.00042\n",
      "Epoch: 1... Training loss: 0.00039... Test loss: 0.00056\n",
      "Epoch: 1... Training loss: 0.00038... Test loss: 0.00036\n",
      "Epoch: 1... Training loss: 0.00032... Test loss: 0.00061\n",
      "Epoch: 1... Training loss: 0.00039... Test loss: 0.00034\n",
      "Epoch: 1... Training loss: 0.00038... Test loss: 0.00051\n",
      "Epoch: 1... Training loss: 0.00032... Test loss: 0.00036\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00034\n",
      "Epoch: 1... Training loss: 0.00031... Test loss: 0.00034\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00036\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00034\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00026... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00024\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00014\n",
      "253.68598815787118\n",
      "Epoch: 1... Training loss: 0.99151... Test loss: 0.28459\n",
      "Epoch: 1... Training loss: 0.44559... Test loss: 0.11071\n",
      "Epoch: 1... Training loss: 0.23304... Test loss: 0.05089\n",
      "Epoch: 1... Training loss: 0.16807... Test loss: 0.04067\n",
      "Epoch: 1... Training loss: 0.12443... Test loss: 0.03133\n",
      "Epoch: 1... Training loss: 0.10465... Test loss: 0.03073\n",
      "Epoch: 1... Training loss: 0.0911... Test loss: 0.02484\n",
      "Epoch: 1... Training loss: 0.07176... Test loss: 0.02394\n",
      "Epoch: 1... Training loss: 0.05789... Test loss: 0.01882\n",
      "Epoch: 1... Training loss: 0.04954... Test loss: 0.0165\n",
      "Epoch: 1... Training loss: 0.0422... Test loss: 0.00941\n",
      "Epoch: 1... Training loss: 0.03872... Test loss: 0.01134\n",
      "Epoch: 1... Training loss: 0.03422... Test loss: 0.00693\n",
      "Epoch: 1... Training loss: 0.03125... Test loss: 0.01063\n",
      "Epoch: 1... Training loss: 0.02853... Test loss: 0.00939\n",
      "Epoch: 1... Training loss: 0.02621... Test loss: 0.00522\n",
      "Epoch: 1... Training loss: 0.02548... Test loss: 0.01329\n",
      "Epoch: 1... Training loss: 0.02352... Test loss: 0.00388\n",
      "Epoch: 1... Training loss: 0.02287... Test loss: 0.01049\n",
      "Epoch: 1... Training loss: 0.02171... Test loss: 0.00454\n",
      "Epoch: 1... Training loss: 0.02066... Test loss: 0.00963\n",
      "Epoch: 1... Training loss: 0.01949... Test loss: 0.00405\n",
      "Epoch: 1... Training loss: 0.01854... Test loss: 0.00756\n",
      "Epoch: 1... Training loss: 0.01768... Test loss: 0.00376\n",
      "Epoch: 1... Training loss: 0.01733... Test loss: 0.00848\n",
      "Epoch: 1... Training loss: 0.01665... Test loss: 0.00508\n",
      "Epoch: 1... Training loss: 0.01558... Test loss: 0.00768\n",
      "Epoch: 1... Training loss: 0.01511... Test loss: 0.00571\n",
      "Epoch: 1... Training loss: 0.01453... Test loss: 0.00809\n",
      "Epoch: 1... Training loss: 0.01412... Test loss: 0.00693\n",
      "Epoch: 1... Training loss: 0.01369... Test loss: 0.00687\n",
      "Epoch: 1... Training loss: 0.01334... Test loss: 0.00659\n",
      "Epoch: 1... Training loss: 0.0128... Test loss: 0.00488\n",
      "Epoch: 1... Training loss: 0.0123... Test loss: 0.01089\n",
      "Epoch: 1... Training loss: 0.01204... Test loss: 0.00324\n",
      "Epoch: 1... Training loss: 0.01177... Test loss: 0.01087\n",
      "Epoch: 1... Training loss: 0.01145... Test loss: 0.00538\n",
      "Epoch: 1... Training loss: 0.01114... Test loss: 0.00984\n",
      "Epoch: 1... Training loss: 0.01074... Test loss: 0.00661\n",
      "Epoch: 1... Training loss: 0.0106... Test loss: 0.00772\n",
      "Epoch: 1... Training loss: 0.01023... Test loss: 0.00985\n",
      "Epoch: 1... Training loss: 0.0098... Test loss: 0.00577\n",
      "Epoch: 1... Training loss: 0.00959... Test loss: 0.00939\n",
      "Epoch: 1... Training loss: 0.0091... Test loss: 0.00619\n",
      "Epoch: 1... Training loss: 0.00886... Test loss: 0.00866\n",
      "Epoch: 1... Training loss: 0.00863... Test loss: 0.00558\n",
      "Epoch: 1... Training loss: 0.00841... Test loss: 0.00803\n",
      "Epoch: 1... Training loss: 0.00813... Test loss: 0.00601\n",
      "Epoch: 1... Training loss: 0.00797... Test loss: 0.00825\n",
      "Epoch: 1... Training loss: 0.00764... Test loss: 0.00679\n",
      "Epoch: 1... Training loss: 0.00755... Test loss: 0.00946\n",
      "Epoch: 1... Training loss: 0.0075... Test loss: 0.00692\n",
      "Epoch: 1... Training loss: 0.00726... Test loss: 0.00832\n",
      "Epoch: 1... Training loss: 0.007... Test loss: 0.00512\n",
      "Epoch: 1... Training loss: 0.0067... Test loss: 0.00724\n",
      "Epoch: 1... Training loss: 0.00665... Test loss: 0.00542\n",
      "Epoch: 1... Training loss: 0.00653... Test loss: 0.0068\n",
      "Epoch: 1... Training loss: 0.00627... Test loss: 0.00505\n",
      "Epoch: 1... Training loss: 0.00618... Test loss: 0.00702\n",
      "Epoch: 1... Training loss: 0.006... Test loss: 0.00547\n",
      "Epoch: 1... Training loss: 0.00583... Test loss: 0.00679\n",
      "Epoch: 1... Training loss: 0.0056... Test loss: 0.00526\n",
      "Epoch: 1... Training loss: 0.00553... Test loss: 0.0064\n",
      "Epoch: 1... Training loss: 0.00527... Test loss: 0.00483\n",
      "Epoch: 1... Training loss: 0.0145... Test loss: 0.01198\n",
      "Epoch: 1... Training loss: 0.01126... Test loss: 0.00955\n",
      "Epoch: 1... Training loss: 0.00944... Test loss: 0.01798\n",
      "Epoch: 1... Training loss: 0.0083... Test loss: 0.0095\n",
      "Epoch: 1... Training loss: 0.00975... Test loss: 0.0077\n",
      "Epoch: 1... Training loss: 0.00898... Test loss: 0.00941\n",
      "Epoch: 1... Training loss: 0.00831... Test loss: 0.0091\n",
      "Epoch: 1... Training loss: 0.00914... Test loss: 0.01074\n",
      "Epoch: 1... Training loss: 0.00793... Test loss: 0.00868\n",
      "Epoch: 1... Training loss: 0.00745... Test loss: 0.00682\n",
      "Epoch: 1... Training loss: 0.00765... Test loss: 0.01017\n",
      "Epoch: 1... Training loss: 0.00765... Test loss: 0.00772\n",
      "Epoch: 1... Training loss: 0.00666... Test loss: 0.00849\n",
      "Epoch: 1... Training loss: 0.00666... Test loss: 0.00637\n",
      "Epoch: 1... Training loss: 0.00663... Test loss: 0.00914\n",
      "Epoch: 1... Training loss: 0.00656... Test loss: 0.0079\n",
      "Epoch: 1... Training loss: 0.00649... Test loss: 0.00673\n",
      "Epoch: 1... Training loss: 0.00596... Test loss: 0.00651\n",
      "Epoch: 1... Training loss: 0.0062... Test loss: 0.00723\n",
      "Epoch: 1... Training loss: 0.00591... Test loss: 0.00707\n",
      "Epoch: 1... Training loss: 0.00548... Test loss: 0.00666\n",
      "Epoch: 1... Training loss: 0.00564... Test loss: 0.00521\n",
      "Epoch: 1... Training loss: 0.00549... Test loss: 0.00626\n",
      "Epoch: 1... Training loss: 0.0052... Test loss: 0.00515\n",
      "Epoch: 1... Training loss: 0.00507... Test loss: 0.00597\n",
      "Epoch: 1... Training loss: 0.00486... Test loss: 0.00519\n",
      "Epoch: 1... Training loss: 0.00478... Test loss: 0.00528\n",
      "Epoch: 1... Training loss: 0.00478... Test loss: 0.00493\n",
      "Epoch: 1... Training loss: 0.00462... Test loss: 0.00466\n",
      "Epoch: 1... Training loss: 0.00452... Test loss: 0.00438\n",
      "Epoch: 1... Training loss: 0.00412... Test loss: 0.00524\n",
      "Epoch: 1... Training loss: 0.00415... Test loss: 0.00432\n",
      "Epoch: 1... Training loss: 0.00405... Test loss: 0.00466\n",
      "Epoch: 1... Training loss: 0.00385... Test loss: 0.00342\n",
      "Epoch: 1... Training loss: 0.00375... Test loss: 0.0044\n",
      "Epoch: 1... Training loss: 0.00351... Test loss: 0.0034\n",
      "Epoch: 1... Training loss: 0.00346... Test loss: 0.00425\n",
      "Epoch: 1... Training loss: 0.00346... Test loss: 0.00311\n",
      "Epoch: 1... Training loss: 0.00347... Test loss: 0.00448\n",
      "Epoch: 1... Training loss: 0.00342... Test loss: 0.00375\n",
      "Epoch: 1... Training loss: 0.00347... Test loss: 0.00409\n",
      "Epoch: 1... Training loss: 0.00334... Test loss: 0.00377\n",
      "Epoch: 1... Training loss: 0.00312... Test loss: 0.00355\n",
      "Epoch: 1... Training loss: 0.00311... Test loss: 0.00342\n",
      "Epoch: 1... Training loss: 0.0031... Test loss: 0.00333\n",
      "Epoch: 1... Training loss: 0.00284... Test loss: 0.00343\n",
      "Epoch: 1... Training loss: 0.00285... Test loss: 0.0036\n",
      "Epoch: 1... Training loss: 0.00277... Test loss: 0.00321\n",
      "Epoch: 1... Training loss: 0.00272... Test loss: 0.00384\n",
      "Epoch: 1... Training loss: 0.00282... Test loss: 0.00249\n",
      "Epoch: 1... Training loss: 0.00285... Test loss: 0.00305\n",
      "Epoch: 1... Training loss: 0.00267... Test loss: 0.00221\n",
      "Epoch: 1... Training loss: 0.00269... Test loss: 0.00298\n",
      "Epoch: 1... Training loss: 0.00255... Test loss: 0.00235\n",
      "Epoch: 1... Training loss: 0.00246... Test loss: 0.00277\n",
      "Epoch: 1... Training loss: 0.00238... Test loss: 0.00224\n",
      "Epoch: 1... Training loss: 0.00234... Test loss: 0.00277\n",
      "Epoch: 1... Training loss: 0.00235... Test loss: 0.00237\n",
      "Epoch: 1... Training loss: 0.00227... Test loss: 0.00282\n",
      "Epoch: 1... Training loss: 0.00214... Test loss: 0.002\n",
      "Epoch: 1... Training loss: 0.00223... Test loss: 0.00234\n",
      "Epoch: 1... Training loss: 0.00211... Test loss: 0.00186\n",
      "Epoch: 1... Training loss: 0.00202... Test loss: 0.00222\n",
      "Epoch: 1... Training loss: 0.00206... Test loss: 0.00225\n",
      "Epoch: 1... Training loss: 0.00208... Test loss: 0.0021\n",
      "Epoch: 1... Training loss: 0.00197... Test loss: 0.00238\n",
      "Epoch: 1... Training loss: 0.00185... Test loss: 0.00195\n",
      "Epoch: 1... Training loss: 0.00176... Test loss: 0.00222\n",
      "Epoch: 1... Training loss: 0.00176... Test loss: 0.00175\n",
      "Epoch: 1... Training loss: 0.00165... Test loss: 0.00192\n",
      "Epoch: 1... Training loss: 0.00166... Test loss: 0.00159\n",
      "Epoch: 1... Training loss: 0.00164... Test loss: 0.00175\n",
      "Epoch: 1... Training loss: 0.0016... Test loss: 0.00144\n",
      "Epoch: 1... Training loss: 0.00167... Test loss: 0.00175\n",
      "Epoch: 1... Training loss: 0.0016... Test loss: 0.0015\n",
      "Epoch: 1... Training loss: 0.00148... Test loss: 0.00153\n",
      "Epoch: 1... Training loss: 0.00147... Test loss: 0.00143\n",
      "Epoch: 1... Training loss: 0.00141... Test loss: 0.00152\n",
      "Epoch: 1... Training loss: 0.00133... Test loss: 0.00138\n",
      "Epoch: 1... Training loss: 0.00128... Test loss: 0.00144\n",
      "Epoch: 1... Training loss: 0.00131... Test loss: 0.00129\n",
      "Epoch: 1... Training loss: 0.00118... Test loss: 0.00144\n",
      "Epoch: 1... Training loss: 0.00119... Test loss: 0.00115\n",
      "Epoch: 1... Training loss: 0.00121... Test loss: 0.0015\n",
      "Epoch: 1... Training loss: 0.00113... Test loss: 0.00117\n",
      "Epoch: 1... Training loss: 0.00112... Test loss: 0.00122\n",
      "Epoch: 1... Training loss: 0.00112... Test loss: 0.00119\n",
      "Epoch: 1... Training loss: 0.00116... Test loss: 0.00116\n",
      "Epoch: 1... Training loss: 0.00101... Test loss: 0.00114\n",
      "Epoch: 1... Training loss: 0.00104... Test loss: 0.00097\n",
      "Epoch: 1... Training loss: 0.00099... Test loss: 0.00088\n",
      "Epoch: 1... Training loss: 0.00092... Test loss: 0.00091\n",
      "Epoch: 1... Training loss: 0.00091... Test loss: 0.00086\n",
      "Epoch: 1... Training loss: 0.00098... Test loss: 0.00091\n",
      "Epoch: 1... Training loss: 0.00092... Test loss: 0.00093\n",
      "Epoch: 1... Training loss: 0.0009... Test loss: 0.00094\n",
      "Epoch: 1... Training loss: 0.00085... Test loss: 0.0009\n",
      "Epoch: 1... Training loss: 0.00095... Test loss: 0.00096\n",
      "Epoch: 1... Training loss: 0.0008... Test loss: 0.00084\n",
      "Epoch: 1... Training loss: 0.00081... Test loss: 0.00078\n",
      "Epoch: 1... Training loss: 0.00077... Test loss: 0.00082\n",
      "Epoch: 1... Training loss: 0.00078... Test loss: 0.00079\n",
      "Epoch: 1... Training loss: 0.00077... Test loss: 0.00075\n",
      "Epoch: 1... Training loss: 0.00072... Test loss: 0.00072\n",
      "Epoch: 1... Training loss: 0.00076... Test loss: 0.00069\n",
      "Epoch: 1... Training loss: 0.00066... Test loss: 0.0008\n",
      "Epoch: 1... Training loss: 0.00068... Test loss: 0.00057\n",
      "Epoch: 1... Training loss: 0.00068... Test loss: 0.00075\n",
      "Epoch: 1... Training loss: 0.00063... Test loss: 0.00053\n",
      "Epoch: 1... Training loss: 0.00062... Test loss: 0.00069\n",
      "Epoch: 1... Training loss: 0.00057... Test loss: 0.00053\n",
      "Epoch: 1... Training loss: 0.00053... Test loss: 0.00055\n",
      "Epoch: 1... Training loss: 0.00055... Test loss: 0.00054\n",
      "Epoch: 1... Training loss: 0.00051... Test loss: 0.00061\n",
      "Epoch: 1... Training loss: 0.00053... Test loss: 0.00052\n",
      "Epoch: 1... Training loss: 0.00045... Test loss: 0.00063\n",
      "Epoch: 1... Training loss: 0.00047... Test loss: 0.00046\n",
      "Epoch: 1... Training loss: 0.00043... Test loss: 0.00056\n",
      "Epoch: 1... Training loss: 0.00042... Test loss: 0.00039\n",
      "Epoch: 1... Training loss: 0.00043... Test loss: 0.00047\n",
      "Epoch: 1... Training loss: 0.0004... Test loss: 0.00036\n",
      "Epoch: 1... Training loss: 0.00035... Test loss: 0.00044\n",
      "Epoch: 1... Training loss: 0.00035... Test loss: 0.00033\n",
      "Epoch: 1... Training loss: 0.00038... Test loss: 0.00036\n",
      "Epoch: 1... Training loss: 0.00034... Test loss: 0.00035\n",
      "Epoch: 1... Training loss: 0.00032... Test loss: 0.00035\n",
      "Epoch: 1... Training loss: 0.00032... Test loss: 0.00032\n",
      "Epoch: 1... Training loss: 0.00031... Test loss: 0.00032\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00033\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00028\n",
      "Epoch: 1... Training loss: 0.00026... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00027\n",
      "336.4741253773682\n",
      "Epoch: 1... Training loss: 0.91879... Test loss: 0.24945\n",
      "Epoch: 1... Training loss: 0.44947... Test loss: 0.13972\n",
      "Epoch: 1... Training loss: 0.30722... Test loss: 0.0966\n",
      "Epoch: 1... Training loss: 0.2087... Test loss: 0.07827\n",
      "Epoch: 1... Training loss: 0.14578... Test loss: 0.06517\n",
      "Epoch: 1... Training loss: 0.11836... Test loss: 0.03989\n",
      "Epoch: 1... Training loss: 0.09838... Test loss: 0.06639\n",
      "Epoch: 1... Training loss: 0.0904... Test loss: 0.02768\n",
      "Epoch: 1... Training loss: 0.07756... Test loss: 0.05359\n",
      "Epoch: 1... Training loss: 0.06382... Test loss: 0.0275\n",
      "Epoch: 1... Training loss: 0.05583... Test loss: 0.03626\n",
      "Epoch: 1... Training loss: 0.04804... Test loss: 0.04523\n",
      "Epoch: 1... Training loss: 0.04666... Test loss: 0.01914\n",
      "Epoch: 1... Training loss: 0.03943... Test loss: 0.03625\n",
      "Epoch: 1... Training loss: 0.03715... Test loss: 0.01435\n",
      "Epoch: 1... Training loss: 0.03424... Test loss: 0.03043\n",
      "Epoch: 1... Training loss: 0.0328... Test loss: 0.01352\n",
      "Epoch: 1... Training loss: 0.03026... Test loss: 0.024\n",
      "Epoch: 1... Training loss: 0.02823... Test loss: 0.01225\n",
      "Epoch: 1... Training loss: 0.02607... Test loss: 0.0211\n",
      "Epoch: 1... Training loss: 0.0245... Test loss: 0.01549\n",
      "Epoch: 1... Training loss: 0.02357... Test loss: 0.01744\n",
      "Epoch: 1... Training loss: 0.02211... Test loss: 0.01735\n",
      "Epoch: 1... Training loss: 0.02128... Test loss: 0.0168\n",
      "Epoch: 1... Training loss: 0.01999... Test loss: 0.01886\n",
      "Epoch: 1... Training loss: 0.01988... Test loss: 0.0123\n",
      "Epoch: 1... Training loss: 0.01859... Test loss: 0.02216\n",
      "Epoch: 1... Training loss: 0.01848... Test loss: 0.01124\n",
      "Epoch: 1... Training loss: 0.0171... Test loss: 0.01959\n",
      "Epoch: 1... Training loss: 0.01612... Test loss: 0.01335\n",
      "Epoch: 1... Training loss: 0.01576... Test loss: 0.01498\n",
      "Epoch: 1... Training loss: 0.01473... Test loss: 0.01259\n",
      "Epoch: 1... Training loss: 0.01408... Test loss: 0.01209\n",
      "Epoch: 1... Training loss: 0.01336... Test loss: 0.01167\n",
      "Epoch: 1... Training loss: 0.01318... Test loss: 0.00965\n",
      "Epoch: 1... Training loss: 0.01246... Test loss: 0.01217\n",
      "Epoch: 1... Training loss: 0.01204... Test loss: 0.00923\n",
      "Epoch: 1... Training loss: 0.01153... Test loss: 0.01174\n",
      "Epoch: 1... Training loss: 0.01122... Test loss: 0.00843\n",
      "Epoch: 1... Training loss: 0.01088... Test loss: 0.01268\n",
      "Epoch: 1... Training loss: 0.01063... Test loss: 0.00689\n",
      "Epoch: 1... Training loss: 0.01022... Test loss: 0.01202\n",
      "Epoch: 1... Training loss: 0.0099... Test loss: 0.00711\n",
      "Epoch: 1... Training loss: 0.00956... Test loss: 0.01069\n",
      "Epoch: 1... Training loss: 0.00943... Test loss: 0.00632\n",
      "Epoch: 1... Training loss: 0.00909... Test loss: 0.00962\n",
      "Epoch: 1... Training loss: 0.00888... Test loss: 0.00608\n",
      "Epoch: 1... Training loss: 0.00869... Test loss: 0.00819\n",
      "Epoch: 1... Training loss: 0.00834... Test loss: 0.00629\n",
      "Epoch: 1... Training loss: 0.00802... Test loss: 0.00686\n",
      "Epoch: 1... Training loss: 0.00784... Test loss: 0.00643\n",
      "Epoch: 1... Training loss: 0.00774... Test loss: 0.00686\n",
      "Epoch: 1... Training loss: 0.0075... Test loss: 0.00728\n",
      "Epoch: 1... Training loss: 0.00728... Test loss: 0.00662\n",
      "Epoch: 1... Training loss: 0.00713... Test loss: 0.00762\n",
      "Epoch: 1... Training loss: 0.00701... Test loss: 0.00584\n",
      "Epoch: 1... Training loss: 0.00679... Test loss: 0.00663\n",
      "Epoch: 1... Training loss: 0.00674... Test loss: 0.00535\n",
      "Epoch: 1... Training loss: 0.00642... Test loss: 0.00566\n",
      "Epoch: 1... Training loss: 0.00634... Test loss: 0.00583\n",
      "Epoch: 1... Training loss: 0.00607... Test loss: 0.00527\n",
      "Epoch: 1... Training loss: 0.00597... Test loss: 0.00613\n",
      "Epoch: 1... Training loss: 0.00583... Test loss: 0.00453\n",
      "Epoch: 1... Training loss: 0.00578... Test loss: 0.00587\n",
      "Epoch: 1... Training loss: 0.01566... Test loss: 0.0123\n",
      "Epoch: 1... Training loss: 0.01641... Test loss: 0.01109\n",
      "Epoch: 1... Training loss: 0.01013... Test loss: 0.00875\n",
      "Epoch: 1... Training loss: 0.00997... Test loss: 0.01263\n",
      "Epoch: 1... Training loss: 0.00981... Test loss: 0.00862\n",
      "Epoch: 1... Training loss: 0.01243... Test loss: 0.0131\n",
      "Epoch: 1... Training loss: 0.01074... Test loss: 0.01251\n",
      "Epoch: 1... Training loss: 0.00949... Test loss: 0.0121\n",
      "Epoch: 1... Training loss: 0.0082... Test loss: 0.01097\n",
      "Epoch: 1... Training loss: 0.00902... Test loss: 0.01283\n",
      "Epoch: 1... Training loss: 0.00858... Test loss: 0.01243\n",
      "Epoch: 1... Training loss: 0.00895... Test loss: 0.01099\n",
      "Epoch: 1... Training loss: 0.00886... Test loss: 0.00934\n",
      "Epoch: 1... Training loss: 0.00795... Test loss: 0.0096\n",
      "Epoch: 1... Training loss: 0.00737... Test loss: 0.00686\n",
      "Epoch: 1... Training loss: 0.00716... Test loss: 0.00967\n",
      "Epoch: 1... Training loss: 0.00719... Test loss: 0.00682\n",
      "Epoch: 1... Training loss: 0.00696... Test loss: 0.00845\n",
      "Epoch: 1... Training loss: 0.00653... Test loss: 0.00633\n",
      "Epoch: 1... Training loss: 0.00643... Test loss: 0.00779\n",
      "Epoch: 1... Training loss: 0.00617... Test loss: 0.00736\n",
      "Epoch: 1... Training loss: 0.00595... Test loss: 0.00663\n",
      "Epoch: 1... Training loss: 0.00615... Test loss: 0.00575\n",
      "Epoch: 1... Training loss: 0.00597... Test loss: 0.00641\n",
      "Epoch: 1... Training loss: 0.00543... Test loss: 0.00657\n",
      "Epoch: 1... Training loss: 0.00546... Test loss: 0.00621\n",
      "Epoch: 1... Training loss: 0.0053... Test loss: 0.00573\n",
      "Epoch: 1... Training loss: 0.00493... Test loss: 0.0059\n",
      "Epoch: 1... Training loss: 0.00493... Test loss: 0.00524\n",
      "Epoch: 1... Training loss: 0.0049... Test loss: 0.0051\n",
      "Epoch: 1... Training loss: 0.00476... Test loss: 0.00458\n",
      "Epoch: 1... Training loss: 0.00487... Test loss: 0.00514\n",
      "Epoch: 1... Training loss: 0.00445... Test loss: 0.00373\n",
      "Epoch: 1... Training loss: 0.00438... Test loss: 0.00497\n",
      "Epoch: 1... Training loss: 0.00419... Test loss: 0.00414\n",
      "Epoch: 1... Training loss: 0.00401... Test loss: 0.00457\n",
      "Epoch: 1... Training loss: 0.00414... Test loss: 0.00344\n",
      "Epoch: 1... Training loss: 0.00387... Test loss: 0.00414\n",
      "Epoch: 1... Training loss: 0.00391... Test loss: 0.00366\n",
      "Epoch: 1... Training loss: 0.00369... Test loss: 0.00432\n",
      "Epoch: 1... Training loss: 0.00356... Test loss: 0.00319\n",
      "Epoch: 1... Training loss: 0.00343... Test loss: 0.00434\n",
      "Epoch: 1... Training loss: 0.00348... Test loss: 0.00314\n",
      "Epoch: 1... Training loss: 0.00334... Test loss: 0.00443\n",
      "Epoch: 1... Training loss: 0.00322... Test loss: 0.00293\n",
      "Epoch: 1... Training loss: 0.00324... Test loss: 0.00385\n",
      "Epoch: 1... Training loss: 0.00326... Test loss: 0.00331\n",
      "Epoch: 1... Training loss: 0.00309... Test loss: 0.00357\n",
      "Epoch: 1... Training loss: 0.00311... Test loss: 0.00354\n",
      "Epoch: 1... Training loss: 0.00286... Test loss: 0.00344\n",
      "Epoch: 1... Training loss: 0.00295... Test loss: 0.00317\n",
      "Epoch: 1... Training loss: 0.00277... Test loss: 0.00327\n",
      "Epoch: 1... Training loss: 0.00279... Test loss: 0.00311\n",
      "Epoch: 1... Training loss: 0.00269... Test loss: 0.00302\n",
      "Epoch: 1... Training loss: 0.00256... Test loss: 0.00309\n",
      "Epoch: 1... Training loss: 0.0027... Test loss: 0.00309\n",
      "Epoch: 1... Training loss: 0.00254... Test loss: 0.00299\n",
      "Epoch: 1... Training loss: 0.00251... Test loss: 0.00313\n",
      "Epoch: 1... Training loss: 0.00243... Test loss: 0.00266\n",
      "Epoch: 1... Training loss: 0.0024... Test loss: 0.00269\n",
      "Epoch: 1... Training loss: 0.00237... Test loss: 0.00292\n",
      "Epoch: 1... Training loss: 0.00236... Test loss: 0.00255\n",
      "Epoch: 1... Training loss: 0.00211... Test loss: 0.00277\n",
      "Epoch: 1... Training loss: 0.00209... Test loss: 0.00249\n",
      "Epoch: 1... Training loss: 0.00198... Test loss: 0.00248\n",
      "Epoch: 1... Training loss: 0.00211... Test loss: 0.0023\n",
      "Epoch: 1... Training loss: 0.00193... Test loss: 0.00219\n",
      "Epoch: 1... Training loss: 0.00205... Test loss: 0.00214\n",
      "Epoch: 1... Training loss: 0.00195... Test loss: 0.00197\n",
      "Epoch: 1... Training loss: 0.00205... Test loss: 0.00202\n",
      "Epoch: 1... Training loss: 0.00192... Test loss: 0.00224\n",
      "Epoch: 1... Training loss: 0.00186... Test loss: 0.00185\n",
      "Epoch: 1... Training loss: 0.00185... Test loss: 0.00209\n",
      "Epoch: 1... Training loss: 0.00172... Test loss: 0.00171\n",
      "Epoch: 1... Training loss: 0.00167... Test loss: 0.00172\n",
      "Epoch: 1... Training loss: 0.00175... Test loss: 0.0016\n",
      "Epoch: 1... Training loss: 0.00157... Test loss: 0.0018\n",
      "Epoch: 1... Training loss: 0.00158... Test loss: 0.00155\n",
      "Epoch: 1... Training loss: 0.00155... Test loss: 0.00157\n",
      "Epoch: 1... Training loss: 0.0015... Test loss: 0.00147\n",
      "Epoch: 1... Training loss: 0.00146... Test loss: 0.00144\n",
      "Epoch: 1... Training loss: 0.00144... Test loss: 0.00138\n",
      "Epoch: 1... Training loss: 0.00142... Test loss: 0.00144\n",
      "Epoch: 1... Training loss: 0.00136... Test loss: 0.00133\n",
      "Epoch: 1... Training loss: 0.00135... Test loss: 0.0014\n",
      "Epoch: 1... Training loss: 0.00126... Test loss: 0.00137\n",
      "Epoch: 1... Training loss: 0.00126... Test loss: 0.00127\n",
      "Epoch: 1... Training loss: 0.00117... Test loss: 0.0013\n",
      "Epoch: 1... Training loss: 0.00125... Test loss: 0.00134\n",
      "Epoch: 1... Training loss: 0.00118... Test loss: 0.00112\n",
      "Epoch: 1... Training loss: 0.00116... Test loss: 0.00124\n",
      "Epoch: 1... Training loss: 0.00117... Test loss: 0.00111\n",
      "Epoch: 1... Training loss: 0.00102... Test loss: 0.00112\n",
      "Epoch: 1... Training loss: 0.001... Test loss: 0.00098\n",
      "Epoch: 1... Training loss: 0.00099... Test loss: 0.00102\n",
      "Epoch: 1... Training loss: 0.00098... Test loss: 0.00089\n",
      "Epoch: 1... Training loss: 0.00093... Test loss: 0.00104\n",
      "Epoch: 1... Training loss: 0.00094... Test loss: 0.0009\n",
      "Epoch: 1... Training loss: 0.00099... Test loss: 0.0011\n",
      "Epoch: 1... Training loss: 0.00088... Test loss: 0.00094\n",
      "Epoch: 1... Training loss: 0.00073... Test loss: 0.00093\n",
      "Epoch: 1... Training loss: 0.00072... Test loss: 0.00088\n",
      "Epoch: 1... Training loss: 0.00072... Test loss: 0.00083\n",
      "Epoch: 1... Training loss: 0.00077... Test loss: 0.00077\n",
      "Epoch: 1... Training loss: 0.00065... Test loss: 0.00079\n",
      "Epoch: 1... Training loss: 0.00068... Test loss: 0.00071\n",
      "Epoch: 1... Training loss: 0.00061... Test loss: 0.00067\n",
      "Epoch: 1... Training loss: 0.0006... Test loss: 0.00064\n",
      "Epoch: 1... Training loss: 0.00056... Test loss: 0.00061\n",
      "Epoch: 1... Training loss: 0.00053... Test loss: 0.00055\n",
      "Epoch: 1... Training loss: 0.00056... Test loss: 0.00072\n",
      "Epoch: 1... Training loss: 0.0005... Test loss: 0.00048\n",
      "Epoch: 1... Training loss: 0.00051... Test loss: 0.00063\n",
      "Epoch: 1... Training loss: 0.00047... Test loss: 0.00055\n",
      "Epoch: 1... Training loss: 0.00047... Test loss: 0.0005\n",
      "Epoch: 1... Training loss: 0.00045... Test loss: 0.00043\n",
      "Epoch: 1... Training loss: 0.00042... Test loss: 0.0005\n",
      "Epoch: 1... Training loss: 0.00043... Test loss: 0.00042\n",
      "Epoch: 1... Training loss: 0.00038... Test loss: 0.00048\n",
      "Epoch: 1... Training loss: 0.00035... Test loss: 0.00034\n",
      "Epoch: 1... Training loss: 0.00036... Test loss: 0.00041\n",
      "Epoch: 1... Training loss: 0.00034... Test loss: 0.00031\n",
      "Epoch: 1... Training loss: 0.00037... Test loss: 0.00039\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00028\n",
      "Epoch: 1... Training loss: 0.00034... Test loss: 0.00038\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00024\n",
      "Epoch: 1... Training loss: 0.00026... Test loss: 0.00037\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00039\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00031\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00024\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00024\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00018\n",
      "280.94214813259896\n",
      "Epoch: 1... Training loss: 0.913... Test loss: 0.25682\n",
      "Epoch: 1... Training loss: 0.42013... Test loss: 0.09634\n",
      "Epoch: 1... Training loss: 0.27401... Test loss: 0.06057\n",
      "Epoch: 1... Training loss: 0.20191... Test loss: 0.05287\n",
      "Epoch: 1... Training loss: 0.15477... Test loss: 0.03844\n",
      "Epoch: 1... Training loss: 0.12363... Test loss: 0.03374\n",
      "Epoch: 1... Training loss: 0.10363... Test loss: 0.04809\n",
      "Epoch: 1... Training loss: 0.082... Test loss: 0.03879\n",
      "Epoch: 1... Training loss: 0.0737... Test loss: 0.02175\n",
      "Epoch: 1... Training loss: 0.06308... Test loss: 0.03846\n",
      "Epoch: 1... Training loss: 0.05713... Test loss: 0.0139\n",
      "Epoch: 1... Training loss: 0.0518... Test loss: 0.02889\n",
      "Epoch: 1... Training loss: 0.0471... Test loss: 0.01992\n",
      "Epoch: 1... Training loss: 0.04424... Test loss: 0.03107\n",
      "Epoch: 1... Training loss: 0.04177... Test loss: 0.03899\n",
      "Epoch: 1... Training loss: 0.03911... Test loss: 0.01407\n",
      "Epoch: 1... Training loss: 0.03578... Test loss: 0.03606\n",
      "Epoch: 1... Training loss: 0.03317... Test loss: 0.01698\n",
      "Epoch: 1... Training loss: 0.03051... Test loss: 0.03371\n",
      "Epoch: 1... Training loss: 0.02866... Test loss: 0.01706\n",
      "Epoch: 1... Training loss: 0.02651... Test loss: 0.03488\n",
      "Epoch: 1... Training loss: 0.02551... Test loss: 0.01517\n",
      "Epoch: 1... Training loss: 0.02304... Test loss: 0.03208\n",
      "Epoch: 1... Training loss: 0.02177... Test loss: 0.016\n",
      "Epoch: 1... Training loss: 0.02065... Test loss: 0.02536\n",
      "Epoch: 1... Training loss: 0.01945... Test loss: 0.0153\n",
      "Epoch: 1... Training loss: 0.01835... Test loss: 0.02503\n",
      "Epoch: 1... Training loss: 0.01802... Test loss: 0.01249\n",
      "Epoch: 1... Training loss: 0.01725... Test loss: 0.01779\n",
      "Epoch: 1... Training loss: 0.016... Test loss: 0.01576\n",
      "Epoch: 1... Training loss: 0.01539... Test loss: 0.01977\n",
      "Epoch: 1... Training loss: 0.01448... Test loss: 0.01124\n",
      "Epoch: 1... Training loss: 0.01371... Test loss: 0.01469\n",
      "Epoch: 1... Training loss: 0.01339... Test loss: 0.0125\n",
      "Epoch: 1... Training loss: 0.01288... Test loss: 0.01273\n",
      "Epoch: 1... Training loss: 0.0124... Test loss: 0.0079\n",
      "Epoch: 1... Training loss: 0.01184... Test loss: 0.01231\n",
      "Epoch: 1... Training loss: 0.01143... Test loss: 0.00849\n",
      "Epoch: 1... Training loss: 0.01108... Test loss: 0.01177\n",
      "Epoch: 1... Training loss: 0.0107... Test loss: 0.00787\n",
      "Epoch: 1... Training loss: 0.0104... Test loss: 0.00919\n",
      "Epoch: 1... Training loss: 0.0101... Test loss: 0.00723\n",
      "Epoch: 1... Training loss: 0.00996... Test loss: 0.00779\n",
      "Epoch: 1... Training loss: 0.00961... Test loss: 0.00751\n",
      "Epoch: 1... Training loss: 0.00938... Test loss: 0.00747\n",
      "Epoch: 1... Training loss: 0.0092... Test loss: 0.00839\n",
      "Epoch: 1... Training loss: 0.00894... Test loss: 0.00667\n",
      "Epoch: 1... Training loss: 0.00874... Test loss: 0.00856\n",
      "Epoch: 1... Training loss: 0.0085... Test loss: 0.00563\n",
      "Epoch: 1... Training loss: 0.00825... Test loss: 0.00824\n",
      "Epoch: 1... Training loss: 0.00802... Test loss: 0.00493\n",
      "Epoch: 1... Training loss: 0.00771... Test loss: 0.00798\n",
      "Epoch: 1... Training loss: 0.00761... Test loss: 0.00542\n",
      "Epoch: 1... Training loss: 0.00736... Test loss: 0.00764\n",
      "Epoch: 1... Training loss: 0.00723... Test loss: 0.0054\n",
      "Epoch: 1... Training loss: 0.00709... Test loss: 0.00739\n",
      "Epoch: 1... Training loss: 0.00691... Test loss: 0.00513\n",
      "Epoch: 1... Training loss: 0.00678... Test loss: 0.00619\n",
      "Epoch: 1... Training loss: 0.00662... Test loss: 0.0053\n",
      "Epoch: 1... Training loss: 0.0064... Test loss: 0.00541\n",
      "Epoch: 1... Training loss: 0.00628... Test loss: 0.00626\n",
      "Epoch: 1... Training loss: 0.00611... Test loss: 0.00631\n",
      "Epoch: 1... Training loss: 0.00595... Test loss: 0.00653\n",
      "Epoch: 1... Training loss: 0.00578... Test loss: 0.00578\n",
      "Epoch: 1... Training loss: 0.01403... Test loss: 0.01682\n",
      "Epoch: 1... Training loss: 0.01029... Test loss: 0.01532\n",
      "Epoch: 1... Training loss: 0.0108... Test loss: 0.01243\n",
      "Epoch: 1... Training loss: 0.01155... Test loss: 0.00939\n",
      "Epoch: 1... Training loss: 0.01057... Test loss: 0.01156\n",
      "Epoch: 1... Training loss: 0.01024... Test loss: 0.0095\n",
      "Epoch: 1... Training loss: 0.01008... Test loss: 0.01092\n",
      "Epoch: 1... Training loss: 0.00915... Test loss: 0.00981\n",
      "Epoch: 1... Training loss: 0.01013... Test loss: 0.01113\n",
      "Epoch: 1... Training loss: 0.00951... Test loss: 0.00922\n",
      "Epoch: 1... Training loss: 0.00814... Test loss: 0.01233\n",
      "Epoch: 1... Training loss: 0.00851... Test loss: 0.00926\n",
      "Epoch: 1... Training loss: 0.00857... Test loss: 0.01182\n",
      "Epoch: 1... Training loss: 0.00767... Test loss: 0.00922\n",
      "Epoch: 1... Training loss: 0.00759... Test loss: 0.01086\n",
      "Epoch: 1... Training loss: 0.00709... Test loss: 0.00944\n",
      "Epoch: 1... Training loss: 0.00697... Test loss: 0.00804\n",
      "Epoch: 1... Training loss: 0.00678... Test loss: 0.00926\n",
      "Epoch: 1... Training loss: 0.00651... Test loss: 0.00712\n",
      "Epoch: 1... Training loss: 0.00646... Test loss: 0.00818\n",
      "Epoch: 1... Training loss: 0.00619... Test loss: 0.00724\n",
      "Epoch: 1... Training loss: 0.0057... Test loss: 0.00865\n",
      "Epoch: 1... Training loss: 0.0061... Test loss: 0.00569\n",
      "Epoch: 1... Training loss: 0.0057... Test loss: 0.0075\n",
      "Epoch: 1... Training loss: 0.00549... Test loss: 0.00597\n",
      "Epoch: 1... Training loss: 0.00574... Test loss: 0.00708\n",
      "Epoch: 1... Training loss: 0.00514... Test loss: 0.0058\n",
      "Epoch: 1... Training loss: 0.00487... Test loss: 0.00742\n",
      "Epoch: 1... Training loss: 0.00486... Test loss: 0.00514\n",
      "Epoch: 1... Training loss: 0.00466... Test loss: 0.00668\n",
      "Epoch: 1... Training loss: 0.00463... Test loss: 0.0045\n",
      "Epoch: 1... Training loss: 0.00439... Test loss: 0.00573\n",
      "Epoch: 1... Training loss: 0.00425... Test loss: 0.00435\n",
      "Epoch: 1... Training loss: 0.00426... Test loss: 0.00556\n",
      "Epoch: 1... Training loss: 0.00412... Test loss: 0.00418\n",
      "Epoch: 1... Training loss: 0.00396... Test loss: 0.00535\n",
      "Epoch: 1... Training loss: 0.0039... Test loss: 0.00391\n",
      "Epoch: 1... Training loss: 0.00375... Test loss: 0.00456\n",
      "Epoch: 1... Training loss: 0.00377... Test loss: 0.00354\n",
      "Epoch: 1... Training loss: 0.00367... Test loss: 0.00491\n",
      "Epoch: 1... Training loss: 0.00355... Test loss: 0.00336\n",
      "Epoch: 1... Training loss: 0.00344... Test loss: 0.00473\n",
      "Epoch: 1... Training loss: 0.00343... Test loss: 0.00342\n",
      "Epoch: 1... Training loss: 0.00338... Test loss: 0.00374\n",
      "Epoch: 1... Training loss: 0.00327... Test loss: 0.00348\n",
      "Epoch: 1... Training loss: 0.00325... Test loss: 0.00334\n",
      "Epoch: 1... Training loss: 0.00322... Test loss: 0.00344\n",
      "Epoch: 1... Training loss: 0.00306... Test loss: 0.00369\n",
      "Epoch: 1... Training loss: 0.00308... Test loss: 0.0027\n",
      "Epoch: 1... Training loss: 0.00302... Test loss: 0.00379\n",
      "Epoch: 1... Training loss: 0.00296... Test loss: 0.00288\n",
      "Epoch: 1... Training loss: 0.00298... Test loss: 0.0034\n",
      "Epoch: 1... Training loss: 0.00275... Test loss: 0.00271\n",
      "Epoch: 1... Training loss: 0.00278... Test loss: 0.00327\n",
      "Epoch: 1... Training loss: 0.00267... Test loss: 0.00268\n",
      "Epoch: 1... Training loss: 0.00259... Test loss: 0.00288\n",
      "Epoch: 1... Training loss: 0.00256... Test loss: 0.00238\n",
      "Epoch: 1... Training loss: 0.00254... Test loss: 0.0026\n",
      "Epoch: 1... Training loss: 0.00264... Test loss: 0.00215\n",
      "Epoch: 1... Training loss: 0.00236... Test loss: 0.00289\n",
      "Epoch: 1... Training loss: 0.00239... Test loss: 0.00224\n",
      "Epoch: 1... Training loss: 0.00241... Test loss: 0.0024\n",
      "Epoch: 1... Training loss: 0.00227... Test loss: 0.0025\n",
      "Epoch: 1... Training loss: 0.00215... Test loss: 0.00246\n",
      "Epoch: 1... Training loss: 0.00229... Test loss: 0.00224\n",
      "Epoch: 1... Training loss: 0.00221... Test loss: 0.00231\n",
      "Epoch: 1... Training loss: 0.00208... Test loss: 0.0022\n",
      "Epoch: 1... Training loss: 0.00201... Test loss: 0.00225\n",
      "Epoch: 1... Training loss: 0.00214... Test loss: 0.00196\n",
      "Epoch: 1... Training loss: 0.00195... Test loss: 0.00234\n",
      "Epoch: 1... Training loss: 0.00196... Test loss: 0.00187\n",
      "Epoch: 1... Training loss: 0.00197... Test loss: 0.00199\n",
      "Epoch: 1... Training loss: 0.00194... Test loss: 0.00181\n",
      "Epoch: 1... Training loss: 0.00185... Test loss: 0.00218\n",
      "Epoch: 1... Training loss: 0.00185... Test loss: 0.00175\n",
      "Epoch: 1... Training loss: 0.00177... Test loss: 0.00212\n",
      "Epoch: 1... Training loss: 0.00169... Test loss: 0.00154\n",
      "Epoch: 1... Training loss: 0.00166... Test loss: 0.00201\n",
      "Epoch: 1... Training loss: 0.00164... Test loss: 0.00155\n",
      "Epoch: 1... Training loss: 0.00163... Test loss: 0.00168\n",
      "Epoch: 1... Training loss: 0.00147... Test loss: 0.00141\n",
      "Epoch: 1... Training loss: 0.00151... Test loss: 0.00166\n",
      "Epoch: 1... Training loss: 0.00145... Test loss: 0.00139\n",
      "Epoch: 1... Training loss: 0.00141... Test loss: 0.00149\n",
      "Epoch: 1... Training loss: 0.00136... Test loss: 0.00127\n",
      "Epoch: 1... Training loss: 0.00138... Test loss: 0.00137\n",
      "Epoch: 1... Training loss: 0.00132... Test loss: 0.00137\n",
      "Epoch: 1... Training loss: 0.0014... Test loss: 0.00121\n",
      "Epoch: 1... Training loss: 0.00124... Test loss: 0.00139\n",
      "Epoch: 1... Training loss: 0.00119... Test loss: 0.00118\n",
      "Epoch: 1... Training loss: 0.00117... Test loss: 0.00123\n",
      "Epoch: 1... Training loss: 0.00115... Test loss: 0.00127\n",
      "Epoch: 1... Training loss: 0.00102... Test loss: 0.00134\n",
      "Epoch: 1... Training loss: 0.00104... Test loss: 0.00116\n",
      "Epoch: 1... Training loss: 0.00103... Test loss: 0.00124\n",
      "Epoch: 1... Training loss: 0.00097... Test loss: 0.00108\n",
      "Epoch: 1... Training loss: 0.00088... Test loss: 0.0013\n",
      "Epoch: 1... Training loss: 0.0009... Test loss: 0.00093\n",
      "Epoch: 1... Training loss: 0.00089... Test loss: 0.00103\n",
      "Epoch: 1... Training loss: 0.0008... Test loss: 0.00086\n",
      "Epoch: 1... Training loss: 0.00083... Test loss: 0.00083\n",
      "Epoch: 1... Training loss: 0.00082... Test loss: 0.00079\n",
      "Epoch: 1... Training loss: 0.00071... Test loss: 0.00086\n",
      "Epoch: 1... Training loss: 0.00068... Test loss: 0.00087\n",
      "Epoch: 1... Training loss: 0.00066... Test loss: 0.00078\n",
      "Epoch: 1... Training loss: 0.00065... Test loss: 0.00072\n",
      "Epoch: 1... Training loss: 0.00056... Test loss: 0.00063\n",
      "Epoch: 1... Training loss: 0.00059... Test loss: 0.00055\n",
      "Epoch: 1... Training loss: 0.00052... Test loss: 0.00062\n",
      "Epoch: 1... Training loss: 0.00055... Test loss: 0.0005\n",
      "Epoch: 1... Training loss: 0.00054... Test loss: 0.00051\n",
      "Epoch: 1... Training loss: 0.00054... Test loss: 0.00048\n",
      "Epoch: 1... Training loss: 0.0005... Test loss: 0.00048\n",
      "Epoch: 1... Training loss: 0.00053... Test loss: 0.00049\n",
      "Epoch: 1... Training loss: 0.0005... Test loss: 0.00043\n",
      "Epoch: 1... Training loss: 0.00044... Test loss: 0.00041\n",
      "Epoch: 1... Training loss: 0.00044... Test loss: 0.00034\n",
      "Epoch: 1... Training loss: 0.00043... Test loss: 0.00041\n",
      "Epoch: 1... Training loss: 0.00041... Test loss: 0.00031\n",
      "Epoch: 1... Training loss: 0.00039... Test loss: 0.00049\n",
      "Epoch: 1... Training loss: 0.00041... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00037... Test loss: 0.00045\n",
      "Epoch: 1... Training loss: 0.00034... Test loss: 0.00032\n",
      "Epoch: 1... Training loss: 0.00035... Test loss: 0.00042\n",
      "Epoch: 1... Training loss: 0.00036... Test loss: 0.00034\n",
      "Epoch: 1... Training loss: 0.00031... Test loss: 0.00042\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.0003\n",
      "Epoch: 1... Training loss: 0.00029... Test loss: 0.00041\n",
      "Epoch: 1... Training loss: 0.00029... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00026... Test loss: 0.00042\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00032\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00022\n",
      "288.54072343208827\n",
      "Epoch: 1... Training loss: 0.91578... Test loss: 0.25154\n",
      "Epoch: 1... Training loss: 0.47459... Test loss: 0.12117\n",
      "Epoch: 1... Training loss: 0.31874... Test loss: 0.08523\n",
      "Epoch: 1... Training loss: 0.22738... Test loss: 0.06349\n",
      "Epoch: 1... Training loss: 0.17187... Test loss: 0.0435\n",
      "Epoch: 1... Training loss: 0.12874... Test loss: 0.03211\n",
      "Epoch: 1... Training loss: 0.11051... Test loss: 0.02748\n",
      "Epoch: 1... Training loss: 0.08369... Test loss: 0.0245\n",
      "Epoch: 1... Training loss: 0.07117... Test loss: 0.03037\n",
      "Epoch: 1... Training loss: 0.06478... Test loss: 0.01987\n",
      "Epoch: 1... Training loss: 0.05747... Test loss: 0.04179\n",
      "Epoch: 1... Training loss: 0.0555... Test loss: 0.01247\n",
      "Epoch: 1... Training loss: 0.04493... Test loss: 0.03093\n",
      "Epoch: 1... Training loss: 0.0413... Test loss: 0.01031\n",
      "Epoch: 1... Training loss: 0.03826... Test loss: 0.0234\n",
      "Epoch: 1... Training loss: 0.036... Test loss: 0.0118\n",
      "Epoch: 1... Training loss: 0.03222... Test loss: 0.02421\n",
      "Epoch: 1... Training loss: 0.0297... Test loss: 0.01541\n",
      "Epoch: 1... Training loss: 0.02684... Test loss: 0.02105\n",
      "Epoch: 1... Training loss: 0.02612... Test loss: 0.01364\n",
      "Epoch: 1... Training loss: 0.02452... Test loss: 0.02374\n",
      "Epoch: 1... Training loss: 0.02371... Test loss: 0.01182\n",
      "Epoch: 1... Training loss: 0.02211... Test loss: 0.02784\n",
      "Epoch: 1... Training loss: 0.02074... Test loss: 0.0116\n",
      "Epoch: 1... Training loss: 0.01942... Test loss: 0.02691\n",
      "Epoch: 1... Training loss: 0.01831... Test loss: 0.01075\n",
      "Epoch: 1... Training loss: 0.01744... Test loss: 0.02185\n",
      "Epoch: 1... Training loss: 0.01687... Test loss: 0.01128\n",
      "Epoch: 1... Training loss: 0.01592... Test loss: 0.01921\n",
      "Epoch: 1... Training loss: 0.0155... Test loss: 0.01232\n",
      "Epoch: 1... Training loss: 0.01497... Test loss: 0.01434\n",
      "Epoch: 1... Training loss: 0.01428... Test loss: 0.01737\n",
      "Epoch: 1... Training loss: 0.01365... Test loss: 0.00801\n",
      "Epoch: 1... Training loss: 0.0131... Test loss: 0.01881\n",
      "Epoch: 1... Training loss: 0.01245... Test loss: 0.0075\n",
      "Epoch: 1... Training loss: 0.01225... Test loss: 0.01392\n",
      "Epoch: 1... Training loss: 0.01193... Test loss: 0.00795\n",
      "Epoch: 1... Training loss: 0.01146... Test loss: 0.01256\n",
      "Epoch: 1... Training loss: 0.01133... Test loss: 0.00676\n",
      "Epoch: 1... Training loss: 0.01065... Test loss: 0.01266\n",
      "Epoch: 1... Training loss: 0.01071... Test loss: 0.00711\n",
      "Epoch: 1... Training loss: 0.01019... Test loss: 0.01097\n",
      "Epoch: 1... Training loss: 0.0101... Test loss: 0.00674\n",
      "Epoch: 1... Training loss: 0.00971... Test loss: 0.00838\n",
      "Epoch: 1... Training loss: 0.0095... Test loss: 0.00923\n",
      "Epoch: 1... Training loss: 0.00921... Test loss: 0.00525\n",
      "Epoch: 1... Training loss: 0.0091... Test loss: 0.01009\n",
      "Epoch: 1... Training loss: 0.00876... Test loss: 0.0046\n",
      "Epoch: 1... Training loss: 0.00865... Test loss: 0.00908\n",
      "Epoch: 1... Training loss: 0.00822... Test loss: 0.00479\n",
      "Epoch: 1... Training loss: 0.00824... Test loss: 0.00777\n",
      "Epoch: 1... Training loss: 0.00795... Test loss: 0.00626\n",
      "Epoch: 1... Training loss: 0.00773... Test loss: 0.00628\n",
      "Epoch: 1... Training loss: 0.00745... Test loss: 0.00723\n",
      "Epoch: 1... Training loss: 0.00724... Test loss: 0.00473\n",
      "Epoch: 1... Training loss: 0.00697... Test loss: 0.00705\n",
      "Epoch: 1... Training loss: 0.00698... Test loss: 0.00469\n",
      "Epoch: 1... Training loss: 0.00665... Test loss: 0.00684\n",
      "Epoch: 1... Training loss: 0.00657... Test loss: 0.00446\n",
      "Epoch: 1... Training loss: 0.00637... Test loss: 0.00669\n",
      "Epoch: 1... Training loss: 0.00626... Test loss: 0.00507\n",
      "Epoch: 1... Training loss: 0.00608... Test loss: 0.00657\n",
      "Epoch: 1... Training loss: 0.00593... Test loss: 0.00583\n",
      "Epoch: 1... Training loss: 0.00575... Test loss: 0.00602\n",
      "Epoch: 1... Training loss: 0.01549... Test loss: 0.01543\n",
      "Epoch: 1... Training loss: 0.01363... Test loss: 0.01241\n",
      "Epoch: 1... Training loss: 0.01134... Test loss: 0.01272\n",
      "Epoch: 1... Training loss: 0.00992... Test loss: 0.01007\n",
      "Epoch: 1... Training loss: 0.01134... Test loss: 0.01254\n",
      "Epoch: 1... Training loss: 0.00988... Test loss: 0.01322\n",
      "Epoch: 1... Training loss: 0.00979... Test loss: 0.01363\n",
      "Epoch: 1... Training loss: 0.00926... Test loss: 0.01288\n",
      "Epoch: 1... Training loss: 0.00866... Test loss: 0.01122\n",
      "Epoch: 1... Training loss: 0.00881... Test loss: 0.01069\n",
      "Epoch: 1... Training loss: 0.0077... Test loss: 0.00987\n",
      "Epoch: 1... Training loss: 0.00792... Test loss: 0.00857\n",
      "Epoch: 1... Training loss: 0.00812... Test loss: 0.0103\n",
      "Epoch: 1... Training loss: 0.00708... Test loss: 0.00814\n",
      "Epoch: 1... Training loss: 0.00695... Test loss: 0.01068\n",
      "Epoch: 1... Training loss: 0.00685... Test loss: 0.00742\n",
      "Epoch: 1... Training loss: 0.00742... Test loss: 0.00952\n",
      "Epoch: 1... Training loss: 0.00696... Test loss: 0.00687\n",
      "Epoch: 1... Training loss: 0.00644... Test loss: 0.00859\n",
      "Epoch: 1... Training loss: 0.0061... Test loss: 0.00677\n",
      "Epoch: 1... Training loss: 0.00584... Test loss: 0.00752\n",
      "Epoch: 1... Training loss: 0.00582... Test loss: 0.00692\n",
      "Epoch: 1... Training loss: 0.00545... Test loss: 0.00718\n",
      "Epoch: 1... Training loss: 0.0054... Test loss: 0.00578\n",
      "Epoch: 1... Training loss: 0.00526... Test loss: 0.00653\n",
      "Epoch: 1... Training loss: 0.00556... Test loss: 0.0059\n",
      "Epoch: 1... Training loss: 0.00493... Test loss: 0.00594\n",
      "Epoch: 1... Training loss: 0.00469... Test loss: 0.00493\n",
      "Epoch: 1... Training loss: 0.00466... Test loss: 0.00641\n",
      "Epoch: 1... Training loss: 0.00436... Test loss: 0.00477\n",
      "Epoch: 1... Training loss: 0.00439... Test loss: 0.0056\n",
      "Epoch: 1... Training loss: 0.00412... Test loss: 0.00447\n",
      "Epoch: 1... Training loss: 0.00406... Test loss: 0.00513\n",
      "Epoch: 1... Training loss: 0.00412... Test loss: 0.00454\n",
      "Epoch: 1... Training loss: 0.00375... Test loss: 0.00521\n",
      "Epoch: 1... Training loss: 0.00375... Test loss: 0.00406\n",
      "Epoch: 1... Training loss: 0.00362... Test loss: 0.00479\n",
      "Epoch: 1... Training loss: 0.00355... Test loss: 0.00315\n",
      "Epoch: 1... Training loss: 0.00353... Test loss: 0.00469\n",
      "Epoch: 1... Training loss: 0.00346... Test loss: 0.0041\n",
      "Epoch: 1... Training loss: 0.00334... Test loss: 0.00421\n",
      "Epoch: 1... Training loss: 0.00336... Test loss: 0.00357\n",
      "Epoch: 1... Training loss: 0.00317... Test loss: 0.00372\n",
      "Epoch: 1... Training loss: 0.00317... Test loss: 0.00345\n",
      "Epoch: 1... Training loss: 0.00311... Test loss: 0.00343\n",
      "Epoch: 1... Training loss: 0.00306... Test loss: 0.00359\n",
      "Epoch: 1... Training loss: 0.00302... Test loss: 0.00311\n",
      "Epoch: 1... Training loss: 0.00303... Test loss: 0.00313\n",
      "Epoch: 1... Training loss: 0.00284... Test loss: 0.0027\n",
      "Epoch: 1... Training loss: 0.00285... Test loss: 0.00329\n",
      "Epoch: 1... Training loss: 0.00281... Test loss: 0.00301\n",
      "Epoch: 1... Training loss: 0.00278... Test loss: 0.00324\n",
      "Epoch: 1... Training loss: 0.00264... Test loss: 0.00259\n",
      "Epoch: 1... Training loss: 0.00257... Test loss: 0.00316\n",
      "Epoch: 1... Training loss: 0.00261... Test loss: 0.00264\n",
      "Epoch: 1... Training loss: 0.00253... Test loss: 0.00272\n",
      "Epoch: 1... Training loss: 0.00236... Test loss: 0.00223\n",
      "Epoch: 1... Training loss: 0.00235... Test loss: 0.00288\n",
      "Epoch: 1... Training loss: 0.00228... Test loss: 0.00263\n",
      "Epoch: 1... Training loss: 0.00231... Test loss: 0.00238\n",
      "Epoch: 1... Training loss: 0.00233... Test loss: 0.00227\n",
      "Epoch: 1... Training loss: 0.00238... Test loss: 0.00263\n",
      "Epoch: 1... Training loss: 0.00221... Test loss: 0.00217\n",
      "Epoch: 1... Training loss: 0.00212... Test loss: 0.00212\n",
      "Epoch: 1... Training loss: 0.00207... Test loss: 0.00197\n",
      "Epoch: 1... Training loss: 0.00206... Test loss: 0.00226\n",
      "Epoch: 1... Training loss: 0.00199... Test loss: 0.00179\n",
      "Epoch: 1... Training loss: 0.0019... Test loss: 0.00221\n",
      "Epoch: 1... Training loss: 0.00184... Test loss: 0.0018\n",
      "Epoch: 1... Training loss: 0.00184... Test loss: 0.002\n",
      "Epoch: 1... Training loss: 0.00175... Test loss: 0.00184\n",
      "Epoch: 1... Training loss: 0.00175... Test loss: 0.00188\n",
      "Epoch: 1... Training loss: 0.00158... Test loss: 0.00195\n",
      "Epoch: 1... Training loss: 0.0017... Test loss: 0.00179\n",
      "Epoch: 1... Training loss: 0.00151... Test loss: 0.00182\n",
      "Epoch: 1... Training loss: 0.00156... Test loss: 0.00149\n",
      "Epoch: 1... Training loss: 0.00142... Test loss: 0.00166\n",
      "Epoch: 1... Training loss: 0.00137... Test loss: 0.00139\n",
      "Epoch: 1... Training loss: 0.0013... Test loss: 0.00172\n",
      "Epoch: 1... Training loss: 0.00128... Test loss: 0.00134\n",
      "Epoch: 1... Training loss: 0.00126... Test loss: 0.00141\n",
      "Epoch: 1... Training loss: 0.00123... Test loss: 0.00134\n",
      "Epoch: 1... Training loss: 0.00119... Test loss: 0.00135\n",
      "Epoch: 1... Training loss: 0.00126... Test loss: 0.00125\n",
      "Epoch: 1... Training loss: 0.00117... Test loss: 0.00126\n",
      "Epoch: 1... Training loss: 0.00114... Test loss: 0.00123\n",
      "Epoch: 1... Training loss: 0.00113... Test loss: 0.00118\n",
      "Epoch: 1... Training loss: 0.00106... Test loss: 0.00124\n",
      "Epoch: 1... Training loss: 0.00099... Test loss: 0.00099\n",
      "Epoch: 1... Training loss: 0.00097... Test loss: 0.00117\n",
      "Epoch: 1... Training loss: 0.00101... Test loss: 0.00105\n",
      "Epoch: 1... Training loss: 0.00088... Test loss: 0.00121\n",
      "Epoch: 1... Training loss: 0.00087... Test loss: 0.00079\n",
      "Epoch: 1... Training loss: 0.00085... Test loss: 0.00083\n",
      "Epoch: 1... Training loss: 0.00083... Test loss: 0.00079\n",
      "Epoch: 1... Training loss: 0.00081... Test loss: 0.00082\n",
      "Epoch: 1... Training loss: 0.00076... Test loss: 0.00085\n",
      "Epoch: 1... Training loss: 0.0008... Test loss: 0.00071\n",
      "Epoch: 1... Training loss: 0.00076... Test loss: 0.00097\n",
      "Epoch: 1... Training loss: 0.00075... Test loss: 0.00072\n",
      "Epoch: 1... Training loss: 0.00077... Test loss: 0.00068\n",
      "Epoch: 1... Training loss: 0.00075... Test loss: 0.00074\n",
      "Epoch: 1... Training loss: 0.00068... Test loss: 0.00086\n",
      "Epoch: 1... Training loss: 0.00067... Test loss: 0.00066\n",
      "Epoch: 1... Training loss: 0.00064... Test loss: 0.00072\n",
      "Epoch: 1... Training loss: 0.0007... Test loss: 0.0007\n",
      "Epoch: 1... Training loss: 0.00065... Test loss: 0.00066\n",
      "Epoch: 1... Training loss: 0.00065... Test loss: 0.00062\n",
      "Epoch: 1... Training loss: 0.00065... Test loss: 0.00065\n",
      "Epoch: 1... Training loss: 0.00068... Test loss: 0.00058\n",
      "Epoch: 1... Training loss: 0.00062... Test loss: 0.00061\n",
      "Epoch: 1... Training loss: 0.00059... Test loss: 0.00056\n",
      "Epoch: 1... Training loss: 0.0005... Test loss: 0.00065\n",
      "Epoch: 1... Training loss: 0.00052... Test loss: 0.00045\n",
      "Epoch: 1... Training loss: 0.00045... Test loss: 0.00068\n",
      "Epoch: 1... Training loss: 0.00052... Test loss: 0.00044\n",
      "Epoch: 1... Training loss: 0.00045... Test loss: 0.00063\n",
      "Epoch: 1... Training loss: 0.00039... Test loss: 0.00038\n",
      "Epoch: 1... Training loss: 0.00042... Test loss: 0.00038\n",
      "Epoch: 1... Training loss: 0.00047... Test loss: 0.00038\n",
      "Epoch: 1... Training loss: 0.00038... Test loss: 0.00038\n",
      "Epoch: 1... Training loss: 0.00038... Test loss: 0.00039\n",
      "Epoch: 1... Training loss: 0.00035... Test loss: 0.00037\n",
      "Epoch: 1... Training loss: 0.0004... Test loss: 0.00037\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00044\n",
      "Epoch: 1... Training loss: 0.00029... Test loss: 0.00036\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00032\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00034\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00028\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00019\n",
      "253.01530592388008\n",
      "Epoch: 1... Training loss: 1.30823... Test loss: 0.62554\n",
      "Epoch: 1... Training loss: 0.55626... Test loss: 0.23501\n",
      "Epoch: 1... Training loss: 0.31455... Test loss: 0.14219\n",
      "Epoch: 1... Training loss: 0.21819... Test loss: 0.07994\n",
      "Epoch: 1... Training loss: 0.14353... Test loss: 0.08675\n",
      "Epoch: 1... Training loss: 0.1032... Test loss: 0.05837\n",
      "Epoch: 1... Training loss: 0.09364... Test loss: 0.03926\n",
      "Epoch: 1... Training loss: 0.0725... Test loss: 0.04826\n",
      "Epoch: 1... Training loss: 0.07147... Test loss: 0.04568\n",
      "Epoch: 1... Training loss: 0.05988... Test loss: 0.02858\n",
      "Epoch: 1... Training loss: 0.05418... Test loss: 0.04694\n",
      "Epoch: 1... Training loss: 0.0494... Test loss: 0.02074\n",
      "Epoch: 1... Training loss: 0.04498... Test loss: 0.03465\n",
      "Epoch: 1... Training loss: 0.04002... Test loss: 0.01789\n",
      "Epoch: 1... Training loss: 0.03484... Test loss: 0.0308\n",
      "Epoch: 1... Training loss: 0.03282... Test loss: 0.02812\n",
      "Epoch: 1... Training loss: 0.03062... Test loss: 0.01379\n",
      "Epoch: 1... Training loss: 0.02859... Test loss: 0.02471\n",
      "Epoch: 1... Training loss: 0.02689... Test loss: 0.02625\n",
      "Epoch: 1... Training loss: 0.0264... Test loss: 0.01264\n",
      "Epoch: 1... Training loss: 0.02379... Test loss: 0.02507\n",
      "Epoch: 1... Training loss: 0.02193... Test loss: 0.01294\n",
      "Epoch: 1... Training loss: 0.0209... Test loss: 0.0186\n",
      "Epoch: 1... Training loss: 0.02032... Test loss: 0.01461\n",
      "Epoch: 1... Training loss: 0.01931... Test loss: 0.01289\n",
      "Epoch: 1... Training loss: 0.01853... Test loss: 0.01977\n",
      "Epoch: 1... Training loss: 0.01748... Test loss: 0.0102\n",
      "Epoch: 1... Training loss: 0.01607... Test loss: 0.01797\n",
      "Epoch: 1... Training loss: 0.01555... Test loss: 0.01033\n",
      "Epoch: 1... Training loss: 0.01485... Test loss: 0.01548\n",
      "Epoch: 1... Training loss: 0.01488... Test loss: 0.00985\n",
      "Epoch: 1... Training loss: 0.01384... Test loss: 0.01623\n",
      "Epoch: 1... Training loss: 0.01388... Test loss: 0.01\n",
      "Epoch: 1... Training loss: 0.01312... Test loss: 0.01506\n",
      "Epoch: 1... Training loss: 0.013... Test loss: 0.01279\n",
      "Epoch: 1... Training loss: 0.01233... Test loss: 0.01094\n",
      "Epoch: 1... Training loss: 0.01213... Test loss: 0.0127\n",
      "Epoch: 1... Training loss: 0.01162... Test loss: 0.00967\n",
      "Epoch: 1... Training loss: 0.01139... Test loss: 0.014\n",
      "Epoch: 1... Training loss: 0.01103... Test loss: 0.00832\n",
      "Epoch: 1... Training loss: 0.01094... Test loss: 0.01268\n",
      "Epoch: 1... Training loss: 0.01036... Test loss: 0.0082\n",
      "Epoch: 1... Training loss: 0.01025... Test loss: 0.01303\n",
      "Epoch: 1... Training loss: 0.00981... Test loss: 0.00772\n",
      "Epoch: 1... Training loss: 0.00965... Test loss: 0.01202\n",
      "Epoch: 1... Training loss: 0.00919... Test loss: 0.00612\n",
      "Epoch: 1... Training loss: 0.00916... Test loss: 0.01125\n",
      "Epoch: 1... Training loss: 0.00881... Test loss: 0.00638\n",
      "Epoch: 1... Training loss: 0.00855... Test loss: 0.00971\n",
      "Epoch: 1... Training loss: 0.00819... Test loss: 0.00653\n",
      "Epoch: 1... Training loss: 0.00813... Test loss: 0.00907\n",
      "Epoch: 1... Training loss: 0.0079... Test loss: 0.00682\n",
      "Epoch: 1... Training loss: 0.00775... Test loss: 0.00873\n",
      "Epoch: 1... Training loss: 0.00752... Test loss: 0.00641\n",
      "Epoch: 1... Training loss: 0.00739... Test loss: 0.00817\n",
      "Epoch: 1... Training loss: 0.0071... Test loss: 0.006\n",
      "Epoch: 1... Training loss: 0.00695... Test loss: 0.00712\n",
      "Epoch: 1... Training loss: 0.00682... Test loss: 0.00628\n",
      "Epoch: 1... Training loss: 0.00664... Test loss: 0.00718\n",
      "Epoch: 1... Training loss: 0.00639... Test loss: 0.00672\n",
      "Epoch: 1... Training loss: 0.00626... Test loss: 0.00608\n",
      "Epoch: 1... Training loss: 0.00612... Test loss: 0.00687\n",
      "Epoch: 1... Training loss: 0.00598... Test loss: 0.00511\n",
      "Epoch: 1... Training loss: 0.00585... Test loss: 0.00713\n",
      "Epoch: 1... Training loss: 0.01688... Test loss: 0.00738\n",
      "Epoch: 1... Training loss: 0.01509... Test loss: 0.01463\n",
      "Epoch: 1... Training loss: 0.01296... Test loss: 0.01546\n",
      "Epoch: 1... Training loss: 0.01159... Test loss: 0.01602\n",
      "Epoch: 1... Training loss: 0.00957... Test loss: 0.01266\n",
      "Epoch: 1... Training loss: 0.0088... Test loss: 0.01127\n",
      "Epoch: 1... Training loss: 0.01006... Test loss: 0.01318\n",
      "Epoch: 1... Training loss: 0.0106... Test loss: 0.01549\n",
      "Epoch: 1... Training loss: 0.00885... Test loss: 0.01049\n",
      "Epoch: 1... Training loss: 0.00857... Test loss: 0.01114\n",
      "Epoch: 1... Training loss: 0.0084... Test loss: 0.0079\n",
      "Epoch: 1... Training loss: 0.0078... Test loss: 0.00959\n",
      "Epoch: 1... Training loss: 0.008... Test loss: 0.00983\n",
      "Epoch: 1... Training loss: 0.00815... Test loss: 0.00913\n",
      "Epoch: 1... Training loss: 0.00747... Test loss: 0.01043\n",
      "Epoch: 1... Training loss: 0.00764... Test loss: 0.01031\n",
      "Epoch: 1... Training loss: 0.00774... Test loss: 0.00988\n",
      "Epoch: 1... Training loss: 0.00683... Test loss: 0.00855\n",
      "Epoch: 1... Training loss: 0.00618... Test loss: 0.00884\n",
      "Epoch: 1... Training loss: 0.00619... Test loss: 0.00756\n",
      "Epoch: 1... Training loss: 0.00601... Test loss: 0.00691\n",
      "Epoch: 1... Training loss: 0.00601... Test loss: 0.0064\n",
      "Epoch: 1... Training loss: 0.00581... Test loss: 0.00616\n",
      "Epoch: 1... Training loss: 0.0058... Test loss: 0.006\n",
      "Epoch: 1... Training loss: 0.00541... Test loss: 0.00624\n",
      "Epoch: 1... Training loss: 0.00526... Test loss: 0.00577\n",
      "Epoch: 1... Training loss: 0.00516... Test loss: 0.00547\n",
      "Epoch: 1... Training loss: 0.00511... Test loss: 0.00503\n",
      "Epoch: 1... Training loss: 0.00483... Test loss: 0.00571\n",
      "Epoch: 1... Training loss: 0.00479... Test loss: 0.00472\n",
      "Epoch: 1... Training loss: 0.00465... Test loss: 0.00555\n",
      "Epoch: 1... Training loss: 0.00452... Test loss: 0.00456\n",
      "Epoch: 1... Training loss: 0.00445... Test loss: 0.00488\n",
      "Epoch: 1... Training loss: 0.0042... Test loss: 0.0046\n",
      "Epoch: 1... Training loss: 0.00405... Test loss: 0.00496\n",
      "Epoch: 1... Training loss: 0.00402... Test loss: 0.00436\n",
      "Epoch: 1... Training loss: 0.00396... Test loss: 0.0043\n",
      "Epoch: 1... Training loss: 0.00371... Test loss: 0.00465\n",
      "Epoch: 1... Training loss: 0.00386... Test loss: 0.00454\n",
      "Epoch: 1... Training loss: 0.00364... Test loss: 0.00525\n",
      "Epoch: 1... Training loss: 0.00354... Test loss: 0.00392\n",
      "Epoch: 1... Training loss: 0.00343... Test loss: 0.00426\n",
      "Epoch: 1... Training loss: 0.0034... Test loss: 0.00347\n",
      "Epoch: 1... Training loss: 0.00328... Test loss: 0.00436\n",
      "Epoch: 1... Training loss: 0.00319... Test loss: 0.00333\n",
      "Epoch: 1... Training loss: 0.00316... Test loss: 0.00474\n",
      "Epoch: 1... Training loss: 0.00314... Test loss: 0.00332\n",
      "Epoch: 1... Training loss: 0.00315... Test loss: 0.00415\n",
      "Epoch: 1... Training loss: 0.00295... Test loss: 0.00284\n",
      "Epoch: 1... Training loss: 0.00293... Test loss: 0.0037\n",
      "Epoch: 1... Training loss: 0.00292... Test loss: 0.00272\n",
      "Epoch: 1... Training loss: 0.0028... Test loss: 0.00376\n",
      "Epoch: 1... Training loss: 0.00275... Test loss: 0.00271\n",
      "Epoch: 1... Training loss: 0.00273... Test loss: 0.00329\n",
      "Epoch: 1... Training loss: 0.00258... Test loss: 0.00265\n",
      "Epoch: 1... Training loss: 0.00252... Test loss: 0.00317\n",
      "Epoch: 1... Training loss: 0.00254... Test loss: 0.00264\n",
      "Epoch: 1... Training loss: 0.00255... Test loss: 0.00247\n",
      "Epoch: 1... Training loss: 0.00254... Test loss: 0.00237\n",
      "Epoch: 1... Training loss: 0.00247... Test loss: 0.0027\n",
      "Epoch: 1... Training loss: 0.00238... Test loss: 0.00232\n",
      "Epoch: 1... Training loss: 0.00233... Test loss: 0.00228\n",
      "Epoch: 1... Training loss: 0.00218... Test loss: 0.00239\n",
      "Epoch: 1... Training loss: 0.00225... Test loss: 0.00236\n",
      "Epoch: 1... Training loss: 0.00218... Test loss: 0.00213\n",
      "Epoch: 1... Training loss: 0.0021... Test loss: 0.00213\n",
      "Epoch: 1... Training loss: 0.00213... Test loss: 0.00234\n",
      "Epoch: 1... Training loss: 0.002... Test loss: 0.00164\n",
      "Epoch: 1... Training loss: 0.00202... Test loss: 0.00237\n",
      "Epoch: 1... Training loss: 0.00192... Test loss: 0.00197\n",
      "Epoch: 1... Training loss: 0.00184... Test loss: 0.00199\n",
      "Epoch: 1... Training loss: 0.00188... Test loss: 0.00191\n",
      "Epoch: 1... Training loss: 0.00183... Test loss: 0.00205\n",
      "Epoch: 1... Training loss: 0.00169... Test loss: 0.00209\n",
      "Epoch: 1... Training loss: 0.00172... Test loss: 0.00188\n",
      "Epoch: 1... Training loss: 0.0016... Test loss: 0.00204\n",
      "Epoch: 1... Training loss: 0.00151... Test loss: 0.00172\n",
      "Epoch: 1... Training loss: 0.00151... Test loss: 0.00181\n",
      "Epoch: 1... Training loss: 0.00158... Test loss: 0.0016\n",
      "Epoch: 1... Training loss: 0.0014... Test loss: 0.0017\n",
      "Epoch: 1... Training loss: 0.0015... Test loss: 0.00142\n",
      "Epoch: 1... Training loss: 0.00137... Test loss: 0.00156\n",
      "Epoch: 1... Training loss: 0.00131... Test loss: 0.00132\n",
      "Epoch: 1... Training loss: 0.0013... Test loss: 0.0015\n",
      "Epoch: 1... Training loss: 0.00122... Test loss: 0.00124\n",
      "Epoch: 1... Training loss: 0.00122... Test loss: 0.00144\n",
      "Epoch: 1... Training loss: 0.00117... Test loss: 0.00127\n",
      "Epoch: 1... Training loss: 0.00109... Test loss: 0.00126\n",
      "Epoch: 1... Training loss: 0.00111... Test loss: 0.00119\n",
      "Epoch: 1... Training loss: 0.00102... Test loss: 0.00127\n",
      "Epoch: 1... Training loss: 0.00103... Test loss: 0.00124\n",
      "Epoch: 1... Training loss: 0.00106... Test loss: 0.0012\n",
      "Epoch: 1... Training loss: 0.00104... Test loss: 0.00098\n",
      "Epoch: 1... Training loss: 0.00103... Test loss: 0.00109\n",
      "Epoch: 1... Training loss: 0.00096... Test loss: 0.00095\n",
      "Epoch: 1... Training loss: 0.00089... Test loss: 0.00096\n",
      "Epoch: 1... Training loss: 0.00089... Test loss: 0.00089\n",
      "Epoch: 1... Training loss: 0.00086... Test loss: 0.00089\n",
      "Epoch: 1... Training loss: 0.00076... Test loss: 0.00082\n",
      "Epoch: 1... Training loss: 0.00079... Test loss: 0.00104\n",
      "Epoch: 1... Training loss: 0.00073... Test loss: 0.00078\n",
      "Epoch: 1... Training loss: 0.00074... Test loss: 0.00082\n",
      "Epoch: 1... Training loss: 0.00075... Test loss: 0.00083\n",
      "Epoch: 1... Training loss: 0.00069... Test loss: 0.00077\n",
      "Epoch: 1... Training loss: 0.00068... Test loss: 0.00081\n",
      "Epoch: 1... Training loss: 0.00064... Test loss: 0.00066\n",
      "Epoch: 1... Training loss: 0.00061... Test loss: 0.00067\n",
      "Epoch: 1... Training loss: 0.00059... Test loss: 0.00066\n",
      "Epoch: 1... Training loss: 0.0006... Test loss: 0.00062\n",
      "Epoch: 1... Training loss: 0.00055... Test loss: 0.0005\n",
      "Epoch: 1... Training loss: 0.0006... Test loss: 0.00054\n",
      "Epoch: 1... Training loss: 0.00051... Test loss: 0.00052\n",
      "Epoch: 1... Training loss: 0.00048... Test loss: 0.00049\n",
      "Epoch: 1... Training loss: 0.00044... Test loss: 0.00044\n",
      "Epoch: 1... Training loss: 0.00044... Test loss: 0.00037\n",
      "Epoch: 1... Training loss: 0.00041... Test loss: 0.00049\n",
      "Epoch: 1... Training loss: 0.00044... Test loss: 0.00038\n",
      "Epoch: 1... Training loss: 0.00038... Test loss: 0.00045\n",
      "Epoch: 1... Training loss: 0.00042... Test loss: 0.00043\n",
      "Epoch: 1... Training loss: 0.00035... Test loss: 0.00033\n",
      "Epoch: 1... Training loss: 0.00033... Test loss: 0.00039\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00035\n",
      "Epoch: 1... Training loss: 0.00029... Test loss: 0.00031\n",
      "Epoch: 1... Training loss: 0.00033... Test loss: 0.0003\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00031\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.00026... Test loss: 0.00031\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00024\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00036\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00024\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00017\n",
      "270.32741695124423\n",
      "Epoch: 1... Training loss: 0.82103... Test loss: 0.15548\n",
      "Epoch: 1... Training loss: 0.4427... Test loss: 0.16079\n",
      "Epoch: 1... Training loss: 0.27731... Test loss: 0.08324\n",
      "Epoch: 1... Training loss: 0.20313... Test loss: 0.06695\n",
      "Epoch: 1... Training loss: 0.16427... Test loss: 0.05216\n",
      "Epoch: 1... Training loss: 0.13737... Test loss: 0.04161\n",
      "Epoch: 1... Training loss: 0.11687... Test loss: 0.03668\n",
      "Epoch: 1... Training loss: 0.09967... Test loss: 0.02806\n",
      "Epoch: 1... Training loss: 0.07589... Test loss: 0.02892\n",
      "Epoch: 1... Training loss: 0.07009... Test loss: 0.01747\n",
      "Epoch: 1... Training loss: 0.05823... Test loss: 0.02223\n",
      "Epoch: 1... Training loss: 0.05167... Test loss: 0.01285\n",
      "Epoch: 1... Training loss: 0.0449... Test loss: 0.01694\n",
      "Epoch: 1... Training loss: 0.04221... Test loss: 0.01515\n",
      "Epoch: 1... Training loss: 0.03706... Test loss: 0.02206\n",
      "Epoch: 1... Training loss: 0.03438... Test loss: 0.00956\n",
      "Epoch: 1... Training loss: 0.0327... Test loss: 0.01853\n",
      "Epoch: 1... Training loss: 0.02908... Test loss: 0.01425\n",
      "Epoch: 1... Training loss: 0.02786... Test loss: 0.01398\n",
      "Epoch: 1... Training loss: 0.02481... Test loss: 0.03048\n",
      "Epoch: 1... Training loss: 0.02453... Test loss: 0.01091\n",
      "Epoch: 1... Training loss: 0.02145... Test loss: 0.02357\n",
      "Epoch: 1... Training loss: 0.01993... Test loss: 0.00885\n",
      "Epoch: 1... Training loss: 0.01935... Test loss: 0.01823\n",
      "Epoch: 1... Training loss: 0.01908... Test loss: 0.009\n",
      "Epoch: 1... Training loss: 0.01784... Test loss: 0.01454\n",
      "Epoch: 1... Training loss: 0.01707... Test loss: 0.00858\n",
      "Epoch: 1... Training loss: 0.01584... Test loss: 0.00892\n",
      "Epoch: 1... Training loss: 0.01488... Test loss: 0.01394\n",
      "Epoch: 1... Training loss: 0.01363... Test loss: 0.00744\n",
      "Epoch: 1... Training loss: 0.01323... Test loss: 0.01228\n",
      "Epoch: 1... Training loss: 0.01311... Test loss: 0.00628\n",
      "Epoch: 1... Training loss: 0.01253... Test loss: 0.01176\n",
      "Epoch: 1... Training loss: 0.01203... Test loss: 0.00675\n",
      "Epoch: 1... Training loss: 0.01173... Test loss: 0.01018\n",
      "Epoch: 1... Training loss: 0.01106... Test loss: 0.00563\n",
      "Epoch: 1... Training loss: 0.01057... Test loss: 0.00938\n",
      "Epoch: 1... Training loss: 0.01038... Test loss: 0.00568\n",
      "Epoch: 1... Training loss: 0.01016... Test loss: 0.00794\n",
      "Epoch: 1... Training loss: 0.01007... Test loss: 0.00683\n",
      "Epoch: 1... Training loss: 0.00956... Test loss: 0.00865\n",
      "Epoch: 1... Training loss: 0.00948... Test loss: 0.00583\n",
      "Epoch: 1... Training loss: 0.00905... Test loss: 0.00956\n",
      "Epoch: 1... Training loss: 0.00895... Test loss: 0.00579\n",
      "Epoch: 1... Training loss: 0.00876... Test loss: 0.00667\n",
      "Epoch: 1... Training loss: 0.00847... Test loss: 0.00598\n",
      "Epoch: 1... Training loss: 0.00835... Test loss: 0.00699\n",
      "Epoch: 1... Training loss: 0.00807... Test loss: 0.00485\n",
      "Epoch: 1... Training loss: 0.00782... Test loss: 0.00757\n",
      "Epoch: 1... Training loss: 0.00757... Test loss: 0.00543\n",
      "Epoch: 1... Training loss: 0.00744... Test loss: 0.00654\n",
      "Epoch: 1... Training loss: 0.00719... Test loss: 0.00576\n",
      "Epoch: 1... Training loss: 0.00701... Test loss: 0.00547\n",
      "Epoch: 1... Training loss: 0.00681... Test loss: 0.00607\n",
      "Epoch: 1... Training loss: 0.00671... Test loss: 0.00547\n",
      "Epoch: 1... Training loss: 0.0065... Test loss: 0.00557\n",
      "Epoch: 1... Training loss: 0.00643... Test loss: 0.00538\n",
      "Epoch: 1... Training loss: 0.00623... Test loss: 0.00466\n",
      "Epoch: 1... Training loss: 0.00611... Test loss: 0.00489\n",
      "Epoch: 1... Training loss: 0.0059... Test loss: 0.00505\n",
      "Epoch: 1... Training loss: 0.00577... Test loss: 0.00474\n",
      "Epoch: 1... Training loss: 0.00572... Test loss: 0.00489\n",
      "Epoch: 1... Training loss: 0.00553... Test loss: 0.00392\n",
      "Epoch: 1... Training loss: 0.00536... Test loss: 0.00517\n",
      "Epoch: 1... Training loss: 0.01475... Test loss: 0.00893\n",
      "Epoch: 1... Training loss: 0.01079... Test loss: 0.00982\n",
      "Epoch: 1... Training loss: 0.00911... Test loss: 0.01101\n",
      "Epoch: 1... Training loss: 0.00925... Test loss: 0.01012\n",
      "Epoch: 1... Training loss: 0.0109... Test loss: 0.0121\n",
      "Epoch: 1... Training loss: 0.00893... Test loss: 0.01055\n",
      "Epoch: 1... Training loss: 0.01173... Test loss: 0.01075\n",
      "Epoch: 1... Training loss: 0.00888... Test loss: 0.01051\n",
      "Epoch: 1... Training loss: 0.0085... Test loss: 0.00934\n",
      "Epoch: 1... Training loss: 0.0081... Test loss: 0.00877\n",
      "Epoch: 1... Training loss: 0.00778... Test loss: 0.00861\n",
      "Epoch: 1... Training loss: 0.00748... Test loss: 0.00773\n",
      "Epoch: 1... Training loss: 0.00727... Test loss: 0.0065\n",
      "Epoch: 1... Training loss: 0.00786... Test loss: 0.00834\n",
      "Epoch: 1... Training loss: 0.00737... Test loss: 0.00752\n",
      "Epoch: 1... Training loss: 0.00686... Test loss: 0.00751\n",
      "Epoch: 1... Training loss: 0.00721... Test loss: 0.00683\n",
      "Epoch: 1... Training loss: 0.00643... Test loss: 0.00768\n",
      "Epoch: 1... Training loss: 0.00619... Test loss: 0.00704\n",
      "Epoch: 1... Training loss: 0.00609... Test loss: 0.00713\n",
      "Epoch: 1... Training loss: 0.00579... Test loss: 0.00613\n",
      "Epoch: 1... Training loss: 0.0057... Test loss: 0.00643\n",
      "Epoch: 1... Training loss: 0.00552... Test loss: 0.00621\n",
      "Epoch: 1... Training loss: 0.00558... Test loss: 0.00577\n",
      "Epoch: 1... Training loss: 0.00502... Test loss: 0.00684\n",
      "Epoch: 1... Training loss: 0.00528... Test loss: 0.00573\n",
      "Epoch: 1... Training loss: 0.00499... Test loss: 0.00561\n",
      "Epoch: 1... Training loss: 0.00467... Test loss: 0.00478\n",
      "Epoch: 1... Training loss: 0.00455... Test loss: 0.00522\n",
      "Epoch: 1... Training loss: 0.00451... Test loss: 0.00502\n",
      "Epoch: 1... Training loss: 0.00442... Test loss: 0.00369\n",
      "Epoch: 1... Training loss: 0.00442... Test loss: 0.00446\n",
      "Epoch: 1... Training loss: 0.0041... Test loss: 0.00418\n",
      "Epoch: 1... Training loss: 0.00396... Test loss: 0.00446\n",
      "Epoch: 1... Training loss: 0.00404... Test loss: 0.00362\n",
      "Epoch: 1... Training loss: 0.00383... Test loss: 0.00437\n",
      "Epoch: 1... Training loss: 0.00374... Test loss: 0.00369\n",
      "Epoch: 1... Training loss: 0.00355... Test loss: 0.00433\n",
      "Epoch: 1... Training loss: 0.00352... Test loss: 0.00345\n",
      "Epoch: 1... Training loss: 0.0035... Test loss: 0.00413\n",
      "Epoch: 1... Training loss: 0.00341... Test loss: 0.00418\n",
      "Epoch: 1... Training loss: 0.00337... Test loss: 0.00393\n",
      "Epoch: 1... Training loss: 0.00322... Test loss: 0.00403\n",
      "Epoch: 1... Training loss: 0.00321... Test loss: 0.00309\n",
      "Epoch: 1... Training loss: 0.00305... Test loss: 0.00394\n",
      "Epoch: 1... Training loss: 0.00299... Test loss: 0.00313\n",
      "Epoch: 1... Training loss: 0.00308... Test loss: 0.00333\n",
      "Epoch: 1... Training loss: 0.00296... Test loss: 0.00245\n",
      "Epoch: 1... Training loss: 0.00306... Test loss: 0.00321\n",
      "Epoch: 1... Training loss: 0.00298... Test loss: 0.00291\n",
      "Epoch: 1... Training loss: 0.00289... Test loss: 0.00271\n",
      "Epoch: 1... Training loss: 0.00281... Test loss: 0.00332\n",
      "Epoch: 1... Training loss: 0.00276... Test loss: 0.00268\n",
      "Epoch: 1... Training loss: 0.00272... Test loss: 0.00284\n",
      "Epoch: 1... Training loss: 0.00271... Test loss: 0.0027\n",
      "Epoch: 1... Training loss: 0.00272... Test loss: 0.00253\n",
      "Epoch: 1... Training loss: 0.00262... Test loss: 0.00264\n",
      "Epoch: 1... Training loss: 0.00259... Test loss: 0.00262\n",
      "Epoch: 1... Training loss: 0.00248... Test loss: 0.0028\n",
      "Epoch: 1... Training loss: 0.00237... Test loss: 0.00216\n",
      "Epoch: 1... Training loss: 0.00237... Test loss: 0.0026\n",
      "Epoch: 1... Training loss: 0.00242... Test loss: 0.00252\n",
      "Epoch: 1... Training loss: 0.00238... Test loss: 0.00276\n",
      "Epoch: 1... Training loss: 0.00235... Test loss: 0.00211\n",
      "Epoch: 1... Training loss: 0.00225... Test loss: 0.00262\n",
      "Epoch: 1... Training loss: 0.00227... Test loss: 0.00198\n",
      "Epoch: 1... Training loss: 0.00216... Test loss: 0.00247\n",
      "Epoch: 1... Training loss: 0.00208... Test loss: 0.00177\n",
      "Epoch: 1... Training loss: 0.00206... Test loss: 0.00211\n",
      "Epoch: 1... Training loss: 0.00205... Test loss: 0.00189\n",
      "Epoch: 1... Training loss: 0.00209... Test loss: 0.00192\n",
      "Epoch: 1... Training loss: 0.00199... Test loss: 0.00239\n",
      "Epoch: 1... Training loss: 0.00193... Test loss: 0.00203\n",
      "Epoch: 1... Training loss: 0.00195... Test loss: 0.00197\n",
      "Epoch: 1... Training loss: 0.00188... Test loss: 0.00183\n",
      "Epoch: 1... Training loss: 0.00188... Test loss: 0.00171\n",
      "Epoch: 1... Training loss: 0.00174... Test loss: 0.00179\n",
      "Epoch: 1... Training loss: 0.00169... Test loss: 0.0017\n",
      "Epoch: 1... Training loss: 0.00179... Test loss: 0.0019\n",
      "Epoch: 1... Training loss: 0.00156... Test loss: 0.00162\n",
      "Epoch: 1... Training loss: 0.0015... Test loss: 0.00163\n",
      "Epoch: 1... Training loss: 0.00156... Test loss: 0.00133\n",
      "Epoch: 1... Training loss: 0.00153... Test loss: 0.00145\n",
      "Epoch: 1... Training loss: 0.00145... Test loss: 0.00145\n",
      "Epoch: 1... Training loss: 0.00149... Test loss: 0.00141\n",
      "Epoch: 1... Training loss: 0.00143... Test loss: 0.00173\n",
      "Epoch: 1... Training loss: 0.00132... Test loss: 0.00138\n",
      "Epoch: 1... Training loss: 0.00127... Test loss: 0.00147\n",
      "Epoch: 1... Training loss: 0.00134... Test loss: 0.00127\n",
      "Epoch: 1... Training loss: 0.00122... Test loss: 0.00125\n",
      "Epoch: 1... Training loss: 0.00124... Test loss: 0.00114\n",
      "Epoch: 1... Training loss: 0.00119... Test loss: 0.0012\n",
      "Epoch: 1... Training loss: 0.00115... Test loss: 0.00105\n",
      "Epoch: 1... Training loss: 0.0011... Test loss: 0.00115\n",
      "Epoch: 1... Training loss: 0.00105... Test loss: 0.00117\n",
      "Epoch: 1... Training loss: 0.00106... Test loss: 0.00116\n",
      "Epoch: 1... Training loss: 0.00107... Test loss: 0.00115\n",
      "Epoch: 1... Training loss: 0.00101... Test loss: 0.00106\n",
      "Epoch: 1... Training loss: 0.00102... Test loss: 0.00095\n",
      "Epoch: 1... Training loss: 0.00091... Test loss: 0.00096\n",
      "Epoch: 1... Training loss: 0.00097... Test loss: 0.00095\n",
      "Epoch: 1... Training loss: 0.00085... Test loss: 0.00092\n",
      "Epoch: 1... Training loss: 0.00085... Test loss: 0.00094\n",
      "Epoch: 1... Training loss: 0.00084... Test loss: 0.00091\n",
      "Epoch: 1... Training loss: 0.0008... Test loss: 0.00086\n",
      "Epoch: 1... Training loss: 0.00077... Test loss: 0.00082\n",
      "Epoch: 1... Training loss: 0.00075... Test loss: 0.00086\n",
      "Epoch: 1... Training loss: 0.00077... Test loss: 0.00062\n",
      "Epoch: 1... Training loss: 0.00073... Test loss: 0.0009\n",
      "Epoch: 1... Training loss: 0.00066... Test loss: 0.00063\n",
      "Epoch: 1... Training loss: 0.00069... Test loss: 0.00075\n",
      "Epoch: 1... Training loss: 0.00064... Test loss: 0.0007\n",
      "Epoch: 1... Training loss: 0.00061... Test loss: 0.00071\n",
      "Epoch: 1... Training loss: 0.00058... Test loss: 0.0007\n",
      "Epoch: 1... Training loss: 0.00058... Test loss: 0.00062\n",
      "Epoch: 1... Training loss: 0.00063... Test loss: 0.00065\n",
      "Epoch: 1... Training loss: 0.00049... Test loss: 0.00059\n",
      "Epoch: 1... Training loss: 0.00049... Test loss: 0.0005\n",
      "Epoch: 1... Training loss: 0.0005... Test loss: 0.00054\n",
      "Epoch: 1... Training loss: 0.00042... Test loss: 0.00048\n",
      "Epoch: 1... Training loss: 0.00044... Test loss: 0.00053\n",
      "Epoch: 1... Training loss: 0.00042... Test loss: 0.00055\n",
      "Epoch: 1... Training loss: 0.00042... Test loss: 0.00035\n",
      "Epoch: 1... Training loss: 0.00038... Test loss: 0.00041\n",
      "Epoch: 1... Training loss: 0.00034... Test loss: 0.00033\n",
      "Epoch: 1... Training loss: 0.00034... Test loss: 0.00034\n",
      "Epoch: 1... Training loss: 0.00032... Test loss: 0.00031\n",
      "Epoch: 1... Training loss: 0.00032... Test loss: 0.00032\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.00032\n",
      "Epoch: 1... Training loss: 0.00031... Test loss: 0.00032\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00032\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00032\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.0003\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00024\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00024\n",
      "309.4710190213518\n",
      "Epoch: 1... Training loss: 1.0554... Test loss: 0.43578\n",
      "Epoch: 1... Training loss: 0.54594... Test loss: 0.22597\n",
      "Epoch: 1... Training loss: 0.33972... Test loss: 0.12601\n",
      "Epoch: 1... Training loss: 0.21839... Test loss: 0.08217\n",
      "Epoch: 1... Training loss: 0.16572... Test loss: 0.06536\n",
      "Epoch: 1... Training loss: 0.12239... Test loss: 0.05542\n",
      "Epoch: 1... Training loss: 0.1032... Test loss: 0.03391\n",
      "Epoch: 1... Training loss: 0.0784... Test loss: 0.03241\n",
      "Epoch: 1... Training loss: 0.06416... Test loss: 0.0293\n",
      "Epoch: 1... Training loss: 0.05534... Test loss: 0.01741\n",
      "Epoch: 1... Training loss: 0.04875... Test loss: 0.01804\n",
      "Epoch: 1... Training loss: 0.04168... Test loss: 0.02192\n",
      "Epoch: 1... Training loss: 0.03656... Test loss: 0.01497\n",
      "Epoch: 1... Training loss: 0.0352... Test loss: 0.01503\n",
      "Epoch: 1... Training loss: 0.03291... Test loss: 0.0081\n",
      "Epoch: 1... Training loss: 0.02954... Test loss: 0.01299\n",
      "Epoch: 1... Training loss: 0.02791... Test loss: 0.00848\n",
      "Epoch: 1... Training loss: 0.02477... Test loss: 0.01569\n",
      "Epoch: 1... Training loss: 0.0247... Test loss: 0.00589\n",
      "Epoch: 1... Training loss: 0.02264... Test loss: 0.01103\n",
      "Epoch: 1... Training loss: 0.0223... Test loss: 0.00583\n",
      "Epoch: 1... Training loss: 0.02073... Test loss: 0.00957\n",
      "Epoch: 1... Training loss: 0.02001... Test loss: 0.00715\n",
      "Epoch: 1... Training loss: 0.01905... Test loss: 0.01192\n",
      "Epoch: 1... Training loss: 0.01857... Test loss: 0.00777\n",
      "Epoch: 1... Training loss: 0.01761... Test loss: 0.01539\n",
      "Epoch: 1... Training loss: 0.01685... Test loss: 0.00715\n",
      "Epoch: 1... Training loss: 0.01635... Test loss: 0.01398\n",
      "Epoch: 1... Training loss: 0.0159... Test loss: 0.00554\n",
      "Epoch: 1... Training loss: 0.01545... Test loss: 0.01329\n",
      "Epoch: 1... Training loss: 0.01483... Test loss: 0.00546\n",
      "Epoch: 1... Training loss: 0.01441... Test loss: 0.01467\n",
      "Epoch: 1... Training loss: 0.01382... Test loss: 0.00479\n",
      "Epoch: 1... Training loss: 0.01349... Test loss: 0.01339\n",
      "Epoch: 1... Training loss: 0.01307... Test loss: 0.00474\n",
      "Epoch: 1... Training loss: 0.01237... Test loss: 0.01255\n",
      "Epoch: 1... Training loss: 0.01196... Test loss: 0.00432\n",
      "Epoch: 1... Training loss: 0.01167... Test loss: 0.01154\n",
      "Epoch: 1... Training loss: 0.01099... Test loss: 0.00424\n",
      "Epoch: 1... Training loss: 0.01063... Test loss: 0.01134\n",
      "Epoch: 1... Training loss: 0.0102... Test loss: 0.00516\n",
      "Epoch: 1... Training loss: 0.00953... Test loss: 0.00779\n",
      "Epoch: 1... Training loss: 0.00927... Test loss: 0.00681\n",
      "Epoch: 1... Training loss: 0.00902... Test loss: 0.0059\n",
      "Epoch: 1... Training loss: 0.00875... Test loss: 0.00723\n",
      "Epoch: 1... Training loss: 0.00859... Test loss: 0.00483\n",
      "Epoch: 1... Training loss: 0.00833... Test loss: 0.00823\n",
      "Epoch: 1... Training loss: 0.00816... Test loss: 0.00458\n",
      "Epoch: 1... Training loss: 0.0079... Test loss: 0.00764\n",
      "Epoch: 1... Training loss: 0.00766... Test loss: 0.0046\n",
      "Epoch: 1... Training loss: 0.00738... Test loss: 0.00732\n",
      "Epoch: 1... Training loss: 0.00714... Test loss: 0.00483\n",
      "Epoch: 1... Training loss: 0.00698... Test loss: 0.00594\n",
      "Epoch: 1... Training loss: 0.00685... Test loss: 0.00498\n",
      "Epoch: 1... Training loss: 0.00667... Test loss: 0.00483\n",
      "Epoch: 1... Training loss: 0.0065... Test loss: 0.00586\n",
      "Epoch: 1... Training loss: 0.00632... Test loss: 0.00547\n",
      "Epoch: 1... Training loss: 0.00613... Test loss: 0.00529\n",
      "Epoch: 1... Training loss: 0.00605... Test loss: 0.00484\n",
      "Epoch: 1... Training loss: 0.00587... Test loss: 0.00574\n",
      "Epoch: 1... Training loss: 0.00575... Test loss: 0.00463\n",
      "Epoch: 1... Training loss: 0.00557... Test loss: 0.00546\n",
      "Epoch: 1... Training loss: 0.00543... Test loss: 0.00465\n",
      "Epoch: 1... Training loss: 0.00525... Test loss: 0.00524\n",
      "Epoch: 1... Training loss: 0.01487... Test loss: 0.00894\n",
      "Epoch: 1... Training loss: 0.00973... Test loss: 0.01168\n",
      "Epoch: 1... Training loss: 0.01162... Test loss: 0.0071\n",
      "Epoch: 1... Training loss: 0.01257... Test loss: 0.01337\n",
      "Epoch: 1... Training loss: 0.00881... Test loss: 0.0095\n",
      "Epoch: 1... Training loss: 0.0086... Test loss: 0.00872\n",
      "Epoch: 1... Training loss: 0.00852... Test loss: 0.00786\n",
      "Epoch: 1... Training loss: 0.00849... Test loss: 0.00829\n",
      "Epoch: 1... Training loss: 0.00864... Test loss: 0.00892\n",
      "Epoch: 1... Training loss: 0.0085... Test loss: 0.01003\n",
      "Epoch: 1... Training loss: 0.00838... Test loss: 0.01153\n",
      "Epoch: 1... Training loss: 0.00744... Test loss: 0.00854\n",
      "Epoch: 1... Training loss: 0.00721... Test loss: 0.00907\n",
      "Epoch: 1... Training loss: 0.00787... Test loss: 0.00809\n",
      "Epoch: 1... Training loss: 0.0071... Test loss: 0.00795\n",
      "Epoch: 1... Training loss: 0.00665... Test loss: 0.00743\n",
      "Epoch: 1... Training loss: 0.0062... Test loss: 0.00705\n",
      "Epoch: 1... Training loss: 0.0066... Test loss: 0.00708\n",
      "Epoch: 1... Training loss: 0.00625... Test loss: 0.00557\n",
      "Epoch: 1... Training loss: 0.00586... Test loss: 0.00579\n",
      "Epoch: 1... Training loss: 0.00617... Test loss: 0.00561\n",
      "Epoch: 1... Training loss: 0.00553... Test loss: 0.00652\n",
      "Epoch: 1... Training loss: 0.00596... Test loss: 0.00564\n",
      "Epoch: 1... Training loss: 0.00518... Test loss: 0.00646\n",
      "Epoch: 1... Training loss: 0.00539... Test loss: 0.00471\n",
      "Epoch: 1... Training loss: 0.00484... Test loss: 0.00618\n",
      "Epoch: 1... Training loss: 0.00498... Test loss: 0.00415\n",
      "Epoch: 1... Training loss: 0.00509... Test loss: 0.00607\n",
      "Epoch: 1... Training loss: 0.00447... Test loss: 0.00489\n",
      "Epoch: 1... Training loss: 0.0043... Test loss: 0.00511\n",
      "Epoch: 1... Training loss: 0.00431... Test loss: 0.00543\n",
      "Epoch: 1... Training loss: 0.00428... Test loss: 0.00495\n",
      "Epoch: 1... Training loss: 0.00417... Test loss: 0.00432\n",
      "Epoch: 1... Training loss: 0.00399... Test loss: 0.00512\n",
      "Epoch: 1... Training loss: 0.00377... Test loss: 0.0039\n",
      "Epoch: 1... Training loss: 0.00378... Test loss: 0.00484\n",
      "Epoch: 1... Training loss: 0.00379... Test loss: 0.00423\n",
      "Epoch: 1... Training loss: 0.00358... Test loss: 0.00436\n",
      "Epoch: 1... Training loss: 0.00352... Test loss: 0.00357\n",
      "Epoch: 1... Training loss: 0.00347... Test loss: 0.00435\n",
      "Epoch: 1... Training loss: 0.00337... Test loss: 0.00372\n",
      "Epoch: 1... Training loss: 0.00326... Test loss: 0.00464\n",
      "Epoch: 1... Training loss: 0.00331... Test loss: 0.0037\n",
      "Epoch: 1... Training loss: 0.00324... Test loss: 0.00396\n",
      "Epoch: 1... Training loss: 0.00323... Test loss: 0.0037\n",
      "Epoch: 1... Training loss: 0.00319... Test loss: 0.00374\n",
      "Epoch: 1... Training loss: 0.00309... Test loss: 0.00307\n",
      "Epoch: 1... Training loss: 0.00318... Test loss: 0.0034\n",
      "Epoch: 1... Training loss: 0.00309... Test loss: 0.00288\n",
      "Epoch: 1... Training loss: 0.00307... Test loss: 0.00362\n",
      "Epoch: 1... Training loss: 0.00291... Test loss: 0.00286\n",
      "Epoch: 1... Training loss: 0.00289... Test loss: 0.00327\n",
      "Epoch: 1... Training loss: 0.0028... Test loss: 0.00297\n",
      "Epoch: 1... Training loss: 0.00285... Test loss: 0.00313\n",
      "Epoch: 1... Training loss: 0.00277... Test loss: 0.00266\n",
      "Epoch: 1... Training loss: 0.00252... Test loss: 0.00297\n",
      "Epoch: 1... Training loss: 0.0025... Test loss: 0.00247\n",
      "Epoch: 1... Training loss: 0.00242... Test loss: 0.00293\n",
      "Epoch: 1... Training loss: 0.00243... Test loss: 0.00232\n",
      "Epoch: 1... Training loss: 0.00226... Test loss: 0.00316\n",
      "Epoch: 1... Training loss: 0.00217... Test loss: 0.00243\n",
      "Epoch: 1... Training loss: 0.00213... Test loss: 0.0032\n",
      "Epoch: 1... Training loss: 0.00212... Test loss: 0.00257\n",
      "Epoch: 1... Training loss: 0.00204... Test loss: 0.00271\n",
      "Epoch: 1... Training loss: 0.00197... Test loss: 0.00221\n",
      "Epoch: 1... Training loss: 0.00191... Test loss: 0.00232\n",
      "Epoch: 1... Training loss: 0.00184... Test loss: 0.00221\n",
      "Epoch: 1... Training loss: 0.00182... Test loss: 0.00203\n",
      "Epoch: 1... Training loss: 0.00177... Test loss: 0.00202\n",
      "Epoch: 1... Training loss: 0.00173... Test loss: 0.0019\n",
      "Epoch: 1... Training loss: 0.00171... Test loss: 0.00191\n",
      "Epoch: 1... Training loss: 0.00163... Test loss: 0.00186\n",
      "Epoch: 1... Training loss: 0.00156... Test loss: 0.00162\n",
      "Epoch: 1... Training loss: 0.00165... Test loss: 0.00175\n",
      "Epoch: 1... Training loss: 0.00148... Test loss: 0.00171\n",
      "Epoch: 1... Training loss: 0.00152... Test loss: 0.00157\n",
      "Epoch: 1... Training loss: 0.00153... Test loss: 0.00148\n",
      "Epoch: 1... Training loss: 0.00152... Test loss: 0.00152\n",
      "Epoch: 1... Training loss: 0.00153... Test loss: 0.00158\n",
      "Epoch: 1... Training loss: 0.00138... Test loss: 0.00156\n",
      "Epoch: 1... Training loss: 0.00128... Test loss: 0.00138\n",
      "Epoch: 1... Training loss: 0.00126... Test loss: 0.00141\n",
      "Epoch: 1... Training loss: 0.00123... Test loss: 0.00144\n",
      "Epoch: 1... Training loss: 0.00122... Test loss: 0.00131\n",
      "Epoch: 1... Training loss: 0.00121... Test loss: 0.00145\n",
      "Epoch: 1... Training loss: 0.00113... Test loss: 0.00123\n",
      "Epoch: 1... Training loss: 0.00117... Test loss: 0.00121\n",
      "Epoch: 1... Training loss: 0.00118... Test loss: 0.0012\n",
      "Epoch: 1... Training loss: 0.00109... Test loss: 0.00117\n",
      "Epoch: 1... Training loss: 0.00103... Test loss: 0.00109\n",
      "Epoch: 1... Training loss: 0.00101... Test loss: 0.00122\n",
      "Epoch: 1... Training loss: 0.00105... Test loss: 0.0011\n",
      "Epoch: 1... Training loss: 0.00105... Test loss: 0.00111\n",
      "Epoch: 1... Training loss: 0.00091... Test loss: 0.00093\n",
      "Epoch: 1... Training loss: 0.00088... Test loss: 0.00097\n",
      "Epoch: 1... Training loss: 0.00093... Test loss: 0.00093\n",
      "Epoch: 1... Training loss: 0.00092... Test loss: 0.00093\n",
      "Epoch: 1... Training loss: 0.00081... Test loss: 0.001\n",
      "Epoch: 1... Training loss: 0.00084... Test loss: 0.00082\n",
      "Epoch: 1... Training loss: 0.00083... Test loss: 0.00098\n",
      "Epoch: 1... Training loss: 0.00077... Test loss: 0.00073\n",
      "Epoch: 1... Training loss: 0.00078... Test loss: 0.00073\n",
      "Epoch: 1... Training loss: 0.00071... Test loss: 0.00065\n",
      "Epoch: 1... Training loss: 0.0007... Test loss: 0.00073\n",
      "Epoch: 1... Training loss: 0.00068... Test loss: 0.00067\n",
      "Epoch: 1... Training loss: 0.00065... Test loss: 0.00067\n",
      "Epoch: 1... Training loss: 0.00062... Test loss: 0.00069\n",
      "Epoch: 1... Training loss: 0.00055... Test loss: 0.0005\n",
      "Epoch: 1... Training loss: 0.00051... Test loss: 0.00059\n",
      "Epoch: 1... Training loss: 0.0005... Test loss: 0.0006\n",
      "Epoch: 1... Training loss: 0.00054... Test loss: 0.00054\n",
      "Epoch: 1... Training loss: 0.00054... Test loss: 0.00053\n",
      "Epoch: 1... Training loss: 0.00043... Test loss: 0.00044\n",
      "Epoch: 1... Training loss: 0.00039... Test loss: 0.00047\n",
      "Epoch: 1... Training loss: 0.0004... Test loss: 0.00045\n",
      "Epoch: 1... Training loss: 0.00037... Test loss: 0.00043\n",
      "Epoch: 1... Training loss: 0.00037... Test loss: 0.0005\n",
      "Epoch: 1... Training loss: 0.00037... Test loss: 0.00039\n",
      "Epoch: 1... Training loss: 0.00036... Test loss: 0.0005\n",
      "Epoch: 1... Training loss: 0.00038... Test loss: 0.00032\n",
      "Epoch: 1... Training loss: 0.00035... Test loss: 0.00054\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00033\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00039\n",
      "Epoch: 1... Training loss: 0.00029... Test loss: 0.00024\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00034\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00028\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00017\n",
      "274.2170136719942\n",
      "Epoch: 1... Training loss: 0.80447... Test loss: 0.16457\n",
      "Epoch: 1... Training loss: 0.39817... Test loss: 0.10986\n",
      "Epoch: 1... Training loss: 0.22173... Test loss: 0.05137\n",
      "Epoch: 1... Training loss: 0.15116... Test loss: 0.03632\n",
      "Epoch: 1... Training loss: 0.11629... Test loss: 0.02445\n",
      "Epoch: 1... Training loss: 0.09233... Test loss: 0.01823\n",
      "Epoch: 1... Training loss: 0.07615... Test loss: 0.01702\n",
      "Epoch: 1... Training loss: 0.06723... Test loss: 0.01321\n",
      "Epoch: 1... Training loss: 0.06193... Test loss: 0.01258\n",
      "Epoch: 1... Training loss: 0.05023... Test loss: 0.01011\n",
      "Epoch: 1... Training loss: 0.04716... Test loss: 0.00878\n",
      "Epoch: 1... Training loss: 0.04363... Test loss: 0.00778\n",
      "Epoch: 1... Training loss: 0.0406... Test loss: 0.00894\n",
      "Epoch: 1... Training loss: 0.03591... Test loss: 0.00523\n",
      "Epoch: 1... Training loss: 0.03241... Test loss: 0.00756\n",
      "Epoch: 1... Training loss: 0.03017... Test loss: 0.00356\n",
      "Epoch: 1... Training loss: 0.02952... Test loss: 0.00626\n",
      "Epoch: 1... Training loss: 0.02684... Test loss: 0.00288\n",
      "Epoch: 1... Training loss: 0.02651... Test loss: 0.00622\n",
      "Epoch: 1... Training loss: 0.024... Test loss: 0.00222\n",
      "Epoch: 1... Training loss: 0.02361... Test loss: 0.00587\n",
      "Epoch: 1... Training loss: 0.02122... Test loss: 0.00213\n",
      "Epoch: 1... Training loss: 0.02121... Test loss: 0.00606\n",
      "Epoch: 1... Training loss: 0.0195... Test loss: 0.00291\n",
      "Epoch: 1... Training loss: 0.01969... Test loss: 0.00629\n",
      "Epoch: 1... Training loss: 0.01808... Test loss: 0.00576\n",
      "Epoch: 1... Training loss: 0.01731... Test loss: 0.00514\n",
      "Epoch: 1... Training loss: 0.01611... Test loss: 0.00714\n",
      "Epoch: 1... Training loss: 0.01561... Test loss: 0.00381\n",
      "Epoch: 1... Training loss: 0.01472... Test loss: 0.00858\n",
      "Epoch: 1... Training loss: 0.01429... Test loss: 0.00364\n",
      "Epoch: 1... Training loss: 0.01385... Test loss: 0.00778\n",
      "Epoch: 1... Training loss: 0.01317... Test loss: 0.00406\n",
      "Epoch: 1... Training loss: 0.01267... Test loss: 0.00847\n",
      "Epoch: 1... Training loss: 0.01224... Test loss: 0.00586\n",
      "Epoch: 1... Training loss: 0.01164... Test loss: 0.00571\n",
      "Epoch: 1... Training loss: 0.01146... Test loss: 0.00801\n",
      "Epoch: 1... Training loss: 0.01079... Test loss: 0.00435\n",
      "Epoch: 1... Training loss: 0.01054... Test loss: 0.0076\n",
      "Epoch: 1... Training loss: 0.01024... Test loss: 0.00449\n",
      "Epoch: 1... Training loss: 0.01008... Test loss: 0.00734\n",
      "Epoch: 1... Training loss: 0.00971... Test loss: 0.00451\n",
      "Epoch: 1... Training loss: 0.00956... Test loss: 0.0062\n",
      "Epoch: 1... Training loss: 0.00928... Test loss: 0.00596\n",
      "Epoch: 1... Training loss: 0.00909... Test loss: 0.00551\n",
      "Epoch: 1... Training loss: 0.00886... Test loss: 0.00819\n",
      "Epoch: 1... Training loss: 0.0086... Test loss: 0.00492\n",
      "Epoch: 1... Training loss: 0.00846... Test loss: 0.00653\n",
      "Epoch: 1... Training loss: 0.00799... Test loss: 0.00502\n",
      "Epoch: 1... Training loss: 0.00778... Test loss: 0.00643\n",
      "Epoch: 1... Training loss: 0.00742... Test loss: 0.00446\n",
      "Epoch: 1... Training loss: 0.00735... Test loss: 0.00556\n",
      "Epoch: 1... Training loss: 0.00713... Test loss: 0.00547\n",
      "Epoch: 1... Training loss: 0.00703... Test loss: 0.00574\n",
      "Epoch: 1... Training loss: 0.00677... Test loss: 0.00608\n",
      "Epoch: 1... Training loss: 0.00652... Test loss: 0.00526\n",
      "Epoch: 1... Training loss: 0.00631... Test loss: 0.00545\n",
      "Epoch: 1... Training loss: 0.00622... Test loss: 0.00378\n",
      "Epoch: 1... Training loss: 0.00604... Test loss: 0.00552\n",
      "Epoch: 1... Training loss: 0.00595... Test loss: 0.00349\n",
      "Epoch: 1... Training loss: 0.00578... Test loss: 0.0047\n",
      "Epoch: 1... Training loss: 0.0057... Test loss: 0.00424\n",
      "Epoch: 1... Training loss: 0.00548... Test loss: 0.00476\n",
      "Epoch: 1... Training loss: 0.00535... Test loss: 0.00384\n",
      "Epoch: 1... Training loss: 0.01449... Test loss: 0.01188\n",
      "Epoch: 1... Training loss: 0.01083... Test loss: 0.00795\n",
      "Epoch: 1... Training loss: 0.01147... Test loss: 0.00983\n",
      "Epoch: 1... Training loss: 0.00827... Test loss: 0.00809\n",
      "Epoch: 1... Training loss: 0.0114... Test loss: 0.01163\n",
      "Epoch: 1... Training loss: 0.01005... Test loss: 0.0083\n",
      "Epoch: 1... Training loss: 0.00916... Test loss: 0.01174\n",
      "Epoch: 1... Training loss: 0.00846... Test loss: 0.00966\n",
      "Epoch: 1... Training loss: 0.00871... Test loss: 0.00948\n",
      "Epoch: 1... Training loss: 0.00805... Test loss: 0.01041\n",
      "Epoch: 1... Training loss: 0.0075... Test loss: 0.00876\n",
      "Epoch: 1... Training loss: 0.00736... Test loss: 0.00739\n",
      "Epoch: 1... Training loss: 0.0071... Test loss: 0.00754\n",
      "Epoch: 1... Training loss: 0.00837... Test loss: 0.00629\n",
      "Epoch: 1... Training loss: 0.00794... Test loss: 0.00795\n",
      "Epoch: 1... Training loss: 0.00738... Test loss: 0.00642\n",
      "Epoch: 1... Training loss: 0.00676... Test loss: 0.00617\n",
      "Epoch: 1... Training loss: 0.00607... Test loss: 0.00585\n",
      "Epoch: 1... Training loss: 0.00642... Test loss: 0.00611\n",
      "Epoch: 1... Training loss: 0.0061... Test loss: 0.00725\n",
      "Epoch: 1... Training loss: 0.00604... Test loss: 0.00636\n",
      "Epoch: 1... Training loss: 0.00613... Test loss: 0.00553\n",
      "Epoch: 1... Training loss: 0.00596... Test loss: 0.00578\n",
      "Epoch: 1... Training loss: 0.00586... Test loss: 0.00562\n",
      "Epoch: 1... Training loss: 0.00535... Test loss: 0.00561\n",
      "Epoch: 1... Training loss: 0.00516... Test loss: 0.00573\n",
      "Epoch: 1... Training loss: 0.00499... Test loss: 0.00607\n",
      "Epoch: 1... Training loss: 0.00493... Test loss: 0.00492\n",
      "Epoch: 1... Training loss: 0.00462... Test loss: 0.00556\n",
      "Epoch: 1... Training loss: 0.00466... Test loss: 0.00456\n",
      "Epoch: 1... Training loss: 0.0045... Test loss: 0.00459\n",
      "Epoch: 1... Training loss: 0.00441... Test loss: 0.00527\n",
      "Epoch: 1... Training loss: 0.00425... Test loss: 0.00457\n",
      "Epoch: 1... Training loss: 0.00399... Test loss: 0.0045\n",
      "Epoch: 1... Training loss: 0.00415... Test loss: 0.00426\n",
      "Epoch: 1... Training loss: 0.00394... Test loss: 0.00403\n",
      "Epoch: 1... Training loss: 0.0038... Test loss: 0.00349\n",
      "Epoch: 1... Training loss: 0.00369... Test loss: 0.00369\n",
      "Epoch: 1... Training loss: 0.00361... Test loss: 0.00358\n",
      "Epoch: 1... Training loss: 0.00358... Test loss: 0.00384\n",
      "Epoch: 1... Training loss: 0.00357... Test loss: 0.00383\n",
      "Epoch: 1... Training loss: 0.00346... Test loss: 0.00378\n",
      "Epoch: 1... Training loss: 0.00335... Test loss: 0.00387\n",
      "Epoch: 1... Training loss: 0.00325... Test loss: 0.00386\n",
      "Epoch: 1... Training loss: 0.00319... Test loss: 0.00341\n",
      "Epoch: 1... Training loss: 0.00308... Test loss: 0.00342\n",
      "Epoch: 1... Training loss: 0.00306... Test loss: 0.00322\n",
      "Epoch: 1... Training loss: 0.00291... Test loss: 0.00309\n",
      "Epoch: 1... Training loss: 0.00302... Test loss: 0.0036\n",
      "Epoch: 1... Training loss: 0.00288... Test loss: 0.00283\n",
      "Epoch: 1... Training loss: 0.00276... Test loss: 0.00336\n",
      "Epoch: 1... Training loss: 0.00281... Test loss: 0.00303\n",
      "Epoch: 1... Training loss: 0.00269... Test loss: 0.00326\n",
      "Epoch: 1... Training loss: 0.0026... Test loss: 0.00268\n",
      "Epoch: 1... Training loss: 0.00251... Test loss: 0.00285\n",
      "Epoch: 1... Training loss: 0.00248... Test loss: 0.00263\n",
      "Epoch: 1... Training loss: 0.00239... Test loss: 0.00256\n",
      "Epoch: 1... Training loss: 0.00231... Test loss: 0.00251\n",
      "Epoch: 1... Training loss: 0.00222... Test loss: 0.00244\n",
      "Epoch: 1... Training loss: 0.00224... Test loss: 0.00222\n",
      "Epoch: 1... Training loss: 0.00211... Test loss: 0.00252\n",
      "Epoch: 1... Training loss: 0.0022... Test loss: 0.00222\n",
      "Epoch: 1... Training loss: 0.00224... Test loss: 0.00211\n",
      "Epoch: 1... Training loss: 0.00212... Test loss: 0.00221\n",
      "Epoch: 1... Training loss: 0.002... Test loss: 0.00225\n",
      "Epoch: 1... Training loss: 0.00208... Test loss: 0.00197\n",
      "Epoch: 1... Training loss: 0.0019... Test loss: 0.0021\n",
      "Epoch: 1... Training loss: 0.00191... Test loss: 0.00191\n",
      "Epoch: 1... Training loss: 0.00181... Test loss: 0.00191\n",
      "Epoch: 1... Training loss: 0.0019... Test loss: 0.00177\n",
      "Epoch: 1... Training loss: 0.00176... Test loss: 0.00229\n",
      "Epoch: 1... Training loss: 0.00175... Test loss: 0.00191\n",
      "Epoch: 1... Training loss: 0.00164... Test loss: 0.00199\n",
      "Epoch: 1... Training loss: 0.00166... Test loss: 0.00177\n",
      "Epoch: 1... Training loss: 0.0016... Test loss: 0.00172\n",
      "Epoch: 1... Training loss: 0.00164... Test loss: 0.0018\n",
      "Epoch: 1... Training loss: 0.00163... Test loss: 0.00182\n",
      "Epoch: 1... Training loss: 0.00151... Test loss: 0.00155\n",
      "Epoch: 1... Training loss: 0.00147... Test loss: 0.00153\n",
      "Epoch: 1... Training loss: 0.00141... Test loss: 0.00167\n",
      "Epoch: 1... Training loss: 0.00133... Test loss: 0.00144\n",
      "Epoch: 1... Training loss: 0.00141... Test loss: 0.00135\n",
      "Epoch: 1... Training loss: 0.00132... Test loss: 0.00143\n",
      "Epoch: 1... Training loss: 0.00134... Test loss: 0.00129\n",
      "Epoch: 1... Training loss: 0.00133... Test loss: 0.00134\n",
      "Epoch: 1... Training loss: 0.00132... Test loss: 0.00121\n",
      "Epoch: 1... Training loss: 0.00123... Test loss: 0.0013\n",
      "Epoch: 1... Training loss: 0.00117... Test loss: 0.0012\n",
      "Epoch: 1... Training loss: 0.00116... Test loss: 0.00119\n",
      "Epoch: 1... Training loss: 0.00112... Test loss: 0.00114\n",
      "Epoch: 1... Training loss: 0.00113... Test loss: 0.00102\n",
      "Epoch: 1... Training loss: 0.00107... Test loss: 0.00103\n",
      "Epoch: 1... Training loss: 0.00113... Test loss: 0.00107\n",
      "Epoch: 1... Training loss: 0.00109... Test loss: 0.00099\n",
      "Epoch: 1... Training loss: 0.00104... Test loss: 0.00115\n",
      "Epoch: 1... Training loss: 0.00109... Test loss: 0.00099\n",
      "Epoch: 1... Training loss: 0.00093... Test loss: 0.00114\n",
      "Epoch: 1... Training loss: 0.00098... Test loss: 0.00095\n",
      "Epoch: 1... Training loss: 0.001... Test loss: 0.00092\n",
      "Epoch: 1... Training loss: 0.00092... Test loss: 0.00088\n",
      "Epoch: 1... Training loss: 0.00088... Test loss: 0.00092\n",
      "Epoch: 1... Training loss: 0.00086... Test loss: 0.0008\n",
      "Epoch: 1... Training loss: 0.00087... Test loss: 0.001\n",
      "Epoch: 1... Training loss: 0.00083... Test loss: 0.00078\n",
      "Epoch: 1... Training loss: 0.00078... Test loss: 0.00088\n",
      "Epoch: 1... Training loss: 0.00079... Test loss: 0.00071\n",
      "Epoch: 1... Training loss: 0.00075... Test loss: 0.00081\n",
      "Epoch: 1... Training loss: 0.00074... Test loss: 0.00079\n",
      "Epoch: 1... Training loss: 0.00074... Test loss: 0.00079\n",
      "Epoch: 1... Training loss: 0.00073... Test loss: 0.00074\n",
      "Epoch: 1... Training loss: 0.00063... Test loss: 0.00073\n",
      "Epoch: 1... Training loss: 0.00063... Test loss: 0.00071\n",
      "Epoch: 1... Training loss: 0.00061... Test loss: 0.00065\n",
      "Epoch: 1... Training loss: 0.00056... Test loss: 0.0006\n",
      "Epoch: 1... Training loss: 0.00053... Test loss: 0.00057\n",
      "Epoch: 1... Training loss: 0.00053... Test loss: 0.00059\n",
      "Epoch: 1... Training loss: 0.0005... Test loss: 0.00051\n",
      "Epoch: 1... Training loss: 0.00049... Test loss: 0.00054\n",
      "Epoch: 1... Training loss: 0.00047... Test loss: 0.00049\n",
      "Epoch: 1... Training loss: 0.00047... Test loss: 0.00058\n",
      "Epoch: 1... Training loss: 0.00042... Test loss: 0.0005\n",
      "Epoch: 1... Training loss: 0.00041... Test loss: 0.00048\n",
      "Epoch: 1... Training loss: 0.00038... Test loss: 0.00047\n",
      "Epoch: 1... Training loss: 0.00038... Test loss: 0.00037\n",
      "Epoch: 1... Training loss: 0.00035... Test loss: 0.00038\n",
      "Epoch: 1... Training loss: 0.00034... Test loss: 0.00033\n",
      "Epoch: 1... Training loss: 0.00031... Test loss: 0.00033\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.0003\n",
      "Epoch: 1... Training loss: 0.00035... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00028\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00024\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00024\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00024\n",
      "299.46093259518966\n",
      "Epoch: 1... Training loss: 0.87156... Test loss: 0.2287\n",
      "Epoch: 1... Training loss: 0.46756... Test loss: 0.16147\n",
      "Epoch: 1... Training loss: 0.29141... Test loss: 0.08041\n",
      "Epoch: 1... Training loss: 0.21266... Test loss: 0.04836\n",
      "Epoch: 1... Training loss: 0.16029... Test loss: 0.03082\n",
      "Epoch: 1... Training loss: 0.13883... Test loss: 0.02589\n",
      "Epoch: 1... Training loss: 0.11955... Test loss: 0.02274\n",
      "Epoch: 1... Training loss: 0.08955... Test loss: 0.01696\n",
      "Epoch: 1... Training loss: 0.07826... Test loss: 0.02057\n",
      "Epoch: 1... Training loss: 0.06428... Test loss: 0.03016\n",
      "Epoch: 1... Training loss: 0.0598... Test loss: 0.00997\n",
      "Epoch: 1... Training loss: 0.05256... Test loss: 0.0245\n",
      "Epoch: 1... Training loss: 0.04643... Test loss: 0.00799\n",
      "Epoch: 1... Training loss: 0.04277... Test loss: 0.0211\n",
      "Epoch: 1... Training loss: 0.03921... Test loss: 0.01166\n",
      "Epoch: 1... Training loss: 0.03606... Test loss: 0.01977\n",
      "Epoch: 1... Training loss: 0.03391... Test loss: 0.01642\n",
      "Epoch: 1... Training loss: 0.03132... Test loss: 0.02003\n",
      "Epoch: 1... Training loss: 0.02988... Test loss: 0.02365\n",
      "Epoch: 1... Training loss: 0.02706... Test loss: 0.01136\n",
      "Epoch: 1... Training loss: 0.02566... Test loss: 0.02451\n",
      "Epoch: 1... Training loss: 0.02463... Test loss: 0.01208\n",
      "Epoch: 1... Training loss: 0.02328... Test loss: 0.02262\n",
      "Epoch: 1... Training loss: 0.02242... Test loss: 0.00999\n",
      "Epoch: 1... Training loss: 0.02097... Test loss: 0.01704\n",
      "Epoch: 1... Training loss: 0.01979... Test loss: 0.01213\n",
      "Epoch: 1... Training loss: 0.01924... Test loss: 0.01816\n",
      "Epoch: 1... Training loss: 0.01765... Test loss: 0.01167\n",
      "Epoch: 1... Training loss: 0.01706... Test loss: 0.01113\n",
      "Epoch: 1... Training loss: 0.01612... Test loss: 0.0147\n",
      "Epoch: 1... Training loss: 0.0158... Test loss: 0.0094\n",
      "Epoch: 1... Training loss: 0.01507... Test loss: 0.01602\n",
      "Epoch: 1... Training loss: 0.01463... Test loss: 0.0128\n",
      "Epoch: 1... Training loss: 0.01408... Test loss: 0.01142\n",
      "Epoch: 1... Training loss: 0.0135... Test loss: 0.01293\n",
      "Epoch: 1... Training loss: 0.01279... Test loss: 0.01059\n",
      "Epoch: 1... Training loss: 0.01254... Test loss: 0.01133\n",
      "Epoch: 1... Training loss: 0.01226... Test loss: 0.01354\n",
      "Epoch: 1... Training loss: 0.01191... Test loss: 0.00783\n",
      "Epoch: 1... Training loss: 0.01152... Test loss: 0.0125\n",
      "Epoch: 1... Training loss: 0.01118... Test loss: 0.00761\n",
      "Epoch: 1... Training loss: 0.01065... Test loss: 0.0115\n",
      "Epoch: 1... Training loss: 0.01039... Test loss: 0.00758\n",
      "Epoch: 1... Training loss: 0.01005... Test loss: 0.01042\n",
      "Epoch: 1... Training loss: 0.00979... Test loss: 0.00653\n",
      "Epoch: 1... Training loss: 0.00965... Test loss: 0.00959\n",
      "Epoch: 1... Training loss: 0.00915... Test loss: 0.00721\n",
      "Epoch: 1... Training loss: 0.009... Test loss: 0.00887\n",
      "Epoch: 1... Training loss: 0.00875... Test loss: 0.00712\n",
      "Epoch: 1... Training loss: 0.00857... Test loss: 0.00739\n",
      "Epoch: 1... Training loss: 0.00823... Test loss: 0.00782\n",
      "Epoch: 1... Training loss: 0.00808... Test loss: 0.00751\n",
      "Epoch: 1... Training loss: 0.00777... Test loss: 0.00726\n",
      "Epoch: 1... Training loss: 0.0077... Test loss: 0.00778\n",
      "Epoch: 1... Training loss: 0.00741... Test loss: 0.00631\n",
      "Epoch: 1... Training loss: 0.00716... Test loss: 0.00581\n",
      "Epoch: 1... Training loss: 0.0069... Test loss: 0.00695\n",
      "Epoch: 1... Training loss: 0.00677... Test loss: 0.00553\n",
      "Epoch: 1... Training loss: 0.0065... Test loss: 0.00752\n",
      "Epoch: 1... Training loss: 0.00635... Test loss: 0.00596\n",
      "Epoch: 1... Training loss: 0.00614... Test loss: 0.00552\n",
      "Epoch: 1... Training loss: 0.00608... Test loss: 0.00604\n",
      "Epoch: 1... Training loss: 0.00587... Test loss: 0.00451\n",
      "Epoch: 1... Training loss: 0.00583... Test loss: 0.00525\n",
      "Epoch: 1... Training loss: 0.01036... Test loss: 0.00499\n",
      "Epoch: 1... Training loss: 0.0113... Test loss: 0.01175\n",
      "Epoch: 1... Training loss: 0.01007... Test loss: 0.00819\n",
      "Epoch: 1... Training loss: 0.01075... Test loss: 0.00973\n",
      "Epoch: 1... Training loss: 0.00917... Test loss: 0.01325\n",
      "Epoch: 1... Training loss: 0.00908... Test loss: 0.01153\n",
      "Epoch: 1... Training loss: 0.00978... Test loss: 0.01083\n",
      "Epoch: 1... Training loss: 0.00861... Test loss: 0.00978\n",
      "Epoch: 1... Training loss: 0.00861... Test loss: 0.01405\n",
      "Epoch: 1... Training loss: 0.00891... Test loss: 0.00945\n",
      "Epoch: 1... Training loss: 0.00802... Test loss: 0.01492\n",
      "Epoch: 1... Training loss: 0.00745... Test loss: 0.00988\n",
      "Epoch: 1... Training loss: 0.00782... Test loss: 0.00812\n",
      "Epoch: 1... Training loss: 0.00741... Test loss: 0.00996\n",
      "Epoch: 1... Training loss: 0.00727... Test loss: 0.00684\n",
      "Epoch: 1... Training loss: 0.00679... Test loss: 0.00833\n",
      "Epoch: 1... Training loss: 0.00695... Test loss: 0.00689\n",
      "Epoch: 1... Training loss: 0.00678... Test loss: 0.00796\n",
      "Epoch: 1... Training loss: 0.00648... Test loss: 0.00653\n",
      "Epoch: 1... Training loss: 0.00611... Test loss: 0.0083\n",
      "Epoch: 1... Training loss: 0.00612... Test loss: 0.00742\n",
      "Epoch: 1... Training loss: 0.00618... Test loss: 0.00715\n",
      "Epoch: 1... Training loss: 0.00569... Test loss: 0.0062\n",
      "Epoch: 1... Training loss: 0.00562... Test loss: 0.00659\n",
      "Epoch: 1... Training loss: 0.00558... Test loss: 0.00657\n",
      "Epoch: 1... Training loss: 0.00534... Test loss: 0.00635\n",
      "Epoch: 1... Training loss: 0.00504... Test loss: 0.00624\n",
      "Epoch: 1... Training loss: 0.00493... Test loss: 0.00634\n",
      "Epoch: 1... Training loss: 0.00474... Test loss: 0.00502\n",
      "Epoch: 1... Training loss: 0.00442... Test loss: 0.00662\n",
      "Epoch: 1... Training loss: 0.00443... Test loss: 0.00419\n",
      "Epoch: 1... Training loss: 0.00432... Test loss: 0.00563\n",
      "Epoch: 1... Training loss: 0.00417... Test loss: 0.00419\n",
      "Epoch: 1... Training loss: 0.00396... Test loss: 0.00466\n",
      "Epoch: 1... Training loss: 0.00393... Test loss: 0.00357\n",
      "Epoch: 1... Training loss: 0.00372... Test loss: 0.00443\n",
      "Epoch: 1... Training loss: 0.00377... Test loss: 0.00364\n",
      "Epoch: 1... Training loss: 0.00349... Test loss: 0.00413\n",
      "Epoch: 1... Training loss: 0.00358... Test loss: 0.0033\n",
      "Epoch: 1... Training loss: 0.00343... Test loss: 0.00399\n",
      "Epoch: 1... Training loss: 0.00341... Test loss: 0.00329\n",
      "Epoch: 1... Training loss: 0.00343... Test loss: 0.00356\n",
      "Epoch: 1... Training loss: 0.00313... Test loss: 0.00345\n",
      "Epoch: 1... Training loss: 0.00308... Test loss: 0.00344\n",
      "Epoch: 1... Training loss: 0.00305... Test loss: 0.00324\n",
      "Epoch: 1... Training loss: 0.00305... Test loss: 0.00388\n",
      "Epoch: 1... Training loss: 0.00298... Test loss: 0.0034\n",
      "Epoch: 1... Training loss: 0.00289... Test loss: 0.00331\n",
      "Epoch: 1... Training loss: 0.00306... Test loss: 0.00276\n",
      "Epoch: 1... Training loss: 0.0027... Test loss: 0.00352\n",
      "Epoch: 1... Training loss: 0.00268... Test loss: 0.00266\n",
      "Epoch: 1... Training loss: 0.00258... Test loss: 0.00305\n",
      "Epoch: 1... Training loss: 0.00252... Test loss: 0.00242\n",
      "Epoch: 1... Training loss: 0.00255... Test loss: 0.00292\n",
      "Epoch: 1... Training loss: 0.0025... Test loss: 0.00253\n",
      "Epoch: 1... Training loss: 0.00238... Test loss: 0.00275\n",
      "Epoch: 1... Training loss: 0.00235... Test loss: 0.0024\n",
      "Epoch: 1... Training loss: 0.00235... Test loss: 0.00254\n",
      "Epoch: 1... Training loss: 0.00226... Test loss: 0.00224\n",
      "Epoch: 1... Training loss: 0.00212... Test loss: 0.00228\n",
      "Epoch: 1... Training loss: 0.00212... Test loss: 0.0019\n",
      "Epoch: 1... Training loss: 0.0021... Test loss: 0.00205\n",
      "Epoch: 1... Training loss: 0.00207... Test loss: 0.00214\n",
      "Epoch: 1... Training loss: 0.00198... Test loss: 0.00209\n",
      "Epoch: 1... Training loss: 0.00194... Test loss: 0.00216\n",
      "Epoch: 1... Training loss: 0.00188... Test loss: 0.00211\n",
      "Epoch: 1... Training loss: 0.00181... Test loss: 0.00194\n",
      "Epoch: 1... Training loss: 0.00185... Test loss: 0.00214\n",
      "Epoch: 1... Training loss: 0.00174... Test loss: 0.00185\n",
      "Epoch: 1... Training loss: 0.00174... Test loss: 0.00186\n",
      "Epoch: 1... Training loss: 0.00157... Test loss: 0.00203\n",
      "Epoch: 1... Training loss: 0.00155... Test loss: 0.00169\n",
      "Epoch: 1... Training loss: 0.0016... Test loss: 0.00154\n",
      "Epoch: 1... Training loss: 0.00146... Test loss: 0.00162\n",
      "Epoch: 1... Training loss: 0.00141... Test loss: 0.00125\n",
      "Epoch: 1... Training loss: 0.00137... Test loss: 0.00161\n",
      "Epoch: 1... Training loss: 0.00137... Test loss: 0.00119\n",
      "Epoch: 1... Training loss: 0.00142... Test loss: 0.00136\n",
      "Epoch: 1... Training loss: 0.00132... Test loss: 0.00099\n",
      "Epoch: 1... Training loss: 0.00123... Test loss: 0.00151\n",
      "Epoch: 1... Training loss: 0.00119... Test loss: 0.00099\n",
      "Epoch: 1... Training loss: 0.00126... Test loss: 0.00149\n",
      "Epoch: 1... Training loss: 0.00117... Test loss: 0.00108\n",
      "Epoch: 1... Training loss: 0.00109... Test loss: 0.00139\n",
      "Epoch: 1... Training loss: 0.0011... Test loss: 0.00096\n",
      "Epoch: 1... Training loss: 0.00107... Test loss: 0.00125\n",
      "Epoch: 1... Training loss: 0.00115... Test loss: 0.00103\n",
      "Epoch: 1... Training loss: 0.00095... Test loss: 0.00123\n",
      "Epoch: 1... Training loss: 0.00098... Test loss: 0.00104\n",
      "Epoch: 1... Training loss: 0.00096... Test loss: 0.00122\n",
      "Epoch: 1... Training loss: 0.00093... Test loss: 0.00094\n",
      "Epoch: 1... Training loss: 0.00098... Test loss: 0.00104\n",
      "Epoch: 1... Training loss: 0.00088... Test loss: 0.00094\n",
      "Epoch: 1... Training loss: 0.0009... Test loss: 0.00105\n",
      "Epoch: 1... Training loss: 0.0009... Test loss: 0.00097\n",
      "Epoch: 1... Training loss: 0.00091... Test loss: 0.00081\n",
      "Epoch: 1... Training loss: 0.00078... Test loss: 0.00093\n",
      "Epoch: 1... Training loss: 0.0008... Test loss: 0.00071\n",
      "Epoch: 1... Training loss: 0.00074... Test loss: 0.00081\n",
      "Epoch: 1... Training loss: 0.00074... Test loss: 0.00075\n",
      "Epoch: 1... Training loss: 0.00073... Test loss: 0.00082\n",
      "Epoch: 1... Training loss: 0.00069... Test loss: 0.00063\n",
      "Epoch: 1... Training loss: 0.0007... Test loss: 0.00072\n",
      "Epoch: 1... Training loss: 0.00074... Test loss: 0.00065\n",
      "Epoch: 1... Training loss: 0.00063... Test loss: 0.00067\n",
      "Epoch: 1... Training loss: 0.00062... Test loss: 0.00057\n",
      "Epoch: 1... Training loss: 0.00059... Test loss: 0.00052\n",
      "Epoch: 1... Training loss: 0.00055... Test loss: 0.00062\n",
      "Epoch: 1... Training loss: 0.00052... Test loss: 0.00057\n",
      "Epoch: 1... Training loss: 0.00051... Test loss: 0.00053\n",
      "Epoch: 1... Training loss: 0.00053... Test loss: 0.00056\n",
      "Epoch: 1... Training loss: 0.00049... Test loss: 0.00048\n",
      "Epoch: 1... Training loss: 0.0005... Test loss: 0.0005\n",
      "Epoch: 1... Training loss: 0.00045... Test loss: 0.00049\n",
      "Epoch: 1... Training loss: 0.0004... Test loss: 0.00055\n",
      "Epoch: 1... Training loss: 0.00039... Test loss: 0.00048\n",
      "Epoch: 1... Training loss: 0.00038... Test loss: 0.00044\n",
      "Epoch: 1... Training loss: 0.00036... Test loss: 0.00041\n",
      "Epoch: 1... Training loss: 0.00038... Test loss: 0.00044\n",
      "Epoch: 1... Training loss: 0.00034... Test loss: 0.00035\n",
      "Epoch: 1... Training loss: 0.00032... Test loss: 0.00043\n",
      "Epoch: 1... Training loss: 0.00031... Test loss: 0.00031\n",
      "Epoch: 1... Training loss: 0.00031... Test loss: 0.00036\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00029... Test loss: 0.00031\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00031... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00029... Test loss: 0.00031\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.0003\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00028\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00015\n",
      "271.78692600282375\n",
      "Epoch: 1... Training loss: 0.83758... Test loss: 0.1518\n",
      "Epoch: 1... Training loss: 0.35516... Test loss: 0.07351\n",
      "Epoch: 1... Training loss: 0.27052... Test loss: 0.07866\n",
      "Epoch: 1... Training loss: 0.16602... Test loss: 0.04358\n",
      "Epoch: 1... Training loss: 0.12108... Test loss: 0.02857\n",
      "Epoch: 1... Training loss: 0.09642... Test loss: 0.01978\n",
      "Epoch: 1... Training loss: 0.07514... Test loss: 0.01537\n",
      "Epoch: 1... Training loss: 0.06877... Test loss: 0.01193\n",
      "Epoch: 1... Training loss: 0.05862... Test loss: 0.011\n",
      "Epoch: 1... Training loss: 0.05244... Test loss: 0.00702\n",
      "Epoch: 1... Training loss: 0.04784... Test loss: 0.00795\n",
      "Epoch: 1... Training loss: 0.04174... Test loss: 0.00539\n",
      "Epoch: 1... Training loss: 0.03691... Test loss: 0.00551\n",
      "Epoch: 1... Training loss: 0.03515... Test loss: 0.00411\n",
      "Epoch: 1... Training loss: 0.03055... Test loss: 0.00452\n",
      "Epoch: 1... Training loss: 0.02925... Test loss: 0.00318\n",
      "Epoch: 1... Training loss: 0.02826... Test loss: 0.00469\n",
      "Epoch: 1... Training loss: 0.02605... Test loss: 0.00291\n",
      "Epoch: 1... Training loss: 0.02477... Test loss: 0.00492\n",
      "Epoch: 1... Training loss: 0.02341... Test loss: 0.00238\n",
      "Epoch: 1... Training loss: 0.02252... Test loss: 0.00474\n",
      "Epoch: 1... Training loss: 0.02125... Test loss: 0.00182\n",
      "Epoch: 1... Training loss: 0.02073... Test loss: 0.00701\n",
      "Epoch: 1... Training loss: 0.01914... Test loss: 0.00541\n",
      "Epoch: 1... Training loss: 0.01828... Test loss: 0.00805\n",
      "Epoch: 1... Training loss: 0.01723... Test loss: 0.003\n",
      "Epoch: 1... Training loss: 0.01681... Test loss: 0.00772\n",
      "Epoch: 1... Training loss: 0.01624... Test loss: 0.0048\n",
      "Epoch: 1... Training loss: 0.01561... Test loss: 0.0039\n",
      "Epoch: 1... Training loss: 0.01507... Test loss: 0.00815\n",
      "Epoch: 1... Training loss: 0.01404... Test loss: 0.00322\n",
      "Epoch: 1... Training loss: 0.01356... Test loss: 0.00815\n",
      "Epoch: 1... Training loss: 0.01287... Test loss: 0.00382\n",
      "Epoch: 1... Training loss: 0.01212... Test loss: 0.00908\n",
      "Epoch: 1... Training loss: 0.01185... Test loss: 0.00417\n",
      "Epoch: 1... Training loss: 0.01146... Test loss: 0.00697\n",
      "Epoch: 1... Training loss: 0.01105... Test loss: 0.00388\n",
      "Epoch: 1... Training loss: 0.01074... Test loss: 0.00512\n",
      "Epoch: 1... Training loss: 0.01036... Test loss: 0.0059\n",
      "Epoch: 1... Training loss: 0.01033... Test loss: 0.00488\n",
      "Epoch: 1... Training loss: 0.00988... Test loss: 0.00693\n",
      "Epoch: 1... Training loss: 0.00975... Test loss: 0.0042\n",
      "Epoch: 1... Training loss: 0.0095... Test loss: 0.0076\n",
      "Epoch: 1... Training loss: 0.00944... Test loss: 0.00448\n",
      "Epoch: 1... Training loss: 0.00903... Test loss: 0.00701\n",
      "Epoch: 1... Training loss: 0.00884... Test loss: 0.00463\n",
      "Epoch: 1... Training loss: 0.00852... Test loss: 0.00719\n",
      "Epoch: 1... Training loss: 0.00831... Test loss: 0.00544\n",
      "Epoch: 1... Training loss: 0.00795... Test loss: 0.00758\n",
      "Epoch: 1... Training loss: 0.00766... Test loss: 0.00588\n",
      "Epoch: 1... Training loss: 0.0073... Test loss: 0.0077\n",
      "Epoch: 1... Training loss: 0.00722... Test loss: 0.00567\n",
      "Epoch: 1... Training loss: 0.00702... Test loss: 0.00697\n",
      "Epoch: 1... Training loss: 0.00687... Test loss: 0.00493\n",
      "Epoch: 1... Training loss: 0.00668... Test loss: 0.0063\n",
      "Epoch: 1... Training loss: 0.00645... Test loss: 0.00496\n",
      "Epoch: 1... Training loss: 0.00633... Test loss: 0.00579\n",
      "Epoch: 1... Training loss: 0.00615... Test loss: 0.00588\n",
      "Epoch: 1... Training loss: 0.00597... Test loss: 0.00498\n",
      "Epoch: 1... Training loss: 0.00583... Test loss: 0.00671\n",
      "Epoch: 1... Training loss: 0.00565... Test loss: 0.00469\n",
      "Epoch: 1... Training loss: 0.00552... Test loss: 0.00603\n",
      "Epoch: 1... Training loss: 0.00537... Test loss: 0.00546\n",
      "Epoch: 1... Training loss: 0.00532... Test loss: 0.00532\n",
      "Epoch: 1... Training loss: 0.01861... Test loss: 0.00732\n",
      "Epoch: 1... Training loss: 0.00966... Test loss: 0.01185\n",
      "Epoch: 1... Training loss: 0.01... Test loss: 0.00807\n",
      "Epoch: 1... Training loss: 0.00844... Test loss: 0.01304\n",
      "Epoch: 1... Training loss: 0.01063... Test loss: 0.00751\n",
      "Epoch: 1... Training loss: 0.01083... Test loss: 0.00975\n",
      "Epoch: 1... Training loss: 0.0101... Test loss: 0.01224\n",
      "Epoch: 1... Training loss: 0.00911... Test loss: 0.00925\n",
      "Epoch: 1... Training loss: 0.00828... Test loss: 0.00863\n",
      "Epoch: 1... Training loss: 0.0078... Test loss: 0.00962\n",
      "Epoch: 1... Training loss: 0.00761... Test loss: 0.00865\n",
      "Epoch: 1... Training loss: 0.00798... Test loss: 0.00897\n",
      "Epoch: 1... Training loss: 0.00755... Test loss: 0.00885\n",
      "Epoch: 1... Training loss: 0.0069... Test loss: 0.00881\n",
      "Epoch: 1... Training loss: 0.00718... Test loss: 0.00727\n",
      "Epoch: 1... Training loss: 0.00677... Test loss: 0.00712\n",
      "Epoch: 1... Training loss: 0.00621... Test loss: 0.0061\n",
      "Epoch: 1... Training loss: 0.00594... Test loss: 0.00769\n",
      "Epoch: 1... Training loss: 0.00585... Test loss: 0.00546\n",
      "Epoch: 1... Training loss: 0.00587... Test loss: 0.00731\n",
      "Epoch: 1... Training loss: 0.00565... Test loss: 0.00558\n",
      "Epoch: 1... Training loss: 0.00568... Test loss: 0.0063\n",
      "Epoch: 1... Training loss: 0.00521... Test loss: 0.00554\n",
      "Epoch: 1... Training loss: 0.00513... Test loss: 0.00647\n",
      "Epoch: 1... Training loss: 0.00525... Test loss: 0.00465\n",
      "Epoch: 1... Training loss: 0.00517... Test loss: 0.00531\n",
      "Epoch: 1... Training loss: 0.00468... Test loss: 0.0048\n",
      "Epoch: 1... Training loss: 0.00466... Test loss: 0.00516\n",
      "Epoch: 1... Training loss: 0.00453... Test loss: 0.00461\n",
      "Epoch: 1... Training loss: 0.00439... Test loss: 0.00511\n",
      "Epoch: 1... Training loss: 0.0042... Test loss: 0.00409\n",
      "Epoch: 1... Training loss: 0.00418... Test loss: 0.00455\n",
      "Epoch: 1... Training loss: 0.00406... Test loss: 0.00469\n",
      "Epoch: 1... Training loss: 0.00379... Test loss: 0.00431\n",
      "Epoch: 1... Training loss: 0.00386... Test loss: 0.00408\n",
      "Epoch: 1... Training loss: 0.0038... Test loss: 0.00409\n",
      "Epoch: 1... Training loss: 0.00354... Test loss: 0.00358\n",
      "Epoch: 1... Training loss: 0.00366... Test loss: 0.00393\n",
      "Epoch: 1... Training loss: 0.00355... Test loss: 0.00383\n",
      "Epoch: 1... Training loss: 0.00346... Test loss: 0.00389\n",
      "Epoch: 1... Training loss: 0.00348... Test loss: 0.00375\n",
      "Epoch: 1... Training loss: 0.00334... Test loss: 0.00328\n",
      "Epoch: 1... Training loss: 0.00329... Test loss: 0.00407\n",
      "Epoch: 1... Training loss: 0.00322... Test loss: 0.00339\n",
      "Epoch: 1... Training loss: 0.00332... Test loss: 0.00369\n",
      "Epoch: 1... Training loss: 0.00314... Test loss: 0.0032\n",
      "Epoch: 1... Training loss: 0.00311... Test loss: 0.0038\n",
      "Epoch: 1... Training loss: 0.00307... Test loss: 0.00346\n",
      "Epoch: 1... Training loss: 0.00293... Test loss: 0.00299\n",
      "Epoch: 1... Training loss: 0.00305... Test loss: 0.00312\n",
      "Epoch: 1... Training loss: 0.00282... Test loss: 0.00325\n",
      "Epoch: 1... Training loss: 0.00283... Test loss: 0.00256\n",
      "Epoch: 1... Training loss: 0.00277... Test loss: 0.00297\n",
      "Epoch: 1... Training loss: 0.00259... Test loss: 0.00238\n",
      "Epoch: 1... Training loss: 0.00263... Test loss: 0.00296\n",
      "Epoch: 1... Training loss: 0.00246... Test loss: 0.00268\n",
      "Epoch: 1... Training loss: 0.00251... Test loss: 0.00245\n",
      "Epoch: 1... Training loss: 0.00232... Test loss: 0.00273\n",
      "Epoch: 1... Training loss: 0.00229... Test loss: 0.00242\n",
      "Epoch: 1... Training loss: 0.0023... Test loss: 0.00231\n",
      "Epoch: 1... Training loss: 0.00225... Test loss: 0.00245\n",
      "Epoch: 1... Training loss: 0.00216... Test loss: 0.00263\n",
      "Epoch: 1... Training loss: 0.00216... Test loss: 0.002\n",
      "Epoch: 1... Training loss: 0.00206... Test loss: 0.00272\n",
      "Epoch: 1... Training loss: 0.00204... Test loss: 0.00219\n",
      "Epoch: 1... Training loss: 0.00196... Test loss: 0.0022\n",
      "Epoch: 1... Training loss: 0.00187... Test loss: 0.00181\n",
      "Epoch: 1... Training loss: 0.00183... Test loss: 0.0022\n",
      "Epoch: 1... Training loss: 0.00185... Test loss: 0.00157\n",
      "Epoch: 1... Training loss: 0.00176... Test loss: 0.0021\n",
      "Epoch: 1... Training loss: 0.00176... Test loss: 0.00198\n",
      "Epoch: 1... Training loss: 0.00171... Test loss: 0.00178\n",
      "Epoch: 1... Training loss: 0.00163... Test loss: 0.00172\n",
      "Epoch: 1... Training loss: 0.00164... Test loss: 0.00172\n",
      "Epoch: 1... Training loss: 0.00157... Test loss: 0.00176\n",
      "Epoch: 1... Training loss: 0.00157... Test loss: 0.00167\n",
      "Epoch: 1... Training loss: 0.00157... Test loss: 0.00174\n",
      "Epoch: 1... Training loss: 0.00142... Test loss: 0.0016\n",
      "Epoch: 1... Training loss: 0.0014... Test loss: 0.0016\n",
      "Epoch: 1... Training loss: 0.00131... Test loss: 0.00154\n",
      "Epoch: 1... Training loss: 0.0013... Test loss: 0.00124\n",
      "Epoch: 1... Training loss: 0.00132... Test loss: 0.00159\n",
      "Epoch: 1... Training loss: 0.0012... Test loss: 0.00134\n",
      "Epoch: 1... Training loss: 0.00119... Test loss: 0.00139\n",
      "Epoch: 1... Training loss: 0.00128... Test loss: 0.00128\n",
      "Epoch: 1... Training loss: 0.00122... Test loss: 0.00116\n",
      "Epoch: 1... Training loss: 0.00111... Test loss: 0.00117\n",
      "Epoch: 1... Training loss: 0.00111... Test loss: 0.00108\n",
      "Epoch: 1... Training loss: 0.00108... Test loss: 0.00102\n",
      "Epoch: 1... Training loss: 0.00106... Test loss: 0.00119\n",
      "Epoch: 1... Training loss: 0.00102... Test loss: 0.00107\n",
      "Epoch: 1... Training loss: 0.00099... Test loss: 0.00111\n",
      "Epoch: 1... Training loss: 0.00107... Test loss: 0.00094\n",
      "Epoch: 1... Training loss: 0.00088... Test loss: 0.00087\n",
      "Epoch: 1... Training loss: 0.00093... Test loss: 0.00088\n",
      "Epoch: 1... Training loss: 0.00086... Test loss: 0.00092\n",
      "Epoch: 1... Training loss: 0.00086... Test loss: 0.00079\n",
      "Epoch: 1... Training loss: 0.00082... Test loss: 0.00096\n",
      "Epoch: 1... Training loss: 0.00083... Test loss: 0.0008\n",
      "Epoch: 1... Training loss: 0.00077... Test loss: 0.00089\n",
      "Epoch: 1... Training loss: 0.00079... Test loss: 0.00085\n",
      "Epoch: 1... Training loss: 0.00073... Test loss: 0.00075\n",
      "Epoch: 1... Training loss: 0.00069... Test loss: 0.00073\n",
      "Epoch: 1... Training loss: 0.00065... Test loss: 0.00069\n",
      "Epoch: 1... Training loss: 0.0006... Test loss: 0.00062\n",
      "Epoch: 1... Training loss: 0.00061... Test loss: 0.00065\n",
      "Epoch: 1... Training loss: 0.00063... Test loss: 0.00062\n",
      "Epoch: 1... Training loss: 0.00055... Test loss: 0.00055\n",
      "Epoch: 1... Training loss: 0.00059... Test loss: 0.00053\n",
      "Epoch: 1... Training loss: 0.00053... Test loss: 0.00059\n",
      "Epoch: 1... Training loss: 0.00051... Test loss: 0.00055\n",
      "Epoch: 1... Training loss: 0.00054... Test loss: 0.00056\n",
      "Epoch: 1... Training loss: 0.00048... Test loss: 0.00047\n",
      "Epoch: 1... Training loss: 0.00046... Test loss: 0.00049\n",
      "Epoch: 1... Training loss: 0.00044... Test loss: 0.00047\n",
      "Epoch: 1... Training loss: 0.00047... Test loss: 0.00043\n",
      "Epoch: 1... Training loss: 0.00039... Test loss: 0.00039\n",
      "Epoch: 1... Training loss: 0.00044... Test loss: 0.00041\n",
      "Epoch: 1... Training loss: 0.00039... Test loss: 0.00037\n",
      "Epoch: 1... Training loss: 0.00038... Test loss: 0.0004\n",
      "Epoch: 1... Training loss: 0.00041... Test loss: 0.00036\n",
      "Epoch: 1... Training loss: 0.00038... Test loss: 0.00039\n",
      "Epoch: 1... Training loss: 0.00039... Test loss: 0.0003\n",
      "Epoch: 1... Training loss: 0.00034... Test loss: 0.00039\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00034\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.00024\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00031\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00028\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00014\n",
      "249.1320189946564\n",
      "Epoch: 1... Training loss: 1.25666... Test loss: 0.58568\n",
      "Epoch: 1... Training loss: 0.57368... Test loss: 0.22186\n",
      "Epoch: 1... Training loss: 0.27509... Test loss: 0.13823\n",
      "Epoch: 1... Training loss: 0.25391... Test loss: 0.09233\n",
      "Epoch: 1... Training loss: 0.1445... Test loss: 0.1017\n",
      "Epoch: 1... Training loss: 0.10641... Test loss: 0.07683\n",
      "Epoch: 1... Training loss: 0.09075... Test loss: 0.03958\n",
      "Epoch: 1... Training loss: 0.07389... Test loss: 0.06565\n",
      "Epoch: 1... Training loss: 0.0655... Test loss: 0.04134\n",
      "Epoch: 1... Training loss: 0.05526... Test loss: 0.05239\n",
      "Epoch: 1... Training loss: 0.05135... Test loss: 0.02454\n",
      "Epoch: 1... Training loss: 0.04488... Test loss: 0.04154\n",
      "Epoch: 1... Training loss: 0.04225... Test loss: 0.02095\n",
      "Epoch: 1... Training loss: 0.03928... Test loss: 0.04178\n",
      "Epoch: 1... Training loss: 0.03738... Test loss: 0.01728\n",
      "Epoch: 1... Training loss: 0.03271... Test loss: 0.02231\n",
      "Epoch: 1... Training loss: 0.03222... Test loss: 0.01551\n",
      "Epoch: 1... Training loss: 0.0289... Test loss: 0.02141\n",
      "Epoch: 1... Training loss: 0.02733... Test loss: 0.0205\n",
      "Epoch: 1... Training loss: 0.0256... Test loss: 0.01412\n",
      "Epoch: 1... Training loss: 0.02332... Test loss: 0.01879\n",
      "Epoch: 1... Training loss: 0.02258... Test loss: 0.0111\n",
      "Epoch: 1... Training loss: 0.0214... Test loss: 0.01925\n",
      "Epoch: 1... Training loss: 0.0205... Test loss: 0.01425\n",
      "Epoch: 1... Training loss: 0.01936... Test loss: 0.01791\n",
      "Epoch: 1... Training loss: 0.0188... Test loss: 0.0177\n",
      "Epoch: 1... Training loss: 0.01791... Test loss: 0.00926\n",
      "Epoch: 1... Training loss: 0.0172... Test loss: 0.01556\n",
      "Epoch: 1... Training loss: 0.01594... Test loss: 0.00939\n",
      "Epoch: 1... Training loss: 0.01561... Test loss: 0.01339\n",
      "Epoch: 1... Training loss: 0.01488... Test loss: 0.01151\n",
      "Epoch: 1... Training loss: 0.01422... Test loss: 0.0124\n",
      "Epoch: 1... Training loss: 0.01372... Test loss: 0.01355\n",
      "Epoch: 1... Training loss: 0.01343... Test loss: 0.00995\n",
      "Epoch: 1... Training loss: 0.0128... Test loss: 0.01257\n",
      "Epoch: 1... Training loss: 0.01227... Test loss: 0.00884\n",
      "Epoch: 1... Training loss: 0.01169... Test loss: 0.01192\n",
      "Epoch: 1... Training loss: 0.01122... Test loss: 0.00899\n",
      "Epoch: 1... Training loss: 0.011... Test loss: 0.01103\n",
      "Epoch: 1... Training loss: 0.01036... Test loss: 0.00738\n",
      "Epoch: 1... Training loss: 0.01028... Test loss: 0.01001\n",
      "Epoch: 1... Training loss: 0.00984... Test loss: 0.00859\n",
      "Epoch: 1... Training loss: 0.00961... Test loss: 0.00986\n",
      "Epoch: 1... Training loss: 0.00953... Test loss: 0.00753\n",
      "Epoch: 1... Training loss: 0.00928... Test loss: 0.00954\n",
      "Epoch: 1... Training loss: 0.00886... Test loss: 0.007\n",
      "Epoch: 1... Training loss: 0.00861... Test loss: 0.00867\n",
      "Epoch: 1... Training loss: 0.0083... Test loss: 0.00766\n",
      "Epoch: 1... Training loss: 0.00808... Test loss: 0.00892\n",
      "Epoch: 1... Training loss: 0.00779... Test loss: 0.00691\n",
      "Epoch: 1... Training loss: 0.00764... Test loss: 0.00816\n",
      "Epoch: 1... Training loss: 0.00745... Test loss: 0.00587\n",
      "Epoch: 1... Training loss: 0.00723... Test loss: 0.007\n",
      "Epoch: 1... Training loss: 0.00704... Test loss: 0.00544\n",
      "Epoch: 1... Training loss: 0.00686... Test loss: 0.00714\n",
      "Epoch: 1... Training loss: 0.00669... Test loss: 0.0059\n",
      "Epoch: 1... Training loss: 0.0065... Test loss: 0.00775\n",
      "Epoch: 1... Training loss: 0.00625... Test loss: 0.00556\n",
      "Epoch: 1... Training loss: 0.00604... Test loss: 0.00741\n",
      "Epoch: 1... Training loss: 0.00595... Test loss: 0.00542\n",
      "Epoch: 1... Training loss: 0.00584... Test loss: 0.00664\n",
      "Epoch: 1... Training loss: 0.0057... Test loss: 0.00507\n",
      "Epoch: 1... Training loss: 0.00564... Test loss: 0.00632\n",
      "Epoch: 1... Training loss: 0.00546... Test loss: 0.00516\n",
      "Epoch: 1... Training loss: 0.00965... Test loss: 0.00964\n",
      "Epoch: 1... Training loss: 0.01099... Test loss: 0.01177\n",
      "Epoch: 1... Training loss: 0.00995... Test loss: 0.01406\n",
      "Epoch: 1... Training loss: 0.01187... Test loss: 0.01266\n",
      "Epoch: 1... Training loss: 0.00923... Test loss: 0.01424\n",
      "Epoch: 1... Training loss: 0.0091... Test loss: 0.01154\n",
      "Epoch: 1... Training loss: 0.00844... Test loss: 0.01304\n",
      "Epoch: 1... Training loss: 0.00817... Test loss: 0.01158\n",
      "Epoch: 1... Training loss: 0.01005... Test loss: 0.00897\n",
      "Epoch: 1... Training loss: 0.00781... Test loss: 0.01094\n",
      "Epoch: 1... Training loss: 0.00817... Test loss: 0.00794\n",
      "Epoch: 1... Training loss: 0.00796... Test loss: 0.01078\n",
      "Epoch: 1... Training loss: 0.00712... Test loss: 0.0088\n",
      "Epoch: 1... Training loss: 0.00706... Test loss: 0.01092\n",
      "Epoch: 1... Training loss: 0.00655... Test loss: 0.0088\n",
      "Epoch: 1... Training loss: 0.00649... Test loss: 0.00808\n",
      "Epoch: 1... Training loss: 0.00631... Test loss: 0.00781\n",
      "Epoch: 1... Training loss: 0.00609... Test loss: 0.0086\n",
      "Epoch: 1... Training loss: 0.00593... Test loss: 0.00664\n",
      "Epoch: 1... Training loss: 0.00603... Test loss: 0.00819\n",
      "Epoch: 1... Training loss: 0.00571... Test loss: 0.00612\n",
      "Epoch: 1... Training loss: 0.00559... Test loss: 0.00695\n",
      "Epoch: 1... Training loss: 0.00536... Test loss: 0.00587\n",
      "Epoch: 1... Training loss: 0.00526... Test loss: 0.00662\n",
      "Epoch: 1... Training loss: 0.00493... Test loss: 0.0055\n",
      "Epoch: 1... Training loss: 0.00452... Test loss: 0.00582\n",
      "Epoch: 1... Training loss: 0.00462... Test loss: 0.0051\n",
      "Epoch: 1... Training loss: 0.00447... Test loss: 0.00513\n",
      "Epoch: 1... Training loss: 0.00433... Test loss: 0.00446\n",
      "Epoch: 1... Training loss: 0.00415... Test loss: 0.00504\n",
      "Epoch: 1... Training loss: 0.00409... Test loss: 0.00408\n",
      "Epoch: 1... Training loss: 0.00389... Test loss: 0.00435\n",
      "Epoch: 1... Training loss: 0.0039... Test loss: 0.00391\n",
      "Epoch: 1... Training loss: 0.00379... Test loss: 0.00435\n",
      "Epoch: 1... Training loss: 0.00363... Test loss: 0.0039\n",
      "Epoch: 1... Training loss: 0.00361... Test loss: 0.00436\n",
      "Epoch: 1... Training loss: 0.00349... Test loss: 0.00352\n",
      "Epoch: 1... Training loss: 0.00344... Test loss: 0.00438\n",
      "Epoch: 1... Training loss: 0.00334... Test loss: 0.0038\n",
      "Epoch: 1... Training loss: 0.00335... Test loss: 0.00425\n",
      "Epoch: 1... Training loss: 0.00316... Test loss: 0.00328\n",
      "Epoch: 1... Training loss: 0.00319... Test loss: 0.00399\n",
      "Epoch: 1... Training loss: 0.00303... Test loss: 0.00323\n",
      "Epoch: 1... Training loss: 0.00297... Test loss: 0.00356\n",
      "Epoch: 1... Training loss: 0.00295... Test loss: 0.00328\n",
      "Epoch: 1... Training loss: 0.00295... Test loss: 0.00288\n",
      "Epoch: 1... Training loss: 0.00295... Test loss: 0.00278\n",
      "Epoch: 1... Training loss: 0.0029... Test loss: 0.00293\n",
      "Epoch: 1... Training loss: 0.0027... Test loss: 0.00301\n",
      "Epoch: 1... Training loss: 0.00269... Test loss: 0.00271\n",
      "Epoch: 1... Training loss: 0.00268... Test loss: 0.00264\n",
      "Epoch: 1... Training loss: 0.00251... Test loss: 0.00256\n",
      "Epoch: 1... Training loss: 0.00244... Test loss: 0.0024\n",
      "Epoch: 1... Training loss: 0.00237... Test loss: 0.00302\n",
      "Epoch: 1... Training loss: 0.00233... Test loss: 0.00249\n",
      "Epoch: 1... Training loss: 0.0023... Test loss: 0.00251\n",
      "Epoch: 1... Training loss: 0.00213... Test loss: 0.00248\n",
      "Epoch: 1... Training loss: 0.00219... Test loss: 0.0025\n",
      "Epoch: 1... Training loss: 0.0021... Test loss: 0.00222\n",
      "Epoch: 1... Training loss: 0.00205... Test loss: 0.0022\n",
      "Epoch: 1... Training loss: 0.00213... Test loss: 0.00206\n",
      "Epoch: 1... Training loss: 0.00193... Test loss: 0.00183\n",
      "Epoch: 1... Training loss: 0.00192... Test loss: 0.00226\n",
      "Epoch: 1... Training loss: 0.00188... Test loss: 0.00187\n",
      "Epoch: 1... Training loss: 0.00185... Test loss: 0.00171\n",
      "Epoch: 1... Training loss: 0.0018... Test loss: 0.00186\n",
      "Epoch: 1... Training loss: 0.00176... Test loss: 0.00147\n",
      "Epoch: 1... Training loss: 0.00173... Test loss: 0.00146\n",
      "Epoch: 1... Training loss: 0.00176... Test loss: 0.0018\n",
      "Epoch: 1... Training loss: 0.00173... Test loss: 0.00153\n",
      "Epoch: 1... Training loss: 0.00158... Test loss: 0.00181\n",
      "Epoch: 1... Training loss: 0.00157... Test loss: 0.00158\n",
      "Epoch: 1... Training loss: 0.00147... Test loss: 0.00191\n",
      "Epoch: 1... Training loss: 0.00147... Test loss: 0.00142\n",
      "Epoch: 1... Training loss: 0.00146... Test loss: 0.00168\n",
      "Epoch: 1... Training loss: 0.00139... Test loss: 0.00131\n",
      "Epoch: 1... Training loss: 0.00137... Test loss: 0.00134\n",
      "Epoch: 1... Training loss: 0.00133... Test loss: 0.00112\n",
      "Epoch: 1... Training loss: 0.00129... Test loss: 0.00135\n",
      "Epoch: 1... Training loss: 0.00124... Test loss: 0.00098\n",
      "Epoch: 1... Training loss: 0.00113... Test loss: 0.00121\n",
      "Epoch: 1... Training loss: 0.00114... Test loss: 0.00104\n",
      "Epoch: 1... Training loss: 0.00108... Test loss: 0.00094\n",
      "Epoch: 1... Training loss: 0.00114... Test loss: 0.0013\n",
      "Epoch: 1... Training loss: 0.00107... Test loss: 0.00101\n",
      "Epoch: 1... Training loss: 0.00108... Test loss: 0.00137\n",
      "Epoch: 1... Training loss: 0.00101... Test loss: 0.00099\n",
      "Epoch: 1... Training loss: 0.00099... Test loss: 0.00119\n",
      "Epoch: 1... Training loss: 0.00096... Test loss: 0.00105\n",
      "Epoch: 1... Training loss: 0.0009... Test loss: 0.00111\n",
      "Epoch: 1... Training loss: 0.00086... Test loss: 0.00097\n",
      "Epoch: 1... Training loss: 0.00093... Test loss: 0.00103\n",
      "Epoch: 1... Training loss: 0.00092... Test loss: 0.0009\n",
      "Epoch: 1... Training loss: 0.00095... Test loss: 0.00091\n",
      "Epoch: 1... Training loss: 0.00083... Test loss: 0.00073\n",
      "Epoch: 1... Training loss: 0.00083... Test loss: 0.00077\n",
      "Epoch: 1... Training loss: 0.0008... Test loss: 0.00081\n",
      "Epoch: 1... Training loss: 0.00073... Test loss: 0.00067\n",
      "Epoch: 1... Training loss: 0.00069... Test loss: 0.00084\n",
      "Epoch: 1... Training loss: 0.00069... Test loss: 0.00066\n",
      "Epoch: 1... Training loss: 0.00071... Test loss: 0.00079\n",
      "Epoch: 1... Training loss: 0.0007... Test loss: 0.00059\n",
      "Epoch: 1... Training loss: 0.00069... Test loss: 0.00078\n",
      "Epoch: 1... Training loss: 0.00062... Test loss: 0.00064\n",
      "Epoch: 1... Training loss: 0.00063... Test loss: 0.00067\n",
      "Epoch: 1... Training loss: 0.00059... Test loss: 0.00063\n",
      "Epoch: 1... Training loss: 0.00058... Test loss: 0.00066\n",
      "Epoch: 1... Training loss: 0.00057... Test loss: 0.00062\n",
      "Epoch: 1... Training loss: 0.0005... Test loss: 0.00062\n",
      "Epoch: 1... Training loss: 0.0005... Test loss: 0.00054\n",
      "Epoch: 1... Training loss: 0.00057... Test loss: 0.00053\n",
      "Epoch: 1... Training loss: 0.00052... Test loss: 0.00066\n",
      "Epoch: 1... Training loss: 0.00047... Test loss: 0.00044\n",
      "Epoch: 1... Training loss: 0.00045... Test loss: 0.00056\n",
      "Epoch: 1... Training loss: 0.00045... Test loss: 0.00042\n",
      "Epoch: 1... Training loss: 0.0005... Test loss: 0.00053\n",
      "Epoch: 1... Training loss: 0.00045... Test loss: 0.00036\n",
      "Epoch: 1... Training loss: 0.00044... Test loss: 0.00049\n",
      "Epoch: 1... Training loss: 0.00046... Test loss: 0.0003\n",
      "Epoch: 1... Training loss: 0.00042... Test loss: 0.00049\n",
      "Epoch: 1... Training loss: 0.00039... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.00036... Test loss: 0.00042\n",
      "Epoch: 1... Training loss: 0.00035... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.00034... Test loss: 0.00047\n",
      "Epoch: 1... Training loss: 0.00036... Test loss: 0.0003\n",
      "Epoch: 1... Training loss: 0.00034... Test loss: 0.00044\n",
      "Epoch: 1... Training loss: 0.00034... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.00029... Test loss: 0.00047\n",
      "Epoch: 1... Training loss: 0.00029... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00036\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00024\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00036\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.00029... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00024\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00019\n",
      "266.73495276016183\n",
      "Epoch: 1... Training loss: 1.00669... Test loss: 0.35407\n",
      "Epoch: 1... Training loss: 0.48605... Test loss: 0.14839\n",
      "Epoch: 1... Training loss: 0.27767... Test loss: 0.07191\n",
      "Epoch: 1... Training loss: 0.17536... Test loss: 0.04029\n",
      "Epoch: 1... Training loss: 0.13652... Test loss: 0.03366\n",
      "Epoch: 1... Training loss: 0.11431... Test loss: 0.02998\n",
      "Epoch: 1... Training loss: 0.0973... Test loss: 0.02714\n",
      "Epoch: 1... Training loss: 0.08412... Test loss: 0.02238\n",
      "Epoch: 1... Training loss: 0.06498... Test loss: 0.02247\n",
      "Epoch: 1... Training loss: 0.05589... Test loss: 0.01448\n",
      "Epoch: 1... Training loss: 0.05254... Test loss: 0.01704\n",
      "Epoch: 1... Training loss: 0.04792... Test loss: 0.01274\n",
      "Epoch: 1... Training loss: 0.04434... Test loss: 0.01696\n",
      "Epoch: 1... Training loss: 0.04147... Test loss: 0.00874\n",
      "Epoch: 1... Training loss: 0.03736... Test loss: 0.01681\n",
      "Epoch: 1... Training loss: 0.03489... Test loss: 0.0069\n",
      "Epoch: 1... Training loss: 0.03171... Test loss: 0.0144\n",
      "Epoch: 1... Training loss: 0.03037... Test loss: 0.00996\n",
      "Epoch: 1... Training loss: 0.02736... Test loss: 0.01143\n",
      "Epoch: 1... Training loss: 0.02637... Test loss: 0.0125\n",
      "Epoch: 1... Training loss: 0.02501... Test loss: 0.00779\n",
      "Epoch: 1... Training loss: 0.02426... Test loss: 0.01395\n",
      "Epoch: 1... Training loss: 0.02281... Test loss: 0.00568\n",
      "Epoch: 1... Training loss: 0.02223... Test loss: 0.0141\n",
      "Epoch: 1... Training loss: 0.0208... Test loss: 0.0059\n",
      "Epoch: 1... Training loss: 0.0202... Test loss: 0.01295\n",
      "Epoch: 1... Training loss: 0.0192... Test loss: 0.00723\n",
      "Epoch: 1... Training loss: 0.01815... Test loss: 0.01208\n",
      "Epoch: 1... Training loss: 0.01746... Test loss: 0.00747\n",
      "Epoch: 1... Training loss: 0.01674... Test loss: 0.01145\n",
      "Epoch: 1... Training loss: 0.01649... Test loss: 0.00903\n",
      "Epoch: 1... Training loss: 0.01546... Test loss: 0.01291\n",
      "Epoch: 1... Training loss: 0.01514... Test loss: 0.00935\n",
      "Epoch: 1... Training loss: 0.01465... Test loss: 0.01168\n",
      "Epoch: 1... Training loss: 0.0142... Test loss: 0.00981\n",
      "Epoch: 1... Training loss: 0.01377... Test loss: 0.00972\n",
      "Epoch: 1... Training loss: 0.01333... Test loss: 0.00951\n",
      "Epoch: 1... Training loss: 0.01284... Test loss: 0.01121\n",
      "Epoch: 1... Training loss: 0.01245... Test loss: 0.00806\n",
      "Epoch: 1... Training loss: 0.012... Test loss: 0.0118\n",
      "Epoch: 1... Training loss: 0.01163... Test loss: 0.00714\n",
      "Epoch: 1... Training loss: 0.01119... Test loss: 0.01266\n",
      "Epoch: 1... Training loss: 0.01105... Test loss: 0.00668\n",
      "Epoch: 1... Training loss: 0.01071... Test loss: 0.01031\n",
      "Epoch: 1... Training loss: 0.01049... Test loss: 0.00648\n",
      "Epoch: 1... Training loss: 0.01018... Test loss: 0.00958\n",
      "Epoch: 1... Training loss: 0.00986... Test loss: 0.0068\n",
      "Epoch: 1... Training loss: 0.00946... Test loss: 0.00995\n",
      "Epoch: 1... Training loss: 0.00921... Test loss: 0.00669\n",
      "Epoch: 1... Training loss: 0.00887... Test loss: 0.00998\n",
      "Epoch: 1... Training loss: 0.0087... Test loss: 0.0069\n",
      "Epoch: 1... Training loss: 0.00857... Test loss: 0.00821\n",
      "Epoch: 1... Training loss: 0.00819... Test loss: 0.00762\n",
      "Epoch: 1... Training loss: 0.00778... Test loss: 0.00645\n",
      "Epoch: 1... Training loss: 0.00758... Test loss: 0.00784\n",
      "Epoch: 1... Training loss: 0.00737... Test loss: 0.00597\n",
      "Epoch: 1... Training loss: 0.00724... Test loss: 0.00755\n",
      "Epoch: 1... Training loss: 0.00702... Test loss: 0.00536\n",
      "Epoch: 1... Training loss: 0.00691... Test loss: 0.00714\n",
      "Epoch: 1... Training loss: 0.00671... Test loss: 0.00555\n",
      "Epoch: 1... Training loss: 0.0066... Test loss: 0.00665\n",
      "Epoch: 1... Training loss: 0.00646... Test loss: 0.00582\n",
      "Epoch: 1... Training loss: 0.00639... Test loss: 0.00541\n",
      "Epoch: 1... Training loss: 0.00628... Test loss: 0.00677\n",
      "Epoch: 1... Training loss: 0.01405... Test loss: 0.02265\n",
      "Epoch: 1... Training loss: 0.01403... Test loss: 0.01159\n",
      "Epoch: 1... Training loss: 0.01212... Test loss: 0.01266\n",
      "Epoch: 1... Training loss: 0.01297... Test loss: 0.0132\n",
      "Epoch: 1... Training loss: 0.01272... Test loss: 0.0138\n",
      "Epoch: 1... Training loss: 0.00967... Test loss: 0.01472\n",
      "Epoch: 1... Training loss: 0.01058... Test loss: 0.0138\n",
      "Epoch: 1... Training loss: 0.00946... Test loss: 0.01334\n",
      "Epoch: 1... Training loss: 0.01046... Test loss: 0.01194\n",
      "Epoch: 1... Training loss: 0.00924... Test loss: 0.01096\n",
      "Epoch: 1... Training loss: 0.00961... Test loss: 0.01006\n",
      "Epoch: 1... Training loss: 0.00858... Test loss: 0.01052\n",
      "Epoch: 1... Training loss: 0.00824... Test loss: 0.00898\n",
      "Epoch: 1... Training loss: 0.00804... Test loss: 0.00862\n",
      "Epoch: 1... Training loss: 0.00858... Test loss: 0.00881\n",
      "Epoch: 1... Training loss: 0.00773... Test loss: 0.00859\n",
      "Epoch: 1... Training loss: 0.00781... Test loss: 0.00889\n",
      "Epoch: 1... Training loss: 0.00746... Test loss: 0.0081\n",
      "Epoch: 1... Training loss: 0.00719... Test loss: 0.00801\n",
      "Epoch: 1... Training loss: 0.00737... Test loss: 0.00889\n",
      "Epoch: 1... Training loss: 0.00707... Test loss: 0.00737\n",
      "Epoch: 1... Training loss: 0.00641... Test loss: 0.00707\n",
      "Epoch: 1... Training loss: 0.00607... Test loss: 0.0068\n",
      "Epoch: 1... Training loss: 0.00627... Test loss: 0.00692\n",
      "Epoch: 1... Training loss: 0.00624... Test loss: 0.00688\n",
      "Epoch: 1... Training loss: 0.00565... Test loss: 0.00715\n",
      "Epoch: 1... Training loss: 0.00546... Test loss: 0.00678\n",
      "Epoch: 1... Training loss: 0.00574... Test loss: 0.00591\n",
      "Epoch: 1... Training loss: 0.00537... Test loss: 0.00596\n",
      "Epoch: 1... Training loss: 0.00532... Test loss: 0.0055\n",
      "Epoch: 1... Training loss: 0.00498... Test loss: 0.00603\n",
      "Epoch: 1... Training loss: 0.00481... Test loss: 0.0051\n",
      "Epoch: 1... Training loss: 0.00489... Test loss: 0.00563\n",
      "Epoch: 1... Training loss: 0.00471... Test loss: 0.00444\n",
      "Epoch: 1... Training loss: 0.0047... Test loss: 0.005\n",
      "Epoch: 1... Training loss: 0.00437... Test loss: 0.00488\n",
      "Epoch: 1... Training loss: 0.00437... Test loss: 0.00517\n",
      "Epoch: 1... Training loss: 0.00432... Test loss: 0.0043\n",
      "Epoch: 1... Training loss: 0.00421... Test loss: 0.00463\n",
      "Epoch: 1... Training loss: 0.00417... Test loss: 0.00423\n",
      "Epoch: 1... Training loss: 0.00416... Test loss: 0.00446\n",
      "Epoch: 1... Training loss: 0.00406... Test loss: 0.00401\n",
      "Epoch: 1... Training loss: 0.00404... Test loss: 0.00417\n",
      "Epoch: 1... Training loss: 0.00385... Test loss: 0.00462\n",
      "Epoch: 1... Training loss: 0.00392... Test loss: 0.00449\n",
      "Epoch: 1... Training loss: 0.0037... Test loss: 0.00439\n",
      "Epoch: 1... Training loss: 0.00373... Test loss: 0.004\n",
      "Epoch: 1... Training loss: 0.00353... Test loss: 0.00391\n",
      "Epoch: 1... Training loss: 0.00352... Test loss: 0.00375\n",
      "Epoch: 1... Training loss: 0.00345... Test loss: 0.00403\n",
      "Epoch: 1... Training loss: 0.00352... Test loss: 0.00388\n",
      "Epoch: 1... Training loss: 0.00341... Test loss: 0.00341\n",
      "Epoch: 1... Training loss: 0.00331... Test loss: 0.00318\n",
      "Epoch: 1... Training loss: 0.00321... Test loss: 0.00347\n",
      "Epoch: 1... Training loss: 0.00301... Test loss: 0.00353\n",
      "Epoch: 1... Training loss: 0.00294... Test loss: 0.00311\n",
      "Epoch: 1... Training loss: 0.00295... Test loss: 0.00336\n",
      "Epoch: 1... Training loss: 0.00282... Test loss: 0.00327\n",
      "Epoch: 1... Training loss: 0.00277... Test loss: 0.00328\n",
      "Epoch: 1... Training loss: 0.00265... Test loss: 0.00304\n",
      "Epoch: 1... Training loss: 0.00264... Test loss: 0.00316\n",
      "Epoch: 1... Training loss: 0.00251... Test loss: 0.00294\n",
      "Epoch: 1... Training loss: 0.00243... Test loss: 0.00296\n",
      "Epoch: 1... Training loss: 0.00242... Test loss: 0.00267\n",
      "Epoch: 1... Training loss: 0.00239... Test loss: 0.00305\n",
      "Epoch: 1... Training loss: 0.00236... Test loss: 0.00274\n",
      "Epoch: 1... Training loss: 0.0024... Test loss: 0.0029\n",
      "Epoch: 1... Training loss: 0.00219... Test loss: 0.00281\n",
      "Epoch: 1... Training loss: 0.0021... Test loss: 0.00233\n",
      "Epoch: 1... Training loss: 0.00205... Test loss: 0.00233\n",
      "Epoch: 1... Training loss: 0.002... Test loss: 0.00214\n",
      "Epoch: 1... Training loss: 0.00195... Test loss: 0.00218\n",
      "Epoch: 1... Training loss: 0.00196... Test loss: 0.00191\n",
      "Epoch: 1... Training loss: 0.00188... Test loss: 0.00186\n",
      "Epoch: 1... Training loss: 0.00187... Test loss: 0.00213\n",
      "Epoch: 1... Training loss: 0.00183... Test loss: 0.00216\n",
      "Epoch: 1... Training loss: 0.00173... Test loss: 0.0017\n",
      "Epoch: 1... Training loss: 0.00158... Test loss: 0.00187\n",
      "Epoch: 1... Training loss: 0.00159... Test loss: 0.0016\n",
      "Epoch: 1... Training loss: 0.00152... Test loss: 0.00178\n",
      "Epoch: 1... Training loss: 0.00158... Test loss: 0.00174\n",
      "Epoch: 1... Training loss: 0.00146... Test loss: 0.00189\n",
      "Epoch: 1... Training loss: 0.00146... Test loss: 0.00172\n",
      "Epoch: 1... Training loss: 0.00149... Test loss: 0.00152\n",
      "Epoch: 1... Training loss: 0.00135... Test loss: 0.00153\n",
      "Epoch: 1... Training loss: 0.00135... Test loss: 0.00152\n",
      "Epoch: 1... Training loss: 0.00129... Test loss: 0.00154\n",
      "Epoch: 1... Training loss: 0.00131... Test loss: 0.00143\n",
      "Epoch: 1... Training loss: 0.00123... Test loss: 0.00133\n",
      "Epoch: 1... Training loss: 0.00129... Test loss: 0.00128\n",
      "Epoch: 1... Training loss: 0.00124... Test loss: 0.00122\n",
      "Epoch: 1... Training loss: 0.00124... Test loss: 0.00123\n",
      "Epoch: 1... Training loss: 0.00114... Test loss: 0.00115\n",
      "Epoch: 1... Training loss: 0.00122... Test loss: 0.00117\n",
      "Epoch: 1... Training loss: 0.00112... Test loss: 0.00119\n",
      "Epoch: 1... Training loss: 0.00111... Test loss: 0.00108\n",
      "Epoch: 1... Training loss: 0.00108... Test loss: 0.00101\n",
      "Epoch: 1... Training loss: 0.001... Test loss: 0.00116\n",
      "Epoch: 1... Training loss: 0.00097... Test loss: 0.00114\n",
      "Epoch: 1... Training loss: 0.00099... Test loss: 0.00095\n",
      "Epoch: 1... Training loss: 0.00088... Test loss: 0.00103\n",
      "Epoch: 1... Training loss: 0.00092... Test loss: 0.00091\n",
      "Epoch: 1... Training loss: 0.00084... Test loss: 0.00091\n",
      "Epoch: 1... Training loss: 0.00085... Test loss: 0.00085\n",
      "Epoch: 1... Training loss: 0.00078... Test loss: 0.00087\n",
      "Epoch: 1... Training loss: 0.00075... Test loss: 0.0008\n",
      "Epoch: 1... Training loss: 0.00076... Test loss: 0.0008\n",
      "Epoch: 1... Training loss: 0.00069... Test loss: 0.00077\n",
      "Epoch: 1... Training loss: 0.00071... Test loss: 0.00075\n",
      "Epoch: 1... Training loss: 0.00063... Test loss: 0.00075\n",
      "Epoch: 1... Training loss: 0.00064... Test loss: 0.00064\n",
      "Epoch: 1... Training loss: 0.00058... Test loss: 0.00065\n",
      "Epoch: 1... Training loss: 0.0006... Test loss: 0.00065\n",
      "Epoch: 1... Training loss: 0.00056... Test loss: 0.00061\n",
      "Epoch: 1... Training loss: 0.00051... Test loss: 0.00057\n",
      "Epoch: 1... Training loss: 0.00052... Test loss: 0.00062\n",
      "Epoch: 1... Training loss: 0.00046... Test loss: 0.00055\n",
      "Epoch: 1... Training loss: 0.00045... Test loss: 0.00058\n",
      "Epoch: 1... Training loss: 0.00043... Test loss: 0.00053\n",
      "Epoch: 1... Training loss: 0.00042... Test loss: 0.00047\n",
      "Epoch: 1... Training loss: 0.00044... Test loss: 0.00043\n",
      "Epoch: 1... Training loss: 0.00035... Test loss: 0.0004\n",
      "Epoch: 1... Training loss: 0.00036... Test loss: 0.00034\n",
      "Epoch: 1... Training loss: 0.00035... Test loss: 0.00036\n",
      "Epoch: 1... Training loss: 0.00034... Test loss: 0.00037\n",
      "Epoch: 1... Training loss: 0.00032... Test loss: 0.00038\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.00038\n",
      "Epoch: 1... Training loss: 0.00029... Test loss: 0.00035\n",
      "Epoch: 1... Training loss: 0.00029... Test loss: 0.00032\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.0003\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00024\n",
      "306.56074177194387\n",
      "Epoch: 1... Training loss: 0.95243... Test loss: 0.25127\n",
      "Epoch: 1... Training loss: 0.46917... Test loss: 0.1685\n",
      "Epoch: 1... Training loss: 0.30261... Test loss: 0.11575\n",
      "Epoch: 1... Training loss: 0.18991... Test loss: 0.06821\n",
      "Epoch: 1... Training loss: 0.13037... Test loss: 0.04696\n",
      "Epoch: 1... Training loss: 0.11095... Test loss: 0.03895\n",
      "Epoch: 1... Training loss: 0.08201... Test loss: 0.02736\n",
      "Epoch: 1... Training loss: 0.0729... Test loss: 0.02252\n",
      "Epoch: 1... Training loss: 0.06076... Test loss: 0.01712\n",
      "Epoch: 1... Training loss: 0.04922... Test loss: 0.0145\n",
      "Epoch: 1... Training loss: 0.04429... Test loss: 0.01034\n",
      "Epoch: 1... Training loss: 0.04183... Test loss: 0.01281\n",
      "Epoch: 1... Training loss: 0.03862... Test loss: 0.00802\n",
      "Epoch: 1... Training loss: 0.03434... Test loss: 0.00651\n",
      "Epoch: 1... Training loss: 0.03252... Test loss: 0.00852\n",
      "Epoch: 1... Training loss: 0.03027... Test loss: 0.00446\n",
      "Epoch: 1... Training loss: 0.02935... Test loss: 0.00907\n",
      "Epoch: 1... Training loss: 0.02683... Test loss: 0.00422\n",
      "Epoch: 1... Training loss: 0.02487... Test loss: 0.00958\n",
      "Epoch: 1... Training loss: 0.02279... Test loss: 0.00359\n",
      "Epoch: 1... Training loss: 0.02267... Test loss: 0.0069\n",
      "Epoch: 1... Training loss: 0.02006... Test loss: 0.00345\n",
      "Epoch: 1... Training loss: 0.01882... Test loss: 0.00694\n",
      "Epoch: 1... Training loss: 0.01748... Test loss: 0.00282\n",
      "Epoch: 1... Training loss: 0.01712... Test loss: 0.00669\n",
      "Epoch: 1... Training loss: 0.01577... Test loss: 0.00358\n",
      "Epoch: 1... Training loss: 0.01479... Test loss: 0.00787\n",
      "Epoch: 1... Training loss: 0.01422... Test loss: 0.00319\n",
      "Epoch: 1... Training loss: 0.01404... Test loss: 0.00557\n",
      "Epoch: 1... Training loss: 0.01303... Test loss: 0.00347\n",
      "Epoch: 1... Training loss: 0.01282... Test loss: 0.00392\n",
      "Epoch: 1... Training loss: 0.01185... Test loss: 0.00549\n",
      "Epoch: 1... Training loss: 0.0115... Test loss: 0.00448\n",
      "Epoch: 1... Training loss: 0.01103... Test loss: 0.00475\n",
      "Epoch: 1... Training loss: 0.0107... Test loss: 0.00501\n",
      "Epoch: 1... Training loss: 0.01016... Test loss: 0.00345\n",
      "Epoch: 1... Training loss: 0.00996... Test loss: 0.00492\n",
      "Epoch: 1... Training loss: 0.00937... Test loss: 0.00316\n",
      "Epoch: 1... Training loss: 0.00908... Test loss: 0.00503\n",
      "Epoch: 1... Training loss: 0.00897... Test loss: 0.00324\n",
      "Epoch: 1... Training loss: 0.00871... Test loss: 0.00653\n",
      "Epoch: 1... Training loss: 0.00842... Test loss: 0.00305\n",
      "Epoch: 1... Training loss: 0.00808... Test loss: 0.00632\n",
      "Epoch: 1... Training loss: 0.00793... Test loss: 0.00265\n",
      "Epoch: 1... Training loss: 0.00773... Test loss: 0.00572\n",
      "Epoch: 1... Training loss: 0.00769... Test loss: 0.00287\n",
      "Epoch: 1... Training loss: 0.00735... Test loss: 0.0057\n",
      "Epoch: 1... Training loss: 0.00723... Test loss: 0.00342\n",
      "Epoch: 1... Training loss: 0.00693... Test loss: 0.00377\n",
      "Epoch: 1... Training loss: 0.00687... Test loss: 0.00476\n",
      "Epoch: 1... Training loss: 0.00656... Test loss: 0.00306\n",
      "Epoch: 1... Training loss: 0.00654... Test loss: 0.00579\n",
      "Epoch: 1... Training loss: 0.00632... Test loss: 0.00366\n",
      "Epoch: 1... Training loss: 0.00629... Test loss: 0.00432\n",
      "Epoch: 1... Training loss: 0.00604... Test loss: 0.0033\n",
      "Epoch: 1... Training loss: 0.0059... Test loss: 0.00418\n",
      "Epoch: 1... Training loss: 0.00583... Test loss: 0.00324\n",
      "Epoch: 1... Training loss: 0.0057... Test loss: 0.00439\n",
      "Epoch: 1... Training loss: 0.00564... Test loss: 0.00362\n",
      "Epoch: 1... Training loss: 0.00561... Test loss: 0.00374\n",
      "Epoch: 1... Training loss: 0.00538... Test loss: 0.00451\n",
      "Epoch: 1... Training loss: 0.00531... Test loss: 0.00381\n",
      "Epoch: 1... Training loss: 0.00513... Test loss: 0.00444\n",
      "Epoch: 1... Training loss: 0.00505... Test loss: 0.00381\n",
      "Epoch: 1... Training loss: 0.01338... Test loss: 0.00905\n",
      "Epoch: 1... Training loss: 0.00967... Test loss: 0.01774\n",
      "Epoch: 1... Training loss: 0.01165... Test loss: 0.00871\n",
      "Epoch: 1... Training loss: 0.00804... Test loss: 0.01162\n",
      "Epoch: 1... Training loss: 0.01027... Test loss: 0.01032\n",
      "Epoch: 1... Training loss: 0.00836... Test loss: 0.01099\n",
      "Epoch: 1... Training loss: 0.0084... Test loss: 0.01015\n",
      "Epoch: 1... Training loss: 0.00904... Test loss: 0.00998\n",
      "Epoch: 1... Training loss: 0.00799... Test loss: 0.00757\n",
      "Epoch: 1... Training loss: 0.00721... Test loss: 0.00889\n",
      "Epoch: 1... Training loss: 0.00694... Test loss: 0.00689\n",
      "Epoch: 1... Training loss: 0.00718... Test loss: 0.00709\n",
      "Epoch: 1... Training loss: 0.00677... Test loss: 0.00699\n",
      "Epoch: 1... Training loss: 0.00679... Test loss: 0.00916\n",
      "Epoch: 1... Training loss: 0.00663... Test loss: 0.00908\n",
      "Epoch: 1... Training loss: 0.00633... Test loss: 0.00756\n",
      "Epoch: 1... Training loss: 0.0058... Test loss: 0.00954\n",
      "Epoch: 1... Training loss: 0.00568... Test loss: 0.0065\n",
      "Epoch: 1... Training loss: 0.00581... Test loss: 0.00585\n",
      "Epoch: 1... Training loss: 0.00578... Test loss: 0.00791\n",
      "Epoch: 1... Training loss: 0.00538... Test loss: 0.00566\n",
      "Epoch: 1... Training loss: 0.00534... Test loss: 0.00559\n",
      "Epoch: 1... Training loss: 0.00485... Test loss: 0.00585\n",
      "Epoch: 1... Training loss: 0.00489... Test loss: 0.00484\n",
      "Epoch: 1... Training loss: 0.00466... Test loss: 0.00725\n",
      "Epoch: 1... Training loss: 0.00437... Test loss: 0.00438\n",
      "Epoch: 1... Training loss: 0.00424... Test loss: 0.00585\n",
      "Epoch: 1... Training loss: 0.00417... Test loss: 0.00467\n",
      "Epoch: 1... Training loss: 0.00389... Test loss: 0.00429\n",
      "Epoch: 1... Training loss: 0.00418... Test loss: 0.00459\n",
      "Epoch: 1... Training loss: 0.00388... Test loss: 0.00401\n",
      "Epoch: 1... Training loss: 0.00379... Test loss: 0.00328\n",
      "Epoch: 1... Training loss: 0.00372... Test loss: 0.0043\n",
      "Epoch: 1... Training loss: 0.00346... Test loss: 0.00378\n",
      "Epoch: 1... Training loss: 0.0034... Test loss: 0.00384\n",
      "Epoch: 1... Training loss: 0.00335... Test loss: 0.0034\n",
      "Epoch: 1... Training loss: 0.00338... Test loss: 0.00386\n",
      "Epoch: 1... Training loss: 0.00321... Test loss: 0.00323\n",
      "Epoch: 1... Training loss: 0.00314... Test loss: 0.00412\n",
      "Epoch: 1... Training loss: 0.00312... Test loss: 0.00282\n",
      "Epoch: 1... Training loss: 0.00316... Test loss: 0.00327\n",
      "Epoch: 1... Training loss: 0.00299... Test loss: 0.0031\n",
      "Epoch: 1... Training loss: 0.00295... Test loss: 0.00288\n",
      "Epoch: 1... Training loss: 0.00289... Test loss: 0.0029\n",
      "Epoch: 1... Training loss: 0.0029... Test loss: 0.00264\n",
      "Epoch: 1... Training loss: 0.00279... Test loss: 0.00303\n",
      "Epoch: 1... Training loss: 0.00279... Test loss: 0.00259\n",
      "Epoch: 1... Training loss: 0.0026... Test loss: 0.00284\n",
      "Epoch: 1... Training loss: 0.0026... Test loss: 0.00263\n",
      "Epoch: 1... Training loss: 0.0026... Test loss: 0.00288\n",
      "Epoch: 1... Training loss: 0.00256... Test loss: 0.00274\n",
      "Epoch: 1... Training loss: 0.00242... Test loss: 0.00233\n",
      "Epoch: 1... Training loss: 0.00249... Test loss: 0.0027\n",
      "Epoch: 1... Training loss: 0.00238... Test loss: 0.00254\n",
      "Epoch: 1... Training loss: 0.00232... Test loss: 0.00319\n",
      "Epoch: 1... Training loss: 0.00228... Test loss: 0.00261\n",
      "Epoch: 1... Training loss: 0.00219... Test loss: 0.00265\n",
      "Epoch: 1... Training loss: 0.00217... Test loss: 0.00218\n",
      "Epoch: 1... Training loss: 0.00212... Test loss: 0.00235\n",
      "Epoch: 1... Training loss: 0.00221... Test loss: 0.0024\n",
      "Epoch: 1... Training loss: 0.00213... Test loss: 0.0019\n",
      "Epoch: 1... Training loss: 0.00208... Test loss: 0.00175\n",
      "Epoch: 1... Training loss: 0.00211... Test loss: 0.0021\n",
      "Epoch: 1... Training loss: 0.00204... Test loss: 0.00177\n",
      "Epoch: 1... Training loss: 0.00201... Test loss: 0.00196\n",
      "Epoch: 1... Training loss: 0.00194... Test loss: 0.00138\n",
      "Epoch: 1... Training loss: 0.00189... Test loss: 0.0021\n",
      "Epoch: 1... Training loss: 0.00196... Test loss: 0.00165\n",
      "Epoch: 1... Training loss: 0.00178... Test loss: 0.00309\n",
      "Epoch: 1... Training loss: 0.00177... Test loss: 0.00161\n",
      "Epoch: 1... Training loss: 0.00161... Test loss: 0.00208\n",
      "Epoch: 1... Training loss: 0.00166... Test loss: 0.00133\n",
      "Epoch: 1... Training loss: 0.0016... Test loss: 0.00192\n",
      "Epoch: 1... Training loss: 0.00167... Test loss: 0.00156\n",
      "Epoch: 1... Training loss: 0.00165... Test loss: 0.00143\n",
      "Epoch: 1... Training loss: 0.00148... Test loss: 0.00136\n",
      "Epoch: 1... Training loss: 0.00163... Test loss: 0.00177\n",
      "Epoch: 1... Training loss: 0.00144... Test loss: 0.00145\n",
      "Epoch: 1... Training loss: 0.0014... Test loss: 0.0016\n",
      "Epoch: 1... Training loss: 0.00139... Test loss: 0.00133\n",
      "Epoch: 1... Training loss: 0.00131... Test loss: 0.00163\n",
      "Epoch: 1... Training loss: 0.00127... Test loss: 0.00124\n",
      "Epoch: 1... Training loss: 0.00126... Test loss: 0.00125\n",
      "Epoch: 1... Training loss: 0.00124... Test loss: 0.0014\n",
      "Epoch: 1... Training loss: 0.00116... Test loss: 0.00132\n",
      "Epoch: 1... Training loss: 0.00111... Test loss: 0.00114\n",
      "Epoch: 1... Training loss: 0.00113... Test loss: 0.00121\n",
      "Epoch: 1... Training loss: 0.0011... Test loss: 0.00128\n",
      "Epoch: 1... Training loss: 0.00111... Test loss: 0.00114\n",
      "Epoch: 1... Training loss: 0.00099... Test loss: 0.00109\n",
      "Epoch: 1... Training loss: 0.001... Test loss: 0.00098\n",
      "Epoch: 1... Training loss: 0.00096... Test loss: 0.00116\n",
      "Epoch: 1... Training loss: 0.00099... Test loss: 0.00094\n",
      "Epoch: 1... Training loss: 0.00088... Test loss: 0.00082\n",
      "Epoch: 1... Training loss: 0.00084... Test loss: 0.00076\n",
      "Epoch: 1... Training loss: 0.00085... Test loss: 0.00078\n",
      "Epoch: 1... Training loss: 0.0009... Test loss: 0.0007\n",
      "Epoch: 1... Training loss: 0.00085... Test loss: 0.00081\n",
      "Epoch: 1... Training loss: 0.00079... Test loss: 0.00081\n",
      "Epoch: 1... Training loss: 0.00072... Test loss: 0.00087\n",
      "Epoch: 1... Training loss: 0.00074... Test loss: 0.00068\n",
      "Epoch: 1... Training loss: 0.00072... Test loss: 0.00089\n",
      "Epoch: 1... Training loss: 0.00067... Test loss: 0.00075\n",
      "Epoch: 1... Training loss: 0.00064... Test loss: 0.00075\n",
      "Epoch: 1... Training loss: 0.00062... Test loss: 0.00065\n",
      "Epoch: 1... Training loss: 0.00059... Test loss: 0.00062\n",
      "Epoch: 1... Training loss: 0.00061... Test loss: 0.00062\n",
      "Epoch: 1... Training loss: 0.00068... Test loss: 0.00058\n",
      "Epoch: 1... Training loss: 0.00055... Test loss: 0.00057\n",
      "Epoch: 1... Training loss: 0.00057... Test loss: 0.00059\n",
      "Epoch: 1... Training loss: 0.00053... Test loss: 0.00053\n",
      "Epoch: 1... Training loss: 0.00052... Test loss: 0.00069\n",
      "Epoch: 1... Training loss: 0.00052... Test loss: 0.00047\n",
      "Epoch: 1... Training loss: 0.00048... Test loss: 0.00051\n",
      "Epoch: 1... Training loss: 0.00045... Test loss: 0.00051\n",
      "Epoch: 1... Training loss: 0.00045... Test loss: 0.00052\n",
      "Epoch: 1... Training loss: 0.00045... Test loss: 0.00052\n",
      "Epoch: 1... Training loss: 0.00043... Test loss: 0.00049\n",
      "Epoch: 1... Training loss: 0.00041... Test loss: 0.00045\n",
      "Epoch: 1... Training loss: 0.00038... Test loss: 0.00046\n",
      "Epoch: 1... Training loss: 0.00042... Test loss: 0.00036\n",
      "Epoch: 1... Training loss: 0.00038... Test loss: 0.00043\n",
      "Epoch: 1... Training loss: 0.00041... Test loss: 0.00033\n",
      "Epoch: 1... Training loss: 0.00035... Test loss: 0.00039\n",
      "Epoch: 1... Training loss: 0.00031... Test loss: 0.00038\n",
      "Epoch: 1... Training loss: 0.00032... Test loss: 0.00035\n",
      "Epoch: 1... Training loss: 0.00032... Test loss: 0.00035\n",
      "Epoch: 1... Training loss: 0.00029... Test loss: 0.0003\n",
      "Epoch: 1... Training loss: 0.00032... Test loss: 0.00035\n",
      "Epoch: 1... Training loss: 0.00029... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00031\n",
      "Epoch: 1... Training loss: 0.00026... Test loss: 0.00024\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00024\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00021\n",
      "331.1277551394887\n",
      "Epoch: 1... Training loss: 0.94748... Test loss: 0.32214\n",
      "Epoch: 1... Training loss: 0.50945... Test loss: 0.18196\n",
      "Epoch: 1... Training loss: 0.33584... Test loss: 0.09924\n",
      "Epoch: 1... Training loss: 0.23464... Test loss: 0.08393\n",
      "Epoch: 1... Training loss: 0.17377... Test loss: 0.11413\n",
      "Epoch: 1... Training loss: 0.13682... Test loss: 0.05755\n",
      "Epoch: 1... Training loss: 0.1198... Test loss: 0.08461\n",
      "Epoch: 1... Training loss: 0.09737... Test loss: 0.04179\n",
      "Epoch: 1... Training loss: 0.07929... Test loss: 0.079\n",
      "Epoch: 1... Training loss: 0.08007... Test loss: 0.0397\n",
      "Epoch: 1... Training loss: 0.06411... Test loss: 0.06214\n",
      "Epoch: 1... Training loss: 0.05713... Test loss: 0.02907\n",
      "Epoch: 1... Training loss: 0.05185... Test loss: 0.06648\n",
      "Epoch: 1... Training loss: 0.0481... Test loss: 0.02365\n",
      "Epoch: 1... Training loss: 0.04145... Test loss: 0.05307\n",
      "Epoch: 1... Training loss: 0.03841... Test loss: 0.02932\n",
      "Epoch: 1... Training loss: 0.03721... Test loss: 0.04141\n",
      "Epoch: 1... Training loss: 0.03457... Test loss: 0.0221\n",
      "Epoch: 1... Training loss: 0.03249... Test loss: 0.04567\n",
      "Epoch: 1... Training loss: 0.03016... Test loss: 0.0231\n",
      "Epoch: 1... Training loss: 0.02862... Test loss: 0.04343\n",
      "Epoch: 1... Training loss: 0.0274... Test loss: 0.02142\n",
      "Epoch: 1... Training loss: 0.02572... Test loss: 0.03542\n",
      "Epoch: 1... Training loss: 0.02356... Test loss: 0.02507\n",
      "Epoch: 1... Training loss: 0.0227... Test loss: 0.0375\n",
      "Epoch: 1... Training loss: 0.02175... Test loss: 0.02482\n",
      "Epoch: 1... Training loss: 0.02093... Test loss: 0.02625\n",
      "Epoch: 1... Training loss: 0.01938... Test loss: 0.02995\n",
      "Epoch: 1... Training loss: 0.01847... Test loss: 0.01925\n",
      "Epoch: 1... Training loss: 0.01793... Test loss: 0.03136\n",
      "Epoch: 1... Training loss: 0.01726... Test loss: 0.01707\n",
      "Epoch: 1... Training loss: 0.01642... Test loss: 0.02766\n",
      "Epoch: 1... Training loss: 0.01595... Test loss: 0.01243\n",
      "Epoch: 1... Training loss: 0.01512... Test loss: 0.02864\n",
      "Epoch: 1... Training loss: 0.01471... Test loss: 0.01191\n",
      "Epoch: 1... Training loss: 0.01432... Test loss: 0.02299\n",
      "Epoch: 1... Training loss: 0.01347... Test loss: 0.01252\n",
      "Epoch: 1... Training loss: 0.01295... Test loss: 0.02002\n",
      "Epoch: 1... Training loss: 0.01244... Test loss: 0.01285\n",
      "Epoch: 1... Training loss: 0.01183... Test loss: 0.02006\n",
      "Epoch: 1... Training loss: 0.0116... Test loss: 0.01275\n",
      "Epoch: 1... Training loss: 0.01102... Test loss: 0.01276\n",
      "Epoch: 1... Training loss: 0.01046... Test loss: 0.01434\n",
      "Epoch: 1... Training loss: 0.01017... Test loss: 0.01092\n",
      "Epoch: 1... Training loss: 0.00977... Test loss: 0.01442\n",
      "Epoch: 1... Training loss: 0.00956... Test loss: 0.00877\n",
      "Epoch: 1... Training loss: 0.0092... Test loss: 0.01341\n",
      "Epoch: 1... Training loss: 0.00895... Test loss: 0.0075\n",
      "Epoch: 1... Training loss: 0.00861... Test loss: 0.01136\n",
      "Epoch: 1... Training loss: 0.00852... Test loss: 0.00697\n",
      "Epoch: 1... Training loss: 0.00808... Test loss: 0.01102\n",
      "Epoch: 1... Training loss: 0.00795... Test loss: 0.00674\n",
      "Epoch: 1... Training loss: 0.00769... Test loss: 0.01035\n",
      "Epoch: 1... Training loss: 0.00755... Test loss: 0.00721\n",
      "Epoch: 1... Training loss: 0.00727... Test loss: 0.00785\n",
      "Epoch: 1... Training loss: 0.00714... Test loss: 0.00721\n",
      "Epoch: 1... Training loss: 0.00698... Test loss: 0.00599\n",
      "Epoch: 1... Training loss: 0.00678... Test loss: 0.00888\n",
      "Epoch: 1... Training loss: 0.00658... Test loss: 0.00635\n",
      "Epoch: 1... Training loss: 0.00651... Test loss: 0.00778\n",
      "Epoch: 1... Training loss: 0.0063... Test loss: 0.00591\n",
      "Epoch: 1... Training loss: 0.00622... Test loss: 0.00703\n",
      "Epoch: 1... Training loss: 0.00602... Test loss: 0.00506\n",
      "Epoch: 1... Training loss: 0.00591... Test loss: 0.00649\n",
      "Epoch: 1... Training loss: 0.01256... Test loss: 0.0094\n",
      "Epoch: 1... Training loss: 0.00998... Test loss: 0.01701\n",
      "Epoch: 1... Training loss: 0.01239... Test loss: 0.00868\n",
      "Epoch: 1... Training loss: 0.01201... Test loss: 0.02087\n",
      "Epoch: 1... Training loss: 0.01078... Test loss: 0.01003\n",
      "Epoch: 1... Training loss: 0.00948... Test loss: 0.01725\n",
      "Epoch: 1... Training loss: 0.00974... Test loss: 0.01146\n",
      "Epoch: 1... Training loss: 0.00922... Test loss: 0.01328\n",
      "Epoch: 1... Training loss: 0.00828... Test loss: 0.00972\n",
      "Epoch: 1... Training loss: 0.00904... Test loss: 0.01125\n",
      "Epoch: 1... Training loss: 0.00934... Test loss: 0.01064\n",
      "Epoch: 1... Training loss: 0.00773... Test loss: 0.00909\n",
      "Epoch: 1... Training loss: 0.00762... Test loss: 0.01021\n",
      "Epoch: 1... Training loss: 0.00719... Test loss: 0.01103\n",
      "Epoch: 1... Training loss: 0.00679... Test loss: 0.00822\n",
      "Epoch: 1... Training loss: 0.00685... Test loss: 0.00886\n",
      "Epoch: 1... Training loss: 0.00661... Test loss: 0.00752\n",
      "Epoch: 1... Training loss: 0.00669... Test loss: 0.00741\n",
      "Epoch: 1... Training loss: 0.00644... Test loss: 0.00656\n",
      "Epoch: 1... Training loss: 0.0064... Test loss: 0.00794\n",
      "Epoch: 1... Training loss: 0.00638... Test loss: 0.00657\n",
      "Epoch: 1... Training loss: 0.00596... Test loss: 0.00648\n",
      "Epoch: 1... Training loss: 0.00558... Test loss: 0.00667\n",
      "Epoch: 1... Training loss: 0.00574... Test loss: 0.00546\n",
      "Epoch: 1... Training loss: 0.00563... Test loss: 0.00716\n",
      "Epoch: 1... Training loss: 0.00518... Test loss: 0.00569\n",
      "Epoch: 1... Training loss: 0.00523... Test loss: 0.00576\n",
      "Epoch: 1... Training loss: 0.00511... Test loss: 0.00542\n",
      "Epoch: 1... Training loss: 0.00498... Test loss: 0.00575\n",
      "Epoch: 1... Training loss: 0.00469... Test loss: 0.00556\n",
      "Epoch: 1... Training loss: 0.00466... Test loss: 0.00474\n",
      "Epoch: 1... Training loss: 0.0045... Test loss: 0.00523\n",
      "Epoch: 1... Training loss: 0.00423... Test loss: 0.00511\n",
      "Epoch: 1... Training loss: 0.00428... Test loss: 0.00457\n",
      "Epoch: 1... Training loss: 0.004... Test loss: 0.00439\n",
      "Epoch: 1... Training loss: 0.00395... Test loss: 0.00396\n",
      "Epoch: 1... Training loss: 0.00371... Test loss: 0.00468\n",
      "Epoch: 1... Training loss: 0.00371... Test loss: 0.00382\n",
      "Epoch: 1... Training loss: 0.00355... Test loss: 0.00433\n",
      "Epoch: 1... Training loss: 0.0036... Test loss: 0.00325\n",
      "Epoch: 1... Training loss: 0.00348... Test loss: 0.00431\n",
      "Epoch: 1... Training loss: 0.00344... Test loss: 0.0033\n",
      "Epoch: 1... Training loss: 0.00335... Test loss: 0.00469\n",
      "Epoch: 1... Training loss: 0.00328... Test loss: 0.00327\n",
      "Epoch: 1... Training loss: 0.00315... Test loss: 0.00419\n",
      "Epoch: 1... Training loss: 0.00306... Test loss: 0.00299\n",
      "Epoch: 1... Training loss: 0.00294... Test loss: 0.00357\n",
      "Epoch: 1... Training loss: 0.00296... Test loss: 0.00284\n",
      "Epoch: 1... Training loss: 0.00282... Test loss: 0.00367\n",
      "Epoch: 1... Training loss: 0.00277... Test loss: 0.00287\n",
      "Epoch: 1... Training loss: 0.00285... Test loss: 0.00308\n",
      "Epoch: 1... Training loss: 0.00262... Test loss: 0.00307\n",
      "Epoch: 1... Training loss: 0.00261... Test loss: 0.00308\n",
      "Epoch: 1... Training loss: 0.00255... Test loss: 0.00306\n",
      "Epoch: 1... Training loss: 0.00255... Test loss: 0.0026\n",
      "Epoch: 1... Training loss: 0.00244... Test loss: 0.00297\n",
      "Epoch: 1... Training loss: 0.00244... Test loss: 0.00249\n",
      "Epoch: 1... Training loss: 0.00229... Test loss: 0.00273\n",
      "Epoch: 1... Training loss: 0.00218... Test loss: 0.00273\n",
      "Epoch: 1... Training loss: 0.00214... Test loss: 0.00223\n",
      "Epoch: 1... Training loss: 0.00212... Test loss: 0.00244\n",
      "Epoch: 1... Training loss: 0.00195... Test loss: 0.00225\n",
      "Epoch: 1... Training loss: 0.00199... Test loss: 0.00213\n",
      "Epoch: 1... Training loss: 0.00197... Test loss: 0.00187\n",
      "Epoch: 1... Training loss: 0.00196... Test loss: 0.00216\n",
      "Epoch: 1... Training loss: 0.00189... Test loss: 0.00197\n",
      "Epoch: 1... Training loss: 0.00174... Test loss: 0.00205\n",
      "Epoch: 1... Training loss: 0.00169... Test loss: 0.002\n",
      "Epoch: 1... Training loss: 0.00165... Test loss: 0.00212\n",
      "Epoch: 1... Training loss: 0.00167... Test loss: 0.00189\n",
      "Epoch: 1... Training loss: 0.00162... Test loss: 0.00184\n",
      "Epoch: 1... Training loss: 0.0016... Test loss: 0.00157\n",
      "Epoch: 1... Training loss: 0.00153... Test loss: 0.00189\n",
      "Epoch: 1... Training loss: 0.00148... Test loss: 0.00155\n",
      "Epoch: 1... Training loss: 0.00143... Test loss: 0.00147\n",
      "Epoch: 1... Training loss: 0.00139... Test loss: 0.00158\n",
      "Epoch: 1... Training loss: 0.00142... Test loss: 0.00124\n",
      "Epoch: 1... Training loss: 0.00137... Test loss: 0.00151\n",
      "Epoch: 1... Training loss: 0.00132... Test loss: 0.00122\n",
      "Epoch: 1... Training loss: 0.00137... Test loss: 0.00167\n",
      "Epoch: 1... Training loss: 0.00127... Test loss: 0.00137\n",
      "Epoch: 1... Training loss: 0.0012... Test loss: 0.00125\n",
      "Epoch: 1... Training loss: 0.00119... Test loss: 0.00125\n",
      "Epoch: 1... Training loss: 0.00122... Test loss: 0.00116\n",
      "Epoch: 1... Training loss: 0.00112... Test loss: 0.00124\n",
      "Epoch: 1... Training loss: 0.0011... Test loss: 0.00118\n",
      "Epoch: 1... Training loss: 0.00107... Test loss: 0.0013\n",
      "Epoch: 1... Training loss: 0.00114... Test loss: 0.00114\n",
      "Epoch: 1... Training loss: 0.00098... Test loss: 0.0011\n",
      "Epoch: 1... Training loss: 0.001... Test loss: 0.00106\n",
      "Epoch: 1... Training loss: 0.00097... Test loss: 0.00101\n",
      "Epoch: 1... Training loss: 0.00092... Test loss: 0.00095\n",
      "Epoch: 1... Training loss: 0.00093... Test loss: 0.00095\n",
      "Epoch: 1... Training loss: 0.00095... Test loss: 0.00108\n",
      "Epoch: 1... Training loss: 0.00086... Test loss: 0.00097\n",
      "Epoch: 1... Training loss: 0.00082... Test loss: 0.00081\n",
      "Epoch: 1... Training loss: 0.00077... Test loss: 0.00094\n",
      "Epoch: 1... Training loss: 0.00084... Test loss: 0.00073\n",
      "Epoch: 1... Training loss: 0.00077... Test loss: 0.00106\n",
      "Epoch: 1... Training loss: 0.00074... Test loss: 0.0008\n",
      "Epoch: 1... Training loss: 0.00072... Test loss: 0.00096\n",
      "Epoch: 1... Training loss: 0.00066... Test loss: 0.00081\n",
      "Epoch: 1... Training loss: 0.0007... Test loss: 0.00083\n",
      "Epoch: 1... Training loss: 0.00065... Test loss: 0.00067\n",
      "Epoch: 1... Training loss: 0.00065... Test loss: 0.0007\n",
      "Epoch: 1... Training loss: 0.0006... Test loss: 0.0007\n",
      "Epoch: 1... Training loss: 0.00064... Test loss: 0.00068\n",
      "Epoch: 1... Training loss: 0.0006... Test loss: 0.00079\n",
      "Epoch: 1... Training loss: 0.00057... Test loss: 0.0005\n",
      "Epoch: 1... Training loss: 0.00059... Test loss: 0.00081\n",
      "Epoch: 1... Training loss: 0.00054... Test loss: 0.00047\n",
      "Epoch: 1... Training loss: 0.00052... Test loss: 0.00069\n",
      "Epoch: 1... Training loss: 0.00058... Test loss: 0.0004\n",
      "Epoch: 1... Training loss: 0.00047... Test loss: 0.00076\n",
      "Epoch: 1... Training loss: 0.00046... Test loss: 0.00052\n",
      "Epoch: 1... Training loss: 0.00041... Test loss: 0.00049\n",
      "Epoch: 1... Training loss: 0.0004... Test loss: 0.00039\n",
      "Epoch: 1... Training loss: 0.00043... Test loss: 0.00055\n",
      "Epoch: 1... Training loss: 0.00036... Test loss: 0.00042\n",
      "Epoch: 1... Training loss: 0.00039... Test loss: 0.00048\n",
      "Epoch: 1... Training loss: 0.00034... Test loss: 0.00044\n",
      "Epoch: 1... Training loss: 0.00033... Test loss: 0.00037\n",
      "Epoch: 1... Training loss: 0.00032... Test loss: 0.00037\n",
      "Epoch: 1... Training loss: 0.00031... Test loss: 0.00035\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.00033\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00028\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.0003\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00026... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00023\n",
      "303.7643426003633\n",
      "Epoch: 1... Training loss: 1.11397... Test loss: 0.50012\n",
      "Epoch: 1... Training loss: 0.55564... Test loss: 0.25576\n",
      "Epoch: 1... Training loss: 0.29911... Test loss: 0.12652\n",
      "Epoch: 1... Training loss: 0.2076... Test loss: 0.08444\n",
      "Epoch: 1... Training loss: 0.14802... Test loss: 0.07623\n",
      "Epoch: 1... Training loss: 0.12856... Test loss: 0.03669\n",
      "Epoch: 1... Training loss: 0.10852... Test loss: 0.05658\n",
      "Epoch: 1... Training loss: 0.08747... Test loss: 0.06284\n",
      "Epoch: 1... Training loss: 0.08069... Test loss: 0.02813\n",
      "Epoch: 1... Training loss: 0.06472... Test loss: 0.05344\n",
      "Epoch: 1... Training loss: 0.05548... Test loss: 0.04977\n",
      "Epoch: 1... Training loss: 0.05012... Test loss: 0.06196\n",
      "Epoch: 1... Training loss: 0.04909... Test loss: 0.02411\n",
      "Epoch: 1... Training loss: 0.0444... Test loss: 0.04814\n",
      "Epoch: 1... Training loss: 0.03918... Test loss: 0.03709\n",
      "Epoch: 1... Training loss: 0.03734... Test loss: 0.05035\n",
      "Epoch: 1... Training loss: 0.03583... Test loss: 0.02042\n",
      "Epoch: 1... Training loss: 0.03299... Test loss: 0.04512\n",
      "Epoch: 1... Training loss: 0.02973... Test loss: 0.0253\n",
      "Epoch: 1... Training loss: 0.02711... Test loss: 0.04311\n",
      "Epoch: 1... Training loss: 0.0256... Test loss: 0.01823\n",
      "Epoch: 1... Training loss: 0.02416... Test loss: 0.028\n",
      "Epoch: 1... Training loss: 0.02326... Test loss: 0.01926\n",
      "Epoch: 1... Training loss: 0.02196... Test loss: 0.02396\n",
      "Epoch: 1... Training loss: 0.02072... Test loss: 0.02209\n",
      "Epoch: 1... Training loss: 0.02013... Test loss: 0.02169\n",
      "Epoch: 1... Training loss: 0.01943... Test loss: 0.02126\n",
      "Epoch: 1... Training loss: 0.01825... Test loss: 0.01954\n",
      "Epoch: 1... Training loss: 0.01755... Test loss: 0.01993\n",
      "Epoch: 1... Training loss: 0.01691... Test loss: 0.0148\n",
      "Epoch: 1... Training loss: 0.01623... Test loss: 0.01381\n",
      "Epoch: 1... Training loss: 0.01555... Test loss: 0.01422\n",
      "Epoch: 1... Training loss: 0.01458... Test loss: 0.01442\n",
      "Epoch: 1... Training loss: 0.01425... Test loss: 0.01478\n",
      "Epoch: 1... Training loss: 0.0134... Test loss: 0.01185\n",
      "Epoch: 1... Training loss: 0.01304... Test loss: 0.01598\n",
      "Epoch: 1... Training loss: 0.01267... Test loss: 0.00784\n",
      "Epoch: 1... Training loss: 0.01191... Test loss: 0.01577\n",
      "Epoch: 1... Training loss: 0.01195... Test loss: 0.0081\n",
      "Epoch: 1... Training loss: 0.01139... Test loss: 0.01584\n",
      "Epoch: 1... Training loss: 0.01112... Test loss: 0.00776\n",
      "Epoch: 1... Training loss: 0.01047... Test loss: 0.01256\n",
      "Epoch: 1... Training loss: 0.01007... Test loss: 0.00706\n",
      "Epoch: 1... Training loss: 0.00997... Test loss: 0.00802\n",
      "Epoch: 1... Training loss: 0.0096... Test loss: 0.01013\n",
      "Epoch: 1... Training loss: 0.00935... Test loss: 0.00648\n",
      "Epoch: 1... Training loss: 0.00916... Test loss: 0.01025\n",
      "Epoch: 1... Training loss: 0.00896... Test loss: 0.00562\n",
      "Epoch: 1... Training loss: 0.00879... Test loss: 0.01032\n",
      "Epoch: 1... Training loss: 0.00857... Test loss: 0.00591\n",
      "Epoch: 1... Training loss: 0.0083... Test loss: 0.0097\n",
      "Epoch: 1... Training loss: 0.00808... Test loss: 0.00703\n",
      "Epoch: 1... Training loss: 0.00782... Test loss: 0.00848\n",
      "Epoch: 1... Training loss: 0.00771... Test loss: 0.00739\n",
      "Epoch: 1... Training loss: 0.00743... Test loss: 0.00781\n",
      "Epoch: 1... Training loss: 0.00734... Test loss: 0.00743\n",
      "Epoch: 1... Training loss: 0.00718... Test loss: 0.00808\n",
      "Epoch: 1... Training loss: 0.00697... Test loss: 0.00584\n",
      "Epoch: 1... Training loss: 0.00679... Test loss: 0.00826\n",
      "Epoch: 1... Training loss: 0.00663... Test loss: 0.00508\n",
      "Epoch: 1... Training loss: 0.00648... Test loss: 0.00713\n",
      "Epoch: 1... Training loss: 0.00631... Test loss: 0.00542\n",
      "Epoch: 1... Training loss: 0.00614... Test loss: 0.00667\n",
      "Epoch: 1... Training loss: 0.00597... Test loss: 0.00518\n",
      "Epoch: 1... Training loss: 0.01392... Test loss: 0.01929\n",
      "Epoch: 1... Training loss: 0.01102... Test loss: 0.01231\n",
      "Epoch: 1... Training loss: 0.01262... Test loss: 0.01373\n",
      "Epoch: 1... Training loss: 0.01311... Test loss: 0.01363\n",
      "Epoch: 1... Training loss: 0.01091... Test loss: 0.01667\n",
      "Epoch: 1... Training loss: 0.00931... Test loss: 0.01127\n",
      "Epoch: 1... Training loss: 0.00956... Test loss: 0.01406\n",
      "Epoch: 1... Training loss: 0.01003... Test loss: 0.01101\n",
      "Epoch: 1... Training loss: 0.00903... Test loss: 0.01135\n",
      "Epoch: 1... Training loss: 0.00888... Test loss: 0.01049\n",
      "Epoch: 1... Training loss: 0.00908... Test loss: 0.01151\n",
      "Epoch: 1... Training loss: 0.00862... Test loss: 0.00954\n",
      "Epoch: 1... Training loss: 0.00826... Test loss: 0.0103\n",
      "Epoch: 1... Training loss: 0.00796... Test loss: 0.00726\n",
      "Epoch: 1... Training loss: 0.00745... Test loss: 0.00959\n",
      "Epoch: 1... Training loss: 0.00779... Test loss: 0.00742\n",
      "Epoch: 1... Training loss: 0.0069... Test loss: 0.00894\n",
      "Epoch: 1... Training loss: 0.00737... Test loss: 0.00671\n",
      "Epoch: 1... Training loss: 0.00688... Test loss: 0.00839\n",
      "Epoch: 1... Training loss: 0.00697... Test loss: 0.00682\n",
      "Epoch: 1... Training loss: 0.00691... Test loss: 0.00747\n",
      "Epoch: 1... Training loss: 0.0068... Test loss: 0.00689\n",
      "Epoch: 1... Training loss: 0.00609... Test loss: 0.00803\n",
      "Epoch: 1... Training loss: 0.00609... Test loss: 0.00779\n",
      "Epoch: 1... Training loss: 0.00584... Test loss: 0.00696\n",
      "Epoch: 1... Training loss: 0.00605... Test loss: 0.00656\n",
      "Epoch: 1... Training loss: 0.00566... Test loss: 0.00699\n",
      "Epoch: 1... Training loss: 0.00536... Test loss: 0.00618\n",
      "Epoch: 1... Training loss: 0.00531... Test loss: 0.0061\n",
      "Epoch: 1... Training loss: 0.00497... Test loss: 0.00596\n",
      "Epoch: 1... Training loss: 0.0049... Test loss: 0.00643\n",
      "Epoch: 1... Training loss: 0.00488... Test loss: 0.00521\n",
      "Epoch: 1... Training loss: 0.00462... Test loss: 0.0058\n",
      "Epoch: 1... Training loss: 0.00447... Test loss: 0.00443\n",
      "Epoch: 1... Training loss: 0.00429... Test loss: 0.00458\n",
      "Epoch: 1... Training loss: 0.00428... Test loss: 0.00461\n",
      "Epoch: 1... Training loss: 0.00411... Test loss: 0.00437\n",
      "Epoch: 1... Training loss: 0.00404... Test loss: 0.00448\n",
      "Epoch: 1... Training loss: 0.00396... Test loss: 0.00448\n",
      "Epoch: 1... Training loss: 0.00389... Test loss: 0.00415\n",
      "Epoch: 1... Training loss: 0.00391... Test loss: 0.00482\n",
      "Epoch: 1... Training loss: 0.00381... Test loss: 0.00431\n",
      "Epoch: 1... Training loss: 0.00364... Test loss: 0.00472\n",
      "Epoch: 1... Training loss: 0.00363... Test loss: 0.00395\n",
      "Epoch: 1... Training loss: 0.00353... Test loss: 0.00441\n",
      "Epoch: 1... Training loss: 0.00351... Test loss: 0.00363\n",
      "Epoch: 1... Training loss: 0.00334... Test loss: 0.00407\n",
      "Epoch: 1... Training loss: 0.00338... Test loss: 0.00306\n",
      "Epoch: 1... Training loss: 0.00332... Test loss: 0.00353\n",
      "Epoch: 1... Training loss: 0.00333... Test loss: 0.00288\n",
      "Epoch: 1... Training loss: 0.00316... Test loss: 0.00343\n",
      "Epoch: 1... Training loss: 0.00314... Test loss: 0.0024\n",
      "Epoch: 1... Training loss: 0.00311... Test loss: 0.00374\n",
      "Epoch: 1... Training loss: 0.00303... Test loss: 0.00254\n",
      "Epoch: 1... Training loss: 0.00299... Test loss: 0.00319\n",
      "Epoch: 1... Training loss: 0.00304... Test loss: 0.00263\n",
      "Epoch: 1... Training loss: 0.0029... Test loss: 0.0026\n",
      "Epoch: 1... Training loss: 0.00284... Test loss: 0.00259\n",
      "Epoch: 1... Training loss: 0.00272... Test loss: 0.00264\n",
      "Epoch: 1... Training loss: 0.00273... Test loss: 0.00242\n",
      "Epoch: 1... Training loss: 0.00262... Test loss: 0.00267\n",
      "Epoch: 1... Training loss: 0.00259... Test loss: 0.00256\n",
      "Epoch: 1... Training loss: 0.00245... Test loss: 0.00323\n",
      "Epoch: 1... Training loss: 0.00256... Test loss: 0.00237\n",
      "Epoch: 1... Training loss: 0.00241... Test loss: 0.00284\n",
      "Epoch: 1... Training loss: 0.00228... Test loss: 0.00236\n",
      "Epoch: 1... Training loss: 0.00237... Test loss: 0.00292\n",
      "Epoch: 1... Training loss: 0.00215... Test loss: 0.0022\n",
      "Epoch: 1... Training loss: 0.00212... Test loss: 0.00249\n",
      "Epoch: 1... Training loss: 0.00221... Test loss: 0.00226\n",
      "Epoch: 1... Training loss: 0.00207... Test loss: 0.00203\n",
      "Epoch: 1... Training loss: 0.00206... Test loss: 0.00192\n",
      "Epoch: 1... Training loss: 0.00204... Test loss: 0.00181\n",
      "Epoch: 1... Training loss: 0.00201... Test loss: 0.00175\n",
      "Epoch: 1... Training loss: 0.00193... Test loss: 0.00217\n",
      "Epoch: 1... Training loss: 0.00188... Test loss: 0.00207\n",
      "Epoch: 1... Training loss: 0.00181... Test loss: 0.00206\n",
      "Epoch: 1... Training loss: 0.0018... Test loss: 0.00201\n",
      "Epoch: 1... Training loss: 0.00178... Test loss: 0.0018\n",
      "Epoch: 1... Training loss: 0.00174... Test loss: 0.00194\n",
      "Epoch: 1... Training loss: 0.00176... Test loss: 0.00166\n",
      "Epoch: 1... Training loss: 0.00168... Test loss: 0.00188\n",
      "Epoch: 1... Training loss: 0.00157... Test loss: 0.00167\n",
      "Epoch: 1... Training loss: 0.00153... Test loss: 0.00175\n",
      "Epoch: 1... Training loss: 0.00146... Test loss: 0.0016\n",
      "Epoch: 1... Training loss: 0.00141... Test loss: 0.00171\n",
      "Epoch: 1... Training loss: 0.00136... Test loss: 0.00172\n",
      "Epoch: 1... Training loss: 0.00127... Test loss: 0.00152\n",
      "Epoch: 1... Training loss: 0.00141... Test loss: 0.00149\n",
      "Epoch: 1... Training loss: 0.0013... Test loss: 0.00134\n",
      "Epoch: 1... Training loss: 0.00115... Test loss: 0.00149\n",
      "Epoch: 1... Training loss: 0.00112... Test loss: 0.00128\n",
      "Epoch: 1... Training loss: 0.00113... Test loss: 0.00149\n",
      "Epoch: 1... Training loss: 0.00104... Test loss: 0.00112\n",
      "Epoch: 1... Training loss: 0.00102... Test loss: 0.00122\n",
      "Epoch: 1... Training loss: 0.00097... Test loss: 0.00129\n",
      "Epoch: 1... Training loss: 0.00096... Test loss: 0.00104\n",
      "Epoch: 1... Training loss: 0.00094... Test loss: 0.00131\n",
      "Epoch: 1... Training loss: 0.00097... Test loss: 0.00112\n",
      "Epoch: 1... Training loss: 0.00092... Test loss: 0.00126\n",
      "Epoch: 1... Training loss: 0.00083... Test loss: 0.00098\n",
      "Epoch: 1... Training loss: 0.00077... Test loss: 0.00091\n",
      "Epoch: 1... Training loss: 0.0008... Test loss: 0.00084\n",
      "Epoch: 1... Training loss: 0.00079... Test loss: 0.00081\n",
      "Epoch: 1... Training loss: 0.00072... Test loss: 0.00074\n",
      "Epoch: 1... Training loss: 0.00072... Test loss: 0.00081\n",
      "Epoch: 1... Training loss: 0.00068... Test loss: 0.00069\n",
      "Epoch: 1... Training loss: 0.00068... Test loss: 0.00067\n",
      "Epoch: 1... Training loss: 0.00063... Test loss: 0.00061\n",
      "Epoch: 1... Training loss: 0.00062... Test loss: 0.00065\n",
      "Epoch: 1... Training loss: 0.00064... Test loss: 0.00072\n",
      "Epoch: 1... Training loss: 0.00057... Test loss: 0.00062\n",
      "Epoch: 1... Training loss: 0.00059... Test loss: 0.00059\n",
      "Epoch: 1... Training loss: 0.00061... Test loss: 0.00056\n",
      "Epoch: 1... Training loss: 0.00047... Test loss: 0.00055\n",
      "Epoch: 1... Training loss: 0.00045... Test loss: 0.00052\n",
      "Epoch: 1... Training loss: 0.00044... Test loss: 0.00047\n",
      "Epoch: 1... Training loss: 0.00041... Test loss: 0.00049\n",
      "Epoch: 1... Training loss: 0.00043... Test loss: 0.00039\n",
      "Epoch: 1... Training loss: 0.0004... Test loss: 0.00044\n",
      "Epoch: 1... Training loss: 0.00037... Test loss: 0.00045\n",
      "Epoch: 1... Training loss: 0.00041... Test loss: 0.00043\n",
      "Epoch: 1... Training loss: 0.00041... Test loss: 0.00041\n",
      "Epoch: 1... Training loss: 0.00033... Test loss: 0.00045\n",
      "Epoch: 1... Training loss: 0.00032... Test loss: 0.00033\n",
      "Epoch: 1... Training loss: 0.00032... Test loss: 0.00036\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00036\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00037\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.0003\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00034\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00024\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00019\n",
      "291.1909749628976\n",
      "Epoch: 1... Training loss: 0.81707... Test loss: 0.15352\n",
      "Epoch: 1... Training loss: 0.41882... Test loss: 0.12905\n",
      "Epoch: 1... Training loss: 0.25504... Test loss: 0.06679\n",
      "Epoch: 1... Training loss: 0.18877... Test loss: 0.05436\n",
      "Epoch: 1... Training loss: 0.15124... Test loss: 0.04175\n",
      "Epoch: 1... Training loss: 0.11683... Test loss: 0.03111\n",
      "Epoch: 1... Training loss: 0.09495... Test loss: 0.02697\n",
      "Epoch: 1... Training loss: 0.07984... Test loss: 0.02363\n",
      "Epoch: 1... Training loss: 0.06604... Test loss: 0.0168\n",
      "Epoch: 1... Training loss: 0.05679... Test loss: 0.01363\n",
      "Epoch: 1... Training loss: 0.04855... Test loss: 0.00892\n",
      "Epoch: 1... Training loss: 0.04626... Test loss: 0.01176\n",
      "Epoch: 1... Training loss: 0.0403... Test loss: 0.00654\n",
      "Epoch: 1... Training loss: 0.03893... Test loss: 0.00585\n",
      "Epoch: 1... Training loss: 0.03484... Test loss: 0.01142\n",
      "Epoch: 1... Training loss: 0.03344... Test loss: 0.00434\n",
      "Epoch: 1... Training loss: 0.03035... Test loss: 0.00933\n",
      "Epoch: 1... Training loss: 0.0283... Test loss: 0.00379\n",
      "Epoch: 1... Training loss: 0.02644... Test loss: 0.0093\n",
      "Epoch: 1... Training loss: 0.02585... Test loss: 0.00374\n",
      "Epoch: 1... Training loss: 0.02385... Test loss: 0.00443\n",
      "Epoch: 1... Training loss: 0.0234... Test loss: 0.00406\n",
      "Epoch: 1... Training loss: 0.02121... Test loss: 0.00855\n",
      "Epoch: 1... Training loss: 0.02001... Test loss: 0.00436\n",
      "Epoch: 1... Training loss: 0.01922... Test loss: 0.00584\n",
      "Epoch: 1... Training loss: 0.01863... Test loss: 0.00749\n",
      "Epoch: 1... Training loss: 0.01776... Test loss: 0.00377\n",
      "Epoch: 1... Training loss: 0.01718... Test loss: 0.00796\n",
      "Epoch: 1... Training loss: 0.01632... Test loss: 0.00466\n",
      "Epoch: 1... Training loss: 0.01553... Test loss: 0.00949\n",
      "Epoch: 1... Training loss: 0.01489... Test loss: 0.00498\n",
      "Epoch: 1... Training loss: 0.01443... Test loss: 0.00786\n",
      "Epoch: 1... Training loss: 0.01403... Test loss: 0.00541\n",
      "Epoch: 1... Training loss: 0.01354... Test loss: 0.0082\n",
      "Epoch: 1... Training loss: 0.01319... Test loss: 0.00711\n",
      "Epoch: 1... Training loss: 0.0128... Test loss: 0.00666\n",
      "Epoch: 1... Training loss: 0.01251... Test loss: 0.00759\n",
      "Epoch: 1... Training loss: 0.01205... Test loss: 0.00702\n",
      "Epoch: 1... Training loss: 0.01179... Test loss: 0.00606\n",
      "Epoch: 1... Training loss: 0.0112... Test loss: 0.00813\n",
      "Epoch: 1... Training loss: 0.01093... Test loss: 0.00589\n",
      "Epoch: 1... Training loss: 0.0105... Test loss: 0.0094\n",
      "Epoch: 1... Training loss: 0.01041... Test loss: 0.00645\n",
      "Epoch: 1... Training loss: 0.01005... Test loss: 0.00698\n",
      "Epoch: 1... Training loss: 0.00997... Test loss: 0.00727\n",
      "Epoch: 1... Training loss: 0.00929... Test loss: 0.00531\n",
      "Epoch: 1... Training loss: 0.00917... Test loss: 0.00788\n",
      "Epoch: 1... Training loss: 0.00878... Test loss: 0.00556\n",
      "Epoch: 1... Training loss: 0.00858... Test loss: 0.00811\n",
      "Epoch: 1... Training loss: 0.00835... Test loss: 0.00548\n",
      "Epoch: 1... Training loss: 0.00819... Test loss: 0.00738\n",
      "Epoch: 1... Training loss: 0.00792... Test loss: 0.0048\n",
      "Epoch: 1... Training loss: 0.00772... Test loss: 0.0071\n",
      "Epoch: 1... Training loss: 0.00753... Test loss: 0.00572\n",
      "Epoch: 1... Training loss: 0.00737... Test loss: 0.00692\n",
      "Epoch: 1... Training loss: 0.00725... Test loss: 0.00561\n",
      "Epoch: 1... Training loss: 0.0071... Test loss: 0.00635\n",
      "Epoch: 1... Training loss: 0.0069... Test loss: 0.00608\n",
      "Epoch: 1... Training loss: 0.00681... Test loss: 0.00583\n",
      "Epoch: 1... Training loss: 0.00664... Test loss: 0.00586\n",
      "Epoch: 1... Training loss: 0.00651... Test loss: 0.00536\n",
      "Epoch: 1... Training loss: 0.00632... Test loss: 0.00562\n",
      "Epoch: 1... Training loss: 0.00612... Test loss: 0.00536\n",
      "Epoch: 1... Training loss: 0.006... Test loss: 0.00612\n",
      "Epoch: 1... Training loss: 0.00869... Test loss: 0.01207\n",
      "Epoch: 1... Training loss: 0.01253... Test loss: 0.01369\n",
      "Epoch: 1... Training loss: 0.00961... Test loss: 0.01246\n",
      "Epoch: 1... Training loss: 0.01014... Test loss: 0.01242\n",
      "Epoch: 1... Training loss: 0.01132... Test loss: 0.0153\n",
      "Epoch: 1... Training loss: 0.00979... Test loss: 0.0153\n",
      "Epoch: 1... Training loss: 0.00949... Test loss: 0.01171\n",
      "Epoch: 1... Training loss: 0.00913... Test loss: 0.01173\n",
      "Epoch: 1... Training loss: 0.00859... Test loss: 0.01015\n",
      "Epoch: 1... Training loss: 0.00953... Test loss: 0.01007\n",
      "Epoch: 1... Training loss: 0.00805... Test loss: 0.01033\n",
      "Epoch: 1... Training loss: 0.00823... Test loss: 0.00875\n",
      "Epoch: 1... Training loss: 0.00802... Test loss: 0.00943\n",
      "Epoch: 1... Training loss: 0.0079... Test loss: 0.00866\n",
      "Epoch: 1... Training loss: 0.00776... Test loss: 0.00915\n",
      "Epoch: 1... Training loss: 0.00758... Test loss: 0.00807\n",
      "Epoch: 1... Training loss: 0.00736... Test loss: 0.00787\n",
      "Epoch: 1... Training loss: 0.00697... Test loss: 0.00731\n",
      "Epoch: 1... Training loss: 0.00681... Test loss: 0.00774\n",
      "Epoch: 1... Training loss: 0.0064... Test loss: 0.00778\n",
      "Epoch: 1... Training loss: 0.00617... Test loss: 0.0079\n",
      "Epoch: 1... Training loss: 0.00601... Test loss: 0.00733\n",
      "Epoch: 1... Training loss: 0.00595... Test loss: 0.00785\n",
      "Epoch: 1... Training loss: 0.00542... Test loss: 0.00707\n",
      "Epoch: 1... Training loss: 0.00563... Test loss: 0.00736\n",
      "Epoch: 1... Training loss: 0.00525... Test loss: 0.0068\n",
      "Epoch: 1... Training loss: 0.00523... Test loss: 0.0059\n",
      "Epoch: 1... Training loss: 0.00498... Test loss: 0.00531\n",
      "Epoch: 1... Training loss: 0.00482... Test loss: 0.00503\n",
      "Epoch: 1... Training loss: 0.0051... Test loss: 0.00542\n",
      "Epoch: 1... Training loss: 0.00464... Test loss: 0.00547\n",
      "Epoch: 1... Training loss: 0.00462... Test loss: 0.00585\n",
      "Epoch: 1... Training loss: 0.00434... Test loss: 0.00477\n",
      "Epoch: 1... Training loss: 0.00419... Test loss: 0.0053\n",
      "Epoch: 1... Training loss: 0.00413... Test loss: 0.00439\n",
      "Epoch: 1... Training loss: 0.00402... Test loss: 0.00516\n",
      "Epoch: 1... Training loss: 0.00381... Test loss: 0.00478\n",
      "Epoch: 1... Training loss: 0.00374... Test loss: 0.00506\n",
      "Epoch: 1... Training loss: 0.00365... Test loss: 0.00381\n",
      "Epoch: 1... Training loss: 0.00366... Test loss: 0.00458\n",
      "Epoch: 1... Training loss: 0.00372... Test loss: 0.0039\n",
      "Epoch: 1... Training loss: 0.00351... Test loss: 0.00449\n",
      "Epoch: 1... Training loss: 0.00366... Test loss: 0.00364\n",
      "Epoch: 1... Training loss: 0.00341... Test loss: 0.00357\n",
      "Epoch: 1... Training loss: 0.00339... Test loss: 0.00339\n",
      "Epoch: 1... Training loss: 0.00333... Test loss: 0.00374\n",
      "Epoch: 1... Training loss: 0.00325... Test loss: 0.00329\n",
      "Epoch: 1... Training loss: 0.0032... Test loss: 0.00347\n",
      "Epoch: 1... Training loss: 0.00321... Test loss: 0.00335\n",
      "Epoch: 1... Training loss: 0.0031... Test loss: 0.00354\n",
      "Epoch: 1... Training loss: 0.00306... Test loss: 0.00311\n",
      "Epoch: 1... Training loss: 0.00301... Test loss: 0.00338\n",
      "Epoch: 1... Training loss: 0.00303... Test loss: 0.00305\n",
      "Epoch: 1... Training loss: 0.00289... Test loss: 0.00297\n",
      "Epoch: 1... Training loss: 0.00292... Test loss: 0.00301\n",
      "Epoch: 1... Training loss: 0.00283... Test loss: 0.00274\n",
      "Epoch: 1... Training loss: 0.00292... Test loss: 0.00311\n",
      "Epoch: 1... Training loss: 0.00266... Test loss: 0.00284\n",
      "Epoch: 1... Training loss: 0.00262... Test loss: 0.00262\n",
      "Epoch: 1... Training loss: 0.00261... Test loss: 0.00271\n",
      "Epoch: 1... Training loss: 0.00247... Test loss: 0.00278\n",
      "Epoch: 1... Training loss: 0.00245... Test loss: 0.00269\n",
      "Epoch: 1... Training loss: 0.00241... Test loss: 0.00223\n",
      "Epoch: 1... Training loss: 0.00238... Test loss: 0.00274\n",
      "Epoch: 1... Training loss: 0.00254... Test loss: 0.00249\n",
      "Epoch: 1... Training loss: 0.00232... Test loss: 0.00237\n",
      "Epoch: 1... Training loss: 0.00224... Test loss: 0.00242\n",
      "Epoch: 1... Training loss: 0.00225... Test loss: 0.00222\n",
      "Epoch: 1... Training loss: 0.00212... Test loss: 0.00203\n",
      "Epoch: 1... Training loss: 0.00205... Test loss: 0.00248\n",
      "Epoch: 1... Training loss: 0.00199... Test loss: 0.00201\n",
      "Epoch: 1... Training loss: 0.00198... Test loss: 0.0022\n",
      "Epoch: 1... Training loss: 0.00187... Test loss: 0.00221\n",
      "Epoch: 1... Training loss: 0.00183... Test loss: 0.00205\n",
      "Epoch: 1... Training loss: 0.00182... Test loss: 0.00189\n",
      "Epoch: 1... Training loss: 0.00182... Test loss: 0.00219\n",
      "Epoch: 1... Training loss: 0.00175... Test loss: 0.00161\n",
      "Epoch: 1... Training loss: 0.0017... Test loss: 0.00166\n",
      "Epoch: 1... Training loss: 0.0018... Test loss: 0.00163\n",
      "Epoch: 1... Training loss: 0.00162... Test loss: 0.00155\n",
      "Epoch: 1... Training loss: 0.00154... Test loss: 0.00171\n",
      "Epoch: 1... Training loss: 0.00157... Test loss: 0.0016\n",
      "Epoch: 1... Training loss: 0.00146... Test loss: 0.00168\n",
      "Epoch: 1... Training loss: 0.00143... Test loss: 0.00153\n",
      "Epoch: 1... Training loss: 0.00139... Test loss: 0.00143\n",
      "Epoch: 1... Training loss: 0.00136... Test loss: 0.0013\n",
      "Epoch: 1... Training loss: 0.00136... Test loss: 0.00158\n",
      "Epoch: 1... Training loss: 0.00134... Test loss: 0.00125\n",
      "Epoch: 1... Training loss: 0.00132... Test loss: 0.0014\n",
      "Epoch: 1... Training loss: 0.00119... Test loss: 0.00125\n",
      "Epoch: 1... Training loss: 0.00115... Test loss: 0.0012\n",
      "Epoch: 1... Training loss: 0.00108... Test loss: 0.00126\n",
      "Epoch: 1... Training loss: 0.00108... Test loss: 0.00109\n",
      "Epoch: 1... Training loss: 0.00105... Test loss: 0.00114\n",
      "Epoch: 1... Training loss: 0.00103... Test loss: 0.00102\n",
      "Epoch: 1... Training loss: 0.001... Test loss: 0.00111\n",
      "Epoch: 1... Training loss: 0.00096... Test loss: 0.00098\n",
      "Epoch: 1... Training loss: 0.00098... Test loss: 0.00107\n",
      "Epoch: 1... Training loss: 0.00085... Test loss: 0.00084\n",
      "Epoch: 1... Training loss: 0.00083... Test loss: 0.00101\n",
      "Epoch: 1... Training loss: 0.0008... Test loss: 0.00092\n",
      "Epoch: 1... Training loss: 0.00089... Test loss: 0.00083\n",
      "Epoch: 1... Training loss: 0.00078... Test loss: 0.0009\n",
      "Epoch: 1... Training loss: 0.00081... Test loss: 0.00079\n",
      "Epoch: 1... Training loss: 0.00077... Test loss: 0.00096\n",
      "Epoch: 1... Training loss: 0.00076... Test loss: 0.0007\n",
      "Epoch: 1... Training loss: 0.00071... Test loss: 0.00087\n",
      "Epoch: 1... Training loss: 0.0007... Test loss: 0.00073\n",
      "Epoch: 1... Training loss: 0.00069... Test loss: 0.00067\n",
      "Epoch: 1... Training loss: 0.00065... Test loss: 0.00081\n",
      "Epoch: 1... Training loss: 0.00065... Test loss: 0.00058\n",
      "Epoch: 1... Training loss: 0.00061... Test loss: 0.00077\n",
      "Epoch: 1... Training loss: 0.0006... Test loss: 0.00061\n",
      "Epoch: 1... Training loss: 0.00057... Test loss: 0.00062\n",
      "Epoch: 1... Training loss: 0.00053... Test loss: 0.00057\n",
      "Epoch: 1... Training loss: 0.00054... Test loss: 0.00054\n",
      "Epoch: 1... Training loss: 0.00051... Test loss: 0.00059\n",
      "Epoch: 1... Training loss: 0.00051... Test loss: 0.00049\n",
      "Epoch: 1... Training loss: 0.00054... Test loss: 0.00056\n",
      "Epoch: 1... Training loss: 0.00047... Test loss: 0.00046\n",
      "Epoch: 1... Training loss: 0.00051... Test loss: 0.00052\n",
      "Epoch: 1... Training loss: 0.00042... Test loss: 0.00042\n",
      "Epoch: 1... Training loss: 0.00043... Test loss: 0.00047\n",
      "Epoch: 1... Training loss: 0.00039... Test loss: 0.0004\n",
      "Epoch: 1... Training loss: 0.00042... Test loss: 0.0004\n",
      "Epoch: 1... Training loss: 0.00036... Test loss: 0.00043\n",
      "Epoch: 1... Training loss: 0.00036... Test loss: 0.00037\n",
      "Epoch: 1... Training loss: 0.00041... Test loss: 0.00037\n",
      "Epoch: 1... Training loss: 0.0004... Test loss: 0.00038\n",
      "Epoch: 1... Training loss: 0.00032... Test loss: 0.00035\n",
      "Epoch: 1... Training loss: 0.00032... Test loss: 0.00035\n",
      "Epoch: 1... Training loss: 0.00034... Test loss: 0.00033\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00035\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00031\n",
      "Epoch: 1... Training loss: 0.00029... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00024\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.00029\n",
      "332.84548699494917\n",
      "Epoch: 1... Training loss: 1.37132... Test loss: 0.68312\n",
      "Epoch: 1... Training loss: 0.67121... Test loss: 0.30452\n",
      "Epoch: 1... Training loss: 0.35897... Test loss: 0.16961\n",
      "Epoch: 1... Training loss: 0.23699... Test loss: 0.13296\n",
      "Epoch: 1... Training loss: 0.18252... Test loss: 0.06901\n",
      "Epoch: 1... Training loss: 0.12534... Test loss: 0.07783\n",
      "Epoch: 1... Training loss: 0.11953... Test loss: 0.04155\n",
      "Epoch: 1... Training loss: 0.08173... Test loss: 0.06691\n",
      "Epoch: 1... Training loss: 0.06981... Test loss: 0.03703\n",
      "Epoch: 1... Training loss: 0.05605... Test loss: 0.01729\n",
      "Epoch: 1... Training loss: 0.05726... Test loss: 0.03541\n",
      "Epoch: 1... Training loss: 0.04805... Test loss: 0.03317\n",
      "Epoch: 1... Training loss: 0.04522... Test loss: 0.02782\n",
      "Epoch: 1... Training loss: 0.03513... Test loss: 0.02747\n",
      "Epoch: 1... Training loss: 0.03343... Test loss: 0.01599\n",
      "Epoch: 1... Training loss: 0.03092... Test loss: 0.03709\n",
      "Epoch: 1... Training loss: 0.02824... Test loss: 0.02708\n",
      "Epoch: 1... Training loss: 0.02696... Test loss: 0.01589\n",
      "Epoch: 1... Training loss: 0.02508... Test loss: 0.02353\n",
      "Epoch: 1... Training loss: 0.02429... Test loss: 0.02035\n",
      "Epoch: 1... Training loss: 0.02313... Test loss: 0.02363\n",
      "Epoch: 1... Training loss: 0.02159... Test loss: 0.0118\n",
      "Epoch: 1... Training loss: 0.02075... Test loss: 0.02156\n",
      "Epoch: 1... Training loss: 0.01951... Test loss: 0.01395\n",
      "Epoch: 1... Training loss: 0.01909... Test loss: 0.01764\n",
      "Epoch: 1... Training loss: 0.01801... Test loss: 0.0104\n",
      "Epoch: 1... Training loss: 0.0174... Test loss: 0.01875\n",
      "Epoch: 1... Training loss: 0.01651... Test loss: 0.00872\n",
      "Epoch: 1... Training loss: 0.01639... Test loss: 0.01622\n",
      "Epoch: 1... Training loss: 0.01513... Test loss: 0.0083\n",
      "Epoch: 1... Training loss: 0.01487... Test loss: 0.01463\n",
      "Epoch: 1... Training loss: 0.01413... Test loss: 0.00683\n",
      "Epoch: 1... Training loss: 0.01376... Test loss: 0.01319\n",
      "Epoch: 1... Training loss: 0.01319... Test loss: 0.00688\n",
      "Epoch: 1... Training loss: 0.01299... Test loss: 0.01329\n",
      "Epoch: 1... Training loss: 0.01227... Test loss: 0.00728\n",
      "Epoch: 1... Training loss: 0.01216... Test loss: 0.0144\n",
      "Epoch: 1... Training loss: 0.01159... Test loss: 0.00762\n",
      "Epoch: 1... Training loss: 0.01149... Test loss: 0.01048\n",
      "Epoch: 1... Training loss: 0.01072... Test loss: 0.01069\n",
      "Epoch: 1... Training loss: 0.01057... Test loss: 0.00982\n",
      "Epoch: 1... Training loss: 0.01009... Test loss: 0.01005\n",
      "Epoch: 1... Training loss: 0.00988... Test loss: 0.00905\n",
      "Epoch: 1... Training loss: 0.00958... Test loss: 0.01028\n",
      "Epoch: 1... Training loss: 0.00944... Test loss: 0.00776\n",
      "Epoch: 1... Training loss: 0.00897... Test loss: 0.0092\n",
      "Epoch: 1... Training loss: 0.00894... Test loss: 0.00691\n",
      "Epoch: 1... Training loss: 0.00847... Test loss: 0.00865\n",
      "Epoch: 1... Training loss: 0.0084... Test loss: 0.0063\n",
      "Epoch: 1... Training loss: 0.00806... Test loss: 0.00715\n",
      "Epoch: 1... Training loss: 0.00794... Test loss: 0.00698\n",
      "Epoch: 1... Training loss: 0.00767... Test loss: 0.0062\n",
      "Epoch: 1... Training loss: 0.00738... Test loss: 0.00845\n",
      "Epoch: 1... Training loss: 0.00708... Test loss: 0.00556\n",
      "Epoch: 1... Training loss: 0.007... Test loss: 0.00801\n",
      "Epoch: 1... Training loss: 0.00678... Test loss: 0.00573\n",
      "Epoch: 1... Training loss: 0.00665... Test loss: 0.00643\n",
      "Epoch: 1... Training loss: 0.00643... Test loss: 0.00721\n",
      "Epoch: 1... Training loss: 0.00635... Test loss: 0.0054\n",
      "Epoch: 1... Training loss: 0.00613... Test loss: 0.00665\n",
      "Epoch: 1... Training loss: 0.00598... Test loss: 0.00511\n",
      "Epoch: 1... Training loss: 0.00587... Test loss: 0.00633\n",
      "Epoch: 1... Training loss: 0.00572... Test loss: 0.00468\n",
      "Epoch: 1... Training loss: 0.00549... Test loss: 0.00558\n",
      "Epoch: 1... Training loss: 0.01072... Test loss: 0.01432\n",
      "Epoch: 1... Training loss: 0.01222... Test loss: 0.02471\n",
      "Epoch: 1... Training loss: 0.01115... Test loss: 0.0121\n",
      "Epoch: 1... Training loss: 0.00808... Test loss: 0.01513\n",
      "Epoch: 1... Training loss: 0.01069... Test loss: 0.00939\n",
      "Epoch: 1... Training loss: 0.00985... Test loss: 0.01272\n",
      "Epoch: 1... Training loss: 0.0087... Test loss: 0.0095\n",
      "Epoch: 1... Training loss: 0.00868... Test loss: 0.01179\n",
      "Epoch: 1... Training loss: 0.00904... Test loss: 0.00993\n",
      "Epoch: 1... Training loss: 0.00843... Test loss: 0.01121\n",
      "Epoch: 1... Training loss: 0.00862... Test loss: 0.0087\n",
      "Epoch: 1... Training loss: 0.00735... Test loss: 0.00868\n",
      "Epoch: 1... Training loss: 0.00757... Test loss: 0.00831\n",
      "Epoch: 1... Training loss: 0.00733... Test loss: 0.00898\n",
      "Epoch: 1... Training loss: 0.0073... Test loss: 0.0067\n",
      "Epoch: 1... Training loss: 0.00648... Test loss: 0.00831\n",
      "Epoch: 1... Training loss: 0.00714... Test loss: 0.00698\n",
      "Epoch: 1... Training loss: 0.00657... Test loss: 0.00828\n",
      "Epoch: 1... Training loss: 0.00641... Test loss: 0.00673\n",
      "Epoch: 1... Training loss: 0.00649... Test loss: 0.00667\n",
      "Epoch: 1... Training loss: 0.00576... Test loss: 0.0062\n",
      "Epoch: 1... Training loss: 0.00611... Test loss: 0.00486\n",
      "Epoch: 1... Training loss: 0.00592... Test loss: 0.00728\n",
      "Epoch: 1... Training loss: 0.00557... Test loss: 0.00471\n",
      "Epoch: 1... Training loss: 0.00533... Test loss: 0.00613\n",
      "Epoch: 1... Training loss: 0.00502... Test loss: 0.00537\n",
      "Epoch: 1... Training loss: 0.00508... Test loss: 0.00578\n",
      "Epoch: 1... Training loss: 0.00507... Test loss: 0.00522\n",
      "Epoch: 1... Training loss: 0.00495... Test loss: 0.00498\n",
      "Epoch: 1... Training loss: 0.00449... Test loss: 0.00727\n",
      "Epoch: 1... Training loss: 0.00444... Test loss: 0.00423\n",
      "Epoch: 1... Training loss: 0.00454... Test loss: 0.00485\n",
      "Epoch: 1... Training loss: 0.00424... Test loss: 0.0044\n",
      "Epoch: 1... Training loss: 0.004... Test loss: 0.00404\n",
      "Epoch: 1... Training loss: 0.0039... Test loss: 0.00402\n",
      "Epoch: 1... Training loss: 0.00376... Test loss: 0.00348\n",
      "Epoch: 1... Training loss: 0.00371... Test loss: 0.00385\n",
      "Epoch: 1... Training loss: 0.00359... Test loss: 0.00354\n",
      "Epoch: 1... Training loss: 0.00345... Test loss: 0.00409\n",
      "Epoch: 1... Training loss: 0.00344... Test loss: 0.00362\n",
      "Epoch: 1... Training loss: 0.00345... Test loss: 0.00402\n",
      "Epoch: 1... Training loss: 0.00351... Test loss: 0.003\n",
      "Epoch: 1... Training loss: 0.00335... Test loss: 0.00409\n",
      "Epoch: 1... Training loss: 0.00326... Test loss: 0.00354\n",
      "Epoch: 1... Training loss: 0.00329... Test loss: 0.00383\n",
      "Epoch: 1... Training loss: 0.00303... Test loss: 0.00405\n",
      "Epoch: 1... Training loss: 0.003... Test loss: 0.00326\n",
      "Epoch: 1... Training loss: 0.00292... Test loss: 0.00321\n",
      "Epoch: 1... Training loss: 0.00291... Test loss: 0.00319\n",
      "Epoch: 1... Training loss: 0.00282... Test loss: 0.00334\n",
      "Epoch: 1... Training loss: 0.00299... Test loss: 0.00316\n",
      "Epoch: 1... Training loss: 0.00278... Test loss: 0.00335\n",
      "Epoch: 1... Training loss: 0.00273... Test loss: 0.00278\n",
      "Epoch: 1... Training loss: 0.0025... Test loss: 0.00348\n",
      "Epoch: 1... Training loss: 0.00257... Test loss: 0.00296\n",
      "Epoch: 1... Training loss: 0.00243... Test loss: 0.00313\n",
      "Epoch: 1... Training loss: 0.00238... Test loss: 0.0027\n",
      "Epoch: 1... Training loss: 0.00235... Test loss: 0.0029\n",
      "Epoch: 1... Training loss: 0.00227... Test loss: 0.00259\n",
      "Epoch: 1... Training loss: 0.00217... Test loss: 0.00311\n",
      "Epoch: 1... Training loss: 0.00214... Test loss: 0.0025\n",
      "Epoch: 1... Training loss: 0.00203... Test loss: 0.00275\n",
      "Epoch: 1... Training loss: 0.00205... Test loss: 0.0022\n",
      "Epoch: 1... Training loss: 0.00207... Test loss: 0.00258\n",
      "Epoch: 1... Training loss: 0.00198... Test loss: 0.00232\n",
      "Epoch: 1... Training loss: 0.00191... Test loss: 0.00266\n",
      "Epoch: 1... Training loss: 0.00191... Test loss: 0.00216\n",
      "Epoch: 1... Training loss: 0.00177... Test loss: 0.00261\n",
      "Epoch: 1... Training loss: 0.00175... Test loss: 0.00168\n",
      "Epoch: 1... Training loss: 0.00168... Test loss: 0.00216\n",
      "Epoch: 1... Training loss: 0.0017... Test loss: 0.0018\n",
      "Epoch: 1... Training loss: 0.00164... Test loss: 0.00177\n",
      "Epoch: 1... Training loss: 0.0016... Test loss: 0.00176\n",
      "Epoch: 1... Training loss: 0.00152... Test loss: 0.00144\n",
      "Epoch: 1... Training loss: 0.00152... Test loss: 0.00155\n",
      "Epoch: 1... Training loss: 0.00141... Test loss: 0.00147\n",
      "Epoch: 1... Training loss: 0.00145... Test loss: 0.00125\n",
      "Epoch: 1... Training loss: 0.00139... Test loss: 0.00152\n",
      "Epoch: 1... Training loss: 0.00134... Test loss: 0.00114\n",
      "Epoch: 1... Training loss: 0.00133... Test loss: 0.0017\n",
      "Epoch: 1... Training loss: 0.00125... Test loss: 0.00123\n",
      "Epoch: 1... Training loss: 0.00121... Test loss: 0.00143\n",
      "Epoch: 1... Training loss: 0.00118... Test loss: 0.00112\n",
      "Epoch: 1... Training loss: 0.00111... Test loss: 0.0012\n",
      "Epoch: 1... Training loss: 0.00116... Test loss: 0.00116\n",
      "Epoch: 1... Training loss: 0.00108... Test loss: 0.00132\n",
      "Epoch: 1... Training loss: 0.00107... Test loss: 0.00107\n",
      "Epoch: 1... Training loss: 0.00109... Test loss: 0.00121\n",
      "Epoch: 1... Training loss: 0.00098... Test loss: 0.00093\n",
      "Epoch: 1... Training loss: 0.00097... Test loss: 0.00098\n",
      "Epoch: 1... Training loss: 0.00103... Test loss: 0.0011\n",
      "Epoch: 1... Training loss: 0.001... Test loss: 0.00107\n",
      "Epoch: 1... Training loss: 0.00089... Test loss: 0.00107\n",
      "Epoch: 1... Training loss: 0.00092... Test loss: 0.00094\n",
      "Epoch: 1... Training loss: 0.00086... Test loss: 0.00104\n",
      "Epoch: 1... Training loss: 0.0009... Test loss: 0.00089\n",
      "Epoch: 1... Training loss: 0.00083... Test loss: 0.00099\n",
      "Epoch: 1... Training loss: 0.00081... Test loss: 0.00083\n",
      "Epoch: 1... Training loss: 0.00079... Test loss: 0.00089\n",
      "Epoch: 1... Training loss: 0.00074... Test loss: 0.00067\n",
      "Epoch: 1... Training loss: 0.0008... Test loss: 0.00084\n",
      "Epoch: 1... Training loss: 0.00069... Test loss: 0.00064\n",
      "Epoch: 1... Training loss: 0.00066... Test loss: 0.00086\n",
      "Epoch: 1... Training loss: 0.00067... Test loss: 0.00066\n",
      "Epoch: 1... Training loss: 0.00065... Test loss: 0.00076\n",
      "Epoch: 1... Training loss: 0.0006... Test loss: 0.00065\n",
      "Epoch: 1... Training loss: 0.00056... Test loss: 0.00064\n",
      "Epoch: 1... Training loss: 0.00056... Test loss: 0.00051\n",
      "Epoch: 1... Training loss: 0.00054... Test loss: 0.00058\n",
      "Epoch: 1... Training loss: 0.00052... Test loss: 0.00052\n",
      "Epoch: 1... Training loss: 0.00048... Test loss: 0.00056\n",
      "Epoch: 1... Training loss: 0.00048... Test loss: 0.00045\n",
      "Epoch: 1... Training loss: 0.00051... Test loss: 0.00049\n",
      "Epoch: 1... Training loss: 0.00046... Test loss: 0.00043\n",
      "Epoch: 1... Training loss: 0.00045... Test loss: 0.00049\n",
      "Epoch: 1... Training loss: 0.00042... Test loss: 0.00043\n",
      "Epoch: 1... Training loss: 0.00042... Test loss: 0.0004\n",
      "Epoch: 1... Training loss: 0.0004... Test loss: 0.00043\n",
      "Epoch: 1... Training loss: 0.00037... Test loss: 0.00036\n",
      "Epoch: 1... Training loss: 0.00038... Test loss: 0.00032\n",
      "Epoch: 1... Training loss: 0.00036... Test loss: 0.00032\n",
      "Epoch: 1... Training loss: 0.00035... Test loss: 0.00032\n",
      "Epoch: 1... Training loss: 0.00035... Test loss: 0.00031\n",
      "Epoch: 1... Training loss: 0.00037... Test loss: 0.00036\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.0003\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00026... Test loss: 0.00031\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00026... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.00026... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00024\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00019\n",
      "284.66514165652916\n",
      "Epoch: 1... Training loss: 1.12646... Test loss: 0.47435\n",
      "Epoch: 1... Training loss: 0.47889... Test loss: 0.15914\n",
      "Epoch: 1... Training loss: 0.24978... Test loss: 0.08488\n",
      "Epoch: 1... Training loss: 0.19507... Test loss: 0.05452\n",
      "Epoch: 1... Training loss: 0.13763... Test loss: 0.04534\n",
      "Epoch: 1... Training loss: 0.10655... Test loss: 0.0354\n",
      "Epoch: 1... Training loss: 0.08192... Test loss: 0.02619\n",
      "Epoch: 1... Training loss: 0.06596... Test loss: 0.02091\n",
      "Epoch: 1... Training loss: 0.05714... Test loss: 0.01712\n",
      "Epoch: 1... Training loss: 0.05203... Test loss: 0.01737\n",
      "Epoch: 1... Training loss: 0.0483... Test loss: 0.01\n",
      "Epoch: 1... Training loss: 0.04322... Test loss: 0.01716\n",
      "Epoch: 1... Training loss: 0.03774... Test loss: 0.00967\n",
      "Epoch: 1... Training loss: 0.03494... Test loss: 0.01464\n",
      "Epoch: 1... Training loss: 0.03402... Test loss: 0.00889\n",
      "Epoch: 1... Training loss: 0.03101... Test loss: 0.01157\n",
      "Epoch: 1... Training loss: 0.02985... Test loss: 0.006\n",
      "Epoch: 1... Training loss: 0.0276... Test loss: 0.01335\n",
      "Epoch: 1... Training loss: 0.02615... Test loss: 0.00574\n",
      "Epoch: 1... Training loss: 0.02346... Test loss: 0.01418\n",
      "Epoch: 1... Training loss: 0.02264... Test loss: 0.01018\n",
      "Epoch: 1... Training loss: 0.02023... Test loss: 0.01436\n",
      "Epoch: 1... Training loss: 0.01935... Test loss: 0.00962\n",
      "Epoch: 1... Training loss: 0.01823... Test loss: 0.01012\n",
      "Epoch: 1... Training loss: 0.01786... Test loss: 0.01074\n",
      "Epoch: 1... Training loss: 0.01686... Test loss: 0.00544\n",
      "Epoch: 1... Training loss: 0.01618... Test loss: 0.00968\n",
      "Epoch: 1... Training loss: 0.01565... Test loss: 0.00497\n",
      "Epoch: 1... Training loss: 0.01471... Test loss: 0.00862\n",
      "Epoch: 1... Training loss: 0.01427... Test loss: 0.00713\n",
      "Epoch: 1... Training loss: 0.01339... Test loss: 0.00897\n",
      "Epoch: 1... Training loss: 0.01296... Test loss: 0.00753\n",
      "Epoch: 1... Training loss: 0.01264... Test loss: 0.00689\n",
      "Epoch: 1... Training loss: 0.01237... Test loss: 0.00777\n",
      "Epoch: 1... Training loss: 0.01213... Test loss: 0.00632\n",
      "Epoch: 1... Training loss: 0.01176... Test loss: 0.00462\n",
      "Epoch: 1... Training loss: 0.01157... Test loss: 0.00918\n",
      "Epoch: 1... Training loss: 0.01101... Test loss: 0.00274\n",
      "Epoch: 1... Training loss: 0.01071... Test loss: 0.0078\n",
      "Epoch: 1... Training loss: 0.01039... Test loss: 0.00278\n",
      "Epoch: 1... Training loss: 0.00982... Test loss: 0.00729\n",
      "Epoch: 1... Training loss: 0.00944... Test loss: 0.00315\n",
      "Epoch: 1... Training loss: 0.00924... Test loss: 0.00664\n",
      "Epoch: 1... Training loss: 0.00896... Test loss: 0.0036\n",
      "Epoch: 1... Training loss: 0.00878... Test loss: 0.00624\n",
      "Epoch: 1... Training loss: 0.00859... Test loss: 0.00443\n",
      "Epoch: 1... Training loss: 0.00832... Test loss: 0.00658\n",
      "Epoch: 1... Training loss: 0.00816... Test loss: 0.00551\n",
      "Epoch: 1... Training loss: 0.00785... Test loss: 0.00619\n",
      "Epoch: 1... Training loss: 0.00774... Test loss: 0.00511\n",
      "Epoch: 1... Training loss: 0.00752... Test loss: 0.00632\n",
      "Epoch: 1... Training loss: 0.00734... Test loss: 0.00464\n",
      "Epoch: 1... Training loss: 0.00717... Test loss: 0.00671\n",
      "Epoch: 1... Training loss: 0.00692... Test loss: 0.00464\n",
      "Epoch: 1... Training loss: 0.00674... Test loss: 0.00639\n",
      "Epoch: 1... Training loss: 0.00654... Test loss: 0.00399\n",
      "Epoch: 1... Training loss: 0.0065... Test loss: 0.00622\n",
      "Epoch: 1... Training loss: 0.0063... Test loss: 0.00473\n",
      "Epoch: 1... Training loss: 0.00611... Test loss: 0.00582\n",
      "Epoch: 1... Training loss: 0.00601... Test loss: 0.00478\n",
      "Epoch: 1... Training loss: 0.00587... Test loss: 0.00598\n",
      "Epoch: 1... Training loss: 0.00568... Test loss: 0.00427\n",
      "Epoch: 1... Training loss: 0.00555... Test loss: 0.00556\n",
      "Epoch: 1... Training loss: 0.00543... Test loss: 0.00444\n",
      "Epoch: 1... Training loss: 0.0165... Test loss: 0.01165\n",
      "Epoch: 1... Training loss: 0.01237... Test loss: 0.01173\n",
      "Epoch: 1... Training loss: 0.01235... Test loss: 0.01432\n",
      "Epoch: 1... Training loss: 0.00931... Test loss: 0.01169\n",
      "Epoch: 1... Training loss: 0.00827... Test loss: 0.01388\n",
      "Epoch: 1... Training loss: 0.00793... Test loss: 0.0087\n",
      "Epoch: 1... Training loss: 0.00898... Test loss: 0.01179\n",
      "Epoch: 1... Training loss: 0.00709... Test loss: 0.01152\n",
      "Epoch: 1... Training loss: 0.00875... Test loss: 0.01199\n",
      "Epoch: 1... Training loss: 0.00813... Test loss: 0.01266\n",
      "Epoch: 1... Training loss: 0.00798... Test loss: 0.0105\n",
      "Epoch: 1... Training loss: 0.00782... Test loss: 0.01132\n",
      "Epoch: 1... Training loss: 0.00731... Test loss: 0.00783\n",
      "Epoch: 1... Training loss: 0.00713... Test loss: 0.00899\n",
      "Epoch: 1... Training loss: 0.00626... Test loss: 0.00821\n",
      "Epoch: 1... Training loss: 0.00642... Test loss: 0.00742\n",
      "Epoch: 1... Training loss: 0.00619... Test loss: 0.00738\n",
      "Epoch: 1... Training loss: 0.00615... Test loss: 0.0078\n",
      "Epoch: 1... Training loss: 0.00587... Test loss: 0.00738\n",
      "Epoch: 1... Training loss: 0.00593... Test loss: 0.00734\n",
      "Epoch: 1... Training loss: 0.00572... Test loss: 0.00612\n",
      "Epoch: 1... Training loss: 0.0058... Test loss: 0.00597\n",
      "Epoch: 1... Training loss: 0.00553... Test loss: 0.00547\n",
      "Epoch: 1... Training loss: 0.00535... Test loss: 0.00548\n",
      "Epoch: 1... Training loss: 0.00532... Test loss: 0.00563\n",
      "Epoch: 1... Training loss: 0.00499... Test loss: 0.00556\n",
      "Epoch: 1... Training loss: 0.00492... Test loss: 0.00528\n",
      "Epoch: 1... Training loss: 0.00457... Test loss: 0.00508\n",
      "Epoch: 1... Training loss: 0.00458... Test loss: 0.00473\n",
      "Epoch: 1... Training loss: 0.00443... Test loss: 0.00513\n",
      "Epoch: 1... Training loss: 0.00439... Test loss: 0.0048\n",
      "Epoch: 1... Training loss: 0.00395... Test loss: 0.0048\n",
      "Epoch: 1... Training loss: 0.00382... Test loss: 0.0043\n",
      "Epoch: 1... Training loss: 0.00393... Test loss: 0.00484\n",
      "Epoch: 1... Training loss: 0.00363... Test loss: 0.00407\n",
      "Epoch: 1... Training loss: 0.0037... Test loss: 0.00398\n",
      "Epoch: 1... Training loss: 0.00359... Test loss: 0.0043\n",
      "Epoch: 1... Training loss: 0.00355... Test loss: 0.00399\n",
      "Epoch: 1... Training loss: 0.00354... Test loss: 0.0041\n",
      "Epoch: 1... Training loss: 0.00344... Test loss: 0.00365\n",
      "Epoch: 1... Training loss: 0.00343... Test loss: 0.00416\n",
      "Epoch: 1... Training loss: 0.0034... Test loss: 0.00372\n",
      "Epoch: 1... Training loss: 0.00332... Test loss: 0.00362\n",
      "Epoch: 1... Training loss: 0.00323... Test loss: 0.00329\n",
      "Epoch: 1... Training loss: 0.00312... Test loss: 0.00359\n",
      "Epoch: 1... Training loss: 0.00305... Test loss: 0.00299\n",
      "Epoch: 1... Training loss: 0.00291... Test loss: 0.00357\n",
      "Epoch: 1... Training loss: 0.00293... Test loss: 0.00282\n",
      "Epoch: 1... Training loss: 0.00281... Test loss: 0.00329\n",
      "Epoch: 1... Training loss: 0.00287... Test loss: 0.00271\n",
      "Epoch: 1... Training loss: 0.0028... Test loss: 0.00289\n",
      "Epoch: 1... Training loss: 0.00284... Test loss: 0.00296\n",
      "Epoch: 1... Training loss: 0.00276... Test loss: 0.00288\n",
      "Epoch: 1... Training loss: 0.00261... Test loss: 0.00284\n",
      "Epoch: 1... Training loss: 0.00255... Test loss: 0.00259\n",
      "Epoch: 1... Training loss: 0.00242... Test loss: 0.00294\n",
      "Epoch: 1... Training loss: 0.00245... Test loss: 0.00256\n",
      "Epoch: 1... Training loss: 0.00239... Test loss: 0.00261\n",
      "Epoch: 1... Training loss: 0.00243... Test loss: 0.00254\n",
      "Epoch: 1... Training loss: 0.00229... Test loss: 0.00262\n",
      "Epoch: 1... Training loss: 0.00241... Test loss: 0.00257\n",
      "Epoch: 1... Training loss: 0.00229... Test loss: 0.00268\n",
      "Epoch: 1... Training loss: 0.00216... Test loss: 0.00222\n",
      "Epoch: 1... Training loss: 0.00216... Test loss: 0.00216\n",
      "Epoch: 1... Training loss: 0.0022... Test loss: 0.00199\n",
      "Epoch: 1... Training loss: 0.0022... Test loss: 0.00241\n",
      "Epoch: 1... Training loss: 0.00209... Test loss: 0.0022\n",
      "Epoch: 1... Training loss: 0.00197... Test loss: 0.00204\n",
      "Epoch: 1... Training loss: 0.00203... Test loss: 0.00185\n",
      "Epoch: 1... Training loss: 0.0018... Test loss: 0.00192\n",
      "Epoch: 1... Training loss: 0.00177... Test loss: 0.00198\n",
      "Epoch: 1... Training loss: 0.0017... Test loss: 0.00196\n",
      "Epoch: 1... Training loss: 0.00173... Test loss: 0.00181\n",
      "Epoch: 1... Training loss: 0.0017... Test loss: 0.00189\n",
      "Epoch: 1... Training loss: 0.00171... Test loss: 0.00167\n",
      "Epoch: 1... Training loss: 0.00153... Test loss: 0.00204\n",
      "Epoch: 1... Training loss: 0.00148... Test loss: 0.00175\n",
      "Epoch: 1... Training loss: 0.00147... Test loss: 0.0018\n",
      "Epoch: 1... Training loss: 0.00138... Test loss: 0.00157\n",
      "Epoch: 1... Training loss: 0.00139... Test loss: 0.00153\n",
      "Epoch: 1... Training loss: 0.00133... Test loss: 0.00151\n",
      "Epoch: 1... Training loss: 0.00128... Test loss: 0.00129\n",
      "Epoch: 1... Training loss: 0.0013... Test loss: 0.00132\n",
      "Epoch: 1... Training loss: 0.00125... Test loss: 0.0011\n",
      "Epoch: 1... Training loss: 0.00122... Test loss: 0.00136\n",
      "Epoch: 1... Training loss: 0.00122... Test loss: 0.00119\n",
      "Epoch: 1... Training loss: 0.00109... Test loss: 0.00136\n",
      "Epoch: 1... Training loss: 0.0012... Test loss: 0.00106\n",
      "Epoch: 1... Training loss: 0.00105... Test loss: 0.00112\n",
      "Epoch: 1... Training loss: 0.00111... Test loss: 0.00099\n",
      "Epoch: 1... Training loss: 0.00105... Test loss: 0.001\n",
      "Epoch: 1... Training loss: 0.00098... Test loss: 0.00098\n",
      "Epoch: 1... Training loss: 0.00093... Test loss: 0.00092\n",
      "Epoch: 1... Training loss: 0.00097... Test loss: 0.00095\n",
      "Epoch: 1... Training loss: 0.00093... Test loss: 0.001\n",
      "Epoch: 1... Training loss: 0.00088... Test loss: 0.00094\n",
      "Epoch: 1... Training loss: 0.00087... Test loss: 0.00094\n",
      "Epoch: 1... Training loss: 0.0009... Test loss: 0.00091\n",
      "Epoch: 1... Training loss: 0.00082... Test loss: 0.00083\n",
      "Epoch: 1... Training loss: 0.00081... Test loss: 0.00099\n",
      "Epoch: 1... Training loss: 0.00082... Test loss: 0.00084\n",
      "Epoch: 1... Training loss: 0.00075... Test loss: 0.00088\n",
      "Epoch: 1... Training loss: 0.00073... Test loss: 0.00079\n",
      "Epoch: 1... Training loss: 0.0007... Test loss: 0.00082\n",
      "Epoch: 1... Training loss: 0.00076... Test loss: 0.0007\n",
      "Epoch: 1... Training loss: 0.00063... Test loss: 0.00071\n",
      "Epoch: 1... Training loss: 0.00068... Test loss: 0.00063\n",
      "Epoch: 1... Training loss: 0.00067... Test loss: 0.0007\n",
      "Epoch: 1... Training loss: 0.00069... Test loss: 0.00059\n",
      "Epoch: 1... Training loss: 0.00065... Test loss: 0.00068\n",
      "Epoch: 1... Training loss: 0.00062... Test loss: 0.00057\n",
      "Epoch: 1... Training loss: 0.00054... Test loss: 0.00061\n",
      "Epoch: 1... Training loss: 0.00055... Test loss: 0.00054\n",
      "Epoch: 1... Training loss: 0.00054... Test loss: 0.00059\n",
      "Epoch: 1... Training loss: 0.00052... Test loss: 0.00053\n",
      "Epoch: 1... Training loss: 0.00051... Test loss: 0.00056\n",
      "Epoch: 1... Training loss: 0.00047... Test loss: 0.0005\n",
      "Epoch: 1... Training loss: 0.00047... Test loss: 0.00046\n",
      "Epoch: 1... Training loss: 0.00048... Test loss: 0.00043\n",
      "Epoch: 1... Training loss: 0.00045... Test loss: 0.00049\n",
      "Epoch: 1... Training loss: 0.00041... Test loss: 0.00044\n",
      "Epoch: 1... Training loss: 0.0004... Test loss: 0.00039\n",
      "Epoch: 1... Training loss: 0.00041... Test loss: 0.00039\n",
      "Epoch: 1... Training loss: 0.00036... Test loss: 0.00031\n",
      "Epoch: 1... Training loss: 0.00033... Test loss: 0.00033\n",
      "Epoch: 1... Training loss: 0.00033... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00031... Test loss: 0.00032\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00031... Test loss: 0.00024\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00023\n",
      "294.1530098837102\n",
      "Epoch: 1... Training loss: 1.36703... Test loss: 0.61755\n",
      "Epoch: 1... Training loss: 0.52903... Test loss: 0.20711\n",
      "Epoch: 1... Training loss: 0.29931... Test loss: 0.12908\n",
      "Epoch: 1... Training loss: 0.2088... Test loss: 0.08675\n",
      "Epoch: 1... Training loss: 0.15149... Test loss: 0.05068\n",
      "Epoch: 1... Training loss: 0.12034... Test loss: 0.07439\n",
      "Epoch: 1... Training loss: 0.10478... Test loss: 0.03802\n",
      "Epoch: 1... Training loss: 0.08066... Test loss: 0.06875\n",
      "Epoch: 1... Training loss: 0.07029... Test loss: 0.02715\n",
      "Epoch: 1... Training loss: 0.06214... Test loss: 0.05773\n",
      "Epoch: 1... Training loss: 0.05441... Test loss: 0.02189\n",
      "Epoch: 1... Training loss: 0.05179... Test loss: 0.05173\n",
      "Epoch: 1... Training loss: 0.04748... Test loss: 0.019\n",
      "Epoch: 1... Training loss: 0.04405... Test loss: 0.04533\n",
      "Epoch: 1... Training loss: 0.03974... Test loss: 0.01544\n",
      "Epoch: 1... Training loss: 0.03696... Test loss: 0.03917\n",
      "Epoch: 1... Training loss: 0.03324... Test loss: 0.02079\n",
      "Epoch: 1... Training loss: 0.03206... Test loss: 0.04148\n",
      "Epoch: 1... Training loss: 0.03054... Test loss: 0.02612\n",
      "Epoch: 1... Training loss: 0.02798... Test loss: 0.03666\n",
      "Epoch: 1... Training loss: 0.02704... Test loss: 0.0161\n",
      "Epoch: 1... Training loss: 0.02477... Test loss: 0.03899\n",
      "Epoch: 1... Training loss: 0.02357... Test loss: 0.01857\n",
      "Epoch: 1... Training loss: 0.02158... Test loss: 0.03366\n",
      "Epoch: 1... Training loss: 0.02117... Test loss: 0.01968\n",
      "Epoch: 1... Training loss: 0.01917... Test loss: 0.02795\n",
      "Epoch: 1... Training loss: 0.01888... Test loss: 0.02384\n",
      "Epoch: 1... Training loss: 0.01742... Test loss: 0.00885\n",
      "Epoch: 1... Training loss: 0.01758... Test loss: 0.02112\n",
      "Epoch: 1... Training loss: 0.01612... Test loss: 0.00898\n",
      "Epoch: 1... Training loss: 0.01604... Test loss: 0.0232\n",
      "Epoch: 1... Training loss: 0.01529... Test loss: 0.00958\n",
      "Epoch: 1... Training loss: 0.01474... Test loss: 0.02098\n",
      "Epoch: 1... Training loss: 0.01418... Test loss: 0.01058\n",
      "Epoch: 1... Training loss: 0.0137... Test loss: 0.01889\n",
      "Epoch: 1... Training loss: 0.01296... Test loss: 0.00914\n",
      "Epoch: 1... Training loss: 0.0124... Test loss: 0.01867\n",
      "Epoch: 1... Training loss: 0.01214... Test loss: 0.00877\n",
      "Epoch: 1... Training loss: 0.01196... Test loss: 0.01655\n",
      "Epoch: 1... Training loss: 0.01161... Test loss: 0.00794\n",
      "Epoch: 1... Training loss: 0.01106... Test loss: 0.01462\n",
      "Epoch: 1... Training loss: 0.01064... Test loss: 0.00799\n",
      "Epoch: 1... Training loss: 0.01042... Test loss: 0.01296\n",
      "Epoch: 1... Training loss: 0.01011... Test loss: 0.00821\n",
      "Epoch: 1... Training loss: 0.00975... Test loss: 0.01071\n",
      "Epoch: 1... Training loss: 0.00924... Test loss: 0.00902\n",
      "Epoch: 1... Training loss: 0.00892... Test loss: 0.00856\n",
      "Epoch: 1... Training loss: 0.00869... Test loss: 0.00895\n",
      "Epoch: 1... Training loss: 0.00846... Test loss: 0.0062\n",
      "Epoch: 1... Training loss: 0.00824... Test loss: 0.00966\n",
      "Epoch: 1... Training loss: 0.00809... Test loss: 0.00591\n",
      "Epoch: 1... Training loss: 0.00787... Test loss: 0.00943\n",
      "Epoch: 1... Training loss: 0.00756... Test loss: 0.00526\n",
      "Epoch: 1... Training loss: 0.00742... Test loss: 0.00931\n",
      "Epoch: 1... Training loss: 0.00714... Test loss: 0.00499\n",
      "Epoch: 1... Training loss: 0.00696... Test loss: 0.00884\n",
      "Epoch: 1... Training loss: 0.00679... Test loss: 0.00586\n",
      "Epoch: 1... Training loss: 0.00649... Test loss: 0.00756\n",
      "Epoch: 1... Training loss: 0.00637... Test loss: 0.00604\n",
      "Epoch: 1... Training loss: 0.00621... Test loss: 0.00634\n",
      "Epoch: 1... Training loss: 0.00617... Test loss: 0.00624\n",
      "Epoch: 1... Training loss: 0.00606... Test loss: 0.00612\n",
      "Epoch: 1... Training loss: 0.006... Test loss: 0.00516\n",
      "Epoch: 1... Training loss: 0.0058... Test loss: 0.00611\n",
      "Epoch: 1... Training loss: 0.00871... Test loss: 0.01721\n",
      "Epoch: 1... Training loss: 0.01252... Test loss: 0.01352\n",
      "Epoch: 1... Training loss: 0.01043... Test loss: 0.01129\n",
      "Epoch: 1... Training loss: 0.01253... Test loss: 0.01229\n",
      "Epoch: 1... Training loss: 0.00907... Test loss: 0.01523\n",
      "Epoch: 1... Training loss: 0.00935... Test loss: 0.01228\n",
      "Epoch: 1... Training loss: 0.01017... Test loss: 0.01284\n",
      "Epoch: 1... Training loss: 0.00936... Test loss: 0.01157\n",
      "Epoch: 1... Training loss: 0.00935... Test loss: 0.00969\n",
      "Epoch: 1... Training loss: 0.00862... Test loss: 0.01137\n",
      "Epoch: 1... Training loss: 0.00757... Test loss: 0.01194\n",
      "Epoch: 1... Training loss: 0.00784... Test loss: 0.01149\n",
      "Epoch: 1... Training loss: 0.00849... Test loss: 0.01239\n",
      "Epoch: 1... Training loss: 0.00728... Test loss: 0.01183\n",
      "Epoch: 1... Training loss: 0.00707... Test loss: 0.00674\n",
      "Epoch: 1... Training loss: 0.00688... Test loss: 0.01352\n",
      "Epoch: 1... Training loss: 0.0068... Test loss: 0.00795\n",
      "Epoch: 1... Training loss: 0.00633... Test loss: 0.01074\n",
      "Epoch: 1... Training loss: 0.007... Test loss: 0.00614\n",
      "Epoch: 1... Training loss: 0.00628... Test loss: 0.00821\n",
      "Epoch: 1... Training loss: 0.00608... Test loss: 0.00609\n",
      "Epoch: 1... Training loss: 0.00619... Test loss: 0.00871\n",
      "Epoch: 1... Training loss: 0.0058... Test loss: 0.00739\n",
      "Epoch: 1... Training loss: 0.00573... Test loss: 0.00559\n",
      "Epoch: 1... Training loss: 0.00552... Test loss: 0.00663\n",
      "Epoch: 1... Training loss: 0.00561... Test loss: 0.00541\n",
      "Epoch: 1... Training loss: 0.00515... Test loss: 0.00536\n",
      "Epoch: 1... Training loss: 0.00496... Test loss: 0.00513\n",
      "Epoch: 1... Training loss: 0.00484... Test loss: 0.00465\n",
      "Epoch: 1... Training loss: 0.00479... Test loss: 0.00585\n",
      "Epoch: 1... Training loss: 0.00463... Test loss: 0.00497\n",
      "Epoch: 1... Training loss: 0.00454... Test loss: 0.00591\n",
      "Epoch: 1... Training loss: 0.00441... Test loss: 0.00432\n",
      "Epoch: 1... Training loss: 0.00431... Test loss: 0.00509\n",
      "Epoch: 1... Training loss: 0.0042... Test loss: 0.00396\n",
      "Epoch: 1... Training loss: 0.00404... Test loss: 0.00477\n",
      "Epoch: 1... Training loss: 0.00389... Test loss: 0.00453\n",
      "Epoch: 1... Training loss: 0.0038... Test loss: 0.00421\n",
      "Epoch: 1... Training loss: 0.00392... Test loss: 0.00468\n",
      "Epoch: 1... Training loss: 0.00382... Test loss: 0.00392\n",
      "Epoch: 1... Training loss: 0.00366... Test loss: 0.00385\n",
      "Epoch: 1... Training loss: 0.00362... Test loss: 0.00397\n",
      "Epoch: 1... Training loss: 0.00361... Test loss: 0.00374\n",
      "Epoch: 1... Training loss: 0.00363... Test loss: 0.00391\n",
      "Epoch: 1... Training loss: 0.00346... Test loss: 0.00364\n",
      "Epoch: 1... Training loss: 0.00333... Test loss: 0.0037\n",
      "Epoch: 1... Training loss: 0.0034... Test loss: 0.00349\n",
      "Epoch: 1... Training loss: 0.00328... Test loss: 0.00341\n",
      "Epoch: 1... Training loss: 0.00321... Test loss: 0.00318\n",
      "Epoch: 1... Training loss: 0.00305... Test loss: 0.00345\n",
      "Epoch: 1... Training loss: 0.00299... Test loss: 0.0031\n",
      "Epoch: 1... Training loss: 0.00304... Test loss: 0.00304\n",
      "Epoch: 1... Training loss: 0.00291... Test loss: 0.00327\n",
      "Epoch: 1... Training loss: 0.00288... Test loss: 0.00277\n",
      "Epoch: 1... Training loss: 0.00281... Test loss: 0.003\n",
      "Epoch: 1... Training loss: 0.0028... Test loss: 0.0026\n",
      "Epoch: 1... Training loss: 0.00252... Test loss: 0.00265\n",
      "Epoch: 1... Training loss: 0.0027... Test loss: 0.00247\n",
      "Epoch: 1... Training loss: 0.00248... Test loss: 0.00255\n",
      "Epoch: 1... Training loss: 0.00244... Test loss: 0.00259\n",
      "Epoch: 1... Training loss: 0.00237... Test loss: 0.00241\n",
      "Epoch: 1... Training loss: 0.00243... Test loss: 0.0024\n",
      "Epoch: 1... Training loss: 0.00228... Test loss: 0.00268\n",
      "Epoch: 1... Training loss: 0.0023... Test loss: 0.00227\n",
      "Epoch: 1... Training loss: 0.00218... Test loss: 0.00254\n",
      "Epoch: 1... Training loss: 0.00212... Test loss: 0.00228\n",
      "Epoch: 1... Training loss: 0.00207... Test loss: 0.00226\n",
      "Epoch: 1... Training loss: 0.00203... Test loss: 0.00216\n",
      "Epoch: 1... Training loss: 0.00195... Test loss: 0.00212\n",
      "Epoch: 1... Training loss: 0.00194... Test loss: 0.00221\n",
      "Epoch: 1... Training loss: 0.00189... Test loss: 0.00207\n",
      "Epoch: 1... Training loss: 0.00193... Test loss: 0.00201\n",
      "Epoch: 1... Training loss: 0.00182... Test loss: 0.00193\n",
      "Epoch: 1... Training loss: 0.00178... Test loss: 0.00179\n",
      "Epoch: 1... Training loss: 0.00172... Test loss: 0.00182\n",
      "Epoch: 1... Training loss: 0.00171... Test loss: 0.00194\n",
      "Epoch: 1... Training loss: 0.00173... Test loss: 0.00177\n",
      "Epoch: 1... Training loss: 0.00159... Test loss: 0.0017\n",
      "Epoch: 1... Training loss: 0.00154... Test loss: 0.00152\n",
      "Epoch: 1... Training loss: 0.0015... Test loss: 0.00139\n",
      "Epoch: 1... Training loss: 0.00152... Test loss: 0.00149\n",
      "Epoch: 1... Training loss: 0.00143... Test loss: 0.00149\n",
      "Epoch: 1... Training loss: 0.00146... Test loss: 0.0015\n",
      "Epoch: 1... Training loss: 0.00143... Test loss: 0.00134\n",
      "Epoch: 1... Training loss: 0.00151... Test loss: 0.00134\n",
      "Epoch: 1... Training loss: 0.00138... Test loss: 0.00113\n",
      "Epoch: 1... Training loss: 0.00131... Test loss: 0.00151\n",
      "Epoch: 1... Training loss: 0.00131... Test loss: 0.00119\n",
      "Epoch: 1... Training loss: 0.00133... Test loss: 0.0015\n",
      "Epoch: 1... Training loss: 0.00124... Test loss: 0.0012\n",
      "Epoch: 1... Training loss: 0.00118... Test loss: 0.00133\n",
      "Epoch: 1... Training loss: 0.00118... Test loss: 0.00104\n",
      "Epoch: 1... Training loss: 0.00112... Test loss: 0.00137\n",
      "Epoch: 1... Training loss: 0.00113... Test loss: 0.00085\n",
      "Epoch: 1... Training loss: 0.00112... Test loss: 0.00136\n",
      "Epoch: 1... Training loss: 0.00104... Test loss: 0.001\n",
      "Epoch: 1... Training loss: 0.00102... Test loss: 0.00092\n",
      "Epoch: 1... Training loss: 0.00095... Test loss: 0.00128\n",
      "Epoch: 1... Training loss: 0.00088... Test loss: 0.0011\n",
      "Epoch: 1... Training loss: 0.00092... Test loss: 0.00116\n",
      "Epoch: 1... Training loss: 0.00083... Test loss: 0.00102\n",
      "Epoch: 1... Training loss: 0.0008... Test loss: 0.00098\n",
      "Epoch: 1... Training loss: 0.00079... Test loss: 0.00113\n",
      "Epoch: 1... Training loss: 0.00079... Test loss: 0.00086\n",
      "Epoch: 1... Training loss: 0.00071... Test loss: 0.00088\n",
      "Epoch: 1... Training loss: 0.00066... Test loss: 0.00077\n",
      "Epoch: 1... Training loss: 0.00065... Test loss: 0.00079\n",
      "Epoch: 1... Training loss: 0.0007... Test loss: 0.00064\n",
      "Epoch: 1... Training loss: 0.0006... Test loss: 0.00076\n",
      "Epoch: 1... Training loss: 0.00059... Test loss: 0.00054\n",
      "Epoch: 1... Training loss: 0.00058... Test loss: 0.00076\n",
      "Epoch: 1... Training loss: 0.00056... Test loss: 0.00048\n",
      "Epoch: 1... Training loss: 0.00056... Test loss: 0.00072\n",
      "Epoch: 1... Training loss: 0.00056... Test loss: 0.00042\n",
      "Epoch: 1... Training loss: 0.0005... Test loss: 0.0007\n",
      "Epoch: 1... Training loss: 0.00052... Test loss: 0.00038\n",
      "Epoch: 1... Training loss: 0.00051... Test loss: 0.00064\n",
      "Epoch: 1... Training loss: 0.00047... Test loss: 0.00038\n",
      "Epoch: 1... Training loss: 0.00042... Test loss: 0.00074\n",
      "Epoch: 1... Training loss: 0.00041... Test loss: 0.00046\n",
      "Epoch: 1... Training loss: 0.00041... Test loss: 0.00041\n",
      "Epoch: 1... Training loss: 0.00036... Test loss: 0.00047\n",
      "Epoch: 1... Training loss: 0.00033... Test loss: 0.00051\n",
      "Epoch: 1... Training loss: 0.00032... Test loss: 0.00034\n",
      "Epoch: 1... Training loss: 0.00029... Test loss: 0.00046\n",
      "Epoch: 1... Training loss: 0.00032... Test loss: 0.00034\n",
      "Epoch: 1... Training loss: 0.00029... Test loss: 0.00039\n",
      "Epoch: 1... Training loss: 0.00026... Test loss: 0.00028\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00034\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00013\n",
      "256.8454174248618\n",
      "Epoch: 1... Training loss: 0.91755... Test loss: 0.24031\n",
      "Epoch: 1... Training loss: 0.40372... Test loss: 0.11264\n",
      "Epoch: 1... Training loss: 0.25252... Test loss: 0.07634\n",
      "Epoch: 1... Training loss: 0.16814... Test loss: 0.04642\n",
      "Epoch: 1... Training loss: 0.12941... Test loss: 0.03729\n",
      "Epoch: 1... Training loss: 0.11231... Test loss: 0.03544\n",
      "Epoch: 1... Training loss: 0.09722... Test loss: 0.02906\n",
      "Epoch: 1... Training loss: 0.08469... Test loss: 0.02722\n",
      "Epoch: 1... Training loss: 0.07087... Test loss: 0.01846\n",
      "Epoch: 1... Training loss: 0.06337... Test loss: 0.02049\n",
      "Epoch: 1... Training loss: 0.05822... Test loss: 0.01782\n",
      "Epoch: 1... Training loss: 0.05268... Test loss: 0.02938\n",
      "Epoch: 1... Training loss: 0.05023... Test loss: 0.01415\n",
      "Epoch: 1... Training loss: 0.04447... Test loss: 0.02326\n",
      "Epoch: 1... Training loss: 0.04411... Test loss: 0.01477\n",
      "Epoch: 1... Training loss: 0.03925... Test loss: 0.02023\n",
      "Epoch: 1... Training loss: 0.03737... Test loss: 0.01057\n",
      "Epoch: 1... Training loss: 0.032... Test loss: 0.01786\n",
      "Epoch: 1... Training loss: 0.03004... Test loss: 0.01152\n",
      "Epoch: 1... Training loss: 0.02792... Test loss: 0.01578\n",
      "Epoch: 1... Training loss: 0.02715... Test loss: 0.01229\n",
      "Epoch: 1... Training loss: 0.02458... Test loss: 0.01129\n",
      "Epoch: 1... Training loss: 0.02401... Test loss: 0.01554\n",
      "Epoch: 1... Training loss: 0.02282... Test loss: 0.00907\n",
      "Epoch: 1... Training loss: 0.02218... Test loss: 0.01707\n",
      "Epoch: 1... Training loss: 0.02066... Test loss: 0.01142\n",
      "Epoch: 1... Training loss: 0.01945... Test loss: 0.01594\n",
      "Epoch: 1... Training loss: 0.01881... Test loss: 0.01097\n",
      "Epoch: 1... Training loss: 0.0174... Test loss: 0.01449\n",
      "Epoch: 1... Training loss: 0.01666... Test loss: 0.01005\n",
      "Epoch: 1... Training loss: 0.01623... Test loss: 0.01297\n",
      "Epoch: 1... Training loss: 0.01511... Test loss: 0.01045\n",
      "Epoch: 1... Training loss: 0.01456... Test loss: 0.01092\n",
      "Epoch: 1... Training loss: 0.01406... Test loss: 0.00988\n",
      "Epoch: 1... Training loss: 0.01323... Test loss: 0.01009\n",
      "Epoch: 1... Training loss: 0.0128... Test loss: 0.00998\n",
      "Epoch: 1... Training loss: 0.0123... Test loss: 0.00872\n",
      "Epoch: 1... Training loss: 0.012... Test loss: 0.00937\n",
      "Epoch: 1... Training loss: 0.01157... Test loss: 0.0086\n",
      "Epoch: 1... Training loss: 0.01128... Test loss: 0.01006\n",
      "Epoch: 1... Training loss: 0.01083... Test loss: 0.00778\n",
      "Epoch: 1... Training loss: 0.01059... Test loss: 0.00971\n",
      "Epoch: 1... Training loss: 0.01035... Test loss: 0.0073\n",
      "Epoch: 1... Training loss: 0.01013... Test loss: 0.01053\n",
      "Epoch: 1... Training loss: 0.00983... Test loss: 0.00601\n",
      "Epoch: 1... Training loss: 0.00975... Test loss: 0.00887\n",
      "Epoch: 1... Training loss: 0.00923... Test loss: 0.00578\n",
      "Epoch: 1... Training loss: 0.00884... Test loss: 0.00844\n",
      "Epoch: 1... Training loss: 0.00852... Test loss: 0.00649\n",
      "Epoch: 1... Training loss: 0.00832... Test loss: 0.00762\n",
      "Epoch: 1... Training loss: 0.00809... Test loss: 0.00678\n",
      "Epoch: 1... Training loss: 0.00775... Test loss: 0.00699\n",
      "Epoch: 1... Training loss: 0.00754... Test loss: 0.008\n",
      "Epoch: 1... Training loss: 0.00737... Test loss: 0.00584\n",
      "Epoch: 1... Training loss: 0.00717... Test loss: 0.00743\n",
      "Epoch: 1... Training loss: 0.00701... Test loss: 0.00535\n",
      "Epoch: 1... Training loss: 0.0068... Test loss: 0.00705\n",
      "Epoch: 1... Training loss: 0.00669... Test loss: 0.0053\n",
      "Epoch: 1... Training loss: 0.00643... Test loss: 0.00637\n",
      "Epoch: 1... Training loss: 0.00637... Test loss: 0.00572\n",
      "Epoch: 1... Training loss: 0.00625... Test loss: 0.00505\n",
      "Epoch: 1... Training loss: 0.00605... Test loss: 0.0067\n",
      "Epoch: 1... Training loss: 0.00585... Test loss: 0.00528\n",
      "Epoch: 1... Training loss: 0.00574... Test loss: 0.00613\n",
      "Epoch: 1... Training loss: 0.01347... Test loss: 0.00896\n",
      "Epoch: 1... Training loss: 0.01017... Test loss: 0.02197\n",
      "Epoch: 1... Training loss: 0.01224... Test loss: 0.01309\n",
      "Epoch: 1... Training loss: 0.01061... Test loss: 0.01593\n",
      "Epoch: 1... Training loss: 0.0102... Test loss: 0.01425\n",
      "Epoch: 1... Training loss: 0.01018... Test loss: 0.01078\n",
      "Epoch: 1... Training loss: 0.00976... Test loss: 0.01187\n",
      "Epoch: 1... Training loss: 0.00837... Test loss: 0.0098\n",
      "Epoch: 1... Training loss: 0.01051... Test loss: 0.01136\n",
      "Epoch: 1... Training loss: 0.00932... Test loss: 0.00943\n",
      "Epoch: 1... Training loss: 0.00795... Test loss: 0.00982\n",
      "Epoch: 1... Training loss: 0.00777... Test loss: 0.008\n",
      "Epoch: 1... Training loss: 0.00791... Test loss: 0.00909\n",
      "Epoch: 1... Training loss: 0.00838... Test loss: 0.0088\n",
      "Epoch: 1... Training loss: 0.0079... Test loss: 0.00922\n",
      "Epoch: 1... Training loss: 0.00754... Test loss: 0.00883\n",
      "Epoch: 1... Training loss: 0.00715... Test loss: 0.00798\n",
      "Epoch: 1... Training loss: 0.00725... Test loss: 0.00654\n",
      "Epoch: 1... Training loss: 0.00648... Test loss: 0.00888\n",
      "Epoch: 1... Training loss: 0.00674... Test loss: 0.00615\n",
      "Epoch: 1... Training loss: 0.00631... Test loss: 0.00762\n",
      "Epoch: 1... Training loss: 0.00626... Test loss: 0.00583\n",
      "Epoch: 1... Training loss: 0.00601... Test loss: 0.00712\n",
      "Epoch: 1... Training loss: 0.00615... Test loss: 0.00559\n",
      "Epoch: 1... Training loss: 0.00586... Test loss: 0.00653\n",
      "Epoch: 1... Training loss: 0.00565... Test loss: 0.00587\n",
      "Epoch: 1... Training loss: 0.00569... Test loss: 0.00566\n",
      "Epoch: 1... Training loss: 0.00524... Test loss: 0.00536\n",
      "Epoch: 1... Training loss: 0.00511... Test loss: 0.00497\n",
      "Epoch: 1... Training loss: 0.00514... Test loss: 0.0052\n",
      "Epoch: 1... Training loss: 0.00493... Test loss: 0.00552\n",
      "Epoch: 1... Training loss: 0.00469... Test loss: 0.00501\n",
      "Epoch: 1... Training loss: 0.0045... Test loss: 0.00525\n",
      "Epoch: 1... Training loss: 0.00441... Test loss: 0.00464\n",
      "Epoch: 1... Training loss: 0.00432... Test loss: 0.00476\n",
      "Epoch: 1... Training loss: 0.00429... Test loss: 0.00443\n",
      "Epoch: 1... Training loss: 0.00419... Test loss: 0.00461\n",
      "Epoch: 1... Training loss: 0.00422... Test loss: 0.00405\n",
      "Epoch: 1... Training loss: 0.0042... Test loss: 0.00448\n",
      "Epoch: 1... Training loss: 0.00402... Test loss: 0.0038\n",
      "Epoch: 1... Training loss: 0.00379... Test loss: 0.00399\n",
      "Epoch: 1... Training loss: 0.00372... Test loss: 0.0038\n",
      "Epoch: 1... Training loss: 0.00362... Test loss: 0.00421\n",
      "Epoch: 1... Training loss: 0.00349... Test loss: 0.00408\n",
      "Epoch: 1... Training loss: 0.00342... Test loss: 0.00376\n",
      "Epoch: 1... Training loss: 0.0035... Test loss: 0.00416\n",
      "Epoch: 1... Training loss: 0.00342... Test loss: 0.00424\n",
      "Epoch: 1... Training loss: 0.00327... Test loss: 0.00373\n",
      "Epoch: 1... Training loss: 0.00319... Test loss: 0.0038\n",
      "Epoch: 1... Training loss: 0.0031... Test loss: 0.0033\n",
      "Epoch: 1... Training loss: 0.00295... Test loss: 0.00297\n",
      "Epoch: 1... Training loss: 0.00295... Test loss: 0.00324\n",
      "Epoch: 1... Training loss: 0.00283... Test loss: 0.00351\n",
      "Epoch: 1... Training loss: 0.00292... Test loss: 0.0029\n",
      "Epoch: 1... Training loss: 0.0028... Test loss: 0.003\n",
      "Epoch: 1... Training loss: 0.00277... Test loss: 0.00289\n",
      "Epoch: 1... Training loss: 0.00272... Test loss: 0.00283\n",
      "Epoch: 1... Training loss: 0.00263... Test loss: 0.00258\n",
      "Epoch: 1... Training loss: 0.00264... Test loss: 0.00276\n",
      "Epoch: 1... Training loss: 0.00265... Test loss: 0.00258\n",
      "Epoch: 1... Training loss: 0.00269... Test loss: 0.00249\n",
      "Epoch: 1... Training loss: 0.00259... Test loss: 0.00243\n",
      "Epoch: 1... Training loss: 0.00245... Test loss: 0.00236\n",
      "Epoch: 1... Training loss: 0.0025... Test loss: 0.0025\n",
      "Epoch: 1... Training loss: 0.00235... Test loss: 0.00197\n",
      "Epoch: 1... Training loss: 0.00237... Test loss: 0.00271\n",
      "Epoch: 1... Training loss: 0.00223... Test loss: 0.00249\n",
      "Epoch: 1... Training loss: 0.00227... Test loss: 0.00256\n",
      "Epoch: 1... Training loss: 0.00229... Test loss: 0.00281\n",
      "Epoch: 1... Training loss: 0.00216... Test loss: 0.0026\n",
      "Epoch: 1... Training loss: 0.00219... Test loss: 0.00237\n",
      "Epoch: 1... Training loss: 0.0021... Test loss: 0.00253\n",
      "Epoch: 1... Training loss: 0.00203... Test loss: 0.00237\n",
      "Epoch: 1... Training loss: 0.00203... Test loss: 0.00211\n",
      "Epoch: 1... Training loss: 0.00195... Test loss: 0.00229\n",
      "Epoch: 1... Training loss: 0.002... Test loss: 0.00199\n",
      "Epoch: 1... Training loss: 0.0019... Test loss: 0.00215\n",
      "Epoch: 1... Training loss: 0.0019... Test loss: 0.00164\n",
      "Epoch: 1... Training loss: 0.0019... Test loss: 0.00209\n",
      "Epoch: 1... Training loss: 0.00186... Test loss: 0.00163\n",
      "Epoch: 1... Training loss: 0.0017... Test loss: 0.00191\n",
      "Epoch: 1... Training loss: 0.00163... Test loss: 0.00166\n",
      "Epoch: 1... Training loss: 0.00165... Test loss: 0.00191\n",
      "Epoch: 1... Training loss: 0.00166... Test loss: 0.00172\n",
      "Epoch: 1... Training loss: 0.0016... Test loss: 0.00161\n",
      "Epoch: 1... Training loss: 0.00145... Test loss: 0.00175\n",
      "Epoch: 1... Training loss: 0.00145... Test loss: 0.00137\n",
      "Epoch: 1... Training loss: 0.0014... Test loss: 0.00155\n",
      "Epoch: 1... Training loss: 0.0014... Test loss: 0.00118\n",
      "Epoch: 1... Training loss: 0.00138... Test loss: 0.00158\n",
      "Epoch: 1... Training loss: 0.00143... Test loss: 0.00138\n",
      "Epoch: 1... Training loss: 0.00134... Test loss: 0.00146\n",
      "Epoch: 1... Training loss: 0.00135... Test loss: 0.00131\n",
      "Epoch: 1... Training loss: 0.0013... Test loss: 0.00141\n",
      "Epoch: 1... Training loss: 0.00122... Test loss: 0.00136\n",
      "Epoch: 1... Training loss: 0.00113... Test loss: 0.00132\n",
      "Epoch: 1... Training loss: 0.00111... Test loss: 0.00106\n",
      "Epoch: 1... Training loss: 0.00108... Test loss: 0.00138\n",
      "Epoch: 1... Training loss: 0.00109... Test loss: 0.00107\n",
      "Epoch: 1... Training loss: 0.00097... Test loss: 0.00137\n",
      "Epoch: 1... Training loss: 0.00107... Test loss: 0.00108\n",
      "Epoch: 1... Training loss: 0.00103... Test loss: 0.00118\n",
      "Epoch: 1... Training loss: 0.00098... Test loss: 0.00093\n",
      "Epoch: 1... Training loss: 0.00102... Test loss: 0.00103\n",
      "Epoch: 1... Training loss: 0.00088... Test loss: 0.0009\n",
      "Epoch: 1... Training loss: 0.00084... Test loss: 0.00095\n",
      "Epoch: 1... Training loss: 0.00078... Test loss: 0.00089\n",
      "Epoch: 1... Training loss: 0.00078... Test loss: 0.00087\n",
      "Epoch: 1... Training loss: 0.00076... Test loss: 0.00082\n",
      "Epoch: 1... Training loss: 0.0007... Test loss: 0.00078\n",
      "Epoch: 1... Training loss: 0.00069... Test loss: 0.00074\n",
      "Epoch: 1... Training loss: 0.00066... Test loss: 0.00079\n",
      "Epoch: 1... Training loss: 0.00065... Test loss: 0.00067\n",
      "Epoch: 1... Training loss: 0.00063... Test loss: 0.0008\n",
      "Epoch: 1... Training loss: 0.00058... Test loss: 0.00069\n",
      "Epoch: 1... Training loss: 0.0006... Test loss: 0.00064\n",
      "Epoch: 1... Training loss: 0.00055... Test loss: 0.00066\n",
      "Epoch: 1... Training loss: 0.00053... Test loss: 0.00057\n",
      "Epoch: 1... Training loss: 0.00047... Test loss: 0.00063\n",
      "Epoch: 1... Training loss: 0.00046... Test loss: 0.00049\n",
      "Epoch: 1... Training loss: 0.00044... Test loss: 0.00052\n",
      "Epoch: 1... Training loss: 0.00045... Test loss: 0.00049\n",
      "Epoch: 1... Training loss: 0.00042... Test loss: 0.00048\n",
      "Epoch: 1... Training loss: 0.00039... Test loss: 0.0004\n",
      "Epoch: 1... Training loss: 0.00036... Test loss: 0.00045\n",
      "Epoch: 1... Training loss: 0.00038... Test loss: 0.00041\n",
      "Epoch: 1... Training loss: 0.00037... Test loss: 0.00036\n",
      "Epoch: 1... Training loss: 0.00031... Test loss: 0.00034\n",
      "Epoch: 1... Training loss: 0.00029... Test loss: 0.0003\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00026... Test loss: 0.00031\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00028\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.0002\n",
      "307.1372244055383\n",
      "Epoch: 1... Training loss: 1.12725... Test loss: 0.4381\n",
      "Epoch: 1... Training loss: 0.50083... Test loss: 0.13517\n",
      "Epoch: 1... Training loss: 0.33033... Test loss: 0.08418\n",
      "Epoch: 1... Training loss: 0.19354... Test loss: 0.05093\n",
      "Epoch: 1... Training loss: 0.13623... Test loss: 0.03362\n",
      "Epoch: 1... Training loss: 0.10561... Test loss: 0.02419\n",
      "Epoch: 1... Training loss: 0.08597... Test loss: 0.02201\n",
      "Epoch: 1... Training loss: 0.07894... Test loss: 0.0186\n",
      "Epoch: 1... Training loss: 0.06914... Test loss: 0.01724\n",
      "Epoch: 1... Training loss: 0.05755... Test loss: 0.0136\n",
      "Epoch: 1... Training loss: 0.04968... Test loss: 0.01087\n",
      "Epoch: 1... Training loss: 0.04726... Test loss: 0.00912\n",
      "Epoch: 1... Training loss: 0.04163... Test loss: 0.01468\n",
      "Epoch: 1... Training loss: 0.03851... Test loss: 0.01861\n",
      "Epoch: 1... Training loss: 0.03545... Test loss: 0.00786\n",
      "Epoch: 1... Training loss: 0.03374... Test loss: 0.01555\n",
      "Epoch: 1... Training loss: 0.03047... Test loss: 0.00833\n",
      "Epoch: 1... Training loss: 0.02894... Test loss: 0.0183\n",
      "Epoch: 1... Training loss: 0.02697... Test loss: 0.01509\n",
      "Epoch: 1... Training loss: 0.02474... Test loss: 0.02916\n",
      "Epoch: 1... Training loss: 0.02376... Test loss: 0.00953\n",
      "Epoch: 1... Training loss: 0.02236... Test loss: 0.02657\n",
      "Epoch: 1... Training loss: 0.02078... Test loss: 0.01087\n",
      "Epoch: 1... Training loss: 0.02002... Test loss: 0.02679\n",
      "Epoch: 1... Training loss: 0.01853... Test loss: 0.01157\n",
      "Epoch: 1... Training loss: 0.01821... Test loss: 0.00898\n",
      "Epoch: 1... Training loss: 0.01721... Test loss: 0.02719\n",
      "Epoch: 1... Training loss: 0.01662... Test loss: 0.00818\n",
      "Epoch: 1... Training loss: 0.01586... Test loss: 0.02252\n",
      "Epoch: 1... Training loss: 0.01542... Test loss: 0.0139\n",
      "Epoch: 1... Training loss: 0.0149... Test loss: 0.01542\n",
      "Epoch: 1... Training loss: 0.01427... Test loss: 0.01404\n",
      "Epoch: 1... Training loss: 0.01402... Test loss: 0.01466\n",
      "Epoch: 1... Training loss: 0.01345... Test loss: 0.00858\n",
      "Epoch: 1... Training loss: 0.01325... Test loss: 0.01659\n",
      "Epoch: 1... Training loss: 0.01253... Test loss: 0.00747\n",
      "Epoch: 1... Training loss: 0.01226... Test loss: 0.0146\n",
      "Epoch: 1... Training loss: 0.01176... Test loss: 0.01285\n",
      "Epoch: 1... Training loss: 0.01142... Test loss: 0.00704\n",
      "Epoch: 1... Training loss: 0.01113... Test loss: 0.01731\n",
      "Epoch: 1... Training loss: 0.01068... Test loss: 0.00652\n",
      "Epoch: 1... Training loss: 0.01039... Test loss: 0.01535\n",
      "Epoch: 1... Training loss: 0.01018... Test loss: 0.00688\n",
      "Epoch: 1... Training loss: 0.0098... Test loss: 0.0146\n",
      "Epoch: 1... Training loss: 0.00956... Test loss: 0.0085\n",
      "Epoch: 1... Training loss: 0.00921... Test loss: 0.00889\n",
      "Epoch: 1... Training loss: 0.00888... Test loss: 0.01099\n",
      "Epoch: 1... Training loss: 0.00857... Test loss: 0.00657\n",
      "Epoch: 1... Training loss: 0.00832... Test loss: 0.01029\n",
      "Epoch: 1... Training loss: 0.00802... Test loss: 0.00616\n",
      "Epoch: 1... Training loss: 0.00783... Test loss: 0.00955\n",
      "Epoch: 1... Training loss: 0.00765... Test loss: 0.00611\n",
      "Epoch: 1... Training loss: 0.00728... Test loss: 0.00938\n",
      "Epoch: 1... Training loss: 0.00715... Test loss: 0.00537\n",
      "Epoch: 1... Training loss: 0.00687... Test loss: 0.00916\n",
      "Epoch: 1... Training loss: 0.00673... Test loss: 0.00452\n",
      "Epoch: 1... Training loss: 0.00662... Test loss: 0.00798\n",
      "Epoch: 1... Training loss: 0.00648... Test loss: 0.005\n",
      "Epoch: 1... Training loss: 0.00637... Test loss: 0.0065\n",
      "Epoch: 1... Training loss: 0.00621... Test loss: 0.00592\n",
      "Epoch: 1... Training loss: 0.00615... Test loss: 0.00571\n",
      "Epoch: 1... Training loss: 0.00603... Test loss: 0.0066\n",
      "Epoch: 1... Training loss: 0.00592... Test loss: 0.00515\n",
      "Epoch: 1... Training loss: 0.00577... Test loss: 0.00679\n",
      "Epoch: 1... Training loss: 0.01309... Test loss: 0.01095\n",
      "Epoch: 1... Training loss: 0.01102... Test loss: 0.01255\n",
      "Epoch: 1... Training loss: 0.00979... Test loss: 0.01106\n",
      "Epoch: 1... Training loss: 0.01129... Test loss: 0.01226\n",
      "Epoch: 1... Training loss: 0.00876... Test loss: 0.00911\n",
      "Epoch: 1... Training loss: 0.0108... Test loss: 0.01024\n",
      "Epoch: 1... Training loss: 0.00983... Test loss: 0.00901\n",
      "Epoch: 1... Training loss: 0.00977... Test loss: 0.00912\n",
      "Epoch: 1... Training loss: 0.00958... Test loss: 0.0125\n",
      "Epoch: 1... Training loss: 0.00912... Test loss: 0.0098\n",
      "Epoch: 1... Training loss: 0.00827... Test loss: 0.0109\n",
      "Epoch: 1... Training loss: 0.00852... Test loss: 0.00953\n",
      "Epoch: 1... Training loss: 0.00833... Test loss: 0.01083\n",
      "Epoch: 1... Training loss: 0.00775... Test loss: 0.00962\n",
      "Epoch: 1... Training loss: 0.00733... Test loss: 0.00888\n",
      "Epoch: 1... Training loss: 0.00687... Test loss: 0.00824\n",
      "Epoch: 1... Training loss: 0.00716... Test loss: 0.00738\n",
      "Epoch: 1... Training loss: 0.00654... Test loss: 0.00685\n",
      "Epoch: 1... Training loss: 0.00673... Test loss: 0.00658\n",
      "Epoch: 1... Training loss: 0.00676... Test loss: 0.00694\n",
      "Epoch: 1... Training loss: 0.0064... Test loss: 0.00621\n",
      "Epoch: 1... Training loss: 0.00617... Test loss: 0.00702\n",
      "Epoch: 1... Training loss: 0.00577... Test loss: 0.00634\n",
      "Epoch: 1... Training loss: 0.00572... Test loss: 0.00659\n",
      "Epoch: 1... Training loss: 0.00585... Test loss: 0.00602\n",
      "Epoch: 1... Training loss: 0.00541... Test loss: 0.00632\n",
      "Epoch: 1... Training loss: 0.00546... Test loss: 0.00583\n",
      "Epoch: 1... Training loss: 0.00497... Test loss: 0.00649\n",
      "Epoch: 1... Training loss: 0.00472... Test loss: 0.00583\n",
      "Epoch: 1... Training loss: 0.00493... Test loss: 0.00611\n",
      "Epoch: 1... Training loss: 0.0046... Test loss: 0.00503\n",
      "Epoch: 1... Training loss: 0.00438... Test loss: 0.00555\n",
      "Epoch: 1... Training loss: 0.0043... Test loss: 0.00414\n",
      "Epoch: 1... Training loss: 0.00405... Test loss: 0.00481\n",
      "Epoch: 1... Training loss: 0.00411... Test loss: 0.00384\n",
      "Epoch: 1... Training loss: 0.00396... Test loss: 0.00505\n",
      "Epoch: 1... Training loss: 0.0038... Test loss: 0.00382\n",
      "Epoch: 1... Training loss: 0.00383... Test loss: 0.0049\n",
      "Epoch: 1... Training loss: 0.00395... Test loss: 0.00381\n",
      "Epoch: 1... Training loss: 0.00365... Test loss: 0.00417\n",
      "Epoch: 1... Training loss: 0.00346... Test loss: 0.00376\n",
      "Epoch: 1... Training loss: 0.00356... Test loss: 0.00422\n",
      "Epoch: 1... Training loss: 0.00337... Test loss: 0.00371\n",
      "Epoch: 1... Training loss: 0.00329... Test loss: 0.00398\n",
      "Epoch: 1... Training loss: 0.00328... Test loss: 0.00327\n",
      "Epoch: 1... Training loss: 0.00326... Test loss: 0.00354\n",
      "Epoch: 1... Training loss: 0.00327... Test loss: 0.00323\n",
      "Epoch: 1... Training loss: 0.0032... Test loss: 0.00323\n",
      "Epoch: 1... Training loss: 0.00306... Test loss: 0.00334\n",
      "Epoch: 1... Training loss: 0.00311... Test loss: 0.00318\n",
      "Epoch: 1... Training loss: 0.00292... Test loss: 0.00308\n",
      "Epoch: 1... Training loss: 0.00295... Test loss: 0.00315\n",
      "Epoch: 1... Training loss: 0.00291... Test loss: 0.00304\n",
      "Epoch: 1... Training loss: 0.00278... Test loss: 0.0029\n",
      "Epoch: 1... Training loss: 0.00276... Test loss: 0.00274\n",
      "Epoch: 1... Training loss: 0.0027... Test loss: 0.00323\n",
      "Epoch: 1... Training loss: 0.00271... Test loss: 0.00249\n",
      "Epoch: 1... Training loss: 0.00262... Test loss: 0.00322\n",
      "Epoch: 1... Training loss: 0.00257... Test loss: 0.00274\n",
      "Epoch: 1... Training loss: 0.00263... Test loss: 0.00254\n",
      "Epoch: 1... Training loss: 0.00258... Test loss: 0.00267\n",
      "Epoch: 1... Training loss: 0.00254... Test loss: 0.00261\n",
      "Epoch: 1... Training loss: 0.00245... Test loss: 0.00253\n",
      "Epoch: 1... Training loss: 0.00239... Test loss: 0.00239\n",
      "Epoch: 1... Training loss: 0.00229... Test loss: 0.00274\n",
      "Epoch: 1... Training loss: 0.00222... Test loss: 0.00214\n",
      "Epoch: 1... Training loss: 0.00219... Test loss: 0.00265\n",
      "Epoch: 1... Training loss: 0.00212... Test loss: 0.00197\n",
      "Epoch: 1... Training loss: 0.00205... Test loss: 0.00232\n",
      "Epoch: 1... Training loss: 0.00196... Test loss: 0.00183\n",
      "Epoch: 1... Training loss: 0.00205... Test loss: 0.00238\n",
      "Epoch: 1... Training loss: 0.00204... Test loss: 0.00183\n",
      "Epoch: 1... Training loss: 0.00184... Test loss: 0.00199\n",
      "Epoch: 1... Training loss: 0.00186... Test loss: 0.00175\n",
      "Epoch: 1... Training loss: 0.00179... Test loss: 0.00194\n",
      "Epoch: 1... Training loss: 0.00178... Test loss: 0.00175\n",
      "Epoch: 1... Training loss: 0.00173... Test loss: 0.00174\n",
      "Epoch: 1... Training loss: 0.00163... Test loss: 0.00146\n",
      "Epoch: 1... Training loss: 0.00171... Test loss: 0.00174\n",
      "Epoch: 1... Training loss: 0.00158... Test loss: 0.00155\n",
      "Epoch: 1... Training loss: 0.00158... Test loss: 0.00187\n",
      "Epoch: 1... Training loss: 0.00162... Test loss: 0.00143\n",
      "Epoch: 1... Training loss: 0.00147... Test loss: 0.00163\n",
      "Epoch: 1... Training loss: 0.00151... Test loss: 0.0014\n",
      "Epoch: 1... Training loss: 0.00147... Test loss: 0.00169\n",
      "Epoch: 1... Training loss: 0.00143... Test loss: 0.00133\n",
      "Epoch: 1... Training loss: 0.00137... Test loss: 0.0013\n",
      "Epoch: 1... Training loss: 0.0013... Test loss: 0.00135\n",
      "Epoch: 1... Training loss: 0.00128... Test loss: 0.00122\n",
      "Epoch: 1... Training loss: 0.00126... Test loss: 0.00134\n",
      "Epoch: 1... Training loss: 0.00125... Test loss: 0.00126\n",
      "Epoch: 1... Training loss: 0.00119... Test loss: 0.00126\n",
      "Epoch: 1... Training loss: 0.00123... Test loss: 0.00137\n",
      "Epoch: 1... Training loss: 0.00114... Test loss: 0.00111\n",
      "Epoch: 1... Training loss: 0.00102... Test loss: 0.0012\n",
      "Epoch: 1... Training loss: 0.00097... Test loss: 0.00097\n",
      "Epoch: 1... Training loss: 0.00096... Test loss: 0.00108\n",
      "Epoch: 1... Training loss: 0.00094... Test loss: 0.00091\n",
      "Epoch: 1... Training loss: 0.00091... Test loss: 0.00095\n",
      "Epoch: 1... Training loss: 0.00082... Test loss: 0.00094\n",
      "Epoch: 1... Training loss: 0.0008... Test loss: 0.00094\n",
      "Epoch: 1... Training loss: 0.00079... Test loss: 0.00084\n",
      "Epoch: 1... Training loss: 0.00076... Test loss: 0.00084\n",
      "Epoch: 1... Training loss: 0.00077... Test loss: 0.00069\n",
      "Epoch: 1... Training loss: 0.00071... Test loss: 0.00076\n",
      "Epoch: 1... Training loss: 0.00068... Test loss: 0.00081\n",
      "Epoch: 1... Training loss: 0.00066... Test loss: 0.00069\n",
      "Epoch: 1... Training loss: 0.00064... Test loss: 0.00073\n",
      "Epoch: 1... Training loss: 0.00062... Test loss: 0.00064\n",
      "Epoch: 1... Training loss: 0.00058... Test loss: 0.00066\n",
      "Epoch: 1... Training loss: 0.00055... Test loss: 0.00069\n",
      "Epoch: 1... Training loss: 0.00057... Test loss: 0.00062\n",
      "Epoch: 1... Training loss: 0.00052... Test loss: 0.00055\n",
      "Epoch: 1... Training loss: 0.0005... Test loss: 0.00065\n",
      "Epoch: 1... Training loss: 0.00047... Test loss: 0.00046\n",
      "Epoch: 1... Training loss: 0.00046... Test loss: 0.00058\n",
      "Epoch: 1... Training loss: 0.00044... Test loss: 0.00037\n",
      "Epoch: 1... Training loss: 0.00045... Test loss: 0.0005\n",
      "Epoch: 1... Training loss: 0.00041... Test loss: 0.00037\n",
      "Epoch: 1... Training loss: 0.00038... Test loss: 0.00042\n",
      "Epoch: 1... Training loss: 0.00038... Test loss: 0.00032\n",
      "Epoch: 1... Training loss: 0.00036... Test loss: 0.00037\n",
      "Epoch: 1... Training loss: 0.00035... Test loss: 0.00035\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00038\n",
      "Epoch: 1... Training loss: 0.00029... Test loss: 0.00038\n",
      "Epoch: 1... Training loss: 0.00037... Test loss: 0.00031\n",
      "Epoch: 1... Training loss: 0.00035... Test loss: 0.00032\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00028\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00031\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00024\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00028\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00024\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.00036\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00033\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00031\n",
      "354.650513642584\n",
      "Epoch: 1... Training loss: 0.98605... Test loss: 0.36333\n",
      "Epoch: 1... Training loss: 0.45381... Test loss: 0.12535\n",
      "Epoch: 1... Training loss: 0.33047... Test loss: 0.09099\n",
      "Epoch: 1... Training loss: 0.20128... Test loss: 0.07515\n",
      "Epoch: 1... Training loss: 0.15721... Test loss: 0.04778\n",
      "Epoch: 1... Training loss: 0.13753... Test loss: 0.04692\n",
      "Epoch: 1... Training loss: 0.10565... Test loss: 0.05861\n",
      "Epoch: 1... Training loss: 0.08532... Test loss: 0.03904\n",
      "Epoch: 1... Training loss: 0.07659... Test loss: 0.04194\n",
      "Epoch: 1... Training loss: 0.06426... Test loss: 0.06511\n",
      "Epoch: 1... Training loss: 0.05862... Test loss: 0.02562\n",
      "Epoch: 1... Training loss: 0.05442... Test loss: 0.0384\n",
      "Epoch: 1... Training loss: 0.0487... Test loss: 0.01843\n",
      "Epoch: 1... Training loss: 0.04325... Test loss: 0.03211\n",
      "Epoch: 1... Training loss: 0.04103... Test loss: 0.02468\n",
      "Epoch: 1... Training loss: 0.03708... Test loss: 0.0299\n",
      "Epoch: 1... Training loss: 0.03547... Test loss: 0.03359\n",
      "Epoch: 1... Training loss: 0.03208... Test loss: 0.01849\n",
      "Epoch: 1... Training loss: 0.02967... Test loss: 0.03232\n",
      "Epoch: 1... Training loss: 0.02826... Test loss: 0.01489\n",
      "Epoch: 1... Training loss: 0.02604... Test loss: 0.02763\n",
      "Epoch: 1... Training loss: 0.02465... Test loss: 0.01536\n",
      "Epoch: 1... Training loss: 0.02355... Test loss: 0.01871\n",
      "Epoch: 1... Training loss: 0.0222... Test loss: 0.02778\n",
      "Epoch: 1... Training loss: 0.02051... Test loss: 0.01406\n",
      "Epoch: 1... Training loss: 0.01951... Test loss: 0.0239\n",
      "Epoch: 1... Training loss: 0.01928... Test loss: 0.01274\n",
      "Epoch: 1... Training loss: 0.01823... Test loss: 0.0204\n",
      "Epoch: 1... Training loss: 0.01783... Test loss: 0.0152\n",
      "Epoch: 1... Training loss: 0.01673... Test loss: 0.01716\n",
      "Epoch: 1... Training loss: 0.016... Test loss: 0.0149\n",
      "Epoch: 1... Training loss: 0.01527... Test loss: 0.01028\n",
      "Epoch: 1... Training loss: 0.01506... Test loss: 0.01604\n",
      "Epoch: 1... Training loss: 0.01404... Test loss: 0.00876\n",
      "Epoch: 1... Training loss: 0.01382... Test loss: 0.01551\n",
      "Epoch: 1... Training loss: 0.01295... Test loss: 0.00851\n",
      "Epoch: 1... Training loss: 0.01255... Test loss: 0.01447\n",
      "Epoch: 1... Training loss: 0.0121... Test loss: 0.00869\n",
      "Epoch: 1... Training loss: 0.01174... Test loss: 0.01348\n",
      "Epoch: 1... Training loss: 0.0113... Test loss: 0.01052\n",
      "Epoch: 1... Training loss: 0.01108... Test loss: 0.01392\n",
      "Epoch: 1... Training loss: 0.01065... Test loss: 0.00892\n",
      "Epoch: 1... Training loss: 0.01041... Test loss: 0.0138\n",
      "Epoch: 1... Training loss: 0.01021... Test loss: 0.00924\n",
      "Epoch: 1... Training loss: 0.00976... Test loss: 0.01291\n",
      "Epoch: 1... Training loss: 0.00957... Test loss: 0.00815\n",
      "Epoch: 1... Training loss: 0.00923... Test loss: 0.01214\n",
      "Epoch: 1... Training loss: 0.00896... Test loss: 0.00655\n",
      "Epoch: 1... Training loss: 0.00881... Test loss: 0.0102\n",
      "Epoch: 1... Training loss: 0.00847... Test loss: 0.00664\n",
      "Epoch: 1... Training loss: 0.00831... Test loss: 0.00951\n",
      "Epoch: 1... Training loss: 0.00798... Test loss: 0.00676\n",
      "Epoch: 1... Training loss: 0.00779... Test loss: 0.00867\n",
      "Epoch: 1... Training loss: 0.00756... Test loss: 0.00586\n",
      "Epoch: 1... Training loss: 0.00746... Test loss: 0.0073\n",
      "Epoch: 1... Training loss: 0.00732... Test loss: 0.00651\n",
      "Epoch: 1... Training loss: 0.00705... Test loss: 0.00768\n",
      "Epoch: 1... Training loss: 0.0069... Test loss: 0.00555\n",
      "Epoch: 1... Training loss: 0.00675... Test loss: 0.0079\n",
      "Epoch: 1... Training loss: 0.00664... Test loss: 0.00548\n",
      "Epoch: 1... Training loss: 0.00651... Test loss: 0.00701\n",
      "Epoch: 1... Training loss: 0.00638... Test loss: 0.00584\n",
      "Epoch: 1... Training loss: 0.00623... Test loss: 0.00597\n",
      "Epoch: 1... Training loss: 0.0061... Test loss: 0.00563\n",
      "Epoch: 1... Training loss: 0.01407... Test loss: 0.01313\n",
      "Epoch: 1... Training loss: 0.01058... Test loss: 0.01146\n",
      "Epoch: 1... Training loss: 0.01253... Test loss: 0.01024\n",
      "Epoch: 1... Training loss: 0.0125... Test loss: 0.01193\n",
      "Epoch: 1... Training loss: 0.00983... Test loss: 0.00889\n",
      "Epoch: 1... Training loss: 0.01055... Test loss: 0.01276\n",
      "Epoch: 1... Training loss: 0.01005... Test loss: 0.00809\n",
      "Epoch: 1... Training loss: 0.01115... Test loss: 0.01395\n",
      "Epoch: 1... Training loss: 0.00986... Test loss: 0.0126\n",
      "Epoch: 1... Training loss: 0.00954... Test loss: 0.01188\n",
      "Epoch: 1... Training loss: 0.00852... Test loss: 0.01129\n",
      "Epoch: 1... Training loss: 0.00903... Test loss: 0.01215\n",
      "Epoch: 1... Training loss: 0.00919... Test loss: 0.01213\n",
      "Epoch: 1... Training loss: 0.00752... Test loss: 0.01001\n",
      "Epoch: 1... Training loss: 0.00744... Test loss: 0.01197\n",
      "Epoch: 1... Training loss: 0.00741... Test loss: 0.009\n",
      "Epoch: 1... Training loss: 0.00732... Test loss: 0.00804\n",
      "Epoch: 1... Training loss: 0.00695... Test loss: 0.00843\n",
      "Epoch: 1... Training loss: 0.00682... Test loss: 0.00855\n",
      "Epoch: 1... Training loss: 0.00651... Test loss: 0.00782\n",
      "Epoch: 1... Training loss: 0.00657... Test loss: 0.00639\n",
      "Epoch: 1... Training loss: 0.00615... Test loss: 0.00919\n",
      "Epoch: 1... Training loss: 0.00601... Test loss: 0.00622\n",
      "Epoch: 1... Training loss: 0.00607... Test loss: 0.00768\n",
      "Epoch: 1... Training loss: 0.00583... Test loss: 0.00636\n",
      "Epoch: 1... Training loss: 0.0058... Test loss: 0.00694\n",
      "Epoch: 1... Training loss: 0.00576... Test loss: 0.00602\n",
      "Epoch: 1... Training loss: 0.00519... Test loss: 0.00612\n",
      "Epoch: 1... Training loss: 0.00516... Test loss: 0.00532\n",
      "Epoch: 1... Training loss: 0.00518... Test loss: 0.00627\n",
      "Epoch: 1... Training loss: 0.00505... Test loss: 0.00509\n",
      "Epoch: 1... Training loss: 0.00498... Test loss: 0.00579\n",
      "Epoch: 1... Training loss: 0.00476... Test loss: 0.00544\n",
      "Epoch: 1... Training loss: 0.0045... Test loss: 0.00535\n",
      "Epoch: 1... Training loss: 0.00443... Test loss: 0.00539\n",
      "Epoch: 1... Training loss: 0.0042... Test loss: 0.00523\n",
      "Epoch: 1... Training loss: 0.00424... Test loss: 0.00442\n",
      "Epoch: 1... Training loss: 0.00414... Test loss: 0.00501\n",
      "Epoch: 1... Training loss: 0.00405... Test loss: 0.00438\n",
      "Epoch: 1... Training loss: 0.00394... Test loss: 0.00497\n",
      "Epoch: 1... Training loss: 0.00382... Test loss: 0.00421\n",
      "Epoch: 1... Training loss: 0.00389... Test loss: 0.0043\n",
      "Epoch: 1... Training loss: 0.00373... Test loss: 0.00384\n",
      "Epoch: 1... Training loss: 0.00378... Test loss: 0.00436\n",
      "Epoch: 1... Training loss: 0.00347... Test loss: 0.00407\n",
      "Epoch: 1... Training loss: 0.00355... Test loss: 0.00401\n",
      "Epoch: 1... Training loss: 0.00355... Test loss: 0.00394\n",
      "Epoch: 1... Training loss: 0.0034... Test loss: 0.00376\n",
      "Epoch: 1... Training loss: 0.00323... Test loss: 0.00371\n",
      "Epoch: 1... Training loss: 0.00325... Test loss: 0.00369\n",
      "Epoch: 1... Training loss: 0.00318... Test loss: 0.00349\n",
      "Epoch: 1... Training loss: 0.00324... Test loss: 0.00336\n",
      "Epoch: 1... Training loss: 0.00306... Test loss: 0.00343\n",
      "Epoch: 1... Training loss: 0.00297... Test loss: 0.00344\n",
      "Epoch: 1... Training loss: 0.00292... Test loss: 0.0031\n",
      "Epoch: 1... Training loss: 0.00291... Test loss: 0.00329\n",
      "Epoch: 1... Training loss: 0.00283... Test loss: 0.00308\n",
      "Epoch: 1... Training loss: 0.00272... Test loss: 0.00291\n",
      "Epoch: 1... Training loss: 0.00271... Test loss: 0.00286\n",
      "Epoch: 1... Training loss: 0.00269... Test loss: 0.0027\n",
      "Epoch: 1... Training loss: 0.00259... Test loss: 0.00242\n",
      "Epoch: 1... Training loss: 0.00265... Test loss: 0.00286\n",
      "Epoch: 1... Training loss: 0.00254... Test loss: 0.00273\n",
      "Epoch: 1... Training loss: 0.00245... Test loss: 0.00268\n",
      "Epoch: 1... Training loss: 0.0024... Test loss: 0.00256\n",
      "Epoch: 1... Training loss: 0.00249... Test loss: 0.00285\n",
      "Epoch: 1... Training loss: 0.00233... Test loss: 0.00237\n",
      "Epoch: 1... Training loss: 0.0023... Test loss: 0.00231\n",
      "Epoch: 1... Training loss: 0.00223... Test loss: 0.00213\n",
      "Epoch: 1... Training loss: 0.00218... Test loss: 0.00236\n",
      "Epoch: 1... Training loss: 0.00223... Test loss: 0.00245\n",
      "Epoch: 1... Training loss: 0.00203... Test loss: 0.00221\n",
      "Epoch: 1... Training loss: 0.00202... Test loss: 0.00231\n",
      "Epoch: 1... Training loss: 0.00203... Test loss: 0.00214\n",
      "Epoch: 1... Training loss: 0.0019... Test loss: 0.00227\n",
      "Epoch: 1... Training loss: 0.00199... Test loss: 0.00173\n",
      "Epoch: 1... Training loss: 0.00185... Test loss: 0.00212\n",
      "Epoch: 1... Training loss: 0.00181... Test loss: 0.00181\n",
      "Epoch: 1... Training loss: 0.00182... Test loss: 0.00201\n",
      "Epoch: 1... Training loss: 0.00174... Test loss: 0.00178\n",
      "Epoch: 1... Training loss: 0.00164... Test loss: 0.00178\n",
      "Epoch: 1... Training loss: 0.00162... Test loss: 0.00166\n",
      "Epoch: 1... Training loss: 0.00156... Test loss: 0.0017\n",
      "Epoch: 1... Training loss: 0.00157... Test loss: 0.00151\n",
      "Epoch: 1... Training loss: 0.00157... Test loss: 0.0015\n",
      "Epoch: 1... Training loss: 0.00139... Test loss: 0.00143\n",
      "Epoch: 1... Training loss: 0.00141... Test loss: 0.00142\n",
      "Epoch: 1... Training loss: 0.00135... Test loss: 0.00148\n",
      "Epoch: 1... Training loss: 0.0013... Test loss: 0.00124\n",
      "Epoch: 1... Training loss: 0.00129... Test loss: 0.00154\n",
      "Epoch: 1... Training loss: 0.00118... Test loss: 0.00126\n",
      "Epoch: 1... Training loss: 0.00123... Test loss: 0.00138\n",
      "Epoch: 1... Training loss: 0.00118... Test loss: 0.00137\n",
      "Epoch: 1... Training loss: 0.00114... Test loss: 0.0012\n",
      "Epoch: 1... Training loss: 0.00107... Test loss: 0.00118\n",
      "Epoch: 1... Training loss: 0.00102... Test loss: 0.00137\n",
      "Epoch: 1... Training loss: 0.00099... Test loss: 0.00102\n",
      "Epoch: 1... Training loss: 0.00097... Test loss: 0.00126\n",
      "Epoch: 1... Training loss: 0.001... Test loss: 0.00101\n",
      "Epoch: 1... Training loss: 0.00087... Test loss: 0.001\n",
      "Epoch: 1... Training loss: 0.00085... Test loss: 0.00094\n",
      "Epoch: 1... Training loss: 0.00086... Test loss: 0.00092\n",
      "Epoch: 1... Training loss: 0.00088... Test loss: 0.00085\n",
      "Epoch: 1... Training loss: 0.00085... Test loss: 0.00097\n",
      "Epoch: 1... Training loss: 0.00077... Test loss: 0.00086\n",
      "Epoch: 1... Training loss: 0.0008... Test loss: 0.00079\n",
      "Epoch: 1... Training loss: 0.00077... Test loss: 0.00075\n",
      "Epoch: 1... Training loss: 0.00075... Test loss: 0.00076\n",
      "Epoch: 1... Training loss: 0.00072... Test loss: 0.0006\n",
      "Epoch: 1... Training loss: 0.0007... Test loss: 0.00079\n",
      "Epoch: 1... Training loss: 0.00071... Test loss: 0.0007\n",
      "Epoch: 1... Training loss: 0.00068... Test loss: 0.00076\n",
      "Epoch: 1... Training loss: 0.00072... Test loss: 0.00063\n",
      "Epoch: 1... Training loss: 0.00063... Test loss: 0.00074\n",
      "Epoch: 1... Training loss: 0.0007... Test loss: 0.00059\n",
      "Epoch: 1... Training loss: 0.0006... Test loss: 0.00061\n",
      "Epoch: 1... Training loss: 0.00057... Test loss: 0.00054\n",
      "Epoch: 1... Training loss: 0.00056... Test loss: 0.00065\n",
      "Epoch: 1... Training loss: 0.00051... Test loss: 0.00057\n",
      "Epoch: 1... Training loss: 0.00049... Test loss: 0.0005\n",
      "Epoch: 1... Training loss: 0.00048... Test loss: 0.00056\n",
      "Epoch: 1... Training loss: 0.00044... Test loss: 0.00051\n",
      "Epoch: 1... Training loss: 0.00044... Test loss: 0.00049\n",
      "Epoch: 1... Training loss: 0.00044... Test loss: 0.00047\n",
      "Epoch: 1... Training loss: 0.00041... Test loss: 0.00048\n",
      "Epoch: 1... Training loss: 0.00036... Test loss: 0.00042\n",
      "Epoch: 1... Training loss: 0.00036... Test loss: 0.00044\n",
      "Epoch: 1... Training loss: 0.00034... Test loss: 0.00037\n",
      "Epoch: 1... Training loss: 0.00036... Test loss: 0.00041\n",
      "Epoch: 1... Training loss: 0.00031... Test loss: 0.00035\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00037\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.00035\n",
      "Epoch: 1... Training loss: 0.00029... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.00026... Test loss: 0.00038\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00023\n",
      "332.1266711152857\n",
      "Epoch: 1... Training loss: 1.1386... Test loss: 0.48807\n",
      "Epoch: 1... Training loss: 0.51074... Test loss: 0.18356\n",
      "Epoch: 1... Training loss: 0.28713... Test loss: 0.09417\n",
      "Epoch: 1... Training loss: 0.19234... Test loss: 0.06969\n",
      "Epoch: 1... Training loss: 0.14727... Test loss: 0.03928\n",
      "Epoch: 1... Training loss: 0.10721... Test loss: 0.03241\n",
      "Epoch: 1... Training loss: 0.07661... Test loss: 0.03007\n",
      "Epoch: 1... Training loss: 0.06589... Test loss: 0.02459\n",
      "Epoch: 1... Training loss: 0.05324... Test loss: 0.03401\n",
      "Epoch: 1... Training loss: 0.04948... Test loss: 0.01384\n",
      "Epoch: 1... Training loss: 0.04406... Test loss: 0.02769\n",
      "Epoch: 1... Training loss: 0.04373... Test loss: 0.01219\n",
      "Epoch: 1... Training loss: 0.03915... Test loss: 0.01106\n",
      "Epoch: 1... Training loss: 0.03922... Test loss: 0.01185\n",
      "Epoch: 1... Training loss: 0.03459... Test loss: 0.01541\n",
      "Epoch: 1... Training loss: 0.03368... Test loss: 0.00697\n",
      "Epoch: 1... Training loss: 0.02885... Test loss: 0.01893\n",
      "Epoch: 1... Training loss: 0.0291... Test loss: 0.00718\n",
      "Epoch: 1... Training loss: 0.02661... Test loss: 0.01311\n",
      "Epoch: 1... Training loss: 0.02519... Test loss: 0.00878\n",
      "Epoch: 1... Training loss: 0.02387... Test loss: 0.02054\n",
      "Epoch: 1... Training loss: 0.02291... Test loss: 0.00811\n",
      "Epoch: 1... Training loss: 0.02131... Test loss: 0.01767\n",
      "Epoch: 1... Training loss: 0.02034... Test loss: 0.00745\n",
      "Epoch: 1... Training loss: 0.01935... Test loss: 0.01715\n",
      "Epoch: 1... Training loss: 0.01886... Test loss: 0.00841\n",
      "Epoch: 1... Training loss: 0.01771... Test loss: 0.01609\n",
      "Epoch: 1... Training loss: 0.0173... Test loss: 0.00836\n",
      "Epoch: 1... Training loss: 0.01666... Test loss: 0.01598\n",
      "Epoch: 1... Training loss: 0.01591... Test loss: 0.00873\n",
      "Epoch: 1... Training loss: 0.01536... Test loss: 0.01458\n",
      "Epoch: 1... Training loss: 0.01477... Test loss: 0.00788\n",
      "Epoch: 1... Training loss: 0.01374... Test loss: 0.01287\n",
      "Epoch: 1... Training loss: 0.01295... Test loss: 0.00632\n",
      "Epoch: 1... Training loss: 0.01242... Test loss: 0.01169\n",
      "Epoch: 1... Training loss: 0.0122... Test loss: 0.00732\n",
      "Epoch: 1... Training loss: 0.01197... Test loss: 0.01191\n",
      "Epoch: 1... Training loss: 0.01141... Test loss: 0.00499\n",
      "Epoch: 1... Training loss: 0.01105... Test loss: 0.01113\n",
      "Epoch: 1... Training loss: 0.01065... Test loss: 0.00726\n",
      "Epoch: 1... Training loss: 0.01047... Test loss: 0.00914\n",
      "Epoch: 1... Training loss: 0.01003... Test loss: 0.0086\n",
      "Epoch: 1... Training loss: 0.00982... Test loss: 0.00941\n",
      "Epoch: 1... Training loss: 0.0097... Test loss: 0.00675\n",
      "Epoch: 1... Training loss: 0.00929... Test loss: 0.0108\n",
      "Epoch: 1... Training loss: 0.00917... Test loss: 0.00616\n",
      "Epoch: 1... Training loss: 0.00885... Test loss: 0.00967\n",
      "Epoch: 1... Training loss: 0.00878... Test loss: 0.00573\n",
      "Epoch: 1... Training loss: 0.00849... Test loss: 0.00845\n",
      "Epoch: 1... Training loss: 0.00824... Test loss: 0.00592\n",
      "Epoch: 1... Training loss: 0.00791... Test loss: 0.00792\n",
      "Epoch: 1... Training loss: 0.00784... Test loss: 0.00636\n",
      "Epoch: 1... Training loss: 0.00765... Test loss: 0.00611\n",
      "Epoch: 1... Training loss: 0.00744... Test loss: 0.00776\n",
      "Epoch: 1... Training loss: 0.0072... Test loss: 0.00749\n",
      "Epoch: 1... Training loss: 0.00712... Test loss: 0.0062\n",
      "Epoch: 1... Training loss: 0.00693... Test loss: 0.00735\n",
      "Epoch: 1... Training loss: 0.00684... Test loss: 0.00646\n",
      "Epoch: 1... Training loss: 0.00654... Test loss: 0.00708\n",
      "Epoch: 1... Training loss: 0.00633... Test loss: 0.00601\n",
      "Epoch: 1... Training loss: 0.00611... Test loss: 0.00681\n",
      "Epoch: 1... Training loss: 0.00593... Test loss: 0.00554\n",
      "Epoch: 1... Training loss: 0.00573... Test loss: 0.00579\n",
      "Epoch: 1... Training loss: 0.00558... Test loss: 0.00596\n",
      "Epoch: 1... Training loss: 0.01314... Test loss: 0.01305\n",
      "Epoch: 1... Training loss: 0.01073... Test loss: 0.016\n",
      "Epoch: 1... Training loss: 0.01088... Test loss: 0.01385\n",
      "Epoch: 1... Training loss: 0.01337... Test loss: 0.01276\n",
      "Epoch: 1... Training loss: 0.01046... Test loss: 0.01221\n",
      "Epoch: 1... Training loss: 0.00874... Test loss: 0.01\n",
      "Epoch: 1... Training loss: 0.00852... Test loss: 0.01024\n",
      "Epoch: 1... Training loss: 0.00929... Test loss: 0.01133\n",
      "Epoch: 1... Training loss: 0.0088... Test loss: 0.01356\n",
      "Epoch: 1... Training loss: 0.00848... Test loss: 0.01144\n",
      "Epoch: 1... Training loss: 0.00753... Test loss: 0.01228\n",
      "Epoch: 1... Training loss: 0.00787... Test loss: 0.00943\n",
      "Epoch: 1... Training loss: 0.00753... Test loss: 0.01045\n",
      "Epoch: 1... Training loss: 0.00719... Test loss: 0.00803\n",
      "Epoch: 1... Training loss: 0.00789... Test loss: 0.00989\n",
      "Epoch: 1... Training loss: 0.00698... Test loss: 0.00769\n",
      "Epoch: 1... Training loss: 0.00646... Test loss: 0.00787\n",
      "Epoch: 1... Training loss: 0.00633... Test loss: 0.00728\n",
      "Epoch: 1... Training loss: 0.00644... Test loss: 0.00873\n",
      "Epoch: 1... Training loss: 0.00577... Test loss: 0.00874\n",
      "Epoch: 1... Training loss: 0.00557... Test loss: 0.00727\n",
      "Epoch: 1... Training loss: 0.00569... Test loss: 0.00652\n",
      "Epoch: 1... Training loss: 0.0057... Test loss: 0.00702\n",
      "Epoch: 1... Training loss: 0.00502... Test loss: 0.00584\n",
      "Epoch: 1... Training loss: 0.00491... Test loss: 0.00602\n",
      "Epoch: 1... Training loss: 0.00512... Test loss: 0.00511\n",
      "Epoch: 1... Training loss: 0.00463... Test loss: 0.00674\n",
      "Epoch: 1... Training loss: 0.00458... Test loss: 0.00508\n",
      "Epoch: 1... Training loss: 0.00448... Test loss: 0.0056\n",
      "Epoch: 1... Training loss: 0.0043... Test loss: 0.00536\n",
      "Epoch: 1... Training loss: 0.00427... Test loss: 0.00403\n",
      "Epoch: 1... Training loss: 0.00413... Test loss: 0.00521\n",
      "Epoch: 1... Training loss: 0.00389... Test loss: 0.00403\n",
      "Epoch: 1... Training loss: 0.00378... Test loss: 0.00413\n",
      "Epoch: 1... Training loss: 0.0037... Test loss: 0.00405\n",
      "Epoch: 1... Training loss: 0.00383... Test loss: 0.00433\n",
      "Epoch: 1... Training loss: 0.00368... Test loss: 0.0041\n",
      "Epoch: 1... Training loss: 0.00355... Test loss: 0.00348\n",
      "Epoch: 1... Training loss: 0.00347... Test loss: 0.00368\n",
      "Epoch: 1... Training loss: 0.00334... Test loss: 0.00366\n",
      "Epoch: 1... Training loss: 0.00335... Test loss: 0.00334\n",
      "Epoch: 1... Training loss: 0.00333... Test loss: 0.00361\n",
      "Epoch: 1... Training loss: 0.00326... Test loss: 0.00362\n",
      "Epoch: 1... Training loss: 0.00323... Test loss: 0.00309\n",
      "Epoch: 1... Training loss: 0.00314... Test loss: 0.00379\n",
      "Epoch: 1... Training loss: 0.00311... Test loss: 0.00285\n",
      "Epoch: 1... Training loss: 0.00294... Test loss: 0.00408\n",
      "Epoch: 1... Training loss: 0.00295... Test loss: 0.00281\n",
      "Epoch: 1... Training loss: 0.0029... Test loss: 0.00349\n",
      "Epoch: 1... Training loss: 0.00296... Test loss: 0.00297\n",
      "Epoch: 1... Training loss: 0.0028... Test loss: 0.00343\n",
      "Epoch: 1... Training loss: 0.00286... Test loss: 0.00276\n",
      "Epoch: 1... Training loss: 0.00276... Test loss: 0.00289\n",
      "Epoch: 1... Training loss: 0.00259... Test loss: 0.00268\n",
      "Epoch: 1... Training loss: 0.00249... Test loss: 0.00278\n",
      "Epoch: 1... Training loss: 0.0025... Test loss: 0.00259\n",
      "Epoch: 1... Training loss: 0.00235... Test loss: 0.00254\n",
      "Epoch: 1... Training loss: 0.00243... Test loss: 0.00244\n",
      "Epoch: 1... Training loss: 0.00231... Test loss: 0.0028\n",
      "Epoch: 1... Training loss: 0.00231... Test loss: 0.00228\n",
      "Epoch: 1... Training loss: 0.00233... Test loss: 0.0024\n",
      "Epoch: 1... Training loss: 0.00219... Test loss: 0.00211\n",
      "Epoch: 1... Training loss: 0.0022... Test loss: 0.00201\n",
      "Epoch: 1... Training loss: 0.00216... Test loss: 0.00213\n",
      "Epoch: 1... Training loss: 0.002... Test loss: 0.00212\n",
      "Epoch: 1... Training loss: 0.00192... Test loss: 0.00214\n",
      "Epoch: 1... Training loss: 0.00192... Test loss: 0.0019\n",
      "Epoch: 1... Training loss: 0.00181... Test loss: 0.00194\n",
      "Epoch: 1... Training loss: 0.0019... Test loss: 0.00173\n",
      "Epoch: 1... Training loss: 0.00176... Test loss: 0.00195\n",
      "Epoch: 1... Training loss: 0.00178... Test loss: 0.00146\n",
      "Epoch: 1... Training loss: 0.00175... Test loss: 0.00192\n",
      "Epoch: 1... Training loss: 0.00168... Test loss: 0.00141\n",
      "Epoch: 1... Training loss: 0.00159... Test loss: 0.00172\n",
      "Epoch: 1... Training loss: 0.00156... Test loss: 0.00145\n",
      "Epoch: 1... Training loss: 0.00147... Test loss: 0.00169\n",
      "Epoch: 1... Training loss: 0.00151... Test loss: 0.0014\n",
      "Epoch: 1... Training loss: 0.00142... Test loss: 0.0018\n",
      "Epoch: 1... Training loss: 0.00138... Test loss: 0.00132\n",
      "Epoch: 1... Training loss: 0.00131... Test loss: 0.00197\n",
      "Epoch: 1... Training loss: 0.00133... Test loss: 0.00127\n",
      "Epoch: 1... Training loss: 0.00127... Test loss: 0.00163\n",
      "Epoch: 1... Training loss: 0.00126... Test loss: 0.00099\n",
      "Epoch: 1... Training loss: 0.00116... Test loss: 0.00135\n",
      "Epoch: 1... Training loss: 0.00111... Test loss: 0.00095\n",
      "Epoch: 1... Training loss: 0.0011... Test loss: 0.00131\n",
      "Epoch: 1... Training loss: 0.00105... Test loss: 0.001\n",
      "Epoch: 1... Training loss: 0.00103... Test loss: 0.00122\n",
      "Epoch: 1... Training loss: 0.00099... Test loss: 0.00095\n",
      "Epoch: 1... Training loss: 0.00094... Test loss: 0.00127\n",
      "Epoch: 1... Training loss: 0.00101... Test loss: 0.00098\n",
      "Epoch: 1... Training loss: 0.00089... Test loss: 0.00105\n",
      "Epoch: 1... Training loss: 0.00079... Test loss: 0.00088\n",
      "Epoch: 1... Training loss: 0.00082... Test loss: 0.00094\n",
      "Epoch: 1... Training loss: 0.00081... Test loss: 0.00078\n",
      "Epoch: 1... Training loss: 0.0008... Test loss: 0.00091\n",
      "Epoch: 1... Training loss: 0.00084... Test loss: 0.00069\n",
      "Epoch: 1... Training loss: 0.00078... Test loss: 0.00083\n",
      "Epoch: 1... Training loss: 0.00077... Test loss: 0.00064\n",
      "Epoch: 1... Training loss: 0.00073... Test loss: 0.00077\n",
      "Epoch: 1... Training loss: 0.00068... Test loss: 0.00071\n",
      "Epoch: 1... Training loss: 0.00067... Test loss: 0.00071\n",
      "Epoch: 1... Training loss: 0.00064... Test loss: 0.00062\n",
      "Epoch: 1... Training loss: 0.00062... Test loss: 0.00074\n",
      "Epoch: 1... Training loss: 0.00066... Test loss: 0.00064\n",
      "Epoch: 1... Training loss: 0.00065... Test loss: 0.00077\n",
      "Epoch: 1... Training loss: 0.00057... Test loss: 0.00053\n",
      "Epoch: 1... Training loss: 0.00056... Test loss: 0.00058\n",
      "Epoch: 1... Training loss: 0.00051... Test loss: 0.00046\n",
      "Epoch: 1... Training loss: 0.00054... Test loss: 0.00051\n",
      "Epoch: 1... Training loss: 0.00057... Test loss: 0.0005\n",
      "Epoch: 1... Training loss: 0.00047... Test loss: 0.00048\n",
      "Epoch: 1... Training loss: 0.0005... Test loss: 0.00042\n",
      "Epoch: 1... Training loss: 0.00045... Test loss: 0.00046\n",
      "Epoch: 1... Training loss: 0.00044... Test loss: 0.00039\n",
      "Epoch: 1... Training loss: 0.00041... Test loss: 0.00047\n",
      "Epoch: 1... Training loss: 0.00037... Test loss: 0.00038\n",
      "Epoch: 1... Training loss: 0.00038... Test loss: 0.00039\n",
      "Epoch: 1... Training loss: 0.00045... Test loss: 0.00036\n",
      "Epoch: 1... Training loss: 0.00039... Test loss: 0.00038\n",
      "Epoch: 1... Training loss: 0.0004... Test loss: 0.00037\n",
      "Epoch: 1... Training loss: 0.00037... Test loss: 0.00048\n",
      "Epoch: 1... Training loss: 0.00035... Test loss: 0.00033\n",
      "Epoch: 1... Training loss: 0.00032... Test loss: 0.00045\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00033\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.00042\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00037\n",
      "Epoch: 1... Training loss: 0.00026... Test loss: 0.00039\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00017\n",
      "267.3824477220187\n",
      "Epoch: 1... Training loss: 1.18893... Test loss: 0.47575\n",
      "Epoch: 1... Training loss: 0.52297... Test loss: 0.17019\n",
      "Epoch: 1... Training loss: 0.3345... Test loss: 0.10787\n",
      "Epoch: 1... Training loss: 0.24126... Test loss: 0.07992\n",
      "Epoch: 1... Training loss: 0.18416... Test loss: 0.06045\n",
      "Epoch: 1... Training loss: 0.14869... Test loss: 0.05933\n",
      "Epoch: 1... Training loss: 0.11153... Test loss: 0.0557\n",
      "Epoch: 1... Training loss: 0.08653... Test loss: 0.02733\n",
      "Epoch: 1... Training loss: 0.07087... Test loss: 0.0261\n",
      "Epoch: 1... Training loss: 0.06068... Test loss: 0.02842\n",
      "Epoch: 1... Training loss: 0.0539... Test loss: 0.02767\n",
      "Epoch: 1... Training loss: 0.04637... Test loss: 0.01926\n",
      "Epoch: 1... Training loss: 0.04185... Test loss: 0.01584\n",
      "Epoch: 1... Training loss: 0.03841... Test loss: 0.01383\n",
      "Epoch: 1... Training loss: 0.03545... Test loss: 0.01354\n",
      "Epoch: 1... Training loss: 0.03449... Test loss: 0.0151\n",
      "Epoch: 1... Training loss: 0.03095... Test loss: 0.0246\n",
      "Epoch: 1... Training loss: 0.02895... Test loss: 0.01086\n",
      "Epoch: 1... Training loss: 0.0269... Test loss: 0.02458\n",
      "Epoch: 1... Training loss: 0.02613... Test loss: 0.01406\n",
      "Epoch: 1... Training loss: 0.0245... Test loss: 0.01248\n",
      "Epoch: 1... Training loss: 0.02276... Test loss: 0.01149\n",
      "Epoch: 1... Training loss: 0.0213... Test loss: 0.01293\n",
      "Epoch: 1... Training loss: 0.02015... Test loss: 0.01345\n",
      "Epoch: 1... Training loss: 0.01921... Test loss: 0.01356\n",
      "Epoch: 1... Training loss: 0.01799... Test loss: 0.01668\n",
      "Epoch: 1... Training loss: 0.01715... Test loss: 0.01082\n",
      "Epoch: 1... Training loss: 0.01626... Test loss: 0.01535\n",
      "Epoch: 1... Training loss: 0.01603... Test loss: 0.00909\n",
      "Epoch: 1... Training loss: 0.01539... Test loss: 0.00876\n",
      "Epoch: 1... Training loss: 0.01499... Test loss: 0.01103\n",
      "Epoch: 1... Training loss: 0.01403... Test loss: 0.00996\n",
      "Epoch: 1... Training loss: 0.01373... Test loss: 0.01095\n",
      "Epoch: 1... Training loss: 0.01319... Test loss: 0.00937\n",
      "Epoch: 1... Training loss: 0.01295... Test loss: 0.00976\n",
      "Epoch: 1... Training loss: 0.01253... Test loss: 0.00751\n",
      "Epoch: 1... Training loss: 0.01229... Test loss: 0.01097\n",
      "Epoch: 1... Training loss: 0.01169... Test loss: 0.00736\n",
      "Epoch: 1... Training loss: 0.01143... Test loss: 0.01213\n",
      "Epoch: 1... Training loss: 0.01113... Test loss: 0.00667\n",
      "Epoch: 1... Training loss: 0.01092... Test loss: 0.01269\n",
      "Epoch: 1... Training loss: 0.01066... Test loss: 0.0059\n",
      "Epoch: 1... Training loss: 0.01027... Test loss: 0.01107\n",
      "Epoch: 1... Training loss: 0.01009... Test loss: 0.00587\n",
      "Epoch: 1... Training loss: 0.00975... Test loss: 0.01057\n",
      "Epoch: 1... Training loss: 0.00955... Test loss: 0.00636\n",
      "Epoch: 1... Training loss: 0.00928... Test loss: 0.01045\n",
      "Epoch: 1... Training loss: 0.00893... Test loss: 0.00566\n",
      "Epoch: 1... Training loss: 0.00882... Test loss: 0.00862\n",
      "Epoch: 1... Training loss: 0.00844... Test loss: 0.00551\n",
      "Epoch: 1... Training loss: 0.00837... Test loss: 0.00811\n",
      "Epoch: 1... Training loss: 0.00804... Test loss: 0.00566\n",
      "Epoch: 1... Training loss: 0.00785... Test loss: 0.00802\n",
      "Epoch: 1... Training loss: 0.00764... Test loss: 0.00553\n",
      "Epoch: 1... Training loss: 0.00741... Test loss: 0.00782\n",
      "Epoch: 1... Training loss: 0.00702... Test loss: 0.00514\n",
      "Epoch: 1... Training loss: 0.00694... Test loss: 0.00746\n",
      "Epoch: 1... Training loss: 0.00676... Test loss: 0.00555\n",
      "Epoch: 1... Training loss: 0.00661... Test loss: 0.00725\n",
      "Epoch: 1... Training loss: 0.00649... Test loss: 0.00552\n",
      "Epoch: 1... Training loss: 0.00633... Test loss: 0.00681\n",
      "Epoch: 1... Training loss: 0.00624... Test loss: 0.00497\n",
      "Epoch: 1... Training loss: 0.00605... Test loss: 0.00668\n",
      "Epoch: 1... Training loss: 0.00588... Test loss: 0.0057\n",
      "Epoch: 1... Training loss: 0.01503... Test loss: 0.01724\n",
      "Epoch: 1... Training loss: 0.01197... Test loss: 0.02509\n",
      "Epoch: 1... Training loss: 0.01029... Test loss: 0.01547\n",
      "Epoch: 1... Training loss: 0.01126... Test loss: 0.026\n",
      "Epoch: 1... Training loss: 0.01006... Test loss: 0.01495\n",
      "Epoch: 1... Training loss: 0.00793... Test loss: 0.02079\n",
      "Epoch: 1... Training loss: 0.0084... Test loss: 0.0136\n",
      "Epoch: 1... Training loss: 0.00924... Test loss: 0.01446\n",
      "Epoch: 1... Training loss: 0.00864... Test loss: 0.01326\n",
      "Epoch: 1... Training loss: 0.00917... Test loss: 0.01148\n",
      "Epoch: 1... Training loss: 0.00797... Test loss: 0.01234\n",
      "Epoch: 1... Training loss: 0.00736... Test loss: 0.01092\n",
      "Epoch: 1... Training loss: 0.00789... Test loss: 0.01004\n",
      "Epoch: 1... Training loss: 0.00731... Test loss: 0.00896\n",
      "Epoch: 1... Training loss: 0.0077... Test loss: 0.00768\n",
      "Epoch: 1... Training loss: 0.00793... Test loss: 0.00831\n",
      "Epoch: 1... Training loss: 0.00738... Test loss: 0.00768\n",
      "Epoch: 1... Training loss: 0.00646... Test loss: 0.009\n",
      "Epoch: 1... Training loss: 0.00686... Test loss: 0.00693\n",
      "Epoch: 1... Training loss: 0.00655... Test loss: 0.00802\n",
      "Epoch: 1... Training loss: 0.00598... Test loss: 0.00654\n",
      "Epoch: 1... Training loss: 0.00617... Test loss: 0.00747\n",
      "Epoch: 1... Training loss: 0.00574... Test loss: 0.00725\n",
      "Epoch: 1... Training loss: 0.0053... Test loss: 0.008\n",
      "Epoch: 1... Training loss: 0.00552... Test loss: 0.00592\n",
      "Epoch: 1... Training loss: 0.00522... Test loss: 0.00636\n",
      "Epoch: 1... Training loss: 0.00514... Test loss: 0.00587\n",
      "Epoch: 1... Training loss: 0.00509... Test loss: 0.00549\n",
      "Epoch: 1... Training loss: 0.00467... Test loss: 0.00567\n",
      "Epoch: 1... Training loss: 0.00463... Test loss: 0.00483\n",
      "Epoch: 1... Training loss: 0.00452... Test loss: 0.00575\n",
      "Epoch: 1... Training loss: 0.00446... Test loss: 0.00547\n",
      "Epoch: 1... Training loss: 0.00421... Test loss: 0.00504\n",
      "Epoch: 1... Training loss: 0.00418... Test loss: 0.00533\n",
      "Epoch: 1... Training loss: 0.00397... Test loss: 0.00443\n",
      "Epoch: 1... Training loss: 0.00387... Test loss: 0.00411\n",
      "Epoch: 1... Training loss: 0.00385... Test loss: 0.00433\n",
      "Epoch: 1... Training loss: 0.00366... Test loss: 0.00359\n",
      "Epoch: 1... Training loss: 0.00368... Test loss: 0.00394\n",
      "Epoch: 1... Training loss: 0.00356... Test loss: 0.00412\n",
      "Epoch: 1... Training loss: 0.00348... Test loss: 0.00424\n",
      "Epoch: 1... Training loss: 0.00336... Test loss: 0.00376\n",
      "Epoch: 1... Training loss: 0.00334... Test loss: 0.00366\n",
      "Epoch: 1... Training loss: 0.0032... Test loss: 0.00337\n",
      "Epoch: 1... Training loss: 0.00327... Test loss: 0.00414\n",
      "Epoch: 1... Training loss: 0.00306... Test loss: 0.00364\n",
      "Epoch: 1... Training loss: 0.00305... Test loss: 0.00345\n",
      "Epoch: 1... Training loss: 0.00299... Test loss: 0.0037\n",
      "Epoch: 1... Training loss: 0.00293... Test loss: 0.00267\n",
      "Epoch: 1... Training loss: 0.00291... Test loss: 0.00342\n",
      "Epoch: 1... Training loss: 0.00285... Test loss: 0.00269\n",
      "Epoch: 1... Training loss: 0.0027... Test loss: 0.00366\n",
      "Epoch: 1... Training loss: 0.00272... Test loss: 0.00271\n",
      "Epoch: 1... Training loss: 0.00276... Test loss: 0.0027\n",
      "Epoch: 1... Training loss: 0.00271... Test loss: 0.00258\n",
      "Epoch: 1... Training loss: 0.00262... Test loss: 0.00267\n",
      "Epoch: 1... Training loss: 0.00253... Test loss: 0.00277\n",
      "Epoch: 1... Training loss: 0.00245... Test loss: 0.00279\n",
      "Epoch: 1... Training loss: 0.00235... Test loss: 0.00301\n",
      "Epoch: 1... Training loss: 0.0023... Test loss: 0.00263\n",
      "Epoch: 1... Training loss: 0.00226... Test loss: 0.00225\n",
      "Epoch: 1... Training loss: 0.00217... Test loss: 0.00218\n",
      "Epoch: 1... Training loss: 0.00233... Test loss: 0.00257\n",
      "Epoch: 1... Training loss: 0.00224... Test loss: 0.00225\n",
      "Epoch: 1... Training loss: 0.00208... Test loss: 0.00231\n",
      "Epoch: 1... Training loss: 0.00204... Test loss: 0.00214\n",
      "Epoch: 1... Training loss: 0.00202... Test loss: 0.00235\n",
      "Epoch: 1... Training loss: 0.00191... Test loss: 0.00204\n",
      "Epoch: 1... Training loss: 0.00185... Test loss: 0.00211\n",
      "Epoch: 1... Training loss: 0.00178... Test loss: 0.00202\n",
      "Epoch: 1... Training loss: 0.00172... Test loss: 0.00178\n",
      "Epoch: 1... Training loss: 0.00167... Test loss: 0.00195\n",
      "Epoch: 1... Training loss: 0.00164... Test loss: 0.00188\n",
      "Epoch: 1... Training loss: 0.0016... Test loss: 0.00172\n",
      "Epoch: 1... Training loss: 0.00156... Test loss: 0.00158\n",
      "Epoch: 1... Training loss: 0.00148... Test loss: 0.00176\n",
      "Epoch: 1... Training loss: 0.00157... Test loss: 0.00139\n",
      "Epoch: 1... Training loss: 0.0014... Test loss: 0.00183\n",
      "Epoch: 1... Training loss: 0.00145... Test loss: 0.00131\n",
      "Epoch: 1... Training loss: 0.00136... Test loss: 0.00158\n",
      "Epoch: 1... Training loss: 0.00129... Test loss: 0.00142\n",
      "Epoch: 1... Training loss: 0.00126... Test loss: 0.00134\n",
      "Epoch: 1... Training loss: 0.00122... Test loss: 0.00142\n",
      "Epoch: 1... Training loss: 0.00118... Test loss: 0.00112\n",
      "Epoch: 1... Training loss: 0.00125... Test loss: 0.00142\n",
      "Epoch: 1... Training loss: 0.0011... Test loss: 0.00106\n",
      "Epoch: 1... Training loss: 0.00113... Test loss: 0.00126\n",
      "Epoch: 1... Training loss: 0.00105... Test loss: 0.0011\n",
      "Epoch: 1... Training loss: 0.00098... Test loss: 0.00104\n",
      "Epoch: 1... Training loss: 0.00101... Test loss: 0.00094\n",
      "Epoch: 1... Training loss: 0.00096... Test loss: 0.00098\n",
      "Epoch: 1... Training loss: 0.00098... Test loss: 0.00098\n",
      "Epoch: 1... Training loss: 0.00099... Test loss: 0.00078\n",
      "Epoch: 1... Training loss: 0.00087... Test loss: 0.00088\n",
      "Epoch: 1... Training loss: 0.0009... Test loss: 0.00081\n",
      "Epoch: 1... Training loss: 0.00083... Test loss: 0.00096\n",
      "Epoch: 1... Training loss: 0.00089... Test loss: 0.00091\n",
      "Epoch: 1... Training loss: 0.00073... Test loss: 0.00081\n",
      "Epoch: 1... Training loss: 0.00072... Test loss: 0.00089\n",
      "Epoch: 1... Training loss: 0.00073... Test loss: 0.0007\n",
      "Epoch: 1... Training loss: 0.00077... Test loss: 0.00085\n",
      "Epoch: 1... Training loss: 0.00068... Test loss: 0.00067\n",
      "Epoch: 1... Training loss: 0.00066... Test loss: 0.00067\n",
      "Epoch: 1... Training loss: 0.00069... Test loss: 0.00071\n",
      "Epoch: 1... Training loss: 0.00066... Test loss: 0.00064\n",
      "Epoch: 1... Training loss: 0.0007... Test loss: 0.00063\n",
      "Epoch: 1... Training loss: 0.00062... Test loss: 0.00067\n",
      "Epoch: 1... Training loss: 0.0006... Test loss: 0.00061\n",
      "Epoch: 1... Training loss: 0.00057... Test loss: 0.00059\n",
      "Epoch: 1... Training loss: 0.00056... Test loss: 0.00058\n",
      "Epoch: 1... Training loss: 0.00053... Test loss: 0.00053\n",
      "Epoch: 1... Training loss: 0.0005... Test loss: 0.00048\n",
      "Epoch: 1... Training loss: 0.00046... Test loss: 0.0005\n",
      "Epoch: 1... Training loss: 0.00044... Test loss: 0.00045\n",
      "Epoch: 1... Training loss: 0.00046... Test loss: 0.00056\n",
      "Epoch: 1... Training loss: 0.00041... Test loss: 0.00042\n",
      "Epoch: 1... Training loss: 0.00035... Test loss: 0.00049\n",
      "Epoch: 1... Training loss: 0.00038... Test loss: 0.0004\n",
      "Epoch: 1... Training loss: 0.00033... Test loss: 0.00042\n",
      "Epoch: 1... Training loss: 0.00034... Test loss: 0.00033\n",
      "Epoch: 1... Training loss: 0.00031... Test loss: 0.00034\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.0003\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.00033\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00034... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00018\n",
      "291.3361105575459\n",
      "Epoch: 1... Training loss: 0.91829... Test loss: 0.2676\n",
      "Epoch: 1... Training loss: 0.45019... Test loss: 0.14263\n",
      "Epoch: 1... Training loss: 0.29784... Test loss: 0.10022\n",
      "Epoch: 1... Training loss: 0.20143... Test loss: 0.07616\n",
      "Epoch: 1... Training loss: 0.15186... Test loss: 0.06566\n",
      "Epoch: 1... Training loss: 0.12454... Test loss: 0.07134\n",
      "Epoch: 1... Training loss: 0.09967... Test loss: 0.06528\n",
      "Epoch: 1... Training loss: 0.07972... Test loss: 0.03108\n",
      "Epoch: 1... Training loss: 0.0698... Test loss: 0.05293\n",
      "Epoch: 1... Training loss: 0.06143... Test loss: 0.01919\n",
      "Epoch: 1... Training loss: 0.05586... Test loss: 0.03539\n",
      "Epoch: 1... Training loss: 0.05124... Test loss: 0.01332\n",
      "Epoch: 1... Training loss: 0.04667... Test loss: 0.02885\n",
      "Epoch: 1... Training loss: 0.04246... Test loss: 0.02071\n",
      "Epoch: 1... Training loss: 0.03959... Test loss: 0.04166\n",
      "Epoch: 1... Training loss: 0.03855... Test loss: 0.0164\n",
      "Epoch: 1... Training loss: 0.03304... Test loss: 0.03272\n",
      "Epoch: 1... Training loss: 0.03147... Test loss: 0.01531\n",
      "Epoch: 1... Training loss: 0.02937... Test loss: 0.0321\n",
      "Epoch: 1... Training loss: 0.02808... Test loss: 0.01349\n",
      "Epoch: 1... Training loss: 0.02643... Test loss: 0.03028\n",
      "Epoch: 1... Training loss: 0.02601... Test loss: 0.01197\n",
      "Epoch: 1... Training loss: 0.02456... Test loss: 0.02288\n",
      "Epoch: 1... Training loss: 0.024... Test loss: 0.01122\n",
      "Epoch: 1... Training loss: 0.02251... Test loss: 0.02172\n",
      "Epoch: 1... Training loss: 0.02179... Test loss: 0.01105\n",
      "Epoch: 1... Training loss: 0.01998... Test loss: 0.01994\n",
      "Epoch: 1... Training loss: 0.01958... Test loss: 0.0115\n",
      "Epoch: 1... Training loss: 0.01869... Test loss: 0.01889\n",
      "Epoch: 1... Training loss: 0.01821... Test loss: 0.01306\n",
      "Epoch: 1... Training loss: 0.01748... Test loss: 0.01646\n",
      "Epoch: 1... Training loss: 0.01664... Test loss: 0.01455\n",
      "Epoch: 1... Training loss: 0.01579... Test loss: 0.01987\n",
      "Epoch: 1... Training loss: 0.01497... Test loss: 0.01091\n",
      "Epoch: 1... Training loss: 0.01422... Test loss: 0.01645\n",
      "Epoch: 1... Training loss: 0.0136... Test loss: 0.0104\n",
      "Epoch: 1... Training loss: 0.01278... Test loss: 0.01524\n",
      "Epoch: 1... Training loss: 0.0122... Test loss: 0.01101\n",
      "Epoch: 1... Training loss: 0.01193... Test loss: 0.01143\n",
      "Epoch: 1... Training loss: 0.01156... Test loss: 0.01078\n",
      "Epoch: 1... Training loss: 0.01096... Test loss: 0.01275\n",
      "Epoch: 1... Training loss: 0.01077... Test loss: 0.00752\n",
      "Epoch: 1... Training loss: 0.0103... Test loss: 0.01146\n",
      "Epoch: 1... Training loss: 0.00999... Test loss: 0.00725\n",
      "Epoch: 1... Training loss: 0.00971... Test loss: 0.00991\n",
      "Epoch: 1... Training loss: 0.00942... Test loss: 0.00797\n",
      "Epoch: 1... Training loss: 0.00902... Test loss: 0.00862\n",
      "Epoch: 1... Training loss: 0.00891... Test loss: 0.00801\n",
      "Epoch: 1... Training loss: 0.00844... Test loss: 0.00822\n",
      "Epoch: 1... Training loss: 0.00833... Test loss: 0.00859\n",
      "Epoch: 1... Training loss: 0.0079... Test loss: 0.00671\n",
      "Epoch: 1... Training loss: 0.00787... Test loss: 0.00853\n",
      "Epoch: 1... Training loss: 0.00754... Test loss: 0.00623\n",
      "Epoch: 1... Training loss: 0.00738... Test loss: 0.00878\n",
      "Epoch: 1... Training loss: 0.00711... Test loss: 0.00741\n",
      "Epoch: 1... Training loss: 0.00718... Test loss: 0.00728\n",
      "Epoch: 1... Training loss: 0.00689... Test loss: 0.00778\n",
      "Epoch: 1... Training loss: 0.00694... Test loss: 0.00615\n",
      "Epoch: 1... Training loss: 0.00661... Test loss: 0.00738\n",
      "Epoch: 1... Training loss: 0.00661... Test loss: 0.00588\n",
      "Epoch: 1... Training loss: 0.00634... Test loss: 0.0071\n",
      "Epoch: 1... Training loss: 0.00622... Test loss: 0.00563\n",
      "Epoch: 1... Training loss: 0.00593... Test loss: 0.00664\n",
      "Epoch: 1... Training loss: 0.00578... Test loss: 0.0056\n",
      "Epoch: 1... Training loss: 0.012... Test loss: 0.00833\n",
      "Epoch: 1... Training loss: 0.01109... Test loss: 0.00848\n",
      "Epoch: 1... Training loss: 0.01237... Test loss: 0.01522\n",
      "Epoch: 1... Training loss: 0.01228... Test loss: 0.01265\n",
      "Epoch: 1... Training loss: 0.01105... Test loss: 0.01469\n",
      "Epoch: 1... Training loss: 0.00852... Test loss: 0.01261\n",
      "Epoch: 1... Training loss: 0.00916... Test loss: 0.01349\n",
      "Epoch: 1... Training loss: 0.0086... Test loss: 0.01226\n",
      "Epoch: 1... Training loss: 0.00903... Test loss: 0.01081\n",
      "Epoch: 1... Training loss: 0.00876... Test loss: 0.00997\n",
      "Epoch: 1... Training loss: 0.00852... Test loss: 0.00917\n",
      "Epoch: 1... Training loss: 0.00823... Test loss: 0.01002\n",
      "Epoch: 1... Training loss: 0.00757... Test loss: 0.0087\n",
      "Epoch: 1... Training loss: 0.00679... Test loss: 0.01071\n",
      "Epoch: 1... Training loss: 0.00727... Test loss: 0.00748\n",
      "Epoch: 1... Training loss: 0.00718... Test loss: 0.00933\n",
      "Epoch: 1... Training loss: 0.00623... Test loss: 0.00816\n",
      "Epoch: 1... Training loss: 0.00651... Test loss: 0.00921\n",
      "Epoch: 1... Training loss: 0.00623... Test loss: 0.007\n",
      "Epoch: 1... Training loss: 0.00619... Test loss: 0.00758\n",
      "Epoch: 1... Training loss: 0.00581... Test loss: 0.00649\n",
      "Epoch: 1... Training loss: 0.00571... Test loss: 0.00617\n",
      "Epoch: 1... Training loss: 0.00528... Test loss: 0.00618\n",
      "Epoch: 1... Training loss: 0.00516... Test loss: 0.00532\n",
      "Epoch: 1... Training loss: 0.00505... Test loss: 0.00616\n",
      "Epoch: 1... Training loss: 0.00518... Test loss: 0.00494\n",
      "Epoch: 1... Training loss: 0.00459... Test loss: 0.00599\n",
      "Epoch: 1... Training loss: 0.00457... Test loss: 0.00477\n",
      "Epoch: 1... Training loss: 0.00461... Test loss: 0.00475\n",
      "Epoch: 1... Training loss: 0.00449... Test loss: 0.00481\n",
      "Epoch: 1... Training loss: 0.00436... Test loss: 0.00479\n",
      "Epoch: 1... Training loss: 0.00404... Test loss: 0.00482\n",
      "Epoch: 1... Training loss: 0.00399... Test loss: 0.00434\n",
      "Epoch: 1... Training loss: 0.00385... Test loss: 0.0047\n",
      "Epoch: 1... Training loss: 0.00379... Test loss: 0.00403\n",
      "Epoch: 1... Training loss: 0.00374... Test loss: 0.00418\n",
      "Epoch: 1... Training loss: 0.00361... Test loss: 0.0035\n",
      "Epoch: 1... Training loss: 0.00356... Test loss: 0.00396\n",
      "Epoch: 1... Training loss: 0.00349... Test loss: 0.00429\n",
      "Epoch: 1... Training loss: 0.00344... Test loss: 0.00424\n",
      "Epoch: 1... Training loss: 0.00331... Test loss: 0.00375\n",
      "Epoch: 1... Training loss: 0.00311... Test loss: 0.00377\n",
      "Epoch: 1... Training loss: 0.00312... Test loss: 0.00338\n",
      "Epoch: 1... Training loss: 0.00339... Test loss: 0.0039\n",
      "Epoch: 1... Training loss: 0.00301... Test loss: 0.00321\n",
      "Epoch: 1... Training loss: 0.00297... Test loss: 0.00349\n",
      "Epoch: 1... Training loss: 0.00289... Test loss: 0.00358\n",
      "Epoch: 1... Training loss: 0.00295... Test loss: 0.00293\n",
      "Epoch: 1... Training loss: 0.00294... Test loss: 0.00312\n",
      "Epoch: 1... Training loss: 0.00272... Test loss: 0.0028\n",
      "Epoch: 1... Training loss: 0.00283... Test loss: 0.00262\n",
      "Epoch: 1... Training loss: 0.00259... Test loss: 0.00277\n",
      "Epoch: 1... Training loss: 0.00257... Test loss: 0.00256\n",
      "Epoch: 1... Training loss: 0.00261... Test loss: 0.00269\n",
      "Epoch: 1... Training loss: 0.00242... Test loss: 0.0029\n",
      "Epoch: 1... Training loss: 0.00247... Test loss: 0.00266\n",
      "Epoch: 1... Training loss: 0.00237... Test loss: 0.00218\n",
      "Epoch: 1... Training loss: 0.0024... Test loss: 0.00245\n",
      "Epoch: 1... Training loss: 0.00216... Test loss: 0.00255\n",
      "Epoch: 1... Training loss: 0.00215... Test loss: 0.00223\n",
      "Epoch: 1... Training loss: 0.00209... Test loss: 0.00272\n",
      "Epoch: 1... Training loss: 0.00204... Test loss: 0.00204\n",
      "Epoch: 1... Training loss: 0.00208... Test loss: 0.00263\n",
      "Epoch: 1... Training loss: 0.00198... Test loss: 0.00212\n",
      "Epoch: 1... Training loss: 0.00194... Test loss: 0.0022\n",
      "Epoch: 1... Training loss: 0.00182... Test loss: 0.0018\n",
      "Epoch: 1... Training loss: 0.00177... Test loss: 0.00215\n",
      "Epoch: 1... Training loss: 0.00176... Test loss: 0.00176\n",
      "Epoch: 1... Training loss: 0.0016... Test loss: 0.00212\n",
      "Epoch: 1... Training loss: 0.00172... Test loss: 0.00148\n",
      "Epoch: 1... Training loss: 0.00164... Test loss: 0.00207\n",
      "Epoch: 1... Training loss: 0.00161... Test loss: 0.00158\n",
      "Epoch: 1... Training loss: 0.00155... Test loss: 0.00222\n",
      "Epoch: 1... Training loss: 0.00151... Test loss: 0.00142\n",
      "Epoch: 1... Training loss: 0.0015... Test loss: 0.00196\n",
      "Epoch: 1... Training loss: 0.00145... Test loss: 0.00133\n",
      "Epoch: 1... Training loss: 0.00153... Test loss: 0.00167\n",
      "Epoch: 1... Training loss: 0.00136... Test loss: 0.00114\n",
      "Epoch: 1... Training loss: 0.00131... Test loss: 0.00147\n",
      "Epoch: 1... Training loss: 0.00135... Test loss: 0.00131\n",
      "Epoch: 1... Training loss: 0.00131... Test loss: 0.00135\n",
      "Epoch: 1... Training loss: 0.00124... Test loss: 0.0012\n",
      "Epoch: 1... Training loss: 0.0012... Test loss: 0.00123\n",
      "Epoch: 1... Training loss: 0.00118... Test loss: 0.00102\n",
      "Epoch: 1... Training loss: 0.00118... Test loss: 0.0012\n",
      "Epoch: 1... Training loss: 0.00114... Test loss: 0.00112\n",
      "Epoch: 1... Training loss: 0.00109... Test loss: 0.00133\n",
      "Epoch: 1... Training loss: 0.00103... Test loss: 0.00095\n",
      "Epoch: 1... Training loss: 0.00101... Test loss: 0.00132\n",
      "Epoch: 1... Training loss: 0.00102... Test loss: 0.00097\n",
      "Epoch: 1... Training loss: 0.00101... Test loss: 0.0012\n",
      "Epoch: 1... Training loss: 0.00097... Test loss: 0.00105\n",
      "Epoch: 1... Training loss: 0.00089... Test loss: 0.00107\n",
      "Epoch: 1... Training loss: 0.00086... Test loss: 0.00086\n",
      "Epoch: 1... Training loss: 0.00087... Test loss: 0.00093\n",
      "Epoch: 1... Training loss: 0.00084... Test loss: 0.00076\n",
      "Epoch: 1... Training loss: 0.00081... Test loss: 0.00101\n",
      "Epoch: 1... Training loss: 0.00082... Test loss: 0.00079\n",
      "Epoch: 1... Training loss: 0.00076... Test loss: 0.00085\n",
      "Epoch: 1... Training loss: 0.00074... Test loss: 0.00077\n",
      "Epoch: 1... Training loss: 0.0007... Test loss: 0.00073\n",
      "Epoch: 1... Training loss: 0.00067... Test loss: 0.00074\n",
      "Epoch: 1... Training loss: 0.00067... Test loss: 0.00066\n",
      "Epoch: 1... Training loss: 0.00071... Test loss: 0.00084\n",
      "Epoch: 1... Training loss: 0.00064... Test loss: 0.00066\n",
      "Epoch: 1... Training loss: 0.00068... Test loss: 0.00067\n",
      "Epoch: 1... Training loss: 0.00057... Test loss: 0.00059\n",
      "Epoch: 1... Training loss: 0.00059... Test loss: 0.00061\n",
      "Epoch: 1... Training loss: 0.00052... Test loss: 0.00059\n",
      "Epoch: 1... Training loss: 0.00053... Test loss: 0.00053\n",
      "Epoch: 1... Training loss: 0.0005... Test loss: 0.00056\n",
      "Epoch: 1... Training loss: 0.00051... Test loss: 0.00046\n",
      "Epoch: 1... Training loss: 0.0005... Test loss: 0.00049\n",
      "Epoch: 1... Training loss: 0.00056... Test loss: 0.00051\n",
      "Epoch: 1... Training loss: 0.00051... Test loss: 0.00055\n",
      "Epoch: 1... Training loss: 0.00047... Test loss: 0.00047\n",
      "Epoch: 1... Training loss: 0.00052... Test loss: 0.00047\n",
      "Epoch: 1... Training loss: 0.00044... Test loss: 0.00046\n",
      "Epoch: 1... Training loss: 0.00041... Test loss: 0.00036\n",
      "Epoch: 1... Training loss: 0.00041... Test loss: 0.00045\n",
      "Epoch: 1... Training loss: 0.00036... Test loss: 0.00037\n",
      "Epoch: 1... Training loss: 0.00035... Test loss: 0.00034\n",
      "Epoch: 1... Training loss: 0.00032... Test loss: 0.00039\n",
      "Epoch: 1... Training loss: 0.00033... Test loss: 0.00036\n",
      "Epoch: 1... Training loss: 0.00035... Test loss: 0.00046\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00033\n",
      "Epoch: 1... Training loss: 0.00031... Test loss: 0.00034\n",
      "Epoch: 1... Training loss: 0.00029... Test loss: 0.00034\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00032\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.0003\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00024\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00021\n",
      "287.5329077647766\n",
      "Epoch: 1... Training loss: 1.20801... Test loss: 0.54963\n",
      "Epoch: 1... Training loss: 0.50335... Test loss: 0.21296\n",
      "Epoch: 1... Training loss: 0.30693... Test loss: 0.1045\n",
      "Epoch: 1... Training loss: 0.20643... Test loss: 0.07983\n",
      "Epoch: 1... Training loss: 0.1638... Test loss: 0.05131\n",
      "Epoch: 1... Training loss: 0.12527... Test loss: 0.04468\n",
      "Epoch: 1... Training loss: 0.09981... Test loss: 0.03339\n",
      "Epoch: 1... Training loss: 0.08717... Test loss: 0.04871\n",
      "Epoch: 1... Training loss: 0.08184... Test loss: 0.03194\n",
      "Epoch: 1... Training loss: 0.05991... Test loss: 0.05019\n",
      "Epoch: 1... Training loss: 0.05503... Test loss: 0.02674\n",
      "Epoch: 1... Training loss: 0.0477... Test loss: 0.05274\n",
      "Epoch: 1... Training loss: 0.0453... Test loss: 0.0267\n",
      "Epoch: 1... Training loss: 0.03976... Test loss: 0.05934\n",
      "Epoch: 1... Training loss: 0.03849... Test loss: 0.02293\n",
      "Epoch: 1... Training loss: 0.03565... Test loss: 0.04026\n",
      "Epoch: 1... Training loss: 0.0342... Test loss: 0.01402\n",
      "Epoch: 1... Training loss: 0.03162... Test loss: 0.0383\n",
      "Epoch: 1... Training loss: 0.02965... Test loss: 0.01845\n",
      "Epoch: 1... Training loss: 0.02699... Test loss: 0.03503\n",
      "Epoch: 1... Training loss: 0.02557... Test loss: 0.01825\n",
      "Epoch: 1... Training loss: 0.02454... Test loss: 0.03188\n",
      "Epoch: 1... Training loss: 0.02383... Test loss: 0.02162\n",
      "Epoch: 1... Training loss: 0.02261... Test loss: 0.02744\n",
      "Epoch: 1... Training loss: 0.02198... Test loss: 0.02281\n",
      "Epoch: 1... Training loss: 0.02061... Test loss: 0.02183\n",
      "Epoch: 1... Training loss: 0.02045... Test loss: 0.01956\n",
      "Epoch: 1... Training loss: 0.01889... Test loss: 0.01487\n",
      "Epoch: 1... Training loss: 0.01827... Test loss: 0.01972\n",
      "Epoch: 1... Training loss: 0.01719... Test loss: 0.0126\n",
      "Epoch: 1... Training loss: 0.01666... Test loss: 0.01694\n",
      "Epoch: 1... Training loss: 0.01609... Test loss: 0.01126\n",
      "Epoch: 1... Training loss: 0.01556... Test loss: 0.01615\n",
      "Epoch: 1... Training loss: 0.01463... Test loss: 0.01198\n",
      "Epoch: 1... Training loss: 0.01425... Test loss: 0.01492\n",
      "Epoch: 1... Training loss: 0.0134... Test loss: 0.01237\n",
      "Epoch: 1... Training loss: 0.013... Test loss: 0.01539\n",
      "Epoch: 1... Training loss: 0.01274... Test loss: 0.00887\n",
      "Epoch: 1... Training loss: 0.01221... Test loss: 0.01297\n",
      "Epoch: 1... Training loss: 0.01169... Test loss: 0.00965\n",
      "Epoch: 1... Training loss: 0.01129... Test loss: 0.01078\n",
      "Epoch: 1... Training loss: 0.01092... Test loss: 0.00889\n",
      "Epoch: 1... Training loss: 0.01054... Test loss: 0.0111\n",
      "Epoch: 1... Training loss: 0.01022... Test loss: 0.00902\n",
      "Epoch: 1... Training loss: 0.00974... Test loss: 0.00917\n",
      "Epoch: 1... Training loss: 0.00941... Test loss: 0.01104\n",
      "Epoch: 1... Training loss: 0.00922... Test loss: 0.00695\n",
      "Epoch: 1... Training loss: 0.0089... Test loss: 0.01258\n",
      "Epoch: 1... Training loss: 0.00876... Test loss: 0.00745\n",
      "Epoch: 1... Training loss: 0.00846... Test loss: 0.01251\n",
      "Epoch: 1... Training loss: 0.00815... Test loss: 0.00736\n",
      "Epoch: 1... Training loss: 0.00786... Test loss: 0.01115\n",
      "Epoch: 1... Training loss: 0.00764... Test loss: 0.00713\n",
      "Epoch: 1... Training loss: 0.00736... Test loss: 0.00902\n",
      "Epoch: 1... Training loss: 0.00722... Test loss: 0.0065\n",
      "Epoch: 1... Training loss: 0.00693... Test loss: 0.00798\n",
      "Epoch: 1... Training loss: 0.00676... Test loss: 0.00586\n",
      "Epoch: 1... Training loss: 0.00661... Test loss: 0.00773\n",
      "Epoch: 1... Training loss: 0.0064... Test loss: 0.00551\n",
      "Epoch: 1... Training loss: 0.00623... Test loss: 0.00796\n",
      "Epoch: 1... Training loss: 0.00618... Test loss: 0.0056\n",
      "Epoch: 1... Training loss: 0.006... Test loss: 0.00819\n",
      "Epoch: 1... Training loss: 0.00593... Test loss: 0.00519\n",
      "Epoch: 1... Training loss: 0.00575... Test loss: 0.0065\n",
      "Epoch: 1... Training loss: 0.012... Test loss: 0.01022\n",
      "Epoch: 1... Training loss: 0.0096... Test loss: 0.01043\n",
      "Epoch: 1... Training loss: 0.01076... Test loss: 0.01438\n",
      "Epoch: 1... Training loss: 0.0113... Test loss: 0.00907\n",
      "Epoch: 1... Training loss: 0.00882... Test loss: 0.01358\n",
      "Epoch: 1... Training loss: 0.01036... Test loss: 0.00889\n",
      "Epoch: 1... Training loss: 0.01034... Test loss: 0.01072\n",
      "Epoch: 1... Training loss: 0.01001... Test loss: 0.00984\n",
      "Epoch: 1... Training loss: 0.009... Test loss: 0.00995\n",
      "Epoch: 1... Training loss: 0.00873... Test loss: 0.0089\n",
      "Epoch: 1... Training loss: 0.00814... Test loss: 0.00778\n",
      "Epoch: 1... Training loss: 0.00813... Test loss: 0.0098\n",
      "Epoch: 1... Training loss: 0.00788... Test loss: 0.00913\n",
      "Epoch: 1... Training loss: 0.00698... Test loss: 0.0079\n",
      "Epoch: 1... Training loss: 0.00715... Test loss: 0.00778\n",
      "Epoch: 1... Training loss: 0.00709... Test loss: 0.00819\n",
      "Epoch: 1... Training loss: 0.00677... Test loss: 0.00758\n",
      "Epoch: 1... Training loss: 0.00659... Test loss: 0.00737\n",
      "Epoch: 1... Training loss: 0.00646... Test loss: 0.00696\n",
      "Epoch: 1... Training loss: 0.00617... Test loss: 0.00674\n",
      "Epoch: 1... Training loss: 0.00588... Test loss: 0.00713\n",
      "Epoch: 1... Training loss: 0.00565... Test loss: 0.00639\n",
      "Epoch: 1... Training loss: 0.00566... Test loss: 0.0071\n",
      "Epoch: 1... Training loss: 0.00554... Test loss: 0.00604\n",
      "Epoch: 1... Training loss: 0.00531... Test loss: 0.00625\n",
      "Epoch: 1... Training loss: 0.00512... Test loss: 0.00612\n",
      "Epoch: 1... Training loss: 0.00492... Test loss: 0.00546\n",
      "Epoch: 1... Training loss: 0.00473... Test loss: 0.00631\n",
      "Epoch: 1... Training loss: 0.0048... Test loss: 0.00545\n",
      "Epoch: 1... Training loss: 0.00453... Test loss: 0.00612\n",
      "Epoch: 1... Training loss: 0.00434... Test loss: 0.00533\n",
      "Epoch: 1... Training loss: 0.00428... Test loss: 0.00521\n",
      "Epoch: 1... Training loss: 0.00427... Test loss: 0.00427\n",
      "Epoch: 1... Training loss: 0.00404... Test loss: 0.00499\n",
      "Epoch: 1... Training loss: 0.00396... Test loss: 0.00401\n",
      "Epoch: 1... Training loss: 0.00373... Test loss: 0.00519\n",
      "Epoch: 1... Training loss: 0.00386... Test loss: 0.00383\n",
      "Epoch: 1... Training loss: 0.00366... Test loss: 0.00373\n",
      "Epoch: 1... Training loss: 0.00357... Test loss: 0.00362\n",
      "Epoch: 1... Training loss: 0.00366... Test loss: 0.00346\n",
      "Epoch: 1... Training loss: 0.00347... Test loss: 0.00357\n",
      "Epoch: 1... Training loss: 0.00343... Test loss: 0.0035\n",
      "Epoch: 1... Training loss: 0.00335... Test loss: 0.0036\n",
      "Epoch: 1... Training loss: 0.00317... Test loss: 0.00339\n",
      "Epoch: 1... Training loss: 0.0033... Test loss: 0.0041\n",
      "Epoch: 1... Training loss: 0.0032... Test loss: 0.00327\n",
      "Epoch: 1... Training loss: 0.00316... Test loss: 0.00363\n",
      "Epoch: 1... Training loss: 0.00321... Test loss: 0.00279\n",
      "Epoch: 1... Training loss: 0.00305... Test loss: 0.00365\n",
      "Epoch: 1... Training loss: 0.00299... Test loss: 0.00301\n",
      "Epoch: 1... Training loss: 0.00296... Test loss: 0.00309\n",
      "Epoch: 1... Training loss: 0.00285... Test loss: 0.00271\n",
      "Epoch: 1... Training loss: 0.00278... Test loss: 0.00306\n",
      "Epoch: 1... Training loss: 0.00268... Test loss: 0.00317\n",
      "Epoch: 1... Training loss: 0.00255... Test loss: 0.00287\n",
      "Epoch: 1... Training loss: 0.00257... Test loss: 0.00294\n",
      "Epoch: 1... Training loss: 0.0025... Test loss: 0.00241\n",
      "Epoch: 1... Training loss: 0.00236... Test loss: 0.00272\n",
      "Epoch: 1... Training loss: 0.00236... Test loss: 0.00234\n",
      "Epoch: 1... Training loss: 0.00233... Test loss: 0.00247\n",
      "Epoch: 1... Training loss: 0.0022... Test loss: 0.00226\n",
      "Epoch: 1... Training loss: 0.00221... Test loss: 0.00227\n",
      "Epoch: 1... Training loss: 0.0021... Test loss: 0.00236\n",
      "Epoch: 1... Training loss: 0.00208... Test loss: 0.0023\n",
      "Epoch: 1... Training loss: 0.00192... Test loss: 0.00208\n",
      "Epoch: 1... Training loss: 0.002... Test loss: 0.00202\n",
      "Epoch: 1... Training loss: 0.00188... Test loss: 0.00201\n",
      "Epoch: 1... Training loss: 0.00187... Test loss: 0.00208\n",
      "Epoch: 1... Training loss: 0.00177... Test loss: 0.0018\n",
      "Epoch: 1... Training loss: 0.00194... Test loss: 0.00184\n",
      "Epoch: 1... Training loss: 0.00176... Test loss: 0.00205\n",
      "Epoch: 1... Training loss: 0.00179... Test loss: 0.00173\n",
      "Epoch: 1... Training loss: 0.00173... Test loss: 0.00156\n",
      "Epoch: 1... Training loss: 0.00163... Test loss: 0.00151\n",
      "Epoch: 1... Training loss: 0.00162... Test loss: 0.00139\n",
      "Epoch: 1... Training loss: 0.00146... Test loss: 0.00143\n",
      "Epoch: 1... Training loss: 0.00145... Test loss: 0.00145\n",
      "Epoch: 1... Training loss: 0.00149... Test loss: 0.00153\n",
      "Epoch: 1... Training loss: 0.00137... Test loss: 0.00147\n",
      "Epoch: 1... Training loss: 0.00142... Test loss: 0.00142\n",
      "Epoch: 1... Training loss: 0.00136... Test loss: 0.00155\n",
      "Epoch: 1... Training loss: 0.00143... Test loss: 0.00134\n",
      "Epoch: 1... Training loss: 0.00125... Test loss: 0.00157\n",
      "Epoch: 1... Training loss: 0.00116... Test loss: 0.00126\n",
      "Epoch: 1... Training loss: 0.0012... Test loss: 0.00133\n",
      "Epoch: 1... Training loss: 0.00111... Test loss: 0.00124\n",
      "Epoch: 1... Training loss: 0.0011... Test loss: 0.00122\n",
      "Epoch: 1... Training loss: 0.00104... Test loss: 0.00127\n",
      "Epoch: 1... Training loss: 0.00105... Test loss: 0.00107\n",
      "Epoch: 1... Training loss: 0.00103... Test loss: 0.00117\n",
      "Epoch: 1... Training loss: 0.001... Test loss: 0.00093\n",
      "Epoch: 1... Training loss: 0.00101... Test loss: 0.00118\n",
      "Epoch: 1... Training loss: 0.00097... Test loss: 0.00084\n",
      "Epoch: 1... Training loss: 0.00097... Test loss: 0.00105\n",
      "Epoch: 1... Training loss: 0.00095... Test loss: 0.00092\n",
      "Epoch: 1... Training loss: 0.00094... Test loss: 0.0011\n",
      "Epoch: 1... Training loss: 0.00086... Test loss: 0.00093\n",
      "Epoch: 1... Training loss: 0.00081... Test loss: 0.00105\n",
      "Epoch: 1... Training loss: 0.00079... Test loss: 0.00076\n",
      "Epoch: 1... Training loss: 0.00077... Test loss: 0.00091\n",
      "Epoch: 1... Training loss: 0.00071... Test loss: 0.00066\n",
      "Epoch: 1... Training loss: 0.00072... Test loss: 0.00068\n",
      "Epoch: 1... Training loss: 0.00067... Test loss: 0.00059\n",
      "Epoch: 1... Training loss: 0.00071... Test loss: 0.00076\n",
      "Epoch: 1... Training loss: 0.00071... Test loss: 0.00058\n",
      "Epoch: 1... Training loss: 0.00065... Test loss: 0.00073\n",
      "Epoch: 1... Training loss: 0.00066... Test loss: 0.00057\n",
      "Epoch: 1... Training loss: 0.00056... Test loss: 0.00066\n",
      "Epoch: 1... Training loss: 0.00055... Test loss: 0.00061\n",
      "Epoch: 1... Training loss: 0.00053... Test loss: 0.0006\n",
      "Epoch: 1... Training loss: 0.00053... Test loss: 0.00053\n",
      "Epoch: 1... Training loss: 0.0005... Test loss: 0.00057\n",
      "Epoch: 1... Training loss: 0.00046... Test loss: 0.00054\n",
      "Epoch: 1... Training loss: 0.00052... Test loss: 0.0005\n",
      "Epoch: 1... Training loss: 0.0006... Test loss: 0.00057\n",
      "Epoch: 1... Training loss: 0.00051... Test loss: 0.00055\n",
      "Epoch: 1... Training loss: 0.00045... Test loss: 0.00044\n",
      "Epoch: 1... Training loss: 0.00048... Test loss: 0.00044\n",
      "Epoch: 1... Training loss: 0.00047... Test loss: 0.00043\n",
      "Epoch: 1... Training loss: 0.00038... Test loss: 0.00042\n",
      "Epoch: 1... Training loss: 0.00038... Test loss: 0.00041\n",
      "Epoch: 1... Training loss: 0.00037... Test loss: 0.00042\n",
      "Epoch: 1... Training loss: 0.00036... Test loss: 0.00039\n",
      "Epoch: 1... Training loss: 0.00035... Test loss: 0.00035\n",
      "Epoch: 1... Training loss: 0.00037... Test loss: 0.00041\n",
      "Epoch: 1... Training loss: 0.00033... Test loss: 0.00034\n",
      "Epoch: 1... Training loss: 0.00031... Test loss: 0.00035\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00032\n",
      "Epoch: 1... Training loss: 0.00034... Test loss: 0.00033\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.0003\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.0003\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00028\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.0003\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.0003\n",
      "336.8970932189841\n",
      "Epoch: 1... Training loss: 1.2935... Test loss: 0.58219\n",
      "Epoch: 1... Training loss: 0.57463... Test loss: 0.21071\n",
      "Epoch: 1... Training loss: 0.33147... Test loss: 0.13304\n",
      "Epoch: 1... Training loss: 0.21301... Test loss: 0.08275\n",
      "Epoch: 1... Training loss: 0.15629... Test loss: 0.05894\n",
      "Epoch: 1... Training loss: 0.12081... Test loss: 0.05052\n",
      "Epoch: 1... Training loss: 0.10418... Test loss: 0.042\n",
      "Epoch: 1... Training loss: 0.08448... Test loss: 0.06653\n",
      "Epoch: 1... Training loss: 0.06962... Test loss: 0.02547\n",
      "Epoch: 1... Training loss: 0.06638... Test loss: 0.03698\n",
      "Epoch: 1... Training loss: 0.05857... Test loss: 0.03661\n",
      "Epoch: 1... Training loss: 0.05005... Test loss: 0.05484\n",
      "Epoch: 1... Training loss: 0.04537... Test loss: 0.02052\n",
      "Epoch: 1... Training loss: 0.04133... Test loss: 0.04984\n",
      "Epoch: 1... Training loss: 0.03994... Test loss: 0.02009\n",
      "Epoch: 1... Training loss: 0.03556... Test loss: 0.04552\n",
      "Epoch: 1... Training loss: 0.03281... Test loss: 0.02241\n",
      "Epoch: 1... Training loss: 0.03037... Test loss: 0.03154\n",
      "Epoch: 1... Training loss: 0.03054... Test loss: 0.01513\n",
      "Epoch: 1... Training loss: 0.02762... Test loss: 0.03232\n",
      "Epoch: 1... Training loss: 0.02685... Test loss: 0.01694\n",
      "Epoch: 1... Training loss: 0.02503... Test loss: 0.01829\n",
      "Epoch: 1... Training loss: 0.02382... Test loss: 0.02763\n",
      "Epoch: 1... Training loss: 0.02289... Test loss: 0.00936\n",
      "Epoch: 1... Training loss: 0.02194... Test loss: 0.02273\n",
      "Epoch: 1... Training loss: 0.02146... Test loss: 0.01193\n",
      "Epoch: 1... Training loss: 0.01995... Test loss: 0.02093\n",
      "Epoch: 1... Training loss: 0.01833... Test loss: 0.01187\n",
      "Epoch: 1... Training loss: 0.01792... Test loss: 0.01846\n",
      "Epoch: 1... Training loss: 0.01679... Test loss: 0.01182\n",
      "Epoch: 1... Training loss: 0.01632... Test loss: 0.01179\n",
      "Epoch: 1... Training loss: 0.01591... Test loss: 0.01405\n",
      "Epoch: 1... Training loss: 0.01498... Test loss: 0.00651\n",
      "Epoch: 1... Training loss: 0.01454... Test loss: 0.01518\n",
      "Epoch: 1... Training loss: 0.01378... Test loss: 0.00783\n",
      "Epoch: 1... Training loss: 0.01317... Test loss: 0.01381\n",
      "Epoch: 1... Training loss: 0.01257... Test loss: 0.01138\n",
      "Epoch: 1... Training loss: 0.0119... Test loss: 0.01089\n",
      "Epoch: 1... Training loss: 0.01175... Test loss: 0.00937\n",
      "Epoch: 1... Training loss: 0.01098... Test loss: 0.01277\n",
      "Epoch: 1... Training loss: 0.01082... Test loss: 0.00667\n",
      "Epoch: 1... Training loss: 0.01058... Test loss: 0.01058\n",
      "Epoch: 1... Training loss: 0.01028... Test loss: 0.007\n",
      "Epoch: 1... Training loss: 0.00995... Test loss: 0.00838\n",
      "Epoch: 1... Training loss: 0.00961... Test loss: 0.00855\n",
      "Epoch: 1... Training loss: 0.00914... Test loss: 0.00683\n",
      "Epoch: 1... Training loss: 0.00889... Test loss: 0.00814\n",
      "Epoch: 1... Training loss: 0.00857... Test loss: 0.00563\n",
      "Epoch: 1... Training loss: 0.0084... Test loss: 0.00889\n",
      "Epoch: 1... Training loss: 0.00818... Test loss: 0.0057\n",
      "Epoch: 1... Training loss: 0.00786... Test loss: 0.00863\n",
      "Epoch: 1... Training loss: 0.00758... Test loss: 0.00551\n",
      "Epoch: 1... Training loss: 0.0075... Test loss: 0.00813\n",
      "Epoch: 1... Training loss: 0.00723... Test loss: 0.00549\n",
      "Epoch: 1... Training loss: 0.00715... Test loss: 0.00722\n",
      "Epoch: 1... Training loss: 0.00694... Test loss: 0.00551\n",
      "Epoch: 1... Training loss: 0.00682... Test loss: 0.00658\n",
      "Epoch: 1... Training loss: 0.00662... Test loss: 0.00509\n",
      "Epoch: 1... Training loss: 0.00652... Test loss: 0.00628\n",
      "Epoch: 1... Training loss: 0.00643... Test loss: 0.00539\n",
      "Epoch: 1... Training loss: 0.00629... Test loss: 0.00673\n",
      "Epoch: 1... Training loss: 0.0061... Test loss: 0.00459\n",
      "Epoch: 1... Training loss: 0.00602... Test loss: 0.00631\n",
      "Epoch: 1... Training loss: 0.00586... Test loss: 0.00459\n",
      "Epoch: 1... Training loss: 0.00915... Test loss: 0.01163\n",
      "Epoch: 1... Training loss: 0.00924... Test loss: 0.00802\n",
      "Epoch: 1... Training loss: 0.00937... Test loss: 0.0117\n",
      "Epoch: 1... Training loss: 0.01048... Test loss: 0.00705\n",
      "Epoch: 1... Training loss: 0.01136... Test loss: 0.01143\n",
      "Epoch: 1... Training loss: 0.01025... Test loss: 0.01044\n",
      "Epoch: 1... Training loss: 0.00913... Test loss: 0.01128\n",
      "Epoch: 1... Training loss: 0.00866... Test loss: 0.01029\n",
      "Epoch: 1... Training loss: 0.00904... Test loss: 0.01267\n",
      "Epoch: 1... Training loss: 0.00904... Test loss: 0.01141\n",
      "Epoch: 1... Training loss: 0.00859... Test loss: 0.01076\n",
      "Epoch: 1... Training loss: 0.00797... Test loss: 0.01042\n",
      "Epoch: 1... Training loss: 0.00766... Test loss: 0.00996\n",
      "Epoch: 1... Training loss: 0.00772... Test loss: 0.00888\n",
      "Epoch: 1... Training loss: 0.00791... Test loss: 0.00766\n",
      "Epoch: 1... Training loss: 0.0074... Test loss: 0.00963\n",
      "Epoch: 1... Training loss: 0.00738... Test loss: 0.0077\n",
      "Epoch: 1... Training loss: 0.00709... Test loss: 0.00809\n",
      "Epoch: 1... Training loss: 0.0065... Test loss: 0.00766\n",
      "Epoch: 1... Training loss: 0.00667... Test loss: 0.00684\n",
      "Epoch: 1... Training loss: 0.0064... Test loss: 0.00815\n",
      "Epoch: 1... Training loss: 0.00592... Test loss: 0.00634\n",
      "Epoch: 1... Training loss: 0.00592... Test loss: 0.00682\n",
      "Epoch: 1... Training loss: 0.00585... Test loss: 0.00704\n",
      "Epoch: 1... Training loss: 0.00553... Test loss: 0.00657\n",
      "Epoch: 1... Training loss: 0.00538... Test loss: 0.0065\n",
      "Epoch: 1... Training loss: 0.00545... Test loss: 0.00612\n",
      "Epoch: 1... Training loss: 0.00516... Test loss: 0.00614\n",
      "Epoch: 1... Training loss: 0.00503... Test loss: 0.00538\n",
      "Epoch: 1... Training loss: 0.0051... Test loss: 0.00605\n",
      "Epoch: 1... Training loss: 0.00478... Test loss: 0.00565\n",
      "Epoch: 1... Training loss: 0.00448... Test loss: 0.00508\n",
      "Epoch: 1... Training loss: 0.00431... Test loss: 0.00495\n",
      "Epoch: 1... Training loss: 0.00435... Test loss: 0.00502\n",
      "Epoch: 1... Training loss: 0.00429... Test loss: 0.00464\n",
      "Epoch: 1... Training loss: 0.00409... Test loss: 0.00478\n",
      "Epoch: 1... Training loss: 0.004... Test loss: 0.0046\n",
      "Epoch: 1... Training loss: 0.00401... Test loss: 0.00492\n",
      "Epoch: 1... Training loss: 0.00402... Test loss: 0.00439\n",
      "Epoch: 1... Training loss: 0.00385... Test loss: 0.00439\n",
      "Epoch: 1... Training loss: 0.00363... Test loss: 0.00412\n",
      "Epoch: 1... Training loss: 0.00354... Test loss: 0.00413\n",
      "Epoch: 1... Training loss: 0.00351... Test loss: 0.00338\n",
      "Epoch: 1... Training loss: 0.0034... Test loss: 0.00378\n",
      "Epoch: 1... Training loss: 0.0034... Test loss: 0.0034\n",
      "Epoch: 1... Training loss: 0.00334... Test loss: 0.00358\n",
      "Epoch: 1... Training loss: 0.00335... Test loss: 0.00324\n",
      "Epoch: 1... Training loss: 0.0032... Test loss: 0.00369\n",
      "Epoch: 1... Training loss: 0.00317... Test loss: 0.00285\n",
      "Epoch: 1... Training loss: 0.00315... Test loss: 0.00357\n",
      "Epoch: 1... Training loss: 0.00294... Test loss: 0.00305\n",
      "Epoch: 1... Training loss: 0.00292... Test loss: 0.00334\n",
      "Epoch: 1... Training loss: 0.0029... Test loss: 0.00272\n",
      "Epoch: 1... Training loss: 0.00289... Test loss: 0.00342\n",
      "Epoch: 1... Training loss: 0.00274... Test loss: 0.00258\n",
      "Epoch: 1... Training loss: 0.00265... Test loss: 0.00305\n",
      "Epoch: 1... Training loss: 0.00264... Test loss: 0.00257\n",
      "Epoch: 1... Training loss: 0.00261... Test loss: 0.00284\n",
      "Epoch: 1... Training loss: 0.00257... Test loss: 0.00255\n",
      "Epoch: 1... Training loss: 0.00246... Test loss: 0.00279\n",
      "Epoch: 1... Training loss: 0.00248... Test loss: 0.00263\n",
      "Epoch: 1... Training loss: 0.00245... Test loss: 0.00267\n",
      "Epoch: 1... Training loss: 0.00232... Test loss: 0.00243\n",
      "Epoch: 1... Training loss: 0.00233... Test loss: 0.00219\n",
      "Epoch: 1... Training loss: 0.00217... Test loss: 0.00223\n",
      "Epoch: 1... Training loss: 0.00214... Test loss: 0.00228\n",
      "Epoch: 1... Training loss: 0.002... Test loss: 0.00203\n",
      "Epoch: 1... Training loss: 0.00212... Test loss: 0.00189\n",
      "Epoch: 1... Training loss: 0.00208... Test loss: 0.00207\n",
      "Epoch: 1... Training loss: 0.00192... Test loss: 0.00215\n",
      "Epoch: 1... Training loss: 0.00191... Test loss: 0.00209\n",
      "Epoch: 1... Training loss: 0.00197... Test loss: 0.00205\n",
      "Epoch: 1... Training loss: 0.00187... Test loss: 0.00205\n",
      "Epoch: 1... Training loss: 0.00181... Test loss: 0.00196\n",
      "Epoch: 1... Training loss: 0.00171... Test loss: 0.00214\n",
      "Epoch: 1... Training loss: 0.00177... Test loss: 0.00171\n",
      "Epoch: 1... Training loss: 0.00166... Test loss: 0.00187\n",
      "Epoch: 1... Training loss: 0.00164... Test loss: 0.00148\n",
      "Epoch: 1... Training loss: 0.00158... Test loss: 0.00185\n",
      "Epoch: 1... Training loss: 0.00157... Test loss: 0.00154\n",
      "Epoch: 1... Training loss: 0.00149... Test loss: 0.0018\n",
      "Epoch: 1... Training loss: 0.00152... Test loss: 0.00151\n",
      "Epoch: 1... Training loss: 0.00153... Test loss: 0.00176\n",
      "Epoch: 1... Training loss: 0.00151... Test loss: 0.00158\n",
      "Epoch: 1... Training loss: 0.0014... Test loss: 0.00156\n",
      "Epoch: 1... Training loss: 0.00142... Test loss: 0.00148\n",
      "Epoch: 1... Training loss: 0.00136... Test loss: 0.00138\n",
      "Epoch: 1... Training loss: 0.00133... Test loss: 0.00138\n",
      "Epoch: 1... Training loss: 0.00124... Test loss: 0.00135\n",
      "Epoch: 1... Training loss: 0.00122... Test loss: 0.00128\n",
      "Epoch: 1... Training loss: 0.00117... Test loss: 0.00128\n",
      "Epoch: 1... Training loss: 0.00116... Test loss: 0.0013\n",
      "Epoch: 1... Training loss: 0.00118... Test loss: 0.00128\n",
      "Epoch: 1... Training loss: 0.00114... Test loss: 0.00132\n",
      "Epoch: 1... Training loss: 0.0012... Test loss: 0.00124\n",
      "Epoch: 1... Training loss: 0.00109... Test loss: 0.00137\n",
      "Epoch: 1... Training loss: 0.00105... Test loss: 0.00104\n",
      "Epoch: 1... Training loss: 0.00104... Test loss: 0.00109\n",
      "Epoch: 1... Training loss: 0.00097... Test loss: 0.00103\n",
      "Epoch: 1... Training loss: 0.00092... Test loss: 0.00108\n",
      "Epoch: 1... Training loss: 0.00089... Test loss: 0.00095\n",
      "Epoch: 1... Training loss: 0.00086... Test loss: 0.00102\n",
      "Epoch: 1... Training loss: 0.00081... Test loss: 0.00087\n",
      "Epoch: 1... Training loss: 0.00082... Test loss: 0.00078\n",
      "Epoch: 1... Training loss: 0.0008... Test loss: 0.00084\n",
      "Epoch: 1... Training loss: 0.00079... Test loss: 0.00067\n",
      "Epoch: 1... Training loss: 0.00082... Test loss: 0.00082\n",
      "Epoch: 1... Training loss: 0.00076... Test loss: 0.00071\n",
      "Epoch: 1... Training loss: 0.00073... Test loss: 0.00075\n",
      "Epoch: 1... Training loss: 0.00063... Test loss: 0.00061\n",
      "Epoch: 1... Training loss: 0.00061... Test loss: 0.00068\n",
      "Epoch: 1... Training loss: 0.00057... Test loss: 0.00062\n",
      "Epoch: 1... Training loss: 0.00054... Test loss: 0.00078\n",
      "Epoch: 1... Training loss: 0.00054... Test loss: 0.00051\n",
      "Epoch: 1... Training loss: 0.00052... Test loss: 0.00064\n",
      "Epoch: 1... Training loss: 0.00051... Test loss: 0.0005\n",
      "Epoch: 1... Training loss: 0.00048... Test loss: 0.00061\n",
      "Epoch: 1... Training loss: 0.00051... Test loss: 0.00049\n",
      "Epoch: 1... Training loss: 0.00039... Test loss: 0.00067\n",
      "Epoch: 1... Training loss: 0.00038... Test loss: 0.00041\n",
      "Epoch: 1... Training loss: 0.00035... Test loss: 0.00054\n",
      "Epoch: 1... Training loss: 0.00034... Test loss: 0.00034\n",
      "Epoch: 1... Training loss: 0.00036... Test loss: 0.00043\n",
      "Epoch: 1... Training loss: 0.00035... Test loss: 0.00036\n",
      "Epoch: 1... Training loss: 0.00032... Test loss: 0.00038\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.0003\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00036\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00035\n",
      "Epoch: 1... Training loss: 0.00026... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00028\n",
      "Epoch: 1... Training loss: 0.00029... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00017\n",
      "269.33134053397225\n",
      "Epoch: 1... Training loss: 1.08178... Test loss: 0.45337\n",
      "Epoch: 1... Training loss: 0.52081... Test loss: 0.18706\n",
      "Epoch: 1... Training loss: 0.33304... Test loss: 0.11666\n",
      "Epoch: 1... Training loss: 0.2218... Test loss: 0.07328\n",
      "Epoch: 1... Training loss: 0.14862... Test loss: 0.04875\n",
      "Epoch: 1... Training loss: 0.12322... Test loss: 0.03898\n",
      "Epoch: 1... Training loss: 0.09482... Test loss: 0.0318\n",
      "Epoch: 1... Training loss: 0.07908... Test loss: 0.01909\n",
      "Epoch: 1... Training loss: 0.0724... Test loss: 0.0273\n",
      "Epoch: 1... Training loss: 0.0612... Test loss: 0.02314\n",
      "Epoch: 1... Training loss: 0.05627... Test loss: 0.01837\n",
      "Epoch: 1... Training loss: 0.05159... Test loss: 0.01889\n",
      "Epoch: 1... Training loss: 0.04425... Test loss: 0.01759\n",
      "Epoch: 1... Training loss: 0.0409... Test loss: 0.00778\n",
      "Epoch: 1... Training loss: 0.03884... Test loss: 0.01916\n",
      "Epoch: 1... Training loss: 0.03411... Test loss: 0.00807\n",
      "Epoch: 1... Training loss: 0.03254... Test loss: 0.01796\n",
      "Epoch: 1... Training loss: 0.03129... Test loss: 0.00763\n",
      "Epoch: 1... Training loss: 0.02859... Test loss: 0.01425\n",
      "Epoch: 1... Training loss: 0.02784... Test loss: 0.00795\n",
      "Epoch: 1... Training loss: 0.02449... Test loss: 0.01298\n",
      "Epoch: 1... Training loss: 0.02288... Test loss: 0.00859\n",
      "Epoch: 1... Training loss: 0.02233... Test loss: 0.01457\n",
      "Epoch: 1... Training loss: 0.02164... Test loss: 0.00769\n",
      "Epoch: 1... Training loss: 0.01981... Test loss: 0.0143\n",
      "Epoch: 1... Training loss: 0.01917... Test loss: 0.00867\n",
      "Epoch: 1... Training loss: 0.01849... Test loss: 0.0118\n",
      "Epoch: 1... Training loss: 0.01744... Test loss: 0.00933\n",
      "Epoch: 1... Training loss: 0.01684... Test loss: 0.01404\n",
      "Epoch: 1... Training loss: 0.01618... Test loss: 0.00881\n",
      "Epoch: 1... Training loss: 0.01549... Test loss: 0.01462\n",
      "Epoch: 1... Training loss: 0.01497... Test loss: 0.00721\n",
      "Epoch: 1... Training loss: 0.01436... Test loss: 0.01353\n",
      "Epoch: 1... Training loss: 0.01365... Test loss: 0.00483\n",
      "Epoch: 1... Training loss: 0.01322... Test loss: 0.0105\n",
      "Epoch: 1... Training loss: 0.0123... Test loss: 0.00638\n",
      "Epoch: 1... Training loss: 0.01188... Test loss: 0.01026\n",
      "Epoch: 1... Training loss: 0.01147... Test loss: 0.00568\n",
      "Epoch: 1... Training loss: 0.01083... Test loss: 0.00989\n",
      "Epoch: 1... Training loss: 0.01066... Test loss: 0.00655\n",
      "Epoch: 1... Training loss: 0.01022... Test loss: 0.00952\n",
      "Epoch: 1... Training loss: 0.01002... Test loss: 0.0063\n",
      "Epoch: 1... Training loss: 0.00961... Test loss: 0.00838\n",
      "Epoch: 1... Training loss: 0.00926... Test loss: 0.00626\n",
      "Epoch: 1... Training loss: 0.00907... Test loss: 0.00757\n",
      "Epoch: 1... Training loss: 0.00887... Test loss: 0.00679\n",
      "Epoch: 1... Training loss: 0.00848... Test loss: 0.00849\n",
      "Epoch: 1... Training loss: 0.0083... Test loss: 0.00729\n",
      "Epoch: 1... Training loss: 0.00803... Test loss: 0.00821\n",
      "Epoch: 1... Training loss: 0.00786... Test loss: 0.00649\n",
      "Epoch: 1... Training loss: 0.00755... Test loss: 0.00793\n",
      "Epoch: 1... Training loss: 0.00736... Test loss: 0.00537\n",
      "Epoch: 1... Training loss: 0.00725... Test loss: 0.00759\n",
      "Epoch: 1... Training loss: 0.00708... Test loss: 0.00503\n",
      "Epoch: 1... Training loss: 0.00692... Test loss: 0.00667\n",
      "Epoch: 1... Training loss: 0.00669... Test loss: 0.00516\n",
      "Epoch: 1... Training loss: 0.00656... Test loss: 0.00608\n",
      "Epoch: 1... Training loss: 0.00636... Test loss: 0.00545\n",
      "Epoch: 1... Training loss: 0.00619... Test loss: 0.00608\n",
      "Epoch: 1... Training loss: 0.00601... Test loss: 0.00594\n",
      "Epoch: 1... Training loss: 0.00594... Test loss: 0.00581\n",
      "Epoch: 1... Training loss: 0.0058... Test loss: 0.00494\n",
      "Epoch: 1... Training loss: 0.00571... Test loss: 0.00535\n",
      "Epoch: 1... Training loss: 0.00553... Test loss: 0.00458\n",
      "Epoch: 1... Training loss: 0.01164... Test loss: 0.0093\n",
      "Epoch: 1... Training loss: 0.00981... Test loss: 0.01176\n",
      "Epoch: 1... Training loss: 0.01176... Test loss: 0.00885\n",
      "Epoch: 1... Training loss: 0.00977... Test loss: 0.01208\n",
      "Epoch: 1... Training loss: 0.01071... Test loss: 0.01271\n",
      "Epoch: 1... Training loss: 0.00977... Test loss: 0.0103\n",
      "Epoch: 1... Training loss: 0.0083... Test loss: 0.01008\n",
      "Epoch: 1... Training loss: 0.00928... Test loss: 0.00897\n",
      "Epoch: 1... Training loss: 0.00856... Test loss: 0.00932\n",
      "Epoch: 1... Training loss: 0.00808... Test loss: 0.00816\n",
      "Epoch: 1... Training loss: 0.00828... Test loss: 0.00938\n",
      "Epoch: 1... Training loss: 0.0079... Test loss: 0.01036\n",
      "Epoch: 1... Training loss: 0.00782... Test loss: 0.00776\n",
      "Epoch: 1... Training loss: 0.00742... Test loss: 0.01027\n",
      "Epoch: 1... Training loss: 0.00736... Test loss: 0.00741\n",
      "Epoch: 1... Training loss: 0.00732... Test loss: 0.0091\n",
      "Epoch: 1... Training loss: 0.00689... Test loss: 0.00681\n",
      "Epoch: 1... Training loss: 0.00664... Test loss: 0.0071\n",
      "Epoch: 1... Training loss: 0.0063... Test loss: 0.00649\n",
      "Epoch: 1... Training loss: 0.00605... Test loss: 0.00688\n",
      "Epoch: 1... Training loss: 0.00583... Test loss: 0.00593\n",
      "Epoch: 1... Training loss: 0.00572... Test loss: 0.00575\n",
      "Epoch: 1... Training loss: 0.00574... Test loss: 0.00567\n",
      "Epoch: 1... Training loss: 0.00546... Test loss: 0.00596\n",
      "Epoch: 1... Training loss: 0.00524... Test loss: 0.00554\n",
      "Epoch: 1... Training loss: 0.00508... Test loss: 0.00562\n",
      "Epoch: 1... Training loss: 0.00504... Test loss: 0.00571\n",
      "Epoch: 1... Training loss: 0.0051... Test loss: 0.00502\n",
      "Epoch: 1... Training loss: 0.00485... Test loss: 0.0057\n",
      "Epoch: 1... Training loss: 0.00472... Test loss: 0.00425\n",
      "Epoch: 1... Training loss: 0.00446... Test loss: 0.0046\n",
      "Epoch: 1... Training loss: 0.00439... Test loss: 0.00446\n",
      "Epoch: 1... Training loss: 0.00431... Test loss: 0.00414\n",
      "Epoch: 1... Training loss: 0.00424... Test loss: 0.00472\n",
      "Epoch: 1... Training loss: 0.004... Test loss: 0.00379\n",
      "Epoch: 1... Training loss: 0.00395... Test loss: 0.00425\n",
      "Epoch: 1... Training loss: 0.00385... Test loss: 0.00461\n",
      "Epoch: 1... Training loss: 0.0038... Test loss: 0.00377\n",
      "Epoch: 1... Training loss: 0.00361... Test loss: 0.00408\n",
      "Epoch: 1... Training loss: 0.00361... Test loss: 0.00391\n",
      "Epoch: 1... Training loss: 0.00358... Test loss: 0.00349\n",
      "Epoch: 1... Training loss: 0.00345... Test loss: 0.00352\n",
      "Epoch: 1... Training loss: 0.00341... Test loss: 0.00354\n",
      "Epoch: 1... Training loss: 0.00331... Test loss: 0.00318\n",
      "Epoch: 1... Training loss: 0.00334... Test loss: 0.0036\n",
      "Epoch: 1... Training loss: 0.00327... Test loss: 0.00267\n",
      "Epoch: 1... Training loss: 0.00336... Test loss: 0.00406\n",
      "Epoch: 1... Training loss: 0.00309... Test loss: 0.00294\n",
      "Epoch: 1... Training loss: 0.00318... Test loss: 0.00335\n",
      "Epoch: 1... Training loss: 0.00309... Test loss: 0.00322\n",
      "Epoch: 1... Training loss: 0.00297... Test loss: 0.00304\n",
      "Epoch: 1... Training loss: 0.00288... Test loss: 0.00293\n",
      "Epoch: 1... Training loss: 0.0029... Test loss: 0.0029\n",
      "Epoch: 1... Training loss: 0.00292... Test loss: 0.00319\n",
      "Epoch: 1... Training loss: 0.00288... Test loss: 0.00248\n",
      "Epoch: 1... Training loss: 0.00281... Test loss: 0.00303\n",
      "Epoch: 1... Training loss: 0.00275... Test loss: 0.00254\n",
      "Epoch: 1... Training loss: 0.00282... Test loss: 0.00307\n",
      "Epoch: 1... Training loss: 0.00259... Test loss: 0.00256\n",
      "Epoch: 1... Training loss: 0.00243... Test loss: 0.00285\n",
      "Epoch: 1... Training loss: 0.00246... Test loss: 0.00236\n",
      "Epoch: 1... Training loss: 0.00239... Test loss: 0.00294\n",
      "Epoch: 1... Training loss: 0.00238... Test loss: 0.00239\n",
      "Epoch: 1... Training loss: 0.00232... Test loss: 0.00253\n",
      "Epoch: 1... Training loss: 0.00229... Test loss: 0.00239\n",
      "Epoch: 1... Training loss: 0.00239... Test loss: 0.00239\n",
      "Epoch: 1... Training loss: 0.00217... Test loss: 0.00198\n",
      "Epoch: 1... Training loss: 0.00217... Test loss: 0.00237\n",
      "Epoch: 1... Training loss: 0.00208... Test loss: 0.00217\n",
      "Epoch: 1... Training loss: 0.00205... Test loss: 0.00208\n",
      "Epoch: 1... Training loss: 0.00197... Test loss: 0.00235\n",
      "Epoch: 1... Training loss: 0.00195... Test loss: 0.00195\n",
      "Epoch: 1... Training loss: 0.00193... Test loss: 0.00178\n",
      "Epoch: 1... Training loss: 0.00195... Test loss: 0.00174\n",
      "Epoch: 1... Training loss: 0.00185... Test loss: 0.00194\n",
      "Epoch: 1... Training loss: 0.00185... Test loss: 0.00172\n",
      "Epoch: 1... Training loss: 0.0018... Test loss: 0.00188\n",
      "Epoch: 1... Training loss: 0.0019... Test loss: 0.00152\n",
      "Epoch: 1... Training loss: 0.00176... Test loss: 0.00203\n",
      "Epoch: 1... Training loss: 0.00162... Test loss: 0.00157\n",
      "Epoch: 1... Training loss: 0.00155... Test loss: 0.00221\n",
      "Epoch: 1... Training loss: 0.00161... Test loss: 0.00151\n",
      "Epoch: 1... Training loss: 0.00148... Test loss: 0.00177\n",
      "Epoch: 1... Training loss: 0.00149... Test loss: 0.0013\n",
      "Epoch: 1... Training loss: 0.0014... Test loss: 0.00149\n",
      "Epoch: 1... Training loss: 0.00141... Test loss: 0.00136\n",
      "Epoch: 1... Training loss: 0.00139... Test loss: 0.00155\n",
      "Epoch: 1... Training loss: 0.00141... Test loss: 0.00134\n",
      "Epoch: 1... Training loss: 0.00131... Test loss: 0.00163\n",
      "Epoch: 1... Training loss: 0.00124... Test loss: 0.0012\n",
      "Epoch: 1... Training loss: 0.00122... Test loss: 0.00151\n",
      "Epoch: 1... Training loss: 0.00118... Test loss: 0.00104\n",
      "Epoch: 1... Training loss: 0.00117... Test loss: 0.00125\n",
      "Epoch: 1... Training loss: 0.00106... Test loss: 0.00094\n",
      "Epoch: 1... Training loss: 0.00104... Test loss: 0.00126\n",
      "Epoch: 1... Training loss: 0.00102... Test loss: 0.00095\n",
      "Epoch: 1... Training loss: 0.00108... Test loss: 0.00117\n",
      "Epoch: 1... Training loss: 0.00102... Test loss: 0.00101\n",
      "Epoch: 1... Training loss: 0.00099... Test loss: 0.00111\n",
      "Epoch: 1... Training loss: 0.00089... Test loss: 0.00103\n",
      "Epoch: 1... Training loss: 0.00089... Test loss: 0.00103\n",
      "Epoch: 1... Training loss: 0.00079... Test loss: 0.00095\n",
      "Epoch: 1... Training loss: 0.00084... Test loss: 0.00085\n",
      "Epoch: 1... Training loss: 0.00077... Test loss: 0.0009\n",
      "Epoch: 1... Training loss: 0.00076... Test loss: 0.0008\n",
      "Epoch: 1... Training loss: 0.00072... Test loss: 0.00097\n",
      "Epoch: 1... Training loss: 0.00072... Test loss: 0.00071\n",
      "Epoch: 1... Training loss: 0.00069... Test loss: 0.00081\n",
      "Epoch: 1... Training loss: 0.00064... Test loss: 0.00074\n",
      "Epoch: 1... Training loss: 0.00059... Test loss: 0.00079\n",
      "Epoch: 1... Training loss: 0.00058... Test loss: 0.00066\n",
      "Epoch: 1... Training loss: 0.00059... Test loss: 0.00068\n",
      "Epoch: 1... Training loss: 0.00059... Test loss: 0.00052\n",
      "Epoch: 1... Training loss: 0.00054... Test loss: 0.00061\n",
      "Epoch: 1... Training loss: 0.00048... Test loss: 0.00053\n",
      "Epoch: 1... Training loss: 0.00048... Test loss: 0.00056\n",
      "Epoch: 1... Training loss: 0.00048... Test loss: 0.00044\n",
      "Epoch: 1... Training loss: 0.00044... Test loss: 0.00052\n",
      "Epoch: 1... Training loss: 0.00042... Test loss: 0.00044\n",
      "Epoch: 1... Training loss: 0.00043... Test loss: 0.00047\n",
      "Epoch: 1... Training loss: 0.0004... Test loss: 0.00041\n",
      "Epoch: 1... Training loss: 0.00044... Test loss: 0.00037\n",
      "Epoch: 1... Training loss: 0.00036... Test loss: 0.00044\n",
      "Epoch: 1... Training loss: 0.00036... Test loss: 0.00035\n",
      "Epoch: 1... Training loss: 0.00031... Test loss: 0.00046\n",
      "Epoch: 1... Training loss: 0.00033... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00048\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00038\n",
      "Epoch: 1... Training loss: 0.00031... Test loss: 0.00028\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00033\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00024\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00035\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00024\n",
      "298.0180579267908\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1... Training loss: 0.00048... Test loss: 0.00046\n",
      "Epoch: 1... Training loss: 0.00044... Test loss: 0.0005\n",
      "Epoch: 1... Training loss: 0.00048... Test loss: 0.00048\n",
      "Epoch: 1... Training loss: 0.00043... Test loss: 0.00046\n",
      "Epoch: 1... Training loss: 0.00044... Test loss: 0.00042\n",
      "Epoch: 1... Training loss: 0.00041... Test loss: 0.00042\n",
      "Epoch: 1... Training loss: 0.00037... Test loss: 0.00035\n",
      "Epoch: 1... Training loss: 0.00037... Test loss: 0.00039\n",
      "Epoch: 1... Training loss: 0.00035... Test loss: 0.00033\n",
      "Epoch: 1... Training loss: 0.00034... Test loss: 0.00034\n",
      "Epoch: 1... Training loss: 0.00037... Test loss: 0.00035\n",
      "Epoch: 1... Training loss: 0.00035... Test loss: 0.00031\n",
      "Epoch: 1... Training loss: 0.00032... Test loss: 0.00031\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00028\n",
      "Epoch: 1... Training loss: 0.00032... Test loss: 0.0003\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00028\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00028\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00028\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00024\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.0003\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00025\n",
      "328.901621079538\n",
      "Epoch: 1... Training loss: 1.01694... Test loss: 0.35924\n",
      "Epoch: 1... Training loss: 0.49282... Test loss: 0.17483\n",
      "Epoch: 1... Training loss: 0.28709... Test loss: 0.10858\n",
      "Epoch: 1... Training loss: 0.19853... Test loss: 0.0782\n",
      "Epoch: 1... Training loss: 0.13768... Test loss: 0.05262\n",
      "Epoch: 1... Training loss: 0.11162... Test loss: 0.03794\n",
      "Epoch: 1... Training loss: 0.09311... Test loss: 0.03895\n",
      "Epoch: 1... Training loss: 0.07748... Test loss: 0.02303\n",
      "Epoch: 1... Training loss: 0.06663... Test loss: 0.03251\n",
      "Epoch: 1... Training loss: 0.05831... Test loss: 0.0218\n",
      "Epoch: 1... Training loss: 0.05265... Test loss: 0.02691\n",
      "Epoch: 1... Training loss: 0.04759... Test loss: 0.02155\n",
      "Epoch: 1... Training loss: 0.04182... Test loss: 0.02237\n",
      "Epoch: 1... Training loss: 0.03791... Test loss: 0.0264\n",
      "Epoch: 1... Training loss: 0.03545... Test loss: 0.01236\n",
      "Epoch: 1... Training loss: 0.03307... Test loss: 0.02606\n",
      "Epoch: 1... Training loss: 0.03025... Test loss: 0.02759\n",
      "Epoch: 1... Training loss: 0.02885... Test loss: 0.02567\n",
      "Epoch: 1... Training loss: 0.02709... Test loss: 0.02807\n",
      "Epoch: 1... Training loss: 0.02644... Test loss: 0.01186\n",
      "Epoch: 1... Training loss: 0.02469... Test loss: 0.02612\n",
      "Epoch: 1... Training loss: 0.02402... Test loss: 0.01222\n",
      "Epoch: 1... Training loss: 0.0228... Test loss: 0.01893\n",
      "Epoch: 1... Training loss: 0.02146... Test loss: 0.01735\n",
      "Epoch: 1... Training loss: 0.0201... Test loss: 0.01944\n",
      "Epoch: 1... Training loss: 0.01932... Test loss: 0.01391\n",
      "Epoch: 1... Training loss: 0.0182... Test loss: 0.01314\n",
      "Epoch: 1... Training loss: 0.01727... Test loss: 0.02043\n",
      "Epoch: 1... Training loss: 0.01623... Test loss: 0.01029\n",
      "Epoch: 1... Training loss: 0.01569... Test loss: 0.01302\n",
      "Epoch: 1... Training loss: 0.01529... Test loss: 0.01639\n",
      "Epoch: 1... Training loss: 0.01449... Test loss: 0.01024\n",
      "Epoch: 1... Training loss: 0.01417... Test loss: 0.01207\n",
      "Epoch: 1... Training loss: 0.01327... Test loss: 0.0136\n",
      "Epoch: 1... Training loss: 0.01294... Test loss: 0.00709\n",
      "Epoch: 1... Training loss: 0.01243... Test loss: 0.01189\n",
      "Epoch: 1... Training loss: 0.0121... Test loss: 0.00773\n",
      "Epoch: 1... Training loss: 0.01158... Test loss: 0.01369\n",
      "Epoch: 1... Training loss: 0.01124... Test loss: 0.00812\n",
      "Epoch: 1... Training loss: 0.01078... Test loss: 0.01345\n",
      "Epoch: 1... Training loss: 0.01058... Test loss: 0.0076\n",
      "Epoch: 1... Training loss: 0.01011... Test loss: 0.01146\n",
      "Epoch: 1... Training loss: 0.00986... Test loss: 0.0097\n",
      "Epoch: 1... Training loss: 0.00957... Test loss: 0.00759\n",
      "Epoch: 1... Training loss: 0.00933... Test loss: 0.00956\n",
      "Epoch: 1... Training loss: 0.00893... Test loss: 0.00741\n",
      "Epoch: 1... Training loss: 0.0087... Test loss: 0.0091\n",
      "Epoch: 1... Training loss: 0.0085... Test loss: 0.0069\n",
      "Epoch: 1... Training loss: 0.00813... Test loss: 0.00879\n",
      "Epoch: 1... Training loss: 0.00798... Test loss: 0.0062\n",
      "Epoch: 1... Training loss: 0.00772... Test loss: 0.00888\n",
      "Epoch: 1... Training loss: 0.00746... Test loss: 0.00496\n",
      "Epoch: 1... Training loss: 0.00741... Test loss: 0.00862\n",
      "Epoch: 1... Training loss: 0.00704... Test loss: 0.00571\n",
      "Epoch: 1... Training loss: 0.00711... Test loss: 0.0072\n",
      "Epoch: 1... Training loss: 0.00675... Test loss: 0.0056\n",
      "Epoch: 1... Training loss: 0.00668... Test loss: 0.00676\n",
      "Epoch: 1... Training loss: 0.00634... Test loss: 0.00525\n",
      "Epoch: 1... Training loss: 0.00628... Test loss: 0.00633\n",
      "Epoch: 1... Training loss: 0.00607... Test loss: 0.00551\n",
      "Epoch: 1... Training loss: 0.00602... Test loss: 0.00623\n",
      "Epoch: 1... Training loss: 0.00586... Test loss: 0.00586\n",
      "Epoch: 1... Training loss: 0.00578... Test loss: 0.00585\n",
      "Epoch: 1... Training loss: 0.00552... Test loss: 0.00532\n",
      "Epoch: 1... Training loss: 0.00985... Test loss: 0.01134\n",
      "Epoch: 1... Training loss: 0.01159... Test loss: 0.00928\n",
      "Epoch: 1... Training loss: 0.01063... Test loss: 0.0102\n",
      "Epoch: 1... Training loss: 0.00953... Test loss: 0.01006\n",
      "Epoch: 1... Training loss: 0.01007... Test loss: 0.01042\n",
      "Epoch: 1... Training loss: 0.01112... Test loss: 0.00747\n",
      "Epoch: 1... Training loss: 0.00959... Test loss: 0.01242\n",
      "Epoch: 1... Training loss: 0.00911... Test loss: 0.0097\n",
      "Epoch: 1... Training loss: 0.00947... Test loss: 0.01209\n",
      "Epoch: 1... Training loss: 0.00851... Test loss: 0.0093\n",
      "Epoch: 1... Training loss: 0.00783... Test loss: 0.01022\n",
      "Epoch: 1... Training loss: 0.00831... Test loss: 0.00948\n",
      "Epoch: 1... Training loss: 0.00713... Test loss: 0.01025\n",
      "Epoch: 1... Training loss: 0.00786... Test loss: 0.00934\n",
      "Epoch: 1... Training loss: 0.00727... Test loss: 0.00929\n",
      "Epoch: 1... Training loss: 0.00675... Test loss: 0.0092\n",
      "Epoch: 1... Training loss: 0.00634... Test loss: 0.00841\n",
      "Epoch: 1... Training loss: 0.00671... Test loss: 0.0076\n",
      "Epoch: 1... Training loss: 0.00601... Test loss: 0.0074\n",
      "Epoch: 1... Training loss: 0.00621... Test loss: 0.00749\n",
      "Epoch: 1... Training loss: 0.00576... Test loss: 0.00613\n",
      "Epoch: 1... Training loss: 0.00581... Test loss: 0.00671\n",
      "Epoch: 1... Training loss: 0.00556... Test loss: 0.00603\n",
      "Epoch: 1... Training loss: 0.00538... Test loss: 0.00632\n",
      "Epoch: 1... Training loss: 0.00502... Test loss: 0.00619\n",
      "Epoch: 1... Training loss: 0.00505... Test loss: 0.00572\n",
      "Epoch: 1... Training loss: 0.00504... Test loss: 0.00607\n",
      "Epoch: 1... Training loss: 0.00468... Test loss: 0.00482\n",
      "Epoch: 1... Training loss: 0.00466... Test loss: 0.00496\n",
      "Epoch: 1... Training loss: 0.00451... Test loss: 0.00447\n",
      "Epoch: 1... Training loss: 0.00429... Test loss: 0.00437\n",
      "Epoch: 1... Training loss: 0.00423... Test loss: 0.00422\n",
      "Epoch: 1... Training loss: 0.00398... Test loss: 0.00433\n",
      "Epoch: 1... Training loss: 0.00389... Test loss: 0.00461\n",
      "Epoch: 1... Training loss: 0.00384... Test loss: 0.00433\n",
      "Epoch: 1... Training loss: 0.00366... Test loss: 0.00449\n",
      "Epoch: 1... Training loss: 0.00357... Test loss: 0.00402\n",
      "Epoch: 1... Training loss: 0.00369... Test loss: 0.00414\n",
      "Epoch: 1... Training loss: 0.00348... Test loss: 0.00416\n",
      "Epoch: 1... Training loss: 0.00335... Test loss: 0.00364\n",
      "Epoch: 1... Training loss: 0.00347... Test loss: 0.00339\n",
      "Epoch: 1... Training loss: 0.00331... Test loss: 0.00425\n",
      "Epoch: 1... Training loss: 0.00318... Test loss: 0.00345\n",
      "Epoch: 1... Training loss: 0.00302... Test loss: 0.00354\n",
      "Epoch: 1... Training loss: 0.00304... Test loss: 0.0033\n",
      "Epoch: 1... Training loss: 0.00307... Test loss: 0.00339\n",
      "Epoch: 1... Training loss: 0.00284... Test loss: 0.00333\n",
      "Epoch: 1... Training loss: 0.00282... Test loss: 0.00326\n",
      "Epoch: 1... Training loss: 0.00278... Test loss: 0.00283\n",
      "Epoch: 1... Training loss: 0.00265... Test loss: 0.00318\n",
      "Epoch: 1... Training loss: 0.0027... Test loss: 0.00243\n",
      "Epoch: 1... Training loss: 0.00259... Test loss: 0.0034\n",
      "Epoch: 1... Training loss: 0.00263... Test loss: 0.00237\n",
      "Epoch: 1... Training loss: 0.00244... Test loss: 0.00277\n",
      "Epoch: 1... Training loss: 0.00241... Test loss: 0.00235\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1... Training loss: 0.00236... Test loss: 0.00315\n",
      "Epoch: 1... Training loss: 0.00231... Test loss: 0.00255\n",
      "Epoch: 1... Training loss: 0.00224... Test loss: 0.00254\n",
      "Epoch: 1... Training loss: 0.00219... Test loss: 0.00224\n",
      "Epoch: 1... Training loss: 0.00222... Test loss: 0.00236\n",
      "Epoch: 1... Training loss: 0.0021... Test loss: 0.00217\n",
      "Epoch: 1... Training loss: 0.00206... Test loss: 0.00221\n",
      "Epoch: 1... Training loss: 0.002... Test loss: 0.0019\n",
      "Epoch: 1... Training loss: 0.00194... Test loss: 0.00255\n",
      "Epoch: 1... Training loss: 0.00205... Test loss: 0.00196\n",
      "Epoch: 1... Training loss: 0.00192... Test loss: 0.00216\n",
      "Epoch: 1... Training loss: 0.0019... Test loss: 0.00202\n",
      "Epoch: 1... Training loss: 0.00192... Test loss: 0.00211\n",
      "Epoch: 1... Training loss: 0.00175... Test loss: 0.00187\n",
      "Epoch: 1... Training loss: 0.00179... Test loss: 0.00211\n",
      "Epoch: 1... Training loss: 0.00181... Test loss: 0.00166\n",
      "Epoch: 1... Training loss: 0.00166... Test loss: 0.00199\n",
      "Epoch: 1... Training loss: 0.00157... Test loss: 0.00156\n",
      "Epoch: 1... Training loss: 0.00154... Test loss: 0.00181\n",
      "Epoch: 1... Training loss: 0.00158... Test loss: 0.00142\n",
      "Epoch: 1... Training loss: 0.00153... Test loss: 0.00165\n",
      "Epoch: 1... Training loss: 0.0014... Test loss: 0.00139\n",
      "Epoch: 1... Training loss: 0.00139... Test loss: 0.0016\n",
      "Epoch: 1... Training loss: 0.00144... Test loss: 0.00134\n",
      "Epoch: 1... Training loss: 0.00131... Test loss: 0.00155\n",
      "Epoch: 1... Training loss: 0.00125... Test loss: 0.00111\n",
      "Epoch: 1... Training loss: 0.00118... Test loss: 0.00157\n",
      "Epoch: 1... Training loss: 0.00124... Test loss: 0.00122\n",
      "Epoch: 1... Training loss: 0.0012... Test loss: 0.00134\n",
      "Epoch: 1... Training loss: 0.00114... Test loss: 0.00127\n",
      "Epoch: 1... Training loss: 0.00114... Test loss: 0.00122\n",
      "Epoch: 1... Training loss: 0.00106... Test loss: 0.00114\n",
      "Epoch: 1... Training loss: 0.001... Test loss: 0.00101\n",
      "Epoch: 1... Training loss: 0.001... Test loss: 0.00104\n",
      "Epoch: 1... Training loss: 0.00093... Test loss: 0.00093\n",
      "Epoch: 1... Training loss: 0.00095... Test loss: 0.00102\n",
      "Epoch: 1... Training loss: 0.0009... Test loss: 0.00091\n",
      "Epoch: 1... Training loss: 0.0009... Test loss: 0.001\n",
      "Epoch: 1... Training loss: 0.00088... Test loss: 0.00086\n",
      "Epoch: 1... Training loss: 0.00086... Test loss: 0.00082\n",
      "Epoch: 1... Training loss: 0.00086... Test loss: 0.00085\n",
      "Epoch: 1... Training loss: 0.00079... Test loss: 0.0009\n",
      "Epoch: 1... Training loss: 0.00076... Test loss: 0.00104\n",
      "Epoch: 1... Training loss: 0.00067... Test loss: 0.00085\n",
      "Epoch: 1... Training loss: 0.00066... Test loss: 0.00078\n",
      "Epoch: 1... Training loss: 0.00072... Test loss: 0.00084\n",
      "Epoch: 1... Training loss: 0.00061... Test loss: 0.0008\n",
      "Epoch: 1... Training loss: 0.0006... Test loss: 0.00068\n",
      "Epoch: 1... Training loss: 0.0006... Test loss: 0.00071\n",
      "Epoch: 1... Training loss: 0.00055... Test loss: 0.00065\n",
      "Epoch: 1... Training loss: 0.00052... Test loss: 0.00054\n",
      "Epoch: 1... Training loss: 0.00045... Test loss: 0.00053\n",
      "Epoch: 1... Training loss: 0.00053... Test loss: 0.00056\n",
      "Epoch: 1... Training loss: 0.00043... Test loss: 0.00052\n",
      "Epoch: 1... Training loss: 0.00042... Test loss: 0.00052\n",
      "Epoch: 1... Training loss: 0.0004... Test loss: 0.00042\n",
      "Epoch: 1... Training loss: 0.00037... Test loss: 0.00048\n",
      "Epoch: 1... Training loss: 0.00036... Test loss: 0.00036\n",
      "Epoch: 1... Training loss: 0.00034... Test loss: 0.00034\n",
      "Epoch: 1... Training loss: 0.00034... Test loss: 0.00037\n",
      "Epoch: 1... Training loss: 0.00037... Test loss: 0.00035\n",
      "Epoch: 1... Training loss: 0.00031... Test loss: 0.00036\n",
      "Epoch: 1... Training loss: 0.00029... Test loss: 0.00035\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.0003\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00028\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00026... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 9e-05... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.0001\n",
      "Epoch: 1... Training loss: 0.0001... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.0001\n",
      "240.2766504099709\n",
      "Epoch: 1... Training loss: 0.952... Test loss: 0.32288\n",
      "Epoch: 1... Training loss: 0.47974... Test loss: 0.14523\n",
      "Epoch: 1... Training loss: 0.28335... Test loss: 0.07622\n",
      "Epoch: 1... Training loss: 0.18905... Test loss: 0.04328\n",
      "Epoch: 1... Training loss: 0.13415... Test loss: 0.03396\n",
      "Epoch: 1... Training loss: 0.10709... Test loss: 0.02805\n",
      "Epoch: 1... Training loss: 0.08701... Test loss: 0.01773\n",
      "Epoch: 1... Training loss: 0.07266... Test loss: 0.0177\n",
      "Epoch: 1... Training loss: 0.06508... Test loss: 0.01299\n",
      "Epoch: 1... Training loss: 0.05689... Test loss: 0.01869\n",
      "Epoch: 1... Training loss: 0.05369... Test loss: 0.00893\n",
      "Epoch: 1... Training loss: 0.04565... Test loss: 0.01669\n",
      "Epoch: 1... Training loss: 0.0411... Test loss: 0.01778\n",
      "Epoch: 1... Training loss: 0.03845... Test loss: 0.02258\n",
      "Epoch: 1... Training loss: 0.0354... Test loss: 0.01236\n",
      "Epoch: 1... Training loss: 0.03192... Test loss: 0.02577\n",
      "Epoch: 1... Training loss: 0.03141... Test loss: 0.02118\n",
      "Epoch: 1... Training loss: 0.02825... Test loss: 0.02344\n",
      "Epoch: 1... Training loss: 0.02815... Test loss: 0.01893\n",
      "Epoch: 1... Training loss: 0.02644... Test loss: 0.00528\n",
      "Epoch: 1... Training loss: 0.02558... Test loss: 0.01905\n",
      "Epoch: 1... Training loss: 0.02418... Test loss: 0.00643\n",
      "Epoch: 1... Training loss: 0.02244... Test loss: 0.01875\n",
      "Epoch: 1... Training loss: 0.02102... Test loss: 0.01029\n",
      "Epoch: 1... Training loss: 0.02031... Test loss: 0.01524\n",
      "Epoch: 1... Training loss: 0.01932... Test loss: 0.01834\n",
      "Epoch: 1... Training loss: 0.01856... Test loss: 0.0129\n",
      "Epoch: 1... Training loss: 0.01732... Test loss: 0.0126\n",
      "Epoch: 1... Training loss: 0.01663... Test loss: 0.01124\n",
      "Epoch: 1... Training loss: 0.01556... Test loss: 0.00867\n",
      "Epoch: 1... Training loss: 0.01471... Test loss: 0.01411\n",
      "Epoch: 1... Training loss: 0.01428... Test loss: 0.00562\n",
      "Epoch: 1... Training loss: 0.01336... Test loss: 0.01506\n",
      "Epoch: 1... Training loss: 0.01323... Test loss: 0.00626\n",
      "Epoch: 1... Training loss: 0.01239... Test loss: 0.01269\n",
      "Epoch: 1... Training loss: 0.01209... Test loss: 0.01056\n",
      "Epoch: 1... Training loss: 0.01141... Test loss: 0.00743\n",
      "Epoch: 1... Training loss: 0.01132... Test loss: 0.01113\n",
      "Epoch: 1... Training loss: 0.01095... Test loss: 0.00698\n",
      "Epoch: 1... Training loss: 0.01055... Test loss: 0.01018\n",
      "Epoch: 1... Training loss: 0.01017... Test loss: 0.0055\n",
      "Epoch: 1... Training loss: 0.01001... Test loss: 0.01029\n",
      "Epoch: 1... Training loss: 0.0095... Test loss: 0.00458\n",
      "Epoch: 1... Training loss: 0.00928... Test loss: 0.01063\n",
      "Epoch: 1... Training loss: 0.00907... Test loss: 0.00446\n",
      "Epoch: 1... Training loss: 0.00872... Test loss: 0.01025\n",
      "Epoch: 1... Training loss: 0.00849... Test loss: 0.00523\n",
      "Epoch: 1... Training loss: 0.00834... Test loss: 0.00832\n",
      "Epoch: 1... Training loss: 0.00803... Test loss: 0.00594\n",
      "Epoch: 1... Training loss: 0.00776... Test loss: 0.00828\n",
      "Epoch: 1... Training loss: 0.00764... Test loss: 0.00421\n",
      "Epoch: 1... Training loss: 0.0074... Test loss: 0.00779\n",
      "Epoch: 1... Training loss: 0.00722... Test loss: 0.0054\n",
      "Epoch: 1... Training loss: 0.00696... Test loss: 0.00669\n",
      "Epoch: 1... Training loss: 0.00683... Test loss: 0.0052\n",
      "Epoch: 1... Training loss: 0.00655... Test loss: 0.00613\n",
      "Epoch: 1... Training loss: 0.00645... Test loss: 0.00508\n",
      "Epoch: 1... Training loss: 0.00629... Test loss: 0.00588\n",
      "Epoch: 1... Training loss: 0.00628... Test loss: 0.00438\n",
      "Epoch: 1... Training loss: 0.00607... Test loss: 0.0061\n",
      "Epoch: 1... Training loss: 0.00595... Test loss: 0.00407\n",
      "Epoch: 1... Training loss: 0.0058... Test loss: 0.00599\n",
      "Epoch: 1... Training loss: 0.00562... Test loss: 0.00427\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1... Training loss: 0.0055... Test loss: 0.00559\n",
      "Epoch: 1... Training loss: 0.00894... Test loss: 0.00951\n",
      "Epoch: 1... Training loss: 0.01433... Test loss: 0.00953\n",
      "Epoch: 1... Training loss: 0.01065... Test loss: 0.01063\n",
      "Epoch: 1... Training loss: 0.01038... Test loss: 0.00871\n",
      "Epoch: 1... Training loss: 0.01449... Test loss: 0.00805\n",
      "Epoch: 1... Training loss: 0.00918... Test loss: 0.01147\n",
      "Epoch: 1... Training loss: 0.01153... Test loss: 0.01028\n",
      "Epoch: 1... Training loss: 0.00909... Test loss: 0.01173\n",
      "Epoch: 1... Training loss: 0.01016... Test loss: 0.01143\n",
      "Epoch: 1... Training loss: 0.009... Test loss: 0.01207\n",
      "Epoch: 1... Training loss: 0.00783... Test loss: 0.01044\n",
      "Epoch: 1... Training loss: 0.00727... Test loss: 0.01245\n",
      "Epoch: 1... Training loss: 0.00793... Test loss: 0.00986\n",
      "Epoch: 1... Training loss: 0.00716... Test loss: 0.01076\n",
      "Epoch: 1... Training loss: 0.00765... Test loss: 0.00845\n",
      "Epoch: 1... Training loss: 0.00738... Test loss: 0.0084\n",
      "Epoch: 1... Training loss: 0.00756... Test loss: 0.007\n",
      "Epoch: 1... Training loss: 0.00659... Test loss: 0.00848\n",
      "Epoch: 1... Training loss: 0.00631... Test loss: 0.00719\n",
      "Epoch: 1... Training loss: 0.00643... Test loss: 0.00703\n",
      "Epoch: 1... Training loss: 0.00604... Test loss: 0.00701\n",
      "Epoch: 1... Training loss: 0.00597... Test loss: 0.00655\n",
      "Epoch: 1... Training loss: 0.00555... Test loss: 0.00614\n",
      "Epoch: 1... Training loss: 0.00552... Test loss: 0.00578\n",
      "Epoch: 1... Training loss: 0.00535... Test loss: 0.00697\n",
      "Epoch: 1... Training loss: 0.00512... Test loss: 0.00517\n",
      "Epoch: 1... Training loss: 0.00509... Test loss: 0.00693\n",
      "Epoch: 1... Training loss: 0.00498... Test loss: 0.00556\n",
      "Epoch: 1... Training loss: 0.00481... Test loss: 0.00547\n",
      "Epoch: 1... Training loss: 0.00467... Test loss: 0.00541\n",
      "Epoch: 1... Training loss: 0.00454... Test loss: 0.0051\n",
      "Epoch: 1... Training loss: 0.00453... Test loss: 0.004\n",
      "Epoch: 1... Training loss: 0.00424... Test loss: 0.00464\n",
      "Epoch: 1... Training loss: 0.00427... Test loss: 0.00335\n",
      "Epoch: 1... Training loss: 0.00413... Test loss: 0.00413\n",
      "Epoch: 1... Training loss: 0.00391... Test loss: 0.0037\n",
      "Epoch: 1... Training loss: 0.00395... Test loss: 0.00404\n",
      "Epoch: 1... Training loss: 0.00381... Test loss: 0.00427\n",
      "Epoch: 1... Training loss: 0.00365... Test loss: 0.00408\n",
      "Epoch: 1... Training loss: 0.00372... Test loss: 0.00357\n",
      "Epoch: 1... Training loss: 0.00365... Test loss: 0.00353\n",
      "Epoch: 1... Training loss: 0.00364... Test loss: 0.00358\n",
      "Epoch: 1... Training loss: 0.00357... Test loss: 0.0037\n",
      "Epoch: 1... Training loss: 0.00339... Test loss: 0.00433\n",
      "Epoch: 1... Training loss: 0.00338... Test loss: 0.00364\n",
      "Epoch: 1... Training loss: 0.0032... Test loss: 0.00437\n",
      "Epoch: 1... Training loss: 0.00315... Test loss: 0.00384\n",
      "Epoch: 1... Training loss: 0.00314... Test loss: 0.00371\n",
      "Epoch: 1... Training loss: 0.00311... Test loss: 0.00335\n",
      "Epoch: 1... Training loss: 0.00308... Test loss: 0.00364\n",
      "Epoch: 1... Training loss: 0.00297... Test loss: 0.00293\n",
      "Epoch: 1... Training loss: 0.00301... Test loss: 0.00327\n",
      "Epoch: 1... Training loss: 0.00284... Test loss: 0.00318\n",
      "Epoch: 1... Training loss: 0.00277... Test loss: 0.00296\n",
      "Epoch: 1... Training loss: 0.00267... Test loss: 0.00275\n",
      "Epoch: 1... Training loss: 0.00275... Test loss: 0.00313\n",
      "Epoch: 1... Training loss: 0.00259... Test loss: 0.00304\n",
      "Epoch: 1... Training loss: 0.00247... Test loss: 0.0026\n",
      "Epoch: 1... Training loss: 0.00242... Test loss: 0.00272\n",
      "Epoch: 1... Training loss: 0.00244... Test loss: 0.00232\n",
      "Epoch: 1... Training loss: 0.00242... Test loss: 0.00254\n",
      "Epoch: 1... Training loss: 0.0025... Test loss: 0.00239\n",
      "Epoch: 1... Training loss: 0.00233... Test loss: 0.00276\n",
      "Epoch: 1... Training loss: 0.0023... Test loss: 0.00231\n",
      "Epoch: 1... Training loss: 0.00224... Test loss: 0.00274\n",
      "Epoch: 1... Training loss: 0.00221... Test loss: 0.00193\n",
      "Epoch: 1... Training loss: 0.00218... Test loss: 0.00254\n",
      "Epoch: 1... Training loss: 0.00209... Test loss: 0.0017\n",
      "Epoch: 1... Training loss: 0.00203... Test loss: 0.0023\n",
      "Epoch: 1... Training loss: 0.0021... Test loss: 0.00188\n",
      "Epoch: 1... Training loss: 0.002... Test loss: 0.00226\n",
      "Epoch: 1... Training loss: 0.00197... Test loss: 0.00181\n",
      "Epoch: 1... Training loss: 0.00197... Test loss: 0.00218\n",
      "Epoch: 1... Training loss: 0.00189... Test loss: 0.00196\n",
      "Epoch: 1... Training loss: 0.00209... Test loss: 0.00223\n",
      "Epoch: 1... Training loss: 0.00178... Test loss: 0.00172\n",
      "Epoch: 1... Training loss: 0.00174... Test loss: 0.00187\n",
      "Epoch: 1... Training loss: 0.00167... Test loss: 0.00165\n",
      "Epoch: 1... Training loss: 0.00165... Test loss: 0.00191\n",
      "Epoch: 1... Training loss: 0.00159... Test loss: 0.00166\n",
      "Epoch: 1... Training loss: 0.00161... Test loss: 0.00171\n",
      "Epoch: 1... Training loss: 0.00153... Test loss: 0.00155\n",
      "Epoch: 1... Training loss: 0.00157... Test loss: 0.00169\n",
      "Epoch: 1... Training loss: 0.00151... Test loss: 0.00149\n",
      "Epoch: 1... Training loss: 0.00156... Test loss: 0.00143\n",
      "Epoch: 1... Training loss: 0.00147... Test loss: 0.00156\n",
      "Epoch: 1... Training loss: 0.00136... Test loss: 0.00151\n",
      "Epoch: 1... Training loss: 0.00142... Test loss: 0.00165\n",
      "Epoch: 1... Training loss: 0.00131... Test loss: 0.00158\n",
      "Epoch: 1... Training loss: 0.00124... Test loss: 0.00146\n",
      "Epoch: 1... Training loss: 0.00122... Test loss: 0.00151\n",
      "Epoch: 1... Training loss: 0.00121... Test loss: 0.00124\n",
      "Epoch: 1... Training loss: 0.00121... Test loss: 0.00142\n",
      "Epoch: 1... Training loss: 0.00123... Test loss: 0.00115\n",
      "Epoch: 1... Training loss: 0.00122... Test loss: 0.00149\n",
      "Epoch: 1... Training loss: 0.00114... Test loss: 0.001\n",
      "Epoch: 1... Training loss: 0.00112... Test loss: 0.00131\n",
      "Epoch: 1... Training loss: 0.00111... Test loss: 0.00105\n",
      "Epoch: 1... Training loss: 0.00101... Test loss: 0.00108\n",
      "Epoch: 1... Training loss: 0.00097... Test loss: 0.00094\n",
      "Epoch: 1... Training loss: 0.00092... Test loss: 0.00113\n",
      "Epoch: 1... Training loss: 0.00096... Test loss: 0.00096\n",
      "Epoch: 1... Training loss: 0.0009... Test loss: 0.00099\n",
      "Epoch: 1... Training loss: 0.00086... Test loss: 0.00084\n",
      "Epoch: 1... Training loss: 0.00089... Test loss: 0.00093\n",
      "Epoch: 1... Training loss: 0.00082... Test loss: 0.00089\n",
      "Epoch: 1... Training loss: 0.00084... Test loss: 0.00083\n",
      "Epoch: 1... Training loss: 0.00083... Test loss: 0.00083\n",
      "Epoch: 1... Training loss: 0.00078... Test loss: 0.0008\n",
      "Epoch: 1... Training loss: 0.00073... Test loss: 0.00067\n",
      "Epoch: 1... Training loss: 0.00067... Test loss: 0.00083\n",
      "Epoch: 1... Training loss: 0.00065... Test loss: 0.00066\n",
      "Epoch: 1... Training loss: 0.00065... Test loss: 0.0008\n",
      "Epoch: 1... Training loss: 0.00056... Test loss: 0.00068\n",
      "Epoch: 1... Training loss: 0.00054... Test loss: 0.00064\n",
      "Epoch: 1... Training loss: 0.00052... Test loss: 0.00062\n",
      "Epoch: 1... Training loss: 0.00054... Test loss: 0.0006\n",
      "Epoch: 1... Training loss: 0.0005... Test loss: 0.00054\n",
      "Epoch: 1... Training loss: 0.00049... Test loss: 0.00052\n",
      "Epoch: 1... Training loss: 0.00047... Test loss: 0.00054\n",
      "Epoch: 1... Training loss: 0.00047... Test loss: 0.00048\n",
      "Epoch: 1... Training loss: 0.00041... Test loss: 0.00046\n",
      "Epoch: 1... Training loss: 0.00041... Test loss: 0.00041\n",
      "Epoch: 1... Training loss: 0.00038... Test loss: 0.00041\n",
      "Epoch: 1... Training loss: 0.0004... Test loss: 0.0004\n",
      "Epoch: 1... Training loss: 0.00037... Test loss: 0.0004\n",
      "Epoch: 1... Training loss: 0.00038... Test loss: 0.00035\n",
      "Epoch: 1... Training loss: 0.00035... Test loss: 0.00035\n",
      "Epoch: 1... Training loss: 0.00033... Test loss: 0.00034\n",
      "Epoch: 1... Training loss: 0.00029... Test loss: 0.00039\n",
      "Epoch: 1... Training loss: 0.00031... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00032... Test loss: 0.00033\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00031\n",
      "Epoch: 1... Training loss: 0.00034... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00028\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00018\n",
      "285.02571704785805\n",
      "Epoch: 1... Training loss: 1.18797... Test loss: 0.49565\n",
      "Epoch: 1... Training loss: 0.49106... Test loss: 0.15548\n",
      "Epoch: 1... Training loss: 0.31695... Test loss: 0.08961\n",
      "Epoch: 1... Training loss: 0.2154... Test loss: 0.0702\n",
      "Epoch: 1... Training loss: 0.16613... Test loss: 0.06179\n",
      "Epoch: 1... Training loss: 0.12823... Test loss: 0.05001\n",
      "Epoch: 1... Training loss: 0.11142... Test loss: 0.03738\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1... Training loss: 0.09355... Test loss: 0.04563\n",
      "Epoch: 1... Training loss: 0.07093... Test loss: 0.02428\n",
      "Epoch: 1... Training loss: 0.06019... Test loss: 0.04869\n",
      "Epoch: 1... Training loss: 0.0516... Test loss: 0.02514\n",
      "Epoch: 1... Training loss: 0.04526... Test loss: 0.03007\n",
      "Epoch: 1... Training loss: 0.04076... Test loss: 0.02744\n",
      "Epoch: 1... Training loss: 0.03864... Test loss: 0.02971\n",
      "Epoch: 1... Training loss: 0.03568... Test loss: 0.0152\n",
      "Epoch: 1... Training loss: 0.03318... Test loss: 0.02477\n",
      "Epoch: 1... Training loss: 0.03186... Test loss: 0.00732\n",
      "Epoch: 1... Training loss: 0.02756... Test loss: 0.01875\n",
      "Epoch: 1... Training loss: 0.02651... Test loss: 0.00904\n",
      "Epoch: 1... Training loss: 0.02554... Test loss: 0.01136\n",
      "Epoch: 1... Training loss: 0.02461... Test loss: 0.01451\n",
      "Epoch: 1... Training loss: 0.02283... Test loss: 0.00537\n",
      "Epoch: 1... Training loss: 0.02231... Test loss: 0.01684\n",
      "Epoch: 1... Training loss: 0.02089... Test loss: 0.01186\n",
      "Epoch: 1... Training loss: 0.01935... Test loss: 0.0155\n",
      "Epoch: 1... Training loss: 0.01833... Test loss: 0.00631\n",
      "Epoch: 1... Training loss: 0.01751... Test loss: 0.01605\n",
      "Epoch: 1... Training loss: 0.01683... Test loss: 0.01026\n",
      "Epoch: 1... Training loss: 0.01608... Test loss: 0.00581\n",
      "Epoch: 1... Training loss: 0.01619... Test loss: 0.01282\n",
      "Epoch: 1... Training loss: 0.01481... Test loss: 0.00635\n",
      "Epoch: 1... Training loss: 0.01465... Test loss: 0.01303\n",
      "Epoch: 1... Training loss: 0.01374... Test loss: 0.00671\n",
      "Epoch: 1... Training loss: 0.01363... Test loss: 0.01336\n",
      "Epoch: 1... Training loss: 0.01304... Test loss: 0.00621\n",
      "Epoch: 1... Training loss: 0.01268... Test loss: 0.0127\n",
      "Epoch: 1... Training loss: 0.01265... Test loss: 0.00797\n",
      "Epoch: 1... Training loss: 0.01173... Test loss: 0.01168\n",
      "Epoch: 1... Training loss: 0.01129... Test loss: 0.0084\n",
      "Epoch: 1... Training loss: 0.01109... Test loss: 0.00953\n",
      "Epoch: 1... Training loss: 0.01065... Test loss: 0.00964\n",
      "Epoch: 1... Training loss: 0.01034... Test loss: 0.01044\n",
      "Epoch: 1... Training loss: 0.00994... Test loss: 0.00768\n",
      "Epoch: 1... Training loss: 0.00982... Test loss: 0.00836\n",
      "Epoch: 1... Training loss: 0.00943... Test loss: 0.00933\n",
      "Epoch: 1... Training loss: 0.00937... Test loss: 0.0056\n",
      "Epoch: 1... Training loss: 0.00893... Test loss: 0.00833\n",
      "Epoch: 1... Training loss: 0.00874... Test loss: 0.00678\n",
      "Epoch: 1... Training loss: 0.00842... Test loss: 0.00819\n",
      "Epoch: 1... Training loss: 0.00813... Test loss: 0.00659\n",
      "Epoch: 1... Training loss: 0.00798... Test loss: 0.00682\n",
      "Epoch: 1... Training loss: 0.00777... Test loss: 0.00633\n",
      "Epoch: 1... Training loss: 0.00766... Test loss: 0.00611\n",
      "Epoch: 1... Training loss: 0.00738... Test loss: 0.00669\n",
      "Epoch: 1... Training loss: 0.00718... Test loss: 0.00625\n",
      "Epoch: 1... Training loss: 0.00703... Test loss: 0.0061\n",
      "Epoch: 1... Training loss: 0.0068... Test loss: 0.00641\n",
      "Epoch: 1... Training loss: 0.00664... Test loss: 0.00601\n",
      "Epoch: 1... Training loss: 0.00635... Test loss: 0.00616\n",
      "Epoch: 1... Training loss: 0.00613... Test loss: 0.00602\n",
      "Epoch: 1... Training loss: 0.00594... Test loss: 0.00541\n",
      "Epoch: 1... Training loss: 0.00582... Test loss: 0.00624\n",
      "Epoch: 1... Training loss: 0.00575... Test loss: 0.00421\n",
      "Epoch: 1... Training loss: 0.00551... Test loss: 0.00677\n",
      "Epoch: 1... Training loss: 0.01781... Test loss: 0.01143\n",
      "Epoch: 1... Training loss: 0.01223... Test loss: 0.01217\n",
      "Epoch: 1... Training loss: 0.01347... Test loss: 0.02107\n",
      "Epoch: 1... Training loss: 0.01038... Test loss: 0.0155\n",
      "Epoch: 1... Training loss: 0.01075... Test loss: 0.01893\n",
      "Epoch: 1... Training loss: 0.01013... Test loss: 0.0123\n",
      "Epoch: 1... Training loss: 0.00978... Test loss: 0.01468\n",
      "Epoch: 1... Training loss: 0.00866... Test loss: 0.01071\n",
      "Epoch: 1... Training loss: 0.0092... Test loss: 0.01116\n",
      "Epoch: 1... Training loss: 0.00892... Test loss: 0.00942\n",
      "Epoch: 1... Training loss: 0.0086... Test loss: 0.01081\n",
      "Epoch: 1... Training loss: 0.00782... Test loss: 0.00972\n",
      "Epoch: 1... Training loss: 0.0073... Test loss: 0.00787\n",
      "Epoch: 1... Training loss: 0.0081... Test loss: 0.01001\n",
      "Epoch: 1... Training loss: 0.0073... Test loss: 0.01032\n",
      "Epoch: 1... Training loss: 0.00712... Test loss: 0.00892\n",
      "Epoch: 1... Training loss: 0.00726... Test loss: 0.00862\n",
      "Epoch: 1... Training loss: 0.00676... Test loss: 0.00864\n",
      "Epoch: 1... Training loss: 0.00689... Test loss: 0.00789\n",
      "Epoch: 1... Training loss: 0.00652... Test loss: 0.00741\n",
      "Epoch: 1... Training loss: 0.00609... Test loss: 0.00825\n",
      "Epoch: 1... Training loss: 0.00613... Test loss: 0.00652\n",
      "Epoch: 1... Training loss: 0.00583... Test loss: 0.00742\n",
      "Epoch: 1... Training loss: 0.00533... Test loss: 0.00714\n",
      "Epoch: 1... Training loss: 0.00524... Test loss: 0.00559\n",
      "Epoch: 1... Training loss: 0.00513... Test loss: 0.0065\n",
      "Epoch: 1... Training loss: 0.00535... Test loss: 0.00468\n",
      "Epoch: 1... Training loss: 0.00478... Test loss: 0.00572\n",
      "Epoch: 1... Training loss: 0.00479... Test loss: 0.00504\n",
      "Epoch: 1... Training loss: 0.0047... Test loss: 0.00411\n",
      "Epoch: 1... Training loss: 0.00464... Test loss: 0.00546\n",
      "Epoch: 1... Training loss: 0.00451... Test loss: 0.00383\n",
      "Epoch: 1... Training loss: 0.00446... Test loss: 0.00605\n",
      "Epoch: 1... Training loss: 0.00438... Test loss: 0.00377\n",
      "Epoch: 1... Training loss: 0.00402... Test loss: 0.00592\n",
      "Epoch: 1... Training loss: 0.00399... Test loss: 0.00405\n",
      "Epoch: 1... Training loss: 0.00396... Test loss: 0.0047\n",
      "Epoch: 1... Training loss: 0.00377... Test loss: 0.004\n",
      "Epoch: 1... Training loss: 0.00367... Test loss: 0.00457\n",
      "Epoch: 1... Training loss: 0.00369... Test loss: 0.00429\n",
      "Epoch: 1... Training loss: 0.00361... Test loss: 0.00433\n",
      "Epoch: 1... Training loss: 0.00353... Test loss: 0.00361\n",
      "Epoch: 1... Training loss: 0.00338... Test loss: 0.00425\n",
      "Epoch: 1... Training loss: 0.00335... Test loss: 0.00303\n",
      "Epoch: 1... Training loss: 0.00333... Test loss: 0.00336\n",
      "Epoch: 1... Training loss: 0.00325... Test loss: 0.00329\n",
      "Epoch: 1... Training loss: 0.00317... Test loss: 0.00319\n",
      "Epoch: 1... Training loss: 0.00317... Test loss: 0.0035\n",
      "Epoch: 1... Training loss: 0.00309... Test loss: 0.00259\n",
      "Epoch: 1... Training loss: 0.003... Test loss: 0.00355\n",
      "Epoch: 1... Training loss: 0.00291... Test loss: 0.00269\n",
      "Epoch: 1... Training loss: 0.00288... Test loss: 0.00294\n",
      "Epoch: 1... Training loss: 0.00284... Test loss: 0.0029\n",
      "Epoch: 1... Training loss: 0.00286... Test loss: 0.00316\n",
      "Epoch: 1... Training loss: 0.00273... Test loss: 0.00291\n",
      "Epoch: 1... Training loss: 0.00272... Test loss: 0.00306\n",
      "Epoch: 1... Training loss: 0.00246... Test loss: 0.00275\n",
      "Epoch: 1... Training loss: 0.00245... Test loss: 0.00329\n",
      "Epoch: 1... Training loss: 0.0025... Test loss: 0.00261\n",
      "Epoch: 1... Training loss: 0.00228... Test loss: 0.00299\n",
      "Epoch: 1... Training loss: 0.00236... Test loss: 0.00261\n",
      "Epoch: 1... Training loss: 0.00231... Test loss: 0.00283\n",
      "Epoch: 1... Training loss: 0.0022... Test loss: 0.00216\n",
      "Epoch: 1... Training loss: 0.00218... Test loss: 0.00237\n",
      "Epoch: 1... Training loss: 0.00208... Test loss: 0.00208\n",
      "Epoch: 1... Training loss: 0.00217... Test loss: 0.00219\n",
      "Epoch: 1... Training loss: 0.00199... Test loss: 0.00224\n",
      "Epoch: 1... Training loss: 0.00198... Test loss: 0.0022\n",
      "Epoch: 1... Training loss: 0.00195... Test loss: 0.00216\n",
      "Epoch: 1... Training loss: 0.00192... Test loss: 0.00185\n",
      "Epoch: 1... Training loss: 0.00179... Test loss: 0.00218\n",
      "Epoch: 1... Training loss: 0.00174... Test loss: 0.00198\n",
      "Epoch: 1... Training loss: 0.00172... Test loss: 0.00209\n",
      "Epoch: 1... Training loss: 0.00173... Test loss: 0.00163\n",
      "Epoch: 1... Training loss: 0.00167... Test loss: 0.00196\n",
      "Epoch: 1... Training loss: 0.00166... Test loss: 0.00162\n",
      "Epoch: 1... Training loss: 0.00159... Test loss: 0.00195\n",
      "Epoch: 1... Training loss: 0.00159... Test loss: 0.00158\n",
      "Epoch: 1... Training loss: 0.00145... Test loss: 0.0018\n",
      "Epoch: 1... Training loss: 0.00147... Test loss: 0.00145\n",
      "Epoch: 1... Training loss: 0.00139... Test loss: 0.00171\n",
      "Epoch: 1... Training loss: 0.0014... Test loss: 0.00145\n",
      "Epoch: 1... Training loss: 0.0013... Test loss: 0.00178\n",
      "Epoch: 1... Training loss: 0.0013... Test loss: 0.00159\n",
      "Epoch: 1... Training loss: 0.00135... Test loss: 0.00144\n",
      "Epoch: 1... Training loss: 0.00129... Test loss: 0.00139\n",
      "Epoch: 1... Training loss: 0.00119... Test loss: 0.00131\n",
      "Epoch: 1... Training loss: 0.00118... Test loss: 0.00134\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1... Training loss: 0.00122... Test loss: 0.00108\n",
      "Epoch: 1... Training loss: 0.00108... Test loss: 0.00126\n",
      "Epoch: 1... Training loss: 0.00107... Test loss: 0.00111\n",
      "Epoch: 1... Training loss: 0.00098... Test loss: 0.00119\n",
      "Epoch: 1... Training loss: 0.00099... Test loss: 0.00094\n",
      "Epoch: 1... Training loss: 0.0009... Test loss: 0.00101\n",
      "Epoch: 1... Training loss: 0.00093... Test loss: 0.0009\n",
      "Epoch: 1... Training loss: 0.00091... Test loss: 0.00097\n",
      "Epoch: 1... Training loss: 0.0009... Test loss: 0.00075\n",
      "Epoch: 1... Training loss: 0.00085... Test loss: 0.00107\n",
      "Epoch: 1... Training loss: 0.00095... Test loss: 0.00096\n",
      "Epoch: 1... Training loss: 0.0008... Test loss: 0.00104\n",
      "Epoch: 1... Training loss: 0.00079... Test loss: 0.00089\n",
      "Epoch: 1... Training loss: 0.00073... Test loss: 0.0009\n",
      "Epoch: 1... Training loss: 0.00072... Test loss: 0.00089\n",
      "Epoch: 1... Training loss: 0.0007... Test loss: 0.0007\n",
      "Epoch: 1... Training loss: 0.00071... Test loss: 0.00073\n",
      "Epoch: 1... Training loss: 0.00063... Test loss: 0.00081\n",
      "Epoch: 1... Training loss: 0.00065... Test loss: 0.00057\n",
      "Epoch: 1... Training loss: 0.00058... Test loss: 0.00081\n",
      "Epoch: 1... Training loss: 0.00057... Test loss: 0.00056\n",
      "Epoch: 1... Training loss: 0.0006... Test loss: 0.00062\n",
      "Epoch: 1... Training loss: 0.00052... Test loss: 0.00057\n",
      "Epoch: 1... Training loss: 0.00055... Test loss: 0.00067\n",
      "Epoch: 1... Training loss: 0.00049... Test loss: 0.00047\n",
      "Epoch: 1... Training loss: 0.0005... Test loss: 0.0007\n",
      "Epoch: 1... Training loss: 0.00048... Test loss: 0.00044\n",
      "Epoch: 1... Training loss: 0.00044... Test loss: 0.00059\n",
      "Epoch: 1... Training loss: 0.00042... Test loss: 0.00038\n",
      "Epoch: 1... Training loss: 0.00044... Test loss: 0.00051\n",
      "Epoch: 1... Training loss: 0.00043... Test loss: 0.00041\n",
      "Epoch: 1... Training loss: 0.0004... Test loss: 0.00042\n",
      "Epoch: 1... Training loss: 0.00036... Test loss: 0.00039\n",
      "Epoch: 1... Training loss: 0.00036... Test loss: 0.00041\n",
      "Epoch: 1... Training loss: 0.00031... Test loss: 0.00039\n",
      "Epoch: 1... Training loss: 0.00032... Test loss: 0.00034\n",
      "Epoch: 1... Training loss: 0.00031... Test loss: 0.00031\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00032\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.0003\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00032\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00031... Test loss: 0.00024\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00013\n",
      "239.42191908881068\n",
      "Epoch: 1... Training loss: 1.07522... Test loss: 0.43249\n",
      "Epoch: 1... Training loss: 0.5474... Test loss: 0.19651\n",
      "Epoch: 1... Training loss: 0.32301... Test loss: 0.10665\n",
      "Epoch: 1... Training loss: 0.20441... Test loss: 0.07535\n",
      "Epoch: 1... Training loss: 0.15849... Test loss: 0.03903\n",
      "Epoch: 1... Training loss: 0.11511... Test loss: 0.04855\n",
      "Epoch: 1... Training loss: 0.09835... Test loss: 0.02283\n",
      "Epoch: 1... Training loss: 0.0791... Test loss: 0.03088\n",
      "Epoch: 1... Training loss: 0.06115... Test loss: 0.02346\n",
      "Epoch: 1... Training loss: 0.05616... Test loss: 0.04099\n",
      "Epoch: 1... Training loss: 0.04682... Test loss: 0.01956\n",
      "Epoch: 1... Training loss: 0.04493... Test loss: 0.03522\n",
      "Epoch: 1... Training loss: 0.03924... Test loss: 0.0217\n",
      "Epoch: 1... Training loss: 0.03894... Test loss: 0.04539\n",
      "Epoch: 1... Training loss: 0.03313... Test loss: 0.0209\n",
      "Epoch: 1... Training loss: 0.03235... Test loss: 0.0266\n",
      "Epoch: 1... Training loss: 0.02805... Test loss: 0.03297\n",
      "Epoch: 1... Training loss: 0.02761... Test loss: 0.01703\n",
      "Epoch: 1... Training loss: 0.02563... Test loss: 0.02785\n",
      "Epoch: 1... Training loss: 0.02441... Test loss: 0.02171\n",
      "Epoch: 1... Training loss: 0.02287... Test loss: 0.02703\n",
      "Epoch: 1... Training loss: 0.02145... Test loss: 0.01636\n",
      "Epoch: 1... Training loss: 0.02018... Test loss: 0.02149\n",
      "Epoch: 1... Training loss: 0.01889... Test loss: 0.01898\n",
      "Epoch: 1... Training loss: 0.01778... Test loss: 0.01945\n",
      "Epoch: 1... Training loss: 0.01726... Test loss: 0.01698\n",
      "Epoch: 1... Training loss: 0.01607... Test loss: 0.02132\n",
      "Epoch: 1... Training loss: 0.01585... Test loss: 0.01105\n",
      "Epoch: 1... Training loss: 0.01526... Test loss: 0.01992\n",
      "Epoch: 1... Training loss: 0.01462... Test loss: 0.01104\n",
      "Epoch: 1... Training loss: 0.01406... Test loss: 0.01793\n",
      "Epoch: 1... Training loss: 0.01396... Test loss: 0.00944\n",
      "Epoch: 1... Training loss: 0.01296... Test loss: 0.01386\n",
      "Epoch: 1... Training loss: 0.0125... Test loss: 0.00942\n",
      "Epoch: 1... Training loss: 0.01197... Test loss: 0.01242\n",
      "Epoch: 1... Training loss: 0.01183... Test loss: 0.00794\n",
      "Epoch: 1... Training loss: 0.01128... Test loss: 0.01216\n",
      "Epoch: 1... Training loss: 0.01106... Test loss: 0.00913\n",
      "Epoch: 1... Training loss: 0.01069... Test loss: 0.01011\n",
      "Epoch: 1... Training loss: 0.01038... Test loss: 0.00895\n",
      "Epoch: 1... Training loss: 0.00991... Test loss: 0.0114\n",
      "Epoch: 1... Training loss: 0.00974... Test loss: 0.00968\n",
      "Epoch: 1... Training loss: 0.00937... Test loss: 0.00822\n",
      "Epoch: 1... Training loss: 0.00909... Test loss: 0.00955\n",
      "Epoch: 1... Training loss: 0.00878... Test loss: 0.00709\n",
      "Epoch: 1... Training loss: 0.00859... Test loss: 0.00817\n",
      "Epoch: 1... Training loss: 0.0082... Test loss: 0.00755\n",
      "Epoch: 1... Training loss: 0.00825... Test loss: 0.00624\n",
      "Epoch: 1... Training loss: 0.00775... Test loss: 0.00924\n",
      "Epoch: 1... Training loss: 0.00754... Test loss: 0.00586\n",
      "Epoch: 1... Training loss: 0.00731... Test loss: 0.00852\n",
      "Epoch: 1... Training loss: 0.00724... Test loss: 0.00532\n",
      "Epoch: 1... Training loss: 0.007... Test loss: 0.00714\n",
      "Epoch: 1... Training loss: 0.00697... Test loss: 0.00562\n",
      "Epoch: 1... Training loss: 0.00667... Test loss: 0.00645\n",
      "Epoch: 1... Training loss: 0.00662... Test loss: 0.00568\n",
      "Epoch: 1... Training loss: 0.00637... Test loss: 0.00645\n",
      "Epoch: 1... Training loss: 0.00639... Test loss: 0.00511\n",
      "Epoch: 1... Training loss: 0.00613... Test loss: 0.00733\n",
      "Epoch: 1... Training loss: 0.00598... Test loss: 0.00481\n",
      "Epoch: 1... Training loss: 0.00577... Test loss: 0.00624\n",
      "Epoch: 1... Training loss: 0.00571... Test loss: 0.00446\n",
      "Epoch: 1... Training loss: 0.0055... Test loss: 0.00623\n",
      "Epoch: 1... Training loss: 0.00537... Test loss: 0.00506\n",
      "Epoch: 1... Training loss: 0.00856... Test loss: 0.01063\n",
      "Epoch: 1... Training loss: 0.01353... Test loss: 0.01154\n",
      "Epoch: 1... Training loss: 0.0085... Test loss: 0.01164\n",
      "Epoch: 1... Training loss: 0.0118... Test loss: 0.01235\n",
      "Epoch: 1... Training loss: 0.00944... Test loss: 0.01489\n",
      "Epoch: 1... Training loss: 0.00974... Test loss: 0.01146\n",
      "Epoch: 1... Training loss: 0.00797... Test loss: 0.01155\n",
      "Epoch: 1... Training loss: 0.00879... Test loss: 0.00958\n",
      "Epoch: 1... Training loss: 0.00781... Test loss: 0.01036\n",
      "Epoch: 1... Training loss: 0.0083... Test loss: 0.00866\n",
      "Epoch: 1... Training loss: 0.0076... Test loss: 0.01008\n",
      "Epoch: 1... Training loss: 0.00759... Test loss: 0.00849\n",
      "Epoch: 1... Training loss: 0.00783... Test loss: 0.00996\n",
      "Epoch: 1... Training loss: 0.00661... Test loss: 0.00806\n",
      "Epoch: 1... Training loss: 0.00756... Test loss: 0.00814\n",
      "Epoch: 1... Training loss: 0.00698... Test loss: 0.01035\n",
      "Epoch: 1... Training loss: 0.00669... Test loss: 0.00709\n",
      "Epoch: 1... Training loss: 0.00614... Test loss: 0.00853\n",
      "Epoch: 1... Training loss: 0.00659... Test loss: 0.00699\n",
      "Epoch: 1... Training loss: 0.00578... Test loss: 0.00804\n",
      "Epoch: 1... Training loss: 0.00539... Test loss: 0.00641\n",
      "Epoch: 1... Training loss: 0.00572... Test loss: 0.00672\n",
      "Epoch: 1... Training loss: 0.00529... Test loss: 0.0061\n",
      "Epoch: 1... Training loss: 0.00528... Test loss: 0.00568\n",
      "Epoch: 1... Training loss: 0.00513... Test loss: 0.00524\n",
      "Epoch: 1... Training loss: 0.00484... Test loss: 0.00557\n",
      "Epoch: 1... Training loss: 0.0048... Test loss: 0.00536\n",
      "Epoch: 1... Training loss: 0.00478... Test loss: 0.00415\n",
      "Epoch: 1... Training loss: 0.00455... Test loss: 0.0053\n",
      "Epoch: 1... Training loss: 0.0046... Test loss: 0.0047\n",
      "Epoch: 1... Training loss: 0.00439... Test loss: 0.00506\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1... Training loss: 0.0043... Test loss: 0.00428\n",
      "Epoch: 1... Training loss: 0.00415... Test loss: 0.00502\n",
      "Epoch: 1... Training loss: 0.00391... Test loss: 0.00411\n",
      "Epoch: 1... Training loss: 0.00387... Test loss: 0.00406\n",
      "Epoch: 1... Training loss: 0.00383... Test loss: 0.00418\n",
      "Epoch: 1... Training loss: 0.00378... Test loss: 0.00371\n",
      "Epoch: 1... Training loss: 0.0037... Test loss: 0.00369\n",
      "Epoch: 1... Training loss: 0.00358... Test loss: 0.00336\n",
      "Epoch: 1... Training loss: 0.0036... Test loss: 0.00369\n",
      "Epoch: 1... Training loss: 0.00362... Test loss: 0.00364\n",
      "Epoch: 1... Training loss: 0.00353... Test loss: 0.00346\n",
      "Epoch: 1... Training loss: 0.0035... Test loss: 0.00295\n",
      "Epoch: 1... Training loss: 0.00346... Test loss: 0.00362\n",
      "Epoch: 1... Training loss: 0.00332... Test loss: 0.00286\n",
      "Epoch: 1... Training loss: 0.00335... Test loss: 0.00323\n",
      "Epoch: 1... Training loss: 0.00331... Test loss: 0.00278\n",
      "Epoch: 1... Training loss: 0.00314... Test loss: 0.00301\n",
      "Epoch: 1... Training loss: 0.00311... Test loss: 0.00294\n",
      "Epoch: 1... Training loss: 0.00304... Test loss: 0.00325\n",
      "Epoch: 1... Training loss: 0.00302... Test loss: 0.0031\n",
      "Epoch: 1... Training loss: 0.00303... Test loss: 0.00306\n",
      "Epoch: 1... Training loss: 0.00296... Test loss: 0.00302\n",
      "Epoch: 1... Training loss: 0.00293... Test loss: 0.00283\n",
      "Epoch: 1... Training loss: 0.00275... Test loss: 0.00262\n",
      "Epoch: 1... Training loss: 0.00277... Test loss: 0.00262\n",
      "Epoch: 1... Training loss: 0.00267... Test loss: 0.00287\n",
      "Epoch: 1... Training loss: 0.00257... Test loss: 0.00277\n",
      "Epoch: 1... Training loss: 0.00251... Test loss: 0.00286\n",
      "Epoch: 1... Training loss: 0.00249... Test loss: 0.0028\n",
      "Epoch: 1... Training loss: 0.00245... Test loss: 0.00229\n",
      "Epoch: 1... Training loss: 0.00232... Test loss: 0.00265\n",
      "Epoch: 1... Training loss: 0.00243... Test loss: 0.00251\n",
      "Epoch: 1... Training loss: 0.00231... Test loss: 0.0024\n",
      "Epoch: 1... Training loss: 0.00222... Test loss: 0.00273\n",
      "Epoch: 1... Training loss: 0.00232... Test loss: 0.00257\n",
      "Epoch: 1... Training loss: 0.00213... Test loss: 0.00272\n",
      "Epoch: 1... Training loss: 0.00204... Test loss: 0.00252\n",
      "Epoch: 1... Training loss: 0.00194... Test loss: 0.00205\n",
      "Epoch: 1... Training loss: 0.00194... Test loss: 0.00227\n",
      "Epoch: 1... Training loss: 0.0019... Test loss: 0.00202\n",
      "Epoch: 1... Training loss: 0.00184... Test loss: 0.0022\n",
      "Epoch: 1... Training loss: 0.00174... Test loss: 0.00176\n",
      "Epoch: 1... Training loss: 0.00177... Test loss: 0.0024\n",
      "Epoch: 1... Training loss: 0.00171... Test loss: 0.00186\n",
      "Epoch: 1... Training loss: 0.00175... Test loss: 0.00202\n",
      "Epoch: 1... Training loss: 0.00168... Test loss: 0.0017\n",
      "Epoch: 1... Training loss: 0.00166... Test loss: 0.00192\n",
      "Epoch: 1... Training loss: 0.00173... Test loss: 0.00166\n",
      "Epoch: 1... Training loss: 0.00157... Test loss: 0.00148\n",
      "Epoch: 1... Training loss: 0.00151... Test loss: 0.00152\n",
      "Epoch: 1... Training loss: 0.00146... Test loss: 0.00158\n",
      "Epoch: 1... Training loss: 0.00143... Test loss: 0.0018\n",
      "Epoch: 1... Training loss: 0.00137... Test loss: 0.00168\n",
      "Epoch: 1... Training loss: 0.00132... Test loss: 0.0015\n",
      "Epoch: 1... Training loss: 0.00136... Test loss: 0.00163\n",
      "Epoch: 1... Training loss: 0.00129... Test loss: 0.00142\n",
      "Epoch: 1... Training loss: 0.00134... Test loss: 0.00164\n",
      "Epoch: 1... Training loss: 0.00122... Test loss: 0.00146\n",
      "Epoch: 1... Training loss: 0.00118... Test loss: 0.0013\n",
      "Epoch: 1... Training loss: 0.00116... Test loss: 0.00144\n",
      "Epoch: 1... Training loss: 0.00105... Test loss: 0.00115\n",
      "Epoch: 1... Training loss: 0.00108... Test loss: 0.00125\n",
      "Epoch: 1... Training loss: 0.00097... Test loss: 0.00119\n",
      "Epoch: 1... Training loss: 0.00101... Test loss: 0.00123\n",
      "Epoch: 1... Training loss: 0.00098... Test loss: 0.0011\n",
      "Epoch: 1... Training loss: 0.00092... Test loss: 0.0011\n",
      "Epoch: 1... Training loss: 0.00098... Test loss: 0.00106\n",
      "Epoch: 1... Training loss: 0.00086... Test loss: 0.00096\n",
      "Epoch: 1... Training loss: 0.00088... Test loss: 0.00091\n",
      "Epoch: 1... Training loss: 0.0009... Test loss: 0.00076\n",
      "Epoch: 1... Training loss: 0.00089... Test loss: 0.00062\n",
      "Epoch: 1... Training loss: 0.00086... Test loss: 0.00083\n",
      "Epoch: 1... Training loss: 0.0008... Test loss: 0.00069\n",
      "Epoch: 1... Training loss: 0.0008... Test loss: 0.00089\n",
      "Epoch: 1... Training loss: 0.00074... Test loss: 0.0008\n",
      "Epoch: 1... Training loss: 0.0007... Test loss: 0.00087\n",
      "Epoch: 1... Training loss: 0.00068... Test loss: 0.00071\n",
      "Epoch: 1... Training loss: 0.00062... Test loss: 0.00083\n",
      "Epoch: 1... Training loss: 0.00063... Test loss: 0.00061\n",
      "Epoch: 1... Training loss: 0.00067... Test loss: 0.00079\n",
      "Epoch: 1... Training loss: 0.00061... Test loss: 0.00062\n",
      "Epoch: 1... Training loss: 0.00056... Test loss: 0.00078\n",
      "Epoch: 1... Training loss: 0.00051... Test loss: 0.00055\n",
      "Epoch: 1... Training loss: 0.00053... Test loss: 0.00068\n",
      "Epoch: 1... Training loss: 0.00048... Test loss: 0.00047\n",
      "Epoch: 1... Training loss: 0.00047... Test loss: 0.00066\n",
      "Epoch: 1... Training loss: 0.00044... Test loss: 0.00051\n",
      "Epoch: 1... Training loss: 0.00041... Test loss: 0.00055\n",
      "Epoch: 1... Training loss: 0.00041... Test loss: 0.00043\n",
      "Epoch: 1... Training loss: 0.00036... Test loss: 0.00051\n",
      "Epoch: 1... Training loss: 0.00037... Test loss: 0.00036\n",
      "Epoch: 1... Training loss: 0.00032... Test loss: 0.0005\n",
      "Epoch: 1... Training loss: 0.00037... Test loss: 0.00034\n",
      "Epoch: 1... Training loss: 0.00031... Test loss: 0.00055\n",
      "Epoch: 1... Training loss: 0.00033... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.00029... Test loss: 0.00046\n",
      "Epoch: 1... Training loss: 0.00029... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00039\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00024\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00028\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00019\n",
      "267.15269417490344\n",
      "Epoch: 1... Training loss: 0.87442... Test loss: 0.20823\n",
      "Epoch: 1... Training loss: 0.39221... Test loss: 0.08104\n",
      "Epoch: 1... Training loss: 0.25806... Test loss: 0.06559\n",
      "Epoch: 1... Training loss: 0.17216... Test loss: 0.04382\n",
      "Epoch: 1... Training loss: 0.1409... Test loss: 0.03626\n",
      "Epoch: 1... Training loss: 0.11708... Test loss: 0.02818\n",
      "Epoch: 1... Training loss: 0.09838... Test loss: 0.02304\n",
      "Epoch: 1... Training loss: 0.08468... Test loss: 0.01751\n",
      "Epoch: 1... Training loss: 0.07685... Test loss: 0.01832\n",
      "Epoch: 1... Training loss: 0.06587... Test loss: 0.01541\n",
      "Epoch: 1... Training loss: 0.06103... Test loss: 0.01787\n",
      "Epoch: 1... Training loss: 0.05635... Test loss: 0.0086\n",
      "Epoch: 1... Training loss: 0.05262... Test loss: 0.01581\n",
      "Epoch: 1... Training loss: 0.0488... Test loss: 0.0067\n",
      "Epoch: 1... Training loss: 0.04189... Test loss: 0.01125\n",
      "Epoch: 1... Training loss: 0.03613... Test loss: 0.00483\n",
      "Epoch: 1... Training loss: 0.03373... Test loss: 0.01156\n",
      "Epoch: 1... Training loss: 0.03125... Test loss: 0.0045\n",
      "Epoch: 1... Training loss: 0.03025... Test loss: 0.0105\n",
      "Epoch: 1... Training loss: 0.02777... Test loss: 0.0052\n",
      "Epoch: 1... Training loss: 0.02622... Test loss: 0.01112\n",
      "Epoch: 1... Training loss: 0.02475... Test loss: 0.00577\n",
      "Epoch: 1... Training loss: 0.02387... Test loss: 0.01144\n",
      "Epoch: 1... Training loss: 0.02299... Test loss: 0.00749\n",
      "Epoch: 1... Training loss: 0.0224... Test loss: 0.01297\n",
      "Epoch: 1... Training loss: 0.0205... Test loss: 0.00647\n",
      "Epoch: 1... Training loss: 0.02002... Test loss: 0.01186\n",
      "Epoch: 1... Training loss: 0.01903... Test loss: 0.00664\n",
      "Epoch: 1... Training loss: 0.01822... Test loss: 0.01398\n",
      "Epoch: 1... Training loss: 0.0174... Test loss: 0.00723\n",
      "Epoch: 1... Training loss: 0.01671... Test loss: 0.01188\n",
      "Epoch: 1... Training loss: 0.01612... Test loss: 0.00836\n",
      "Epoch: 1... Training loss: 0.01561... Test loss: 0.01289\n",
      "Epoch: 1... Training loss: 0.01482... Test loss: 0.00661\n",
      "Epoch: 1... Training loss: 0.01408... Test loss: 0.01303\n",
      "Epoch: 1... Training loss: 0.01383... Test loss: 0.0095\n",
      "Epoch: 1... Training loss: 0.01321... Test loss: 0.01145\n",
      "Epoch: 1... Training loss: 0.01283... Test loss: 0.00912\n",
      "Epoch: 1... Training loss: 0.01248... Test loss: 0.00878\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1... Training loss: 0.01214... Test loss: 0.0081\n",
      "Epoch: 1... Training loss: 0.01165... Test loss: 0.00971\n",
      "Epoch: 1... Training loss: 0.01162... Test loss: 0.00705\n",
      "Epoch: 1... Training loss: 0.01109... Test loss: 0.01046\n",
      "Epoch: 1... Training loss: 0.01107... Test loss: 0.00723\n",
      "Epoch: 1... Training loss: 0.01041... Test loss: 0.01001\n",
      "Epoch: 1... Training loss: 0.01009... Test loss: 0.00674\n",
      "Epoch: 1... Training loss: 0.0097... Test loss: 0.00921\n",
      "Epoch: 1... Training loss: 0.00954... Test loss: 0.00656\n",
      "Epoch: 1... Training loss: 0.00917... Test loss: 0.00883\n",
      "Epoch: 1... Training loss: 0.00891... Test loss: 0.00707\n",
      "Epoch: 1... Training loss: 0.00854... Test loss: 0.00778\n",
      "Epoch: 1... Training loss: 0.0084... Test loss: 0.00585\n",
      "Epoch: 1... Training loss: 0.00793... Test loss: 0.00665\n",
      "Epoch: 1... Training loss: 0.00778... Test loss: 0.00641\n",
      "Epoch: 1... Training loss: 0.00758... Test loss: 0.00634\n",
      "Epoch: 1... Training loss: 0.00745... Test loss: 0.0063\n",
      "Epoch: 1... Training loss: 0.00714... Test loss: 0.00683\n",
      "Epoch: 1... Training loss: 0.00695... Test loss: 0.00523\n",
      "Epoch: 1... Training loss: 0.00681... Test loss: 0.00619\n",
      "Epoch: 1... Training loss: 0.00659... Test loss: 0.00566\n",
      "Epoch: 1... Training loss: 0.00638... Test loss: 0.00555\n",
      "Epoch: 1... Training loss: 0.00622... Test loss: 0.0062\n",
      "Epoch: 1... Training loss: 0.00614... Test loss: 0.00544\n",
      "Epoch: 1... Training loss: 0.00601... Test loss: 0.00557\n",
      "Epoch: 1... Training loss: 0.00938... Test loss: 0.00827\n",
      "Epoch: 1... Training loss: 0.01158... Test loss: 0.00764\n",
      "Epoch: 1... Training loss: 0.01026... Test loss: 0.01107\n",
      "Epoch: 1... Training loss: 0.01073... Test loss: 0.00893\n",
      "Epoch: 1... Training loss: 0.01147... Test loss: 0.01132\n",
      "Epoch: 1... Training loss: 0.01194... Test loss: 0.01217\n",
      "Epoch: 1... Training loss: 0.01051... Test loss: 0.01138\n",
      "Epoch: 1... Training loss: 0.01059... Test loss: 0.01148\n",
      "Epoch: 1... Training loss: 0.00871... Test loss: 0.01044\n",
      "Epoch: 1... Training loss: 0.00825... Test loss: 0.00945\n",
      "Epoch: 1... Training loss: 0.00817... Test loss: 0.01\n",
      "Epoch: 1... Training loss: 0.00779... Test loss: 0.00974\n",
      "Epoch: 1... Training loss: 0.00804... Test loss: 0.00926\n",
      "Epoch: 1... Training loss: 0.00707... Test loss: 0.00996\n",
      "Epoch: 1... Training loss: 0.00848... Test loss: 0.00942\n",
      "Epoch: 1... Training loss: 0.00733... Test loss: 0.00949\n",
      "Epoch: 1... Training loss: 0.0072... Test loss: 0.00738\n",
      "Epoch: 1... Training loss: 0.00701... Test loss: 0.01017\n",
      "Epoch: 1... Training loss: 0.00697... Test loss: 0.00829\n",
      "Epoch: 1... Training loss: 0.00665... Test loss: 0.0075\n",
      "Epoch: 1... Training loss: 0.00664... Test loss: 0.00727\n",
      "Epoch: 1... Training loss: 0.00633... Test loss: 0.0066\n",
      "Epoch: 1... Training loss: 0.00581... Test loss: 0.00662\n",
      "Epoch: 1... Training loss: 0.00596... Test loss: 0.00662\n",
      "Epoch: 1... Training loss: 0.00576... Test loss: 0.00565\n",
      "Epoch: 1... Training loss: 0.00562... Test loss: 0.00669\n",
      "Epoch: 1... Training loss: 0.00544... Test loss: 0.00588\n",
      "Epoch: 1... Training loss: 0.00534... Test loss: 0.00591\n",
      "Epoch: 1... Training loss: 0.00528... Test loss: 0.00643\n",
      "Epoch: 1... Training loss: 0.00488... Test loss: 0.00664\n",
      "Epoch: 1... Training loss: 0.0048... Test loss: 0.00653\n",
      "Epoch: 1... Training loss: 0.00464... Test loss: 0.00583\n",
      "Epoch: 1... Training loss: 0.00452... Test loss: 0.00662\n",
      "Epoch: 1... Training loss: 0.00433... Test loss: 0.00503\n",
      "Epoch: 1... Training loss: 0.00425... Test loss: 0.00565\n",
      "Epoch: 1... Training loss: 0.00406... Test loss: 0.00497\n",
      "Epoch: 1... Training loss: 0.00408... Test loss: 0.0046\n",
      "Epoch: 1... Training loss: 0.00395... Test loss: 0.00466\n",
      "Epoch: 1... Training loss: 0.0038... Test loss: 0.00429\n",
      "Epoch: 1... Training loss: 0.00362... Test loss: 0.00449\n",
      "Epoch: 1... Training loss: 0.0036... Test loss: 0.00412\n",
      "Epoch: 1... Training loss: 0.0036... Test loss: 0.00413\n",
      "Epoch: 1... Training loss: 0.00342... Test loss: 0.00396\n",
      "Epoch: 1... Training loss: 0.00325... Test loss: 0.0033\n",
      "Epoch: 1... Training loss: 0.00338... Test loss: 0.0034\n",
      "Epoch: 1... Training loss: 0.00327... Test loss: 0.003\n",
      "Epoch: 1... Training loss: 0.00316... Test loss: 0.00334\n",
      "Epoch: 1... Training loss: 0.00316... Test loss: 0.00302\n",
      "Epoch: 1... Training loss: 0.003... Test loss: 0.00356\n",
      "Epoch: 1... Training loss: 0.003... Test loss: 0.0028\n",
      "Epoch: 1... Training loss: 0.00286... Test loss: 0.00347\n",
      "Epoch: 1... Training loss: 0.00286... Test loss: 0.00259\n",
      "Epoch: 1... Training loss: 0.00292... Test loss: 0.00314\n",
      "Epoch: 1... Training loss: 0.00276... Test loss: 0.00266\n",
      "Epoch: 1... Training loss: 0.00272... Test loss: 0.00284\n",
      "Epoch: 1... Training loss: 0.00282... Test loss: 0.00289\n",
      "Epoch: 1... Training loss: 0.00266... Test loss: 0.00291\n",
      "Epoch: 1... Training loss: 0.00258... Test loss: 0.00295\n",
      "Epoch: 1... Training loss: 0.00249... Test loss: 0.0025\n",
      "Epoch: 1... Training loss: 0.00252... Test loss: 0.00276\n",
      "Epoch: 1... Training loss: 0.0024... Test loss: 0.00263\n",
      "Epoch: 1... Training loss: 0.00238... Test loss: 0.00278\n",
      "Epoch: 1... Training loss: 0.00235... Test loss: 0.00249\n",
      "Epoch: 1... Training loss: 0.0024... Test loss: 0.00254\n",
      "Epoch: 1... Training loss: 0.00218... Test loss: 0.0024\n",
      "Epoch: 1... Training loss: 0.00206... Test loss: 0.00306\n",
      "Epoch: 1... Training loss: 0.00211... Test loss: 0.00214\n",
      "Epoch: 1... Training loss: 0.00199... Test loss: 0.0027\n",
      "Epoch: 1... Training loss: 0.00197... Test loss: 0.00183\n",
      "Epoch: 1... Training loss: 0.00193... Test loss: 0.00216\n",
      "Epoch: 1... Training loss: 0.00197... Test loss: 0.00179\n",
      "Epoch: 1... Training loss: 0.002... Test loss: 0.00215\n",
      "Epoch: 1... Training loss: 0.00173... Test loss: 0.00179\n",
      "Epoch: 1... Training loss: 0.00173... Test loss: 0.00204\n",
      "Epoch: 1... Training loss: 0.00168... Test loss: 0.00182\n",
      "Epoch: 1... Training loss: 0.00163... Test loss: 0.00173\n",
      "Epoch: 1... Training loss: 0.00155... Test loss: 0.00176\n",
      "Epoch: 1... Training loss: 0.00148... Test loss: 0.0016\n",
      "Epoch: 1... Training loss: 0.00151... Test loss: 0.00157\n",
      "Epoch: 1... Training loss: 0.00138... Test loss: 0.00153\n",
      "Epoch: 1... Training loss: 0.00137... Test loss: 0.00144\n",
      "Epoch: 1... Training loss: 0.00142... Test loss: 0.00144\n",
      "Epoch: 1... Training loss: 0.00139... Test loss: 0.00125\n",
      "Epoch: 1... Training loss: 0.00137... Test loss: 0.00131\n",
      "Epoch: 1... Training loss: 0.00129... Test loss: 0.0012\n",
      "Epoch: 1... Training loss: 0.00129... Test loss: 0.00116\n",
      "Epoch: 1... Training loss: 0.00125... Test loss: 0.00127\n",
      "Epoch: 1... Training loss: 0.00122... Test loss: 0.00115\n",
      "Epoch: 1... Training loss: 0.00124... Test loss: 0.00137\n",
      "Epoch: 1... Training loss: 0.00116... Test loss: 0.0011\n",
      "Epoch: 1... Training loss: 0.00115... Test loss: 0.00129\n",
      "Epoch: 1... Training loss: 0.00115... Test loss: 0.00103\n",
      "Epoch: 1... Training loss: 0.00112... Test loss: 0.00128\n",
      "Epoch: 1... Training loss: 0.00117... Test loss: 0.00115\n",
      "Epoch: 1... Training loss: 0.00101... Test loss: 0.00116\n",
      "Epoch: 1... Training loss: 0.00108... Test loss: 0.00103\n",
      "Epoch: 1... Training loss: 0.001... Test loss: 0.0011\n",
      "Epoch: 1... Training loss: 0.001... Test loss: 0.00091\n",
      "Epoch: 1... Training loss: 0.00097... Test loss: 0.00115\n",
      "Epoch: 1... Training loss: 0.00086... Test loss: 0.00091\n",
      "Epoch: 1... Training loss: 0.00089... Test loss: 0.00091\n",
      "Epoch: 1... Training loss: 0.00085... Test loss: 0.0009\n",
      "Epoch: 1... Training loss: 0.00079... Test loss: 0.00091\n",
      "Epoch: 1... Training loss: 0.00077... Test loss: 0.00093\n",
      "Epoch: 1... Training loss: 0.00075... Test loss: 0.00085\n",
      "Epoch: 1... Training loss: 0.00076... Test loss: 0.00084\n",
      "Epoch: 1... Training loss: 0.00073... Test loss: 0.00073\n",
      "Epoch: 1... Training loss: 0.00072... Test loss: 0.00081\n",
      "Epoch: 1... Training loss: 0.00069... Test loss: 0.00076\n",
      "Epoch: 1... Training loss: 0.00062... Test loss: 0.00073\n",
      "Epoch: 1... Training loss: 0.00058... Test loss: 0.00062\n",
      "Epoch: 1... Training loss: 0.00057... Test loss: 0.00071\n",
      "Epoch: 1... Training loss: 0.00058... Test loss: 0.00054\n",
      "Epoch: 1... Training loss: 0.00055... Test loss: 0.00058\n",
      "Epoch: 1... Training loss: 0.00054... Test loss: 0.00056\n",
      "Epoch: 1... Training loss: 0.00052... Test loss: 0.00053\n",
      "Epoch: 1... Training loss: 0.00051... Test loss: 0.00057\n",
      "Epoch: 1... Training loss: 0.00052... Test loss: 0.00048\n",
      "Epoch: 1... Training loss: 0.00045... Test loss: 0.0005\n",
      "Epoch: 1... Training loss: 0.00044... Test loss: 0.00044\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1... Training loss: 0.00043... Test loss: 0.00051\n",
      "Epoch: 1... Training loss: 0.00043... Test loss: 0.0004\n",
      "Epoch: 1... Training loss: 0.00042... Test loss: 0.0005\n",
      "Epoch: 1... Training loss: 0.00036... Test loss: 0.00038\n",
      "Epoch: 1... Training loss: 0.00036... Test loss: 0.00043\n",
      "Epoch: 1... Training loss: 0.00038... Test loss: 0.00038\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.0004\n",
      "Epoch: 1... Training loss: 0.00032... Test loss: 0.00033\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00032\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00028\n",
      "Epoch: 1... Training loss: 0.00026... Test loss: 0.00031\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00028\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00024\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00021\n",
      "305.489882113412\n",
      "Epoch: 1... Training loss: 0.78558... Test loss: 0.13708\n",
      "Epoch: 1... Training loss: 0.37034... Test loss: 0.09866\n",
      "Epoch: 1... Training loss: 0.22672... Test loss: 0.07195\n",
      "Epoch: 1... Training loss: 0.16172... Test loss: 0.047\n",
      "Epoch: 1... Training loss: 0.13068... Test loss: 0.03677\n",
      "Epoch: 1... Training loss: 0.10779... Test loss: 0.02711\n",
      "Epoch: 1... Training loss: 0.09431... Test loss: 0.0237\n",
      "Epoch: 1... Training loss: 0.08297... Test loss: 0.02103\n",
      "Epoch: 1... Training loss: 0.06984... Test loss: 0.01782\n",
      "Epoch: 1... Training loss: 0.06067... Test loss: 0.0147\n",
      "Epoch: 1... Training loss: 0.054... Test loss: 0.01553\n",
      "Epoch: 1... Training loss: 0.04743... Test loss: 0.01364\n",
      "Epoch: 1... Training loss: 0.0446... Test loss: 0.01642\n",
      "Epoch: 1... Training loss: 0.04119... Test loss: 0.00827\n",
      "Epoch: 1... Training loss: 0.03573... Test loss: 0.01356\n",
      "Epoch: 1... Training loss: 0.03301... Test loss: 0.0071\n",
      "Epoch: 1... Training loss: 0.03102... Test loss: 0.01343\n",
      "Epoch: 1... Training loss: 0.02956... Test loss: 0.00545\n",
      "Epoch: 1... Training loss: 0.02683... Test loss: 0.01194\n",
      "Epoch: 1... Training loss: 0.02437... Test loss: 0.00528\n",
      "Epoch: 1... Training loss: 0.02218... Test loss: 0.01167\n",
      "Epoch: 1... Training loss: 0.02189... Test loss: 0.00432\n",
      "Epoch: 1... Training loss: 0.01997... Test loss: 0.01001\n",
      "Epoch: 1... Training loss: 0.01992... Test loss: 0.00622\n",
      "Epoch: 1... Training loss: 0.01871... Test loss: 0.01348\n",
      "Epoch: 1... Training loss: 0.01828... Test loss: 0.00546\n",
      "Epoch: 1... Training loss: 0.01743... Test loss: 0.01368\n",
      "Epoch: 1... Training loss: 0.01647... Test loss: 0.00602\n",
      "Epoch: 1... Training loss: 0.01518... Test loss: 0.01596\n",
      "Epoch: 1... Training loss: 0.01504... Test loss: 0.00493\n",
      "Epoch: 1... Training loss: 0.01431... Test loss: 0.01015\n",
      "Epoch: 1... Training loss: 0.01387... Test loss: 0.00714\n",
      "Epoch: 1... Training loss: 0.01351... Test loss: 0.01235\n",
      "Epoch: 1... Training loss: 0.01302... Test loss: 0.00723\n",
      "Epoch: 1... Training loss: 0.01262... Test loss: 0.01057\n",
      "Epoch: 1... Training loss: 0.01223... Test loss: 0.00681\n",
      "Epoch: 1... Training loss: 0.01174... Test loss: 0.00932\n",
      "Epoch: 1... Training loss: 0.01123... Test loss: 0.00719\n",
      "Epoch: 1... Training loss: 0.01109... Test loss: 0.01349\n",
      "Epoch: 1... Training loss: 0.01079... Test loss: 0.00639\n",
      "Epoch: 1... Training loss: 0.00999... Test loss: 0.01244\n",
      "Epoch: 1... Training loss: 0.01017... Test loss: 0.00627\n",
      "Epoch: 1... Training loss: 0.00967... Test loss: 0.00927\n",
      "Epoch: 1... Training loss: 0.00936... Test loss: 0.0061\n",
      "Epoch: 1... Training loss: 0.00902... Test loss: 0.00935\n",
      "Epoch: 1... Training loss: 0.00871... Test loss: 0.00687\n",
      "Epoch: 1... Training loss: 0.0085... Test loss: 0.00848\n",
      "Epoch: 1... Training loss: 0.00822... Test loss: 0.00634\n",
      "Epoch: 1... Training loss: 0.00794... Test loss: 0.00546\n",
      "Epoch: 1... Training loss: 0.00775... Test loss: 0.00791\n",
      "Epoch: 1... Training loss: 0.00747... Test loss: 0.00515\n",
      "Epoch: 1... Training loss: 0.0073... Test loss: 0.00682\n",
      "Epoch: 1... Training loss: 0.00712... Test loss: 0.00507\n",
      "Epoch: 1... Training loss: 0.00699... Test loss: 0.0072\n",
      "Epoch: 1... Training loss: 0.00685... Test loss: 0.00512\n",
      "Epoch: 1... Training loss: 0.00671... Test loss: 0.0066\n",
      "Epoch: 1... Training loss: 0.00646... Test loss: 0.00502\n",
      "Epoch: 1... Training loss: 0.00625... Test loss: 0.0062\n",
      "Epoch: 1... Training loss: 0.00609... Test loss: 0.00501\n",
      "Epoch: 1... Training loss: 0.00599... Test loss: 0.00546\n",
      "Epoch: 1... Training loss: 0.0058... Test loss: 0.00518\n",
      "Epoch: 1... Training loss: 0.00565... Test loss: 0.00585\n",
      "Epoch: 1... Training loss: 0.00552... Test loss: 0.00489\n",
      "Epoch: 1... Training loss: 0.00545... Test loss: 0.00558\n",
      "Epoch: 1... Training loss: 0.0117... Test loss: 0.0097\n",
      "Epoch: 1... Training loss: 0.01018... Test loss: 0.02101\n",
      "Epoch: 1... Training loss: 0.01067... Test loss: 0.01476\n",
      "Epoch: 1... Training loss: 0.00879... Test loss: 0.01482\n",
      "Epoch: 1... Training loss: 0.00824... Test loss: 0.01281\n",
      "Epoch: 1... Training loss: 0.00922... Test loss: 0.01137\n",
      "Epoch: 1... Training loss: 0.00867... Test loss: 0.01178\n",
      "Epoch: 1... Training loss: 0.0076... Test loss: 0.00961\n",
      "Epoch: 1... Training loss: 0.00793... Test loss: 0.00844\n",
      "Epoch: 1... Training loss: 0.00813... Test loss: 0.01088\n",
      "Epoch: 1... Training loss: 0.00822... Test loss: 0.01042\n",
      "Epoch: 1... Training loss: 0.00751... Test loss: 0.00664\n",
      "Epoch: 1... Training loss: 0.00676... Test loss: 0.00746\n",
      "Epoch: 1... Training loss: 0.00741... Test loss: 0.00656\n",
      "Epoch: 1... Training loss: 0.00621... Test loss: 0.01147\n",
      "Epoch: 1... Training loss: 0.00643... Test loss: 0.00687\n",
      "Epoch: 1... Training loss: 0.00596... Test loss: 0.00746\n",
      "Epoch: 1... Training loss: 0.00626... Test loss: 0.00739\n",
      "Epoch: 1... Training loss: 0.0059... Test loss: 0.00546\n",
      "Epoch: 1... Training loss: 0.0055... Test loss: 0.00741\n",
      "Epoch: 1... Training loss: 0.00561... Test loss: 0.00526\n",
      "Epoch: 1... Training loss: 0.00585... Test loss: 0.00816\n",
      "Epoch: 1... Training loss: 0.00529... Test loss: 0.00475\n",
      "Epoch: 1... Training loss: 0.0053... Test loss: 0.00806\n",
      "Epoch: 1... Training loss: 0.00471... Test loss: 0.00511\n",
      "Epoch: 1... Training loss: 0.00485... Test loss: 0.00648\n",
      "Epoch: 1... Training loss: 0.00467... Test loss: 0.0048\n",
      "Epoch: 1... Training loss: 0.00447... Test loss: 0.00519\n",
      "Epoch: 1... Training loss: 0.00427... Test loss: 0.00486\n",
      "Epoch: 1... Training loss: 0.00432... Test loss: 0.00559\n",
      "Epoch: 1... Training loss: 0.00425... Test loss: 0.00444\n",
      "Epoch: 1... Training loss: 0.0043... Test loss: 0.00479\n",
      "Epoch: 1... Training loss: 0.00406... Test loss: 0.00399\n",
      "Epoch: 1... Training loss: 0.00391... Test loss: 0.00369\n",
      "Epoch: 1... Training loss: 0.00363... Test loss: 0.00418\n",
      "Epoch: 1... Training loss: 0.00368... Test loss: 0.0039\n",
      "Epoch: 1... Training loss: 0.00353... Test loss: 0.00459\n",
      "Epoch: 1... Training loss: 0.00347... Test loss: 0.00363\n",
      "Epoch: 1... Training loss: 0.00329... Test loss: 0.00431\n",
      "Epoch: 1... Training loss: 0.00334... Test loss: 0.0031\n",
      "Epoch: 1... Training loss: 0.00325... Test loss: 0.00398\n",
      "Epoch: 1... Training loss: 0.00309... Test loss: 0.00315\n",
      "Epoch: 1... Training loss: 0.00307... Test loss: 0.00376\n",
      "Epoch: 1... Training loss: 0.00298... Test loss: 0.00291\n",
      "Epoch: 1... Training loss: 0.00289... Test loss: 0.00334\n",
      "Epoch: 1... Training loss: 0.00278... Test loss: 0.00325\n",
      "Epoch: 1... Training loss: 0.00278... Test loss: 0.00285\n",
      "Epoch: 1... Training loss: 0.0029... Test loss: 0.00307\n",
      "Epoch: 1... Training loss: 0.00262... Test loss: 0.00327\n",
      "Epoch: 1... Training loss: 0.00262... Test loss: 0.00307\n",
      "Epoch: 1... Training loss: 0.00261... Test loss: 0.00284\n",
      "Epoch: 1... Training loss: 0.00254... Test loss: 0.00272\n",
      "Epoch: 1... Training loss: 0.00237... Test loss: 0.00259\n",
      "Epoch: 1... Training loss: 0.00229... Test loss: 0.00275\n",
      "Epoch: 1... Training loss: 0.00235... Test loss: 0.00257\n",
      "Epoch: 1... Training loss: 0.00235... Test loss: 0.00224\n",
      "Epoch: 1... Training loss: 0.00219... Test loss: 0.0029\n",
      "Epoch: 1... Training loss: 0.00231... Test loss: 0.00211\n",
      "Epoch: 1... Training loss: 0.00217... Test loss: 0.00278\n",
      "Epoch: 1... Training loss: 0.00221... Test loss: 0.00192\n",
      "Epoch: 1... Training loss: 0.0019... Test loss: 0.00275\n",
      "Epoch: 1... Training loss: 0.002... Test loss: 0.00202\n",
      "Epoch: 1... Training loss: 0.00187... Test loss: 0.00235\n",
      "Epoch: 1... Training loss: 0.00181... Test loss: 0.00218\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1... Training loss: 0.00182... Test loss: 0.00207\n",
      "Epoch: 1... Training loss: 0.00174... Test loss: 0.00184\n",
      "Epoch: 1... Training loss: 0.00169... Test loss: 0.00204\n",
      "Epoch: 1... Training loss: 0.00166... Test loss: 0.00186\n",
      "Epoch: 1... Training loss: 0.00151... Test loss: 0.00193\n",
      "Epoch: 1... Training loss: 0.00154... Test loss: 0.00199\n",
      "Epoch: 1... Training loss: 0.0014... Test loss: 0.00195\n",
      "Epoch: 1... Training loss: 0.00138... Test loss: 0.00141\n",
      "Epoch: 1... Training loss: 0.00138... Test loss: 0.00159\n",
      "Epoch: 1... Training loss: 0.00129... Test loss: 0.00145\n",
      "Epoch: 1... Training loss: 0.00132... Test loss: 0.00139\n",
      "Epoch: 1... Training loss: 0.00124... Test loss: 0.00151\n",
      "Epoch: 1... Training loss: 0.00124... Test loss: 0.0012\n",
      "Epoch: 1... Training loss: 0.0012... Test loss: 0.00146\n",
      "Epoch: 1... Training loss: 0.00113... Test loss: 0.00118\n",
      "Epoch: 1... Training loss: 0.00107... Test loss: 0.00112\n",
      "Epoch: 1... Training loss: 0.00109... Test loss: 0.00139\n",
      "Epoch: 1... Training loss: 0.00102... Test loss: 0.00126\n",
      "Epoch: 1... Training loss: 0.00098... Test loss: 0.00105\n",
      "Epoch: 1... Training loss: 0.00094... Test loss: 0.00108\n",
      "Epoch: 1... Training loss: 0.00095... Test loss: 0.00102\n",
      "Epoch: 1... Training loss: 0.00089... Test loss: 0.00101\n",
      "Epoch: 1... Training loss: 0.00087... Test loss: 0.00105\n",
      "Epoch: 1... Training loss: 0.00089... Test loss: 0.0009\n",
      "Epoch: 1... Training loss: 0.00085... Test loss: 0.00109\n",
      "Epoch: 1... Training loss: 0.00077... Test loss: 0.00089\n",
      "Epoch: 1... Training loss: 0.00074... Test loss: 0.00094\n",
      "Epoch: 1... Training loss: 0.00074... Test loss: 0.00072\n",
      "Epoch: 1... Training loss: 0.00067... Test loss: 0.00086\n",
      "Epoch: 1... Training loss: 0.00067... Test loss: 0.0006\n",
      "Epoch: 1... Training loss: 0.00066... Test loss: 0.00081\n",
      "Epoch: 1... Training loss: 0.00072... Test loss: 0.00064\n",
      "Epoch: 1... Training loss: 0.00063... Test loss: 0.00078\n",
      "Epoch: 1... Training loss: 0.00061... Test loss: 0.00061\n",
      "Epoch: 1... Training loss: 0.00059... Test loss: 0.00064\n",
      "Epoch: 1... Training loss: 0.00056... Test loss: 0.00054\n",
      "Epoch: 1... Training loss: 0.00055... Test loss: 0.00055\n",
      "Epoch: 1... Training loss: 0.00049... Test loss: 0.00057\n",
      "Epoch: 1... Training loss: 0.00049... Test loss: 0.00055\n",
      "Epoch: 1... Training loss: 0.00051... Test loss: 0.00049\n",
      "Epoch: 1... Training loss: 0.00049... Test loss: 0.00049\n",
      "Epoch: 1... Training loss: 0.00045... Test loss: 0.00045\n",
      "Epoch: 1... Training loss: 0.00046... Test loss: 0.00045\n",
      "Epoch: 1... Training loss: 0.00045... Test loss: 0.00043\n",
      "Epoch: 1... Training loss: 0.00042... Test loss: 0.00054\n",
      "Epoch: 1... Training loss: 0.0004... Test loss: 0.00047\n",
      "Epoch: 1... Training loss: 0.00041... Test loss: 0.00048\n",
      "Epoch: 1... Training loss: 0.00035... Test loss: 0.00037\n",
      "Epoch: 1... Training loss: 0.00037... Test loss: 0.00045\n",
      "Epoch: 1... Training loss: 0.00034... Test loss: 0.00032\n",
      "Epoch: 1... Training loss: 0.00041... Test loss: 0.00039\n",
      "Epoch: 1... Training loss: 0.00032... Test loss: 0.0003\n",
      "Epoch: 1... Training loss: 0.00036... Test loss: 0.00034\n",
      "Epoch: 1... Training loss: 0.00031... Test loss: 0.00038\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00031\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00015\n",
      "280.57834579609334\n",
      "Epoch: 1... Training loss: 1.2745... Test loss: 0.59154\n",
      "Epoch: 1... Training loss: 0.53286... Test loss: 0.20742\n",
      "Epoch: 1... Training loss: 0.29585... Test loss: 0.11092\n",
      "Epoch: 1... Training loss: 0.23291... Test loss: 0.07343\n",
      "Epoch: 1... Training loss: 0.16214... Test loss: 0.0697\n",
      "Epoch: 1... Training loss: 0.12934... Test loss: 0.03928\n",
      "Epoch: 1... Training loss: 0.1052... Test loss: 0.07531\n",
      "Epoch: 1... Training loss: 0.08426... Test loss: 0.03643\n",
      "Epoch: 1... Training loss: 0.06613... Test loss: 0.05769\n",
      "Epoch: 1... Training loss: 0.05724... Test loss: 0.02735\n",
      "Epoch: 1... Training loss: 0.05271... Test loss: 0.049\n",
      "Epoch: 1... Training loss: 0.044... Test loss: 0.02482\n",
      "Epoch: 1... Training loss: 0.03962... Test loss: 0.05294\n",
      "Epoch: 1... Training loss: 0.03654... Test loss: 0.01805\n",
      "Epoch: 1... Training loss: 0.03353... Test loss: 0.04208\n",
      "Epoch: 1... Training loss: 0.03216... Test loss: 0.01783\n",
      "Epoch: 1... Training loss: 0.02988... Test loss: 0.03633\n",
      "Epoch: 1... Training loss: 0.02937... Test loss: 0.01162\n",
      "Epoch: 1... Training loss: 0.0265... Test loss: 0.03171\n",
      "Epoch: 1... Training loss: 0.0252... Test loss: 0.01331\n",
      "Epoch: 1... Training loss: 0.0237... Test loss: 0.02686\n",
      "Epoch: 1... Training loss: 0.02254... Test loss: 0.01796\n",
      "Epoch: 1... Training loss: 0.0216... Test loss: 0.00979\n",
      "Epoch: 1... Training loss: 0.02096... Test loss: 0.03031\n",
      "Epoch: 1... Training loss: 0.01981... Test loss: 0.01184\n",
      "Epoch: 1... Training loss: 0.01896... Test loss: 0.03221\n",
      "Epoch: 1... Training loss: 0.01795... Test loss: 0.00767\n",
      "Epoch: 1... Training loss: 0.01714... Test loss: 0.02842\n",
      "Epoch: 1... Training loss: 0.01714... Test loss: 0.01002\n",
      "Epoch: 1... Training loss: 0.01599... Test loss: 0.02376\n",
      "Epoch: 1... Training loss: 0.01577... Test loss: 0.00765\n",
      "Epoch: 1... Training loss: 0.01527... Test loss: 0.01688\n",
      "Epoch: 1... Training loss: 0.01477... Test loss: 0.0218\n",
      "Epoch: 1... Training loss: 0.01423... Test loss: 0.00795\n",
      "Epoch: 1... Training loss: 0.01381... Test loss: 0.02101\n",
      "Epoch: 1... Training loss: 0.01354... Test loss: 0.00687\n",
      "Epoch: 1... Training loss: 0.01302... Test loss: 0.01996\n",
      "Epoch: 1... Training loss: 0.01263... Test loss: 0.0071\n",
      "Epoch: 1... Training loss: 0.01217... Test loss: 0.01557\n",
      "Epoch: 1... Training loss: 0.01171... Test loss: 0.00823\n",
      "Epoch: 1... Training loss: 0.0114... Test loss: 0.01148\n",
      "Epoch: 1... Training loss: 0.01109... Test loss: 0.01078\n",
      "Epoch: 1... Training loss: 0.01084... Test loss: 0.00806\n",
      "Epoch: 1... Training loss: 0.01052... Test loss: 0.01283\n",
      "Epoch: 1... Training loss: 0.01055... Test loss: 0.00631\n",
      "Epoch: 1... Training loss: 0.00998... Test loss: 0.01143\n",
      "Epoch: 1... Training loss: 0.00974... Test loss: 0.00677\n",
      "Epoch: 1... Training loss: 0.0092... Test loss: 0.01114\n",
      "Epoch: 1... Training loss: 0.00906... Test loss: 0.00654\n",
      "Epoch: 1... Training loss: 0.00867... Test loss: 0.01051\n",
      "Epoch: 1... Training loss: 0.00826... Test loss: 0.00696\n",
      "Epoch: 1... Training loss: 0.00813... Test loss: 0.00859\n",
      "Epoch: 1... Training loss: 0.00784... Test loss: 0.00744\n",
      "Epoch: 1... Training loss: 0.00765... Test loss: 0.00818\n",
      "Epoch: 1... Training loss: 0.00736... Test loss: 0.00686\n",
      "Epoch: 1... Training loss: 0.0072... Test loss: 0.00967\n",
      "Epoch: 1... Training loss: 0.00693... Test loss: 0.00707\n",
      "Epoch: 1... Training loss: 0.00674... Test loss: 0.0091\n",
      "Epoch: 1... Training loss: 0.00654... Test loss: 0.00821\n",
      "Epoch: 1... Training loss: 0.00638... Test loss: 0.00774\n",
      "Epoch: 1... Training loss: 0.00616... Test loss: 0.0071\n",
      "Epoch: 1... Training loss: 0.00608... Test loss: 0.00732\n",
      "Epoch: 1... Training loss: 0.00586... Test loss: 0.00588\n",
      "Epoch: 1... Training loss: 0.0058... Test loss: 0.00666\n",
      "Epoch: 1... Training loss: 0.01415... Test loss: 0.01052\n",
      "Epoch: 1... Training loss: 0.0102... Test loss: 0.0108\n",
      "Epoch: 1... Training loss: 0.00995... Test loss: 0.00931\n",
      "Epoch: 1... Training loss: 0.01038... Test loss: 0.01261\n",
      "Epoch: 1... Training loss: 0.01013... Test loss: 0.00915\n",
      "Epoch: 1... Training loss: 0.00915... Test loss: 0.01263\n",
      "Epoch: 1... Training loss: 0.00981... Test loss: 0.01013\n",
      "Epoch: 1... Training loss: 0.00926... Test loss: 0.01061\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1... Training loss: 0.00986... Test loss: 0.00975\n",
      "Epoch: 1... Training loss: 0.00907... Test loss: 0.00801\n",
      "Epoch: 1... Training loss: 0.00947... Test loss: 0.01036\n",
      "Epoch: 1... Training loss: 0.00861... Test loss: 0.00802\n",
      "Epoch: 1... Training loss: 0.00837... Test loss: 0.01087\n",
      "Epoch: 1... Training loss: 0.00836... Test loss: 0.00899\n",
      "Epoch: 1... Training loss: 0.00767... Test loss: 0.00975\n",
      "Epoch: 1... Training loss: 0.00758... Test loss: 0.00823\n",
      "Epoch: 1... Training loss: 0.00728... Test loss: 0.00999\n",
      "Epoch: 1... Training loss: 0.00678... Test loss: 0.00847\n",
      "Epoch: 1... Training loss: 0.00645... Test loss: 0.00897\n",
      "Epoch: 1... Training loss: 0.00664... Test loss: 0.00777\n",
      "Epoch: 1... Training loss: 0.00647... Test loss: 0.00734\n",
      "Epoch: 1... Training loss: 0.00643... Test loss: 0.00646\n",
      "Epoch: 1... Training loss: 0.0062... Test loss: 0.00686\n",
      "Epoch: 1... Training loss: 0.00571... Test loss: 0.00676\n",
      "Epoch: 1... Training loss: 0.00572... Test loss: 0.00661\n",
      "Epoch: 1... Training loss: 0.00529... Test loss: 0.0056\n",
      "Epoch: 1... Training loss: 0.00524... Test loss: 0.00618\n",
      "Epoch: 1... Training loss: 0.00524... Test loss: 0.00514\n",
      "Epoch: 1... Training loss: 0.00497... Test loss: 0.00546\n",
      "Epoch: 1... Training loss: 0.00492... Test loss: 0.00535\n",
      "Epoch: 1... Training loss: 0.00466... Test loss: 0.00524\n",
      "Epoch: 1... Training loss: 0.00448... Test loss: 0.00532\n",
      "Epoch: 1... Training loss: 0.00459... Test loss: 0.00544\n",
      "Epoch: 1... Training loss: 0.00465... Test loss: 0.00463\n",
      "Epoch: 1... Training loss: 0.0043... Test loss: 0.00481\n",
      "Epoch: 1... Training loss: 0.00421... Test loss: 0.00457\n",
      "Epoch: 1... Training loss: 0.00414... Test loss: 0.00425\n",
      "Epoch: 1... Training loss: 0.00405... Test loss: 0.00477\n",
      "Epoch: 1... Training loss: 0.00393... Test loss: 0.00447\n",
      "Epoch: 1... Training loss: 0.00384... Test loss: 0.0045\n",
      "Epoch: 1... Training loss: 0.00365... Test loss: 0.00436\n",
      "Epoch: 1... Training loss: 0.00357... Test loss: 0.0037\n",
      "Epoch: 1... Training loss: 0.00357... Test loss: 0.00443\n",
      "Epoch: 1... Training loss: 0.00354... Test loss: 0.00359\n",
      "Epoch: 1... Training loss: 0.00364... Test loss: 0.00413\n",
      "Epoch: 1... Training loss: 0.00353... Test loss: 0.00326\n",
      "Epoch: 1... Training loss: 0.00343... Test loss: 0.004\n",
      "Epoch: 1... Training loss: 0.00339... Test loss: 0.00322\n",
      "Epoch: 1... Training loss: 0.00324... Test loss: 0.0036\n",
      "Epoch: 1... Training loss: 0.00322... Test loss: 0.00329\n",
      "Epoch: 1... Training loss: 0.00311... Test loss: 0.00358\n",
      "Epoch: 1... Training loss: 0.00298... Test loss: 0.00302\n",
      "Epoch: 1... Training loss: 0.00294... Test loss: 0.00345\n",
      "Epoch: 1... Training loss: 0.0029... Test loss: 0.00286\n",
      "Epoch: 1... Training loss: 0.00283... Test loss: 0.00333\n",
      "Epoch: 1... Training loss: 0.0027... Test loss: 0.0028\n",
      "Epoch: 1... Training loss: 0.00276... Test loss: 0.00302\n",
      "Epoch: 1... Training loss: 0.00259... Test loss: 0.00241\n",
      "Epoch: 1... Training loss: 0.00263... Test loss: 0.00298\n",
      "Epoch: 1... Training loss: 0.00247... Test loss: 0.00256\n",
      "Epoch: 1... Training loss: 0.0025... Test loss: 0.00284\n",
      "Epoch: 1... Training loss: 0.00238... Test loss: 0.0024\n",
      "Epoch: 1... Training loss: 0.00228... Test loss: 0.00248\n",
      "Epoch: 1... Training loss: 0.00226... Test loss: 0.0022\n",
      "Epoch: 1... Training loss: 0.00216... Test loss: 0.00243\n",
      "Epoch: 1... Training loss: 0.0021... Test loss: 0.00247\n",
      "Epoch: 1... Training loss: 0.00206... Test loss: 0.00247\n",
      "Epoch: 1... Training loss: 0.00206... Test loss: 0.00197\n",
      "Epoch: 1... Training loss: 0.00206... Test loss: 0.00248\n",
      "Epoch: 1... Training loss: 0.00187... Test loss: 0.00184\n",
      "Epoch: 1... Training loss: 0.00182... Test loss: 0.0024\n",
      "Epoch: 1... Training loss: 0.00176... Test loss: 0.00188\n",
      "Epoch: 1... Training loss: 0.00168... Test loss: 0.00234\n",
      "Epoch: 1... Training loss: 0.00163... Test loss: 0.00177\n",
      "Epoch: 1... Training loss: 0.00161... Test loss: 0.00214\n",
      "Epoch: 1... Training loss: 0.00167... Test loss: 0.00156\n",
      "Epoch: 1... Training loss: 0.00155... Test loss: 0.0022\n",
      "Epoch: 1... Training loss: 0.00151... Test loss: 0.00171\n",
      "Epoch: 1... Training loss: 0.00144... Test loss: 0.00184\n",
      "Epoch: 1... Training loss: 0.00145... Test loss: 0.0015\n",
      "Epoch: 1... Training loss: 0.00144... Test loss: 0.00178\n",
      "Epoch: 1... Training loss: 0.00134... Test loss: 0.00142\n",
      "Epoch: 1... Training loss: 0.00132... Test loss: 0.00165\n",
      "Epoch: 1... Training loss: 0.00127... Test loss: 0.00135\n",
      "Epoch: 1... Training loss: 0.00123... Test loss: 0.00161\n",
      "Epoch: 1... Training loss: 0.00116... Test loss: 0.00131\n",
      "Epoch: 1... Training loss: 0.00115... Test loss: 0.00119\n",
      "Epoch: 1... Training loss: 0.00115... Test loss: 0.00118\n",
      "Epoch: 1... Training loss: 0.00112... Test loss: 0.00094\n",
      "Epoch: 1... Training loss: 0.00106... Test loss: 0.00111\n",
      "Epoch: 1... Training loss: 0.00102... Test loss: 0.00101\n",
      "Epoch: 1... Training loss: 0.00098... Test loss: 0.00101\n",
      "Epoch: 1... Training loss: 0.00095... Test loss: 0.00098\n",
      "Epoch: 1... Training loss: 0.00091... Test loss: 0.00105\n",
      "Epoch: 1... Training loss: 0.00086... Test loss: 0.00081\n",
      "Epoch: 1... Training loss: 0.00079... Test loss: 0.00106\n",
      "Epoch: 1... Training loss: 0.00085... Test loss: 0.00065\n",
      "Epoch: 1... Training loss: 0.00074... Test loss: 0.00108\n",
      "Epoch: 1... Training loss: 0.00076... Test loss: 0.00071\n",
      "Epoch: 1... Training loss: 0.00069... Test loss: 0.00081\n",
      "Epoch: 1... Training loss: 0.00069... Test loss: 0.00063\n",
      "Epoch: 1... Training loss: 0.00067... Test loss: 0.00077\n",
      "Epoch: 1... Training loss: 0.00059... Test loss: 0.00063\n",
      "Epoch: 1... Training loss: 0.00059... Test loss: 0.0007\n",
      "Epoch: 1... Training loss: 0.00058... Test loss: 0.00059\n",
      "Epoch: 1... Training loss: 0.00057... Test loss: 0.00064\n",
      "Epoch: 1... Training loss: 0.00052... Test loss: 0.00052\n",
      "Epoch: 1... Training loss: 0.00049... Test loss: 0.00053\n",
      "Epoch: 1... Training loss: 0.00054... Test loss: 0.00049\n",
      "Epoch: 1... Training loss: 0.00045... Test loss: 0.00058\n",
      "Epoch: 1... Training loss: 0.00043... Test loss: 0.00055\n",
      "Epoch: 1... Training loss: 0.00041... Test loss: 0.00045\n",
      "Epoch: 1... Training loss: 0.00043... Test loss: 0.00051\n",
      "Epoch: 1... Training loss: 0.00044... Test loss: 0.00036\n",
      "Epoch: 1... Training loss: 0.00035... Test loss: 0.0005\n",
      "Epoch: 1... Training loss: 0.00039... Test loss: 0.00032\n",
      "Epoch: 1... Training loss: 0.00034... Test loss: 0.00053\n",
      "Epoch: 1... Training loss: 0.00032... Test loss: 0.0003\n",
      "Epoch: 1... Training loss: 0.00031... Test loss: 0.00049\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00031... Test loss: 0.00032\n",
      "Epoch: 1... Training loss: 0.00026... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00026... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00024\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00012\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00012... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00011... Test loss: 0.00011\n",
      "235.51861838652985\n",
      "Epoch: 1... Training loss: 0.89625... Test loss: 0.26506\n",
      "Epoch: 1... Training loss: 0.38718... Test loss: 0.09324\n",
      "Epoch: 1... Training loss: 0.21783... Test loss: 0.06171\n",
      "Epoch: 1... Training loss: 0.21982... Test loss: 0.04471\n",
      "Epoch: 1... Training loss: 0.14604... Test loss: 0.04279\n",
      "Epoch: 1... Training loss: 0.10962... Test loss: 0.04432\n",
      "Epoch: 1... Training loss: 0.09166... Test loss: 0.04972\n",
      "Epoch: 1... Training loss: 0.06858... Test loss: 0.03072\n",
      "Epoch: 1... Training loss: 0.05563... Test loss: 0.04231\n",
      "Epoch: 1... Training loss: 0.04699... Test loss: 0.0278\n",
      "Epoch: 1... Training loss: 0.04328... Test loss: 0.0167\n",
      "Epoch: 1... Training loss: 0.03947... Test loss: 0.01612\n",
      "Epoch: 1... Training loss: 0.03588... Test loss: 0.01216\n",
      "Epoch: 1... Training loss: 0.03411... Test loss: 0.01151\n",
      "Epoch: 1... Training loss: 0.03083... Test loss: 0.01136\n",
      "Epoch: 1... Training loss: 0.02899... Test loss: 0.01678\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1... Training loss: 0.02789... Test loss: 0.00878\n",
      "Epoch: 1... Training loss: 0.02574... Test loss: 0.00775\n",
      "Epoch: 1... Training loss: 0.02484... Test loss: 0.00844\n",
      "Epoch: 1... Training loss: 0.02372... Test loss: 0.00792\n",
      "Epoch: 1... Training loss: 0.0229... Test loss: 0.00811\n",
      "Epoch: 1... Training loss: 0.02194... Test loss: 0.00425\n",
      "Epoch: 1... Training loss: 0.02108... Test loss: 0.01284\n",
      "Epoch: 1... Training loss: 0.02013... Test loss: 0.00484\n",
      "Epoch: 1... Training loss: 0.01908... Test loss: 0.0116\n",
      "Epoch: 1... Training loss: 0.0184... Test loss: 0.00443\n",
      "Epoch: 1... Training loss: 0.0179... Test loss: 0.01133\n",
      "Epoch: 1... Training loss: 0.01709... Test loss: 0.00445\n",
      "Epoch: 1... Training loss: 0.01675... Test loss: 0.00979\n",
      "Epoch: 1... Training loss: 0.01591... Test loss: 0.00483\n",
      "Epoch: 1... Training loss: 0.01536... Test loss: 0.00878\n",
      "Epoch: 1... Training loss: 0.01476... Test loss: 0.00641\n",
      "Epoch: 1... Training loss: 0.0143... Test loss: 0.01027\n",
      "Epoch: 1... Training loss: 0.01367... Test loss: 0.00509\n",
      "Epoch: 1... Training loss: 0.01337... Test loss: 0.01086\n",
      "Epoch: 1... Training loss: 0.01249... Test loss: 0.00542\n",
      "Epoch: 1... Training loss: 0.01207... Test loss: 0.01111\n",
      "Epoch: 1... Training loss: 0.01172... Test loss: 0.00508\n",
      "Epoch: 1... Training loss: 0.01143... Test loss: 0.00956\n",
      "Epoch: 1... Training loss: 0.01092... Test loss: 0.00494\n",
      "Epoch: 1... Training loss: 0.01046... Test loss: 0.00856\n",
      "Epoch: 1... Training loss: 0.01025... Test loss: 0.00585\n",
      "Epoch: 1... Training loss: 0.00993... Test loss: 0.00747\n",
      "Epoch: 1... Training loss: 0.00965... Test loss: 0.00663\n",
      "Epoch: 1... Training loss: 0.00934... Test loss: 0.00754\n",
      "Epoch: 1... Training loss: 0.00926... Test loss: 0.00674\n",
      "Epoch: 1... Training loss: 0.00874... Test loss: 0.00784\n",
      "Epoch: 1... Training loss: 0.00871... Test loss: 0.00557\n",
      "Epoch: 1... Training loss: 0.00849... Test loss: 0.00793\n",
      "Epoch: 1... Training loss: 0.00824... Test loss: 0.00464\n",
      "Epoch: 1... Training loss: 0.00803... Test loss: 0.00695\n",
      "Epoch: 1... Training loss: 0.00788... Test loss: 0.00459\n",
      "Epoch: 1... Training loss: 0.00747... Test loss: 0.00659\n",
      "Epoch: 1... Training loss: 0.00722... Test loss: 0.00447\n",
      "Epoch: 1... Training loss: 0.0072... Test loss: 0.00543\n",
      "Epoch: 1... Training loss: 0.00685... Test loss: 0.00526\n",
      "Epoch: 1... Training loss: 0.00669... Test loss: 0.00518\n",
      "Epoch: 1... Training loss: 0.00649... Test loss: 0.00474\n",
      "Epoch: 1... Training loss: 0.00634... Test loss: 0.00531\n",
      "Epoch: 1... Training loss: 0.00613... Test loss: 0.00506\n",
      "Epoch: 1... Training loss: 0.00594... Test loss: 0.00549\n",
      "Epoch: 1... Training loss: 0.00578... Test loss: 0.00491\n",
      "Epoch: 1... Training loss: 0.00555... Test loss: 0.00543\n",
      "Epoch: 1... Training loss: 0.00546... Test loss: 0.00418\n",
      "Epoch: 1... Training loss: 0.01437... Test loss: 0.01221\n",
      "Epoch: 1... Training loss: 0.01203... Test loss: 0.00675\n",
      "Epoch: 1... Training loss: 0.01186... Test loss: 0.01205\n",
      "Epoch: 1... Training loss: 0.01196... Test loss: 0.00826\n",
      "Epoch: 1... Training loss: 0.01048... Test loss: 0.01384\n",
      "Epoch: 1... Training loss: 0.00899... Test loss: 0.01074\n",
      "Epoch: 1... Training loss: 0.00939... Test loss: 0.01018\n",
      "Epoch: 1... Training loss: 0.00878... Test loss: 0.00989\n",
      "Epoch: 1... Training loss: 0.01013... Test loss: 0.01026\n",
      "Epoch: 1... Training loss: 0.00886... Test loss: 0.00986\n",
      "Epoch: 1... Training loss: 0.00925... Test loss: 0.00875\n",
      "Epoch: 1... Training loss: 0.0078... Test loss: 0.00751\n",
      "Epoch: 1... Training loss: 0.00863... Test loss: 0.00866\n",
      "Epoch: 1... Training loss: 0.00756... Test loss: 0.01014\n",
      "Epoch: 1... Training loss: 0.00819... Test loss: 0.00865\n",
      "Epoch: 1... Training loss: 0.00698... Test loss: 0.00887\n",
      "Epoch: 1... Training loss: 0.00659... Test loss: 0.00721\n",
      "Epoch: 1... Training loss: 0.00662... Test loss: 0.00595\n",
      "Epoch: 1... Training loss: 0.00687... Test loss: 0.00653\n",
      "Epoch: 1... Training loss: 0.00635... Test loss: 0.00645\n",
      "Epoch: 1... Training loss: 0.0069... Test loss: 0.00718\n",
      "Epoch: 1... Training loss: 0.00618... Test loss: 0.00797\n",
      "Epoch: 1... Training loss: 0.0061... Test loss: 0.00677\n",
      "Epoch: 1... Training loss: 0.00592... Test loss: 0.00655\n",
      "Epoch: 1... Training loss: 0.00573... Test loss: 0.00558\n",
      "Epoch: 1... Training loss: 0.00569... Test loss: 0.00599\n",
      "Epoch: 1... Training loss: 0.00535... Test loss: 0.00498\n",
      "Epoch: 1... Training loss: 0.0055... Test loss: 0.00481\n",
      "Epoch: 1... Training loss: 0.00515... Test loss: 0.00507\n",
      "Epoch: 1... Training loss: 0.00523... Test loss: 0.00537\n",
      "Epoch: 1... Training loss: 0.00488... Test loss: 0.00505\n",
      "Epoch: 1... Training loss: 0.0047... Test loss: 0.00459\n",
      "Epoch: 1... Training loss: 0.00478... Test loss: 0.0047\n",
      "Epoch: 1... Training loss: 0.00449... Test loss: 0.00505\n",
      "Epoch: 1... Training loss: 0.0043... Test loss: 0.00443\n",
      "Epoch: 1... Training loss: 0.00436... Test loss: 0.00453\n",
      "Epoch: 1... Training loss: 0.00411... Test loss: 0.00391\n",
      "Epoch: 1... Training loss: 0.00414... Test loss: 0.00413\n",
      "Epoch: 1... Training loss: 0.00423... Test loss: 0.00335\n",
      "Epoch: 1... Training loss: 0.00407... Test loss: 0.00442\n",
      "Epoch: 1... Training loss: 0.00385... Test loss: 0.00352\n",
      "Epoch: 1... Training loss: 0.00383... Test loss: 0.00397\n",
      "Epoch: 1... Training loss: 0.00394... Test loss: 0.0035\n",
      "Epoch: 1... Training loss: 0.00389... Test loss: 0.00348\n",
      "Epoch: 1... Training loss: 0.00364... Test loss: 0.00353\n",
      "Epoch: 1... Training loss: 0.00376... Test loss: 0.00296\n",
      "Epoch: 1... Training loss: 0.00371... Test loss: 0.00375\n",
      "Epoch: 1... Training loss: 0.00371... Test loss: 0.00309\n",
      "Epoch: 1... Training loss: 0.00354... Test loss: 0.00342\n",
      "Epoch: 1... Training loss: 0.00354... Test loss: 0.00332\n",
      "Epoch: 1... Training loss: 0.00328... Test loss: 0.00377\n",
      "Epoch: 1... Training loss: 0.00333... Test loss: 0.00356\n",
      "Epoch: 1... Training loss: 0.00316... Test loss: 0.00419\n",
      "Epoch: 1... Training loss: 0.00315... Test loss: 0.00327\n",
      "Epoch: 1... Training loss: 0.00308... Test loss: 0.00378\n",
      "Epoch: 1... Training loss: 0.00299... Test loss: 0.00312\n",
      "Epoch: 1... Training loss: 0.00288... Test loss: 0.0036\n",
      "Epoch: 1... Training loss: 0.00282... Test loss: 0.00311\n",
      "Epoch: 1... Training loss: 0.00264... Test loss: 0.00294\n",
      "Epoch: 1... Training loss: 0.00262... Test loss: 0.00301\n",
      "Epoch: 1... Training loss: 0.00245... Test loss: 0.00365\n",
      "Epoch: 1... Training loss: 0.00243... Test loss: 0.00246\n",
      "Epoch: 1... Training loss: 0.00232... Test loss: 0.00302\n",
      "Epoch: 1... Training loss: 0.00231... Test loss: 0.00241\n",
      "Epoch: 1... Training loss: 0.00232... Test loss: 0.00229\n",
      "Epoch: 1... Training loss: 0.00215... Test loss: 0.00238\n",
      "Epoch: 1... Training loss: 0.00212... Test loss: 0.00222\n",
      "Epoch: 1... Training loss: 0.00198... Test loss: 0.0022\n",
      "Epoch: 1... Training loss: 0.00196... Test loss: 0.00211\n",
      "Epoch: 1... Training loss: 0.00194... Test loss: 0.00202\n",
      "Epoch: 1... Training loss: 0.00188... Test loss: 0.00199\n",
      "Epoch: 1... Training loss: 0.0019... Test loss: 0.0021\n",
      "Epoch: 1... Training loss: 0.0019... Test loss: 0.00201\n",
      "Epoch: 1... Training loss: 0.00183... Test loss: 0.00209\n",
      "Epoch: 1... Training loss: 0.00174... Test loss: 0.00216\n",
      "Epoch: 1... Training loss: 0.00165... Test loss: 0.00214\n",
      "Epoch: 1... Training loss: 0.00172... Test loss: 0.00176\n",
      "Epoch: 1... Training loss: 0.0016... Test loss: 0.00216\n",
      "Epoch: 1... Training loss: 0.00158... Test loss: 0.0016\n",
      "Epoch: 1... Training loss: 0.00151... Test loss: 0.00215\n",
      "Epoch: 1... Training loss: 0.0015... Test loss: 0.00141\n",
      "Epoch: 1... Training loss: 0.00144... Test loss: 0.00169\n",
      "Epoch: 1... Training loss: 0.00141... Test loss: 0.00162\n",
      "Epoch: 1... Training loss: 0.00135... Test loss: 0.00154\n",
      "Epoch: 1... Training loss: 0.00133... Test loss: 0.00167\n",
      "Epoch: 1... Training loss: 0.0013... Test loss: 0.0016\n",
      "Epoch: 1... Training loss: 0.00122... Test loss: 0.00145\n",
      "Epoch: 1... Training loss: 0.00116... Test loss: 0.00173\n",
      "Epoch: 1... Training loss: 0.00118... Test loss: 0.00128\n",
      "Epoch: 1... Training loss: 0.00117... Test loss: 0.00128\n",
      "Epoch: 1... Training loss: 0.00112... Test loss: 0.00117\n",
      "Epoch: 1... Training loss: 0.00114... Test loss: 0.00132\n",
      "Epoch: 1... Training loss: 0.00106... Test loss: 0.00126\n",
      "Epoch: 1... Training loss: 0.00104... Test loss: 0.00114\n",
      "Epoch: 1... Training loss: 0.00103... Test loss: 0.00108\n",
      "Epoch: 1... Training loss: 0.00098... Test loss: 0.00115\n",
      "Epoch: 1... Training loss: 0.00098... Test loss: 0.001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1... Training loss: 0.00092... Test loss: 0.001\n",
      "Epoch: 1... Training loss: 0.00096... Test loss: 0.00094\n",
      "Epoch: 1... Training loss: 0.00088... Test loss: 0.001\n",
      "Epoch: 1... Training loss: 0.00089... Test loss: 0.00104\n",
      "Epoch: 1... Training loss: 0.00077... Test loss: 0.00091\n",
      "Epoch: 1... Training loss: 0.00074... Test loss: 0.00101\n",
      "Epoch: 1... Training loss: 0.00073... Test loss: 0.0008\n",
      "Epoch: 1... Training loss: 0.00066... Test loss: 0.00078\n",
      "Epoch: 1... Training loss: 0.00065... Test loss: 0.00073\n",
      "Epoch: 1... Training loss: 0.00062... Test loss: 0.00075\n",
      "Epoch: 1... Training loss: 0.00063... Test loss: 0.00063\n",
      "Epoch: 1... Training loss: 0.00059... Test loss: 0.00071\n",
      "Epoch: 1... Training loss: 0.00053... Test loss: 0.00049\n",
      "Epoch: 1... Training loss: 0.0006... Test loss: 0.00054\n",
      "Epoch: 1... Training loss: 0.0005... Test loss: 0.0005\n",
      "Epoch: 1... Training loss: 0.00051... Test loss: 0.00055\n",
      "Epoch: 1... Training loss: 0.0005... Test loss: 0.00053\n",
      "Epoch: 1... Training loss: 0.00051... Test loss: 0.00052\n",
      "Epoch: 1... Training loss: 0.00043... Test loss: 0.00058\n",
      "Epoch: 1... Training loss: 0.00043... Test loss: 0.00046\n",
      "Epoch: 1... Training loss: 0.00041... Test loss: 0.00046\n",
      "Epoch: 1... Training loss: 0.00041... Test loss: 0.00037\n",
      "Epoch: 1... Training loss: 0.00041... Test loss: 0.00042\n",
      "Epoch: 1... Training loss: 0.00034... Test loss: 0.00036\n",
      "Epoch: 1... Training loss: 0.00034... Test loss: 0.00048\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.0003\n",
      "Epoch: 1... Training loss: 0.00031... Test loss: 0.00036\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00033\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.0003\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00014\n",
      "Epoch: 1... Training loss: 0.00015... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00013\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00013\n",
      "256.1004722501384\n",
      "Epoch: 1... Training loss: 0.94014... Test loss: 0.28861\n",
      "Epoch: 1... Training loss: 0.46081... Test loss: 0.13386\n",
      "Epoch: 1... Training loss: 0.28141... Test loss: 0.06125\n",
      "Epoch: 1... Training loss: 0.20065... Test loss: 0.04166\n",
      "Epoch: 1... Training loss: 0.15692... Test loss: 0.03392\n",
      "Epoch: 1... Training loss: 0.12271... Test loss: 0.0281\n",
      "Epoch: 1... Training loss: 0.10311... Test loss: 0.02192\n",
      "Epoch: 1... Training loss: 0.09043... Test loss: 0.01818\n",
      "Epoch: 1... Training loss: 0.07571... Test loss: 0.01461\n",
      "Epoch: 1... Training loss: 0.06759... Test loss: 0.01874\n",
      "Epoch: 1... Training loss: 0.06276... Test loss: 0.01132\n",
      "Epoch: 1... Training loss: 0.05762... Test loss: 0.01661\n",
      "Epoch: 1... Training loss: 0.04972... Test loss: 0.01052\n",
      "Epoch: 1... Training loss: 0.04636... Test loss: 0.01578\n",
      "Epoch: 1... Training loss: 0.04422... Test loss: 0.00886\n",
      "Epoch: 1... Training loss: 0.039... Test loss: 0.0119\n",
      "Epoch: 1... Training loss: 0.03387... Test loss: 0.01052\n",
      "Epoch: 1... Training loss: 0.03077... Test loss: 0.01133\n",
      "Epoch: 1... Training loss: 0.02828... Test loss: 0.01233\n",
      "Epoch: 1... Training loss: 0.02751... Test loss: 0.00595\n",
      "Epoch: 1... Training loss: 0.02621... Test loss: 0.01326\n",
      "Epoch: 1... Training loss: 0.02495... Test loss: 0.00664\n",
      "Epoch: 1... Training loss: 0.02337... Test loss: 0.01507\n",
      "Epoch: 1... Training loss: 0.02224... Test loss: 0.00845\n",
      "Epoch: 1... Training loss: 0.02106... Test loss: 0.01577\n",
      "Epoch: 1... Training loss: 0.01974... Test loss: 0.01015\n",
      "Epoch: 1... Training loss: 0.01917... Test loss: 0.01164\n",
      "Epoch: 1... Training loss: 0.01791... Test loss: 0.00953\n",
      "Epoch: 1... Training loss: 0.01685... Test loss: 0.01319\n",
      "Epoch: 1... Training loss: 0.0165... Test loss: 0.00639\n",
      "Epoch: 1... Training loss: 0.01579... Test loss: 0.01197\n",
      "Epoch: 1... Training loss: 0.01531... Test loss: 0.00693\n",
      "Epoch: 1... Training loss: 0.01474... Test loss: 0.0113\n",
      "Epoch: 1... Training loss: 0.01408... Test loss: 0.00703\n",
      "Epoch: 1... Training loss: 0.01378... Test loss: 0.00917\n",
      "Epoch: 1... Training loss: 0.01336... Test loss: 0.00888\n",
      "Epoch: 1... Training loss: 0.01292... Test loss: 0.00678\n",
      "Epoch: 1... Training loss: 0.0124... Test loss: 0.00947\n",
      "Epoch: 1... Training loss: 0.012... Test loss: 0.00528\n",
      "Epoch: 1... Training loss: 0.01163... Test loss: 0.0089\n",
      "Epoch: 1... Training loss: 0.0113... Test loss: 0.00527\n",
      "Epoch: 1... Training loss: 0.01096... Test loss: 0.00879\n",
      "Epoch: 1... Training loss: 0.01055... Test loss: 0.00467\n",
      "Epoch: 1... Training loss: 0.01038... Test loss: 0.00813\n",
      "Epoch: 1... Training loss: 0.01012... Test loss: 0.00561\n",
      "Epoch: 1... Training loss: 0.00984... Test loss: 0.00808\n",
      "Epoch: 1... Training loss: 0.00957... Test loss: 0.00547\n",
      "Epoch: 1... Training loss: 0.00941... Test loss: 0.00797\n",
      "Epoch: 1... Training loss: 0.00912... Test loss: 0.00569\n",
      "Epoch: 1... Training loss: 0.00884... Test loss: 0.0064\n",
      "Epoch: 1... Training loss: 0.00833... Test loss: 0.00523\n",
      "Epoch: 1... Training loss: 0.0083... Test loss: 0.00705\n",
      "Epoch: 1... Training loss: 0.00793... Test loss: 0.0062\n",
      "Epoch: 1... Training loss: 0.00776... Test loss: 0.00727\n",
      "Epoch: 1... Training loss: 0.00754... Test loss: 0.00663\n",
      "Epoch: 1... Training loss: 0.00743... Test loss: 0.00674\n",
      "Epoch: 1... Training loss: 0.00725... Test loss: 0.00685\n",
      "Epoch: 1... Training loss: 0.00701... Test loss: 0.00666\n",
      "Epoch: 1... Training loss: 0.00684... Test loss: 0.0061\n",
      "Epoch: 1... Training loss: 0.00673... Test loss: 0.0068\n",
      "Epoch: 1... Training loss: 0.00656... Test loss: 0.00542\n",
      "Epoch: 1... Training loss: 0.00637... Test loss: 0.0065\n",
      "Epoch: 1... Training loss: 0.00608... Test loss: 0.00606\n",
      "Epoch: 1... Training loss: 0.006... Test loss: 0.00544\n",
      "Epoch: 1... Training loss: 0.01094... Test loss: 0.01329\n",
      "Epoch: 1... Training loss: 0.00984... Test loss: 0.00945\n",
      "Epoch: 1... Training loss: 0.01013... Test loss: 0.01066\n",
      "Epoch: 1... Training loss: 0.01245... Test loss: 0.00935\n",
      "Epoch: 1... Training loss: 0.01202... Test loss: 0.01242\n",
      "Epoch: 1... Training loss: 0.01041... Test loss: 0.01272\n",
      "Epoch: 1... Training loss: 0.00955... Test loss: 0.01158\n",
      "Epoch: 1... Training loss: 0.0097... Test loss: 0.01137\n",
      "Epoch: 1... Training loss: 0.00962... Test loss: 0.01215\n",
      "Epoch: 1... Training loss: 0.0087... Test loss: 0.01047\n",
      "Epoch: 1... Training loss: 0.00879... Test loss: 0.01009\n",
      "Epoch: 1... Training loss: 0.00857... Test loss: 0.00994\n",
      "Epoch: 1... Training loss: 0.00758... Test loss: 0.00817\n",
      "Epoch: 1... Training loss: 0.00825... Test loss: 0.0086\n",
      "Epoch: 1... Training loss: 0.0081... Test loss: 0.00935\n",
      "Epoch: 1... Training loss: 0.00733... Test loss: 0.00746\n",
      "Epoch: 1... Training loss: 0.00702... Test loss: 0.0092\n",
      "Epoch: 1... Training loss: 0.0073... Test loss: 0.0077\n",
      "Epoch: 1... Training loss: 0.00643... Test loss: 0.00892\n",
      "Epoch: 1... Training loss: 0.00659... Test loss: 0.00675\n",
      "Epoch: 1... Training loss: 0.00659... Test loss: 0.00769\n",
      "Epoch: 1... Training loss: 0.00592... Test loss: 0.00719\n",
      "Epoch: 1... Training loss: 0.00605... Test loss: 0.00605\n",
      "Epoch: 1... Training loss: 0.00596... Test loss: 0.00565\n",
      "Epoch: 1... Training loss: 0.00583... Test loss: 0.00653\n",
      "Epoch: 1... Training loss: 0.00581... Test loss: 0.00531\n",
      "Epoch: 1... Training loss: 0.00524... Test loss: 0.00597\n",
      "Epoch: 1... Training loss: 0.00536... Test loss: 0.00553\n",
      "Epoch: 1... Training loss: 0.00523... Test loss: 0.00549\n",
      "Epoch: 1... Training loss: 0.00508... Test loss: 0.00511\n",
      "Epoch: 1... Training loss: 0.00508... Test loss: 0.00589\n",
      "Epoch: 1... Training loss: 0.00454... Test loss: 0.00506\n",
      "Epoch: 1... Training loss: 0.00445... Test loss: 0.00432\n",
      "Epoch: 1... Training loss: 0.00448... Test loss: 0.00476\n",
      "Epoch: 1... Training loss: 0.00423... Test loss: 0.00355\n",
      "Epoch: 1... Training loss: 0.00417... Test loss: 0.00426\n",
      "Epoch: 1... Training loss: 0.00404... Test loss: 0.00402\n",
      "Epoch: 1... Training loss: 0.00394... Test loss: 0.00458\n",
      "Epoch: 1... Training loss: 0.00402... Test loss: 0.00387\n",
      "Epoch: 1... Training loss: 0.00392... Test loss: 0.00476\n",
      "Epoch: 1... Training loss: 0.0037... Test loss: 0.00324\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1... Training loss: 0.00359... Test loss: 0.004\n",
      "Epoch: 1... Training loss: 0.00363... Test loss: 0.00337\n",
      "Epoch: 1... Training loss: 0.00342... Test loss: 0.00427\n",
      "Epoch: 1... Training loss: 0.00342... Test loss: 0.00353\n",
      "Epoch: 1... Training loss: 0.00338... Test loss: 0.0042\n",
      "Epoch: 1... Training loss: 0.00321... Test loss: 0.00326\n",
      "Epoch: 1... Training loss: 0.00328... Test loss: 0.00419\n",
      "Epoch: 1... Training loss: 0.00327... Test loss: 0.00335\n",
      "Epoch: 1... Training loss: 0.00315... Test loss: 0.00362\n",
      "Epoch: 1... Training loss: 0.00301... Test loss: 0.00304\n",
      "Epoch: 1... Training loss: 0.00295... Test loss: 0.00348\n",
      "Epoch: 1... Training loss: 0.00309... Test loss: 0.00313\n",
      "Epoch: 1... Training loss: 0.00286... Test loss: 0.00329\n",
      "Epoch: 1... Training loss: 0.0028... Test loss: 0.00312\n",
      "Epoch: 1... Training loss: 0.00279... Test loss: 0.00303\n",
      "Epoch: 1... Training loss: 0.0027... Test loss: 0.00285\n",
      "Epoch: 1... Training loss: 0.00259... Test loss: 0.00306\n",
      "Epoch: 1... Training loss: 0.00257... Test loss: 0.00281\n",
      "Epoch: 1... Training loss: 0.00251... Test loss: 0.00249\n",
      "Epoch: 1... Training loss: 0.00253... Test loss: 0.00276\n",
      "Epoch: 1... Training loss: 0.00247... Test loss: 0.00248\n",
      "Epoch: 1... Training loss: 0.00246... Test loss: 0.00256\n",
      "Epoch: 1... Training loss: 0.00234... Test loss: 0.00259\n",
      "Epoch: 1... Training loss: 0.00235... Test loss: 0.00266\n",
      "Epoch: 1... Training loss: 0.00227... Test loss: 0.0025\n",
      "Epoch: 1... Training loss: 0.00219... Test loss: 0.00215\n",
      "Epoch: 1... Training loss: 0.00209... Test loss: 0.00248\n",
      "Epoch: 1... Training loss: 0.00212... Test loss: 0.00235\n",
      "Epoch: 1... Training loss: 0.00206... Test loss: 0.00266\n",
      "Epoch: 1... Training loss: 0.00201... Test loss: 0.00215\n",
      "Epoch: 1... Training loss: 0.00192... Test loss: 0.00221\n",
      "Epoch: 1... Training loss: 0.00195... Test loss: 0.00225\n",
      "Epoch: 1... Training loss: 0.00178... Test loss: 0.0019\n",
      "Epoch: 1... Training loss: 0.00178... Test loss: 0.00198\n",
      "Epoch: 1... Training loss: 0.00174... Test loss: 0.00198\n",
      "Epoch: 1... Training loss: 0.0017... Test loss: 0.00193\n",
      "Epoch: 1... Training loss: 0.00158... Test loss: 0.00198\n",
      "Epoch: 1... Training loss: 0.00159... Test loss: 0.00171\n",
      "Epoch: 1... Training loss: 0.00152... Test loss: 0.00183\n",
      "Epoch: 1... Training loss: 0.00147... Test loss: 0.0016\n",
      "Epoch: 1... Training loss: 0.00141... Test loss: 0.00147\n",
      "Epoch: 1... Training loss: 0.00141... Test loss: 0.00148\n",
      "Epoch: 1... Training loss: 0.00136... Test loss: 0.00164\n",
      "Epoch: 1... Training loss: 0.00133... Test loss: 0.00144\n",
      "Epoch: 1... Training loss: 0.00127... Test loss: 0.00154\n",
      "Epoch: 1... Training loss: 0.00122... Test loss: 0.00124\n",
      "Epoch: 1... Training loss: 0.00118... Test loss: 0.00143\n",
      "Epoch: 1... Training loss: 0.00116... Test loss: 0.00121\n",
      "Epoch: 1... Training loss: 0.00119... Test loss: 0.00117\n",
      "Epoch: 1... Training loss: 0.00115... Test loss: 0.00108\n",
      "Epoch: 1... Training loss: 0.00108... Test loss: 0.00114\n",
      "Epoch: 1... Training loss: 0.00108... Test loss: 0.00118\n",
      "Epoch: 1... Training loss: 0.00101... Test loss: 0.00099\n",
      "Epoch: 1... Training loss: 0.00098... Test loss: 0.00107\n",
      "Epoch: 1... Training loss: 0.001... Test loss: 0.00099\n",
      "Epoch: 1... Training loss: 0.00088... Test loss: 0.00125\n",
      "Epoch: 1... Training loss: 0.00096... Test loss: 0.00125\n",
      "Epoch: 1... Training loss: 0.00094... Test loss: 0.00118\n",
      "Epoch: 1... Training loss: 0.00088... Test loss: 0.00112\n",
      "Epoch: 1... Training loss: 0.00084... Test loss: 0.00092\n",
      "Epoch: 1... Training loss: 0.00082... Test loss: 0.00087\n",
      "Epoch: 1... Training loss: 0.00083... Test loss: 0.00096\n",
      "Epoch: 1... Training loss: 0.00075... Test loss: 0.00083\n",
      "Epoch: 1... Training loss: 0.00074... Test loss: 0.00091\n",
      "Epoch: 1... Training loss: 0.00072... Test loss: 0.00076\n",
      "Epoch: 1... Training loss: 0.00066... Test loss: 0.0008\n",
      "Epoch: 1... Training loss: 0.00063... Test loss: 0.00075\n",
      "Epoch: 1... Training loss: 0.00065... Test loss: 0.00074\n",
      "Epoch: 1... Training loss: 0.00061... Test loss: 0.00074\n",
      "Epoch: 1... Training loss: 0.00064... Test loss: 0.00059\n",
      "Epoch: 1... Training loss: 0.00054... Test loss: 0.00052\n",
      "Epoch: 1... Training loss: 0.00051... Test loss: 0.00051\n",
      "Epoch: 1... Training loss: 0.00052... Test loss: 0.00067\n",
      "Epoch: 1... Training loss: 0.00049... Test loss: 0.00048\n",
      "Epoch: 1... Training loss: 0.00049... Test loss: 0.00055\n",
      "Epoch: 1... Training loss: 0.00046... Test loss: 0.00042\n",
      "Epoch: 1... Training loss: 0.00048... Test loss: 0.00046\n",
      "Epoch: 1... Training loss: 0.00045... Test loss: 0.00041\n",
      "Epoch: 1... Training loss: 0.0004... Test loss: 0.00048\n",
      "Epoch: 1... Training loss: 0.00041... Test loss: 0.00036\n",
      "Epoch: 1... Training loss: 0.00038... Test loss: 0.00046\n",
      "Epoch: 1... Training loss: 0.00036... Test loss: 0.0003\n",
      "Epoch: 1... Training loss: 0.00036... Test loss: 0.00042\n",
      "Epoch: 1... Training loss: 0.00033... Test loss: 0.0003\n",
      "Epoch: 1... Training loss: 0.00038... Test loss: 0.00034\n",
      "Epoch: 1... Training loss: 0.00031... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00037\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.0003\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00024\n",
      "Epoch: 1... Training loss: 0.00026... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00021\n",
      "297.96152263658587\n",
      "Epoch: 1... Training loss: 1.3809... Test loss: 0.67299\n",
      "Epoch: 1... Training loss: 0.54873... Test loss: 0.20407\n",
      "Epoch: 1... Training loss: 0.31892... Test loss: 0.10326\n",
      "Epoch: 1... Training loss: 0.19385... Test loss: 0.08115\n",
      "Epoch: 1... Training loss: 0.16143... Test loss: 0.0491\n",
      "Epoch: 1... Training loss: 0.12287... Test loss: 0.05192\n",
      "Epoch: 1... Training loss: 0.09799... Test loss: 0.03428\n",
      "Epoch: 1... Training loss: 0.08337... Test loss: 0.05782\n",
      "Epoch: 1... Training loss: 0.07407... Test loss: 0.05105\n",
      "Epoch: 1... Training loss: 0.06042... Test loss: 0.05187\n",
      "Epoch: 1... Training loss: 0.05399... Test loss: 0.0822\n",
      "Epoch: 1... Training loss: 0.04855... Test loss: 0.02588\n",
      "Epoch: 1... Training loss: 0.04533... Test loss: 0.0327\n",
      "Epoch: 1... Training loss: 0.04082... Test loss: 0.04692\n",
      "Epoch: 1... Training loss: 0.03843... Test loss: 0.02185\n",
      "Epoch: 1... Training loss: 0.03403... Test loss: 0.02557\n",
      "Epoch: 1... Training loss: 0.03236... Test loss: 0.01047\n",
      "Epoch: 1... Training loss: 0.03036... Test loss: 0.026\n",
      "Epoch: 1... Training loss: 0.0291... Test loss: 0.01956\n",
      "Epoch: 1... Training loss: 0.026... Test loss: 0.02004\n",
      "Epoch: 1... Training loss: 0.02648... Test loss: 0.01379\n",
      "Epoch: 1... Training loss: 0.02441... Test loss: 0.02154\n",
      "Epoch: 1... Training loss: 0.02306... Test loss: 0.01357\n",
      "Epoch: 1... Training loss: 0.02096... Test loss: 0.02077\n",
      "Epoch: 1... Training loss: 0.02029... Test loss: 0.01421\n",
      "Epoch: 1... Training loss: 0.01921... Test loss: 0.01086\n",
      "Epoch: 1... Training loss: 0.01878... Test loss: 0.01737\n",
      "Epoch: 1... Training loss: 0.01687... Test loss: 0.01\n",
      "Epoch: 1... Training loss: 0.01624... Test loss: 0.01692\n",
      "Epoch: 1... Training loss: 0.01546... Test loss: 0.00967\n",
      "Epoch: 1... Training loss: 0.01525... Test loss: 0.01285\n",
      "Epoch: 1... Training loss: 0.01443... Test loss: 0.01124\n",
      "Epoch: 1... Training loss: 0.01416... Test loss: 0.01056\n",
      "Epoch: 1... Training loss: 0.0132... Test loss: 0.00929\n",
      "Epoch: 1... Training loss: 0.01289... Test loss: 0.01326\n",
      "Epoch: 1... Training loss: 0.01248... Test loss: 0.00668\n",
      "Epoch: 1... Training loss: 0.01175... Test loss: 0.00998\n",
      "Epoch: 1... Training loss: 0.01142... Test loss: 0.0077\n",
      "Epoch: 1... Training loss: 0.01091... Test loss: 0.0087\n",
      "Epoch: 1... Training loss: 0.01038... Test loss: 0.00671\n",
      "Epoch: 1... Training loss: 0.0102... Test loss: 0.00784\n",
      "Epoch: 1... Training loss: 0.00975... Test loss: 0.00707\n",
      "Epoch: 1... Training loss: 0.00953... Test loss: 0.00725\n",
      "Epoch: 1... Training loss: 0.00922... Test loss: 0.00764\n",
      "Epoch: 1... Training loss: 0.00891... Test loss: 0.00488\n",
      "Epoch: 1... Training loss: 0.00881... Test loss: 0.00854\n",
      "Epoch: 1... Training loss: 0.00863... Test loss: 0.00489\n",
      "Epoch: 1... Training loss: 0.00832... Test loss: 0.00867\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1... Training loss: 0.00816... Test loss: 0.00555\n",
      "Epoch: 1... Training loss: 0.00797... Test loss: 0.00799\n",
      "Epoch: 1... Training loss: 0.00776... Test loss: 0.00535\n",
      "Epoch: 1... Training loss: 0.00762... Test loss: 0.00742\n",
      "Epoch: 1... Training loss: 0.00743... Test loss: 0.006\n",
      "Epoch: 1... Training loss: 0.00717... Test loss: 0.00638\n",
      "Epoch: 1... Training loss: 0.00698... Test loss: 0.00578\n",
      "Epoch: 1... Training loss: 0.00665... Test loss: 0.00598\n",
      "Epoch: 1... Training loss: 0.00646... Test loss: 0.00623\n",
      "Epoch: 1... Training loss: 0.00627... Test loss: 0.00589\n",
      "Epoch: 1... Training loss: 0.0062... Test loss: 0.0056\n",
      "Epoch: 1... Training loss: 0.00595... Test loss: 0.00619\n",
      "Epoch: 1... Training loss: 0.00587... Test loss: 0.00571\n",
      "Epoch: 1... Training loss: 0.0057... Test loss: 0.00582\n",
      "Epoch: 1... Training loss: 0.00562... Test loss: 0.0056\n",
      "Epoch: 1... Training loss: 0.00544... Test loss: 0.00509\n",
      "Epoch: 1... Training loss: 0.01565... Test loss: 0.01229\n",
      "Epoch: 1... Training loss: 0.01238... Test loss: 0.02031\n",
      "Epoch: 1... Training loss: 0.01163... Test loss: 0.0133\n",
      "Epoch: 1... Training loss: 0.01132... Test loss: 0.01156\n",
      "Epoch: 1... Training loss: 0.01022... Test loss: 0.01189\n",
      "Epoch: 1... Training loss: 0.01179... Test loss: 0.01125\n",
      "Epoch: 1... Training loss: 0.00895... Test loss: 0.01531\n",
      "Epoch: 1... Training loss: 0.00971... Test loss: 0.00995\n",
      "Epoch: 1... Training loss: 0.00777... Test loss: 0.01377\n",
      "Epoch: 1... Training loss: 0.00793... Test loss: 0.00958\n",
      "Epoch: 1... Training loss: 0.00819... Test loss: 0.0092\n",
      "Epoch: 1... Training loss: 0.00742... Test loss: 0.0089\n",
      "Epoch: 1... Training loss: 0.00707... Test loss: 0.0094\n",
      "Epoch: 1... Training loss: 0.0067... Test loss: 0.00696\n",
      "Epoch: 1... Training loss: 0.00747... Test loss: 0.00788\n",
      "Epoch: 1... Training loss: 0.00738... Test loss: 0.00713\n",
      "Epoch: 1... Training loss: 0.00688... Test loss: 0.00876\n",
      "Epoch: 1... Training loss: 0.00616... Test loss: 0.00683\n",
      "Epoch: 1... Training loss: 0.00673... Test loss: 0.00748\n",
      "Epoch: 1... Training loss: 0.00638... Test loss: 0.00669\n",
      "Epoch: 1... Training loss: 0.00602... Test loss: 0.006\n",
      "Epoch: 1... Training loss: 0.00575... Test loss: 0.0055\n",
      "Epoch: 1... Training loss: 0.00529... Test loss: 0.00637\n",
      "Epoch: 1... Training loss: 0.00573... Test loss: 0.00558\n",
      "Epoch: 1... Training loss: 0.00531... Test loss: 0.00586\n",
      "Epoch: 1... Training loss: 0.00531... Test loss: 0.00469\n",
      "Epoch: 1... Training loss: 0.00512... Test loss: 0.00512\n",
      "Epoch: 1... Training loss: 0.0048... Test loss: 0.00489\n",
      "Epoch: 1... Training loss: 0.00479... Test loss: 0.00474\n",
      "Epoch: 1... Training loss: 0.00448... Test loss: 0.00501\n",
      "Epoch: 1... Training loss: 0.00439... Test loss: 0.00452\n",
      "Epoch: 1... Training loss: 0.00453... Test loss: 0.00429\n",
      "Epoch: 1... Training loss: 0.00432... Test loss: 0.00478\n",
      "Epoch: 1... Training loss: 0.00408... Test loss: 0.0043\n",
      "Epoch: 1... Training loss: 0.00406... Test loss: 0.00378\n",
      "Epoch: 1... Training loss: 0.00393... Test loss: 0.00439\n",
      "Epoch: 1... Training loss: 0.00381... Test loss: 0.00389\n",
      "Epoch: 1... Training loss: 0.00366... Test loss: 0.00382\n",
      "Epoch: 1... Training loss: 0.00363... Test loss: 0.00453\n",
      "Epoch: 1... Training loss: 0.00357... Test loss: 0.00374\n",
      "Epoch: 1... Training loss: 0.00355... Test loss: 0.00434\n",
      "Epoch: 1... Training loss: 0.0034... Test loss: 0.00436\n",
      "Epoch: 1... Training loss: 0.00332... Test loss: 0.00413\n",
      "Epoch: 1... Training loss: 0.00322... Test loss: 0.00379\n",
      "Epoch: 1... Training loss: 0.00324... Test loss: 0.00286\n",
      "Epoch: 1... Training loss: 0.00323... Test loss: 0.00371\n",
      "Epoch: 1... Training loss: 0.00314... Test loss: 0.0027\n",
      "Epoch: 1... Training loss: 0.00311... Test loss: 0.00371\n",
      "Epoch: 1... Training loss: 0.003... Test loss: 0.00294\n",
      "Epoch: 1... Training loss: 0.00297... Test loss: 0.00401\n",
      "Epoch: 1... Training loss: 0.00295... Test loss: 0.00324\n",
      "Epoch: 1... Training loss: 0.00277... Test loss: 0.00312\n",
      "Epoch: 1... Training loss: 0.00276... Test loss: 0.00307\n",
      "Epoch: 1... Training loss: 0.0027... Test loss: 0.00327\n",
      "Epoch: 1... Training loss: 0.00279... Test loss: 0.00285\n",
      "Epoch: 1... Training loss: 0.00268... Test loss: 0.0033\n",
      "Epoch: 1... Training loss: 0.00248... Test loss: 0.0028\n",
      "Epoch: 1... Training loss: 0.00236... Test loss: 0.00297\n",
      "Epoch: 1... Training loss: 0.00253... Test loss: 0.00247\n",
      "Epoch: 1... Training loss: 0.00232... Test loss: 0.00289\n",
      "Epoch: 1... Training loss: 0.00228... Test loss: 0.002\n",
      "Epoch: 1... Training loss: 0.00227... Test loss: 0.00269\n",
      "Epoch: 1... Training loss: 0.00228... Test loss: 0.0021\n",
      "Epoch: 1... Training loss: 0.00213... Test loss: 0.00272\n",
      "Epoch: 1... Training loss: 0.00207... Test loss: 0.00216\n",
      "Epoch: 1... Training loss: 0.00204... Test loss: 0.002\n",
      "Epoch: 1... Training loss: 0.00205... Test loss: 0.00228\n",
      "Epoch: 1... Training loss: 0.00198... Test loss: 0.00206\n",
      "Epoch: 1... Training loss: 0.002... Test loss: 0.00206\n",
      "Epoch: 1... Training loss: 0.00193... Test loss: 0.00179\n",
      "Epoch: 1... Training loss: 0.00193... Test loss: 0.0022\n",
      "Epoch: 1... Training loss: 0.00184... Test loss: 0.00183\n",
      "Epoch: 1... Training loss: 0.00182... Test loss: 0.00187\n",
      "Epoch: 1... Training loss: 0.00178... Test loss: 0.00159\n",
      "Epoch: 1... Training loss: 0.00171... Test loss: 0.00179\n",
      "Epoch: 1... Training loss: 0.00168... Test loss: 0.00172\n",
      "Epoch: 1... Training loss: 0.0017... Test loss: 0.00169\n",
      "Epoch: 1... Training loss: 0.00162... Test loss: 0.00157\n",
      "Epoch: 1... Training loss: 0.00151... Test loss: 0.0015\n",
      "Epoch: 1... Training loss: 0.0015... Test loss: 0.00171\n",
      "Epoch: 1... Training loss: 0.00155... Test loss: 0.00145\n",
      "Epoch: 1... Training loss: 0.0015... Test loss: 0.00162\n",
      "Epoch: 1... Training loss: 0.00148... Test loss: 0.00154\n",
      "Epoch: 1... Training loss: 0.00146... Test loss: 0.00145\n",
      "Epoch: 1... Training loss: 0.00135... Test loss: 0.00139\n",
      "Epoch: 1... Training loss: 0.00137... Test loss: 0.00132\n",
      "Epoch: 1... Training loss: 0.0013... Test loss: 0.00127\n",
      "Epoch: 1... Training loss: 0.00124... Test loss: 0.00141\n",
      "Epoch: 1... Training loss: 0.0012... Test loss: 0.00114\n",
      "Epoch: 1... Training loss: 0.00116... Test loss: 0.00142\n",
      "Epoch: 1... Training loss: 0.00129... Test loss: 0.00118\n",
      "Epoch: 1... Training loss: 0.00112... Test loss: 0.00125\n",
      "Epoch: 1... Training loss: 0.00115... Test loss: 0.00122\n",
      "Epoch: 1... Training loss: 0.00105... Test loss: 0.00131\n",
      "Epoch: 1... Training loss: 0.00106... Test loss: 0.00108\n",
      "Epoch: 1... Training loss: 0.00107... Test loss: 0.00127\n",
      "Epoch: 1... Training loss: 0.00102... Test loss: 0.001\n",
      "Epoch: 1... Training loss: 0.00091... Test loss: 0.00122\n",
      "Epoch: 1... Training loss: 0.00094... Test loss: 0.00091\n",
      "Epoch: 1... Training loss: 0.00092... Test loss: 0.00095\n",
      "Epoch: 1... Training loss: 0.00088... Test loss: 0.00094\n",
      "Epoch: 1... Training loss: 0.00085... Test loss: 0.00101\n",
      "Epoch: 1... Training loss: 0.00087... Test loss: 0.00077\n",
      "Epoch: 1... Training loss: 0.00078... Test loss: 0.00102\n",
      "Epoch: 1... Training loss: 0.00087... Test loss: 0.00081\n",
      "Epoch: 1... Training loss: 0.00075... Test loss: 0.00093\n",
      "Epoch: 1... Training loss: 0.0008... Test loss: 0.00074\n",
      "Epoch: 1... Training loss: 0.00075... Test loss: 0.00088\n",
      "Epoch: 1... Training loss: 0.00068... Test loss: 0.00077\n",
      "Epoch: 1... Training loss: 0.00069... Test loss: 0.00074\n",
      "Epoch: 1... Training loss: 0.00066... Test loss: 0.00073\n",
      "Epoch: 1... Training loss: 0.00067... Test loss: 0.0007\n",
      "Epoch: 1... Training loss: 0.00065... Test loss: 0.00065\n",
      "Epoch: 1... Training loss: 0.00059... Test loss: 0.00065\n",
      "Epoch: 1... Training loss: 0.00058... Test loss: 0.00059\n",
      "Epoch: 1... Training loss: 0.00056... Test loss: 0.00063\n",
      "Epoch: 1... Training loss: 0.00058... Test loss: 0.00046\n",
      "Epoch: 1... Training loss: 0.00056... Test loss: 0.00053\n",
      "Epoch: 1... Training loss: 0.00054... Test loss: 0.0005\n",
      "Epoch: 1... Training loss: 0.00051... Test loss: 0.00056\n",
      "Epoch: 1... Training loss: 0.0005... Test loss: 0.00052\n",
      "Epoch: 1... Training loss: 0.00045... Test loss: 0.00048\n",
      "Epoch: 1... Training loss: 0.00043... Test loss: 0.00049\n",
      "Epoch: 1... Training loss: 0.00043... Test loss: 0.00049\n",
      "Epoch: 1... Training loss: 0.00041... Test loss: 0.00038\n",
      "Epoch: 1... Training loss: 0.00041... Test loss: 0.0005\n",
      "Epoch: 1... Training loss: 0.00041... Test loss: 0.00041\n",
      "Epoch: 1... Training loss: 0.00037... Test loss: 0.00036\n",
      "Epoch: 1... Training loss: 0.00036... Test loss: 0.00041\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1... Training loss: 0.00036... Test loss: 0.00035\n",
      "Epoch: 1... Training loss: 0.00036... Test loss: 0.00034\n",
      "Epoch: 1... Training loss: 0.00031... Test loss: 0.00037\n",
      "Epoch: 1... Training loss: 0.00033... Test loss: 0.0003\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.00041\n",
      "Epoch: 1... Training loss: 0.00026... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00017\n",
      "238.53286083083367\n",
      "Epoch: 1... Training loss: 0.8778... Test loss: 0.28201\n",
      "Epoch: 1... Training loss: 0.44851... Test loss: 0.1234\n",
      "Epoch: 1... Training loss: 0.27799... Test loss: 0.09106\n",
      "Epoch: 1... Training loss: 0.18377... Test loss: 0.06161\n",
      "Epoch: 1... Training loss: 0.14717... Test loss: 0.04291\n",
      "Epoch: 1... Training loss: 0.1212... Test loss: 0.03674\n",
      "Epoch: 1... Training loss: 0.10302... Test loss: 0.03684\n",
      "Epoch: 1... Training loss: 0.08388... Test loss: 0.02674\n",
      "Epoch: 1... Training loss: 0.07957... Test loss: 0.02216\n",
      "Epoch: 1... Training loss: 0.06343... Test loss: 0.02573\n",
      "Epoch: 1... Training loss: 0.05907... Test loss: 0.01349\n",
      "Epoch: 1... Training loss: 0.05173... Test loss: 0.02506\n",
      "Epoch: 1... Training loss: 0.04921... Test loss: 0.01701\n",
      "Epoch: 1... Training loss: 0.04233... Test loss: 0.01743\n",
      "Epoch: 1... Training loss: 0.03937... Test loss: 0.01823\n",
      "Epoch: 1... Training loss: 0.03511... Test loss: 0.03738\n",
      "Epoch: 1... Training loss: 0.03479... Test loss: 0.01129\n",
      "Epoch: 1... Training loss: 0.0322... Test loss: 0.02723\n",
      "Epoch: 1... Training loss: 0.03002... Test loss: 0.01045\n",
      "Epoch: 1... Training loss: 0.0284... Test loss: 0.01983\n",
      "Epoch: 1... Training loss: 0.02676... Test loss: 0.01213\n",
      "Epoch: 1... Training loss: 0.02504... Test loss: 0.02675\n",
      "Epoch: 1... Training loss: 0.02355... Test loss: 0.01126\n",
      "Epoch: 1... Training loss: 0.02198... Test loss: 0.01913\n",
      "Epoch: 1... Training loss: 0.02034... Test loss: 0.01049\n",
      "Epoch: 1... Training loss: 0.01908... Test loss: 0.01805\n",
      "Epoch: 1... Training loss: 0.01849... Test loss: 0.00883\n",
      "Epoch: 1... Training loss: 0.01795... Test loss: 0.01809\n",
      "Epoch: 1... Training loss: 0.01691... Test loss: 0.01601\n",
      "Epoch: 1... Training loss: 0.01606... Test loss: 0.01308\n",
      "Epoch: 1... Training loss: 0.01581... Test loss: 0.01827\n",
      "Epoch: 1... Training loss: 0.01462... Test loss: 0.01531\n",
      "Epoch: 1... Training loss: 0.0145... Test loss: 0.01023\n",
      "Epoch: 1... Training loss: 0.01382... Test loss: 0.01777\n",
      "Epoch: 1... Training loss: 0.01324... Test loss: 0.00886\n",
      "Epoch: 1... Training loss: 0.01315... Test loss: 0.0123\n",
      "Epoch: 1... Training loss: 0.01247... Test loss: 0.01034\n",
      "Epoch: 1... Training loss: 0.01195... Test loss: 0.01613\n",
      "Epoch: 1... Training loss: 0.01185... Test loss: 0.00893\n",
      "Epoch: 1... Training loss: 0.01116... Test loss: 0.01474\n",
      "Epoch: 1... Training loss: 0.01089... Test loss: 0.00767\n",
      "Epoch: 1... Training loss: 0.01047... Test loss: 0.01195\n",
      "Epoch: 1... Training loss: 0.01019... Test loss: 0.00719\n",
      "Epoch: 1... Training loss: 0.00986... Test loss: 0.01079\n",
      "Epoch: 1... Training loss: 0.00968... Test loss: 0.00814\n",
      "Epoch: 1... Training loss: 0.00929... Test loss: 0.00995\n",
      "Epoch: 1... Training loss: 0.00916... Test loss: 0.01082\n",
      "Epoch: 1... Training loss: 0.00881... Test loss: 0.00703\n",
      "Epoch: 1... Training loss: 0.00874... Test loss: 0.00983\n",
      "Epoch: 1... Training loss: 0.0083... Test loss: 0.00644\n",
      "Epoch: 1... Training loss: 0.00817... Test loss: 0.00893\n",
      "Epoch: 1... Training loss: 0.00786... Test loss: 0.00593\n",
      "Epoch: 1... Training loss: 0.00779... Test loss: 0.00829\n",
      "Epoch: 1... Training loss: 0.00748... Test loss: 0.00544\n",
      "Epoch: 1... Training loss: 0.00741... Test loss: 0.00807\n",
      "Epoch: 1... Training loss: 0.00713... Test loss: 0.00575\n",
      "Epoch: 1... Training loss: 0.00692... Test loss: 0.00775\n",
      "Epoch: 1... Training loss: 0.00672... Test loss: 0.00697\n",
      "Epoch: 1... Training loss: 0.00647... Test loss: 0.00745\n",
      "Epoch: 1... Training loss: 0.00631... Test loss: 0.00674\n",
      "Epoch: 1... Training loss: 0.00617... Test loss: 0.00663\n",
      "Epoch: 1... Training loss: 0.00597... Test loss: 0.00659\n",
      "Epoch: 1... Training loss: 0.00588... Test loss: 0.00586\n",
      "Epoch: 1... Training loss: 0.00564... Test loss: 0.00538\n",
      "Epoch: 1... Training loss: 0.01347... Test loss: 0.01653\n",
      "Epoch: 1... Training loss: 0.01281... Test loss: 0.01557\n",
      "Epoch: 1... Training loss: 0.00998... Test loss: 0.01363\n",
      "Epoch: 1... Training loss: 0.00876... Test loss: 0.01423\n",
      "Epoch: 1... Training loss: 0.0095... Test loss: 0.01029\n",
      "Epoch: 1... Training loss: 0.00968... Test loss: 0.01268\n",
      "Epoch: 1... Training loss: 0.01091... Test loss: 0.01242\n",
      "Epoch: 1... Training loss: 0.00906... Test loss: 0.0103\n",
      "Epoch: 1... Training loss: 0.00891... Test loss: 0.00905\n",
      "Epoch: 1... Training loss: 0.00862... Test loss: 0.01227\n",
      "Epoch: 1... Training loss: 0.00866... Test loss: 0.01028\n",
      "Epoch: 1... Training loss: 0.00813... Test loss: 0.00967\n",
      "Epoch: 1... Training loss: 0.00742... Test loss: 0.00942\n",
      "Epoch: 1... Training loss: 0.00791... Test loss: 0.00837\n",
      "Epoch: 1... Training loss: 0.00717... Test loss: 0.01058\n",
      "Epoch: 1... Training loss: 0.00687... Test loss: 0.00995\n",
      "Epoch: 1... Training loss: 0.00696... Test loss: 0.00952\n",
      "Epoch: 1... Training loss: 0.00625... Test loss: 0.00864\n",
      "Epoch: 1... Training loss: 0.00664... Test loss: 0.00842\n",
      "Epoch: 1... Training loss: 0.0064... Test loss: 0.00737\n",
      "Epoch: 1... Training loss: 0.00598... Test loss: 0.00667\n",
      "Epoch: 1... Training loss: 0.0058... Test loss: 0.00584\n",
      "Epoch: 1... Training loss: 0.00575... Test loss: 0.00684\n",
      "Epoch: 1... Training loss: 0.00585... Test loss: 0.00634\n",
      "Epoch: 1... Training loss: 0.00542... Test loss: 0.00637\n",
      "Epoch: 1... Training loss: 0.00508... Test loss: 0.00497\n",
      "Epoch: 1... Training loss: 0.00505... Test loss: 0.00532\n",
      "Epoch: 1... Training loss: 0.00471... Test loss: 0.00489\n",
      "Epoch: 1... Training loss: 0.00475... Test loss: 0.00513\n",
      "Epoch: 1... Training loss: 0.00456... Test loss: 0.00553\n",
      "Epoch: 1... Training loss: 0.00435... Test loss: 0.00442\n",
      "Epoch: 1... Training loss: 0.00431... Test loss: 0.00516\n",
      "Epoch: 1... Training loss: 0.00417... Test loss: 0.00421\n",
      "Epoch: 1... Training loss: 0.00409... Test loss: 0.00527\n",
      "Epoch: 1... Training loss: 0.00414... Test loss: 0.00436\n",
      "Epoch: 1... Training loss: 0.00393... Test loss: 0.00459\n",
      "Epoch: 1... Training loss: 0.00387... Test loss: 0.00372\n",
      "Epoch: 1... Training loss: 0.00369... Test loss: 0.00444\n",
      "Epoch: 1... Training loss: 0.00364... Test loss: 0.00371\n",
      "Epoch: 1... Training loss: 0.00354... Test loss: 0.00417\n",
      "Epoch: 1... Training loss: 0.0035... Test loss: 0.00347\n",
      "Epoch: 1... Training loss: 0.00343... Test loss: 0.00348\n",
      "Epoch: 1... Training loss: 0.00339... Test loss: 0.00334\n",
      "Epoch: 1... Training loss: 0.00323... Test loss: 0.00358\n",
      "Epoch: 1... Training loss: 0.00334... Test loss: 0.0033\n",
      "Epoch: 1... Training loss: 0.00323... Test loss: 0.00382\n",
      "Epoch: 1... Training loss: 0.00306... Test loss: 0.00268\n",
      "Epoch: 1... Training loss: 0.00291... Test loss: 0.00351\n",
      "Epoch: 1... Training loss: 0.00299... Test loss: 0.00305\n",
      "Epoch: 1... Training loss: 0.0028... Test loss: 0.00331\n",
      "Epoch: 1... Training loss: 0.00297... Test loss: 0.00345\n",
      "Epoch: 1... Training loss: 0.00284... Test loss: 0.00308\n",
      "Epoch: 1... Training loss: 0.0028... Test loss: 0.00329\n",
      "Epoch: 1... Training loss: 0.00262... Test loss: 0.00301\n",
      "Epoch: 1... Training loss: 0.00263... Test loss: 0.00354\n",
      "Epoch: 1... Training loss: 0.00251... Test loss: 0.00235\n",
      "Epoch: 1... Training loss: 0.0024... Test loss: 0.00282\n",
      "Epoch: 1... Training loss: 0.00237... Test loss: 0.00227\n",
      "Epoch: 1... Training loss: 0.00243... Test loss: 0.00286\n",
      "Epoch: 1... Training loss: 0.00229... Test loss: 0.00237\n",
      "Epoch: 1... Training loss: 0.00228... Test loss: 0.00254\n",
      "Epoch: 1... Training loss: 0.00225... Test loss: 0.0024\n",
      "Epoch: 1... Training loss: 0.00212... Test loss: 0.0026\n",
      "Epoch: 1... Training loss: 0.00213... Test loss: 0.00231\n",
      "Epoch: 1... Training loss: 0.002... Test loss: 0.00215\n",
      "Epoch: 1... Training loss: 0.00198... Test loss: 0.00213\n",
      "Epoch: 1... Training loss: 0.00189... Test loss: 0.00202\n",
      "Epoch: 1... Training loss: 0.00203... Test loss: 0.00195\n",
      "Epoch: 1... Training loss: 0.00184... Test loss: 0.00211\n",
      "Epoch: 1... Training loss: 0.00179... Test loss: 0.00173\n",
      "Epoch: 1... Training loss: 0.00177... Test loss: 0.0018\n",
      "Epoch: 1... Training loss: 0.00173... Test loss: 0.00151\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1... Training loss: 0.00161... Test loss: 0.00205\n",
      "Epoch: 1... Training loss: 0.00157... Test loss: 0.00146\n",
      "Epoch: 1... Training loss: 0.00158... Test loss: 0.00184\n",
      "Epoch: 1... Training loss: 0.00156... Test loss: 0.00166\n",
      "Epoch: 1... Training loss: 0.00145... Test loss: 0.00218\n",
      "Epoch: 1... Training loss: 0.00142... Test loss: 0.00144\n",
      "Epoch: 1... Training loss: 0.00137... Test loss: 0.00181\n",
      "Epoch: 1... Training loss: 0.00129... Test loss: 0.00147\n",
      "Epoch: 1... Training loss: 0.00128... Test loss: 0.00145\n",
      "Epoch: 1... Training loss: 0.00125... Test loss: 0.00128\n",
      "Epoch: 1... Training loss: 0.00117... Test loss: 0.00125\n",
      "Epoch: 1... Training loss: 0.0011... Test loss: 0.00117\n",
      "Epoch: 1... Training loss: 0.00116... Test loss: 0.0011\n",
      "Epoch: 1... Training loss: 0.00109... Test loss: 0.00119\n",
      "Epoch: 1... Training loss: 0.00113... Test loss: 0.00119\n",
      "Epoch: 1... Training loss: 0.00098... Test loss: 0.00121\n",
      "Epoch: 1... Training loss: 0.00103... Test loss: 0.00109\n",
      "Epoch: 1... Training loss: 0.00092... Test loss: 0.00116\n",
      "Epoch: 1... Training loss: 0.00091... Test loss: 0.00104\n",
      "Epoch: 1... Training loss: 0.00082... Test loss: 0.00082\n",
      "Epoch: 1... Training loss: 0.00087... Test loss: 0.001\n",
      "Epoch: 1... Training loss: 0.0008... Test loss: 0.00086\n",
      "Epoch: 1... Training loss: 0.0008... Test loss: 0.00093\n",
      "Epoch: 1... Training loss: 0.00077... Test loss: 0.00078\n",
      "Epoch: 1... Training loss: 0.00081... Test loss: 0.00095\n",
      "Epoch: 1... Training loss: 0.00075... Test loss: 0.00074\n",
      "Epoch: 1... Training loss: 0.0007... Test loss: 0.00085\n",
      "Epoch: 1... Training loss: 0.00071... Test loss: 0.00066\n",
      "Epoch: 1... Training loss: 0.0007... Test loss: 0.00092\n",
      "Epoch: 1... Training loss: 0.00061... Test loss: 0.00075\n",
      "Epoch: 1... Training loss: 0.00059... Test loss: 0.00079\n",
      "Epoch: 1... Training loss: 0.00061... Test loss: 0.00064\n",
      "Epoch: 1... Training loss: 0.00055... Test loss: 0.00065\n",
      "Epoch: 1... Training loss: 0.00056... Test loss: 0.00056\n",
      "Epoch: 1... Training loss: 0.00053... Test loss: 0.0006\n",
      "Epoch: 1... Training loss: 0.00057... Test loss: 0.00058\n",
      "Epoch: 1... Training loss: 0.0005... Test loss: 0.00057\n",
      "Epoch: 1... Training loss: 0.00052... Test loss: 0.00062\n",
      "Epoch: 1... Training loss: 0.00052... Test loss: 0.00059\n",
      "Epoch: 1... Training loss: 0.00047... Test loss: 0.00053\n",
      "Epoch: 1... Training loss: 0.00048... Test loss: 0.00054\n",
      "Epoch: 1... Training loss: 0.00045... Test loss: 0.00048\n",
      "Epoch: 1... Training loss: 0.00044... Test loss: 0.00043\n",
      "Epoch: 1... Training loss: 0.00038... Test loss: 0.00042\n",
      "Epoch: 1... Training loss: 0.00041... Test loss: 0.00037\n",
      "Epoch: 1... Training loss: 0.00038... Test loss: 0.00042\n",
      "Epoch: 1... Training loss: 0.00038... Test loss: 0.00035\n",
      "Epoch: 1... Training loss: 0.00035... Test loss: 0.00033\n",
      "Epoch: 1... Training loss: 0.00034... Test loss: 0.00032\n",
      "Epoch: 1... Training loss: 0.00033... Test loss: 0.00034\n",
      "Epoch: 1... Training loss: 0.00035... Test loss: 0.00034\n",
      "Epoch: 1... Training loss: 0.00029... Test loss: 0.00034\n",
      "Epoch: 1... Training loss: 0.00029... Test loss: 0.00035\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00031\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.00026... Test loss: 0.00024\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00024\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.00018\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00017\n",
      "285.74567994545214\n",
      "Epoch: 1... Training loss: 0.87646... Test loss: 0.24296\n",
      "Epoch: 1... Training loss: 0.42912... Test loss: 0.09824\n",
      "Epoch: 1... Training loss: 0.26799... Test loss: 0.05015\n",
      "Epoch: 1... Training loss: 0.19643... Test loss: 0.0437\n",
      "Epoch: 1... Training loss: 0.14079... Test loss: 0.03096\n",
      "Epoch: 1... Training loss: 0.11156... Test loss: 0.02488\n",
      "Epoch: 1... Training loss: 0.09047... Test loss: 0.02005\n",
      "Epoch: 1... Training loss: 0.07294... Test loss: 0.01685\n",
      "Epoch: 1... Training loss: 0.06473... Test loss: 0.01382\n",
      "Epoch: 1... Training loss: 0.05524... Test loss: 0.0124\n",
      "Epoch: 1... Training loss: 0.05139... Test loss: 0.01093\n",
      "Epoch: 1... Training loss: 0.04374... Test loss: 0.01048\n",
      "Epoch: 1... Training loss: 0.04164... Test loss: 0.01047\n",
      "Epoch: 1... Training loss: 0.03659... Test loss: 0.01544\n",
      "Epoch: 1... Training loss: 0.03393... Test loss: 0.00735\n",
      "Epoch: 1... Training loss: 0.03105... Test loss: 0.01519\n",
      "Epoch: 1... Training loss: 0.03013... Test loss: 0.00679\n",
      "Epoch: 1... Training loss: 0.0277... Test loss: 0.01932\n",
      "Epoch: 1... Training loss: 0.02721... Test loss: 0.0068\n",
      "Epoch: 1... Training loss: 0.02424... Test loss: 0.01993\n",
      "Epoch: 1... Training loss: 0.0233... Test loss: 0.00766\n",
      "Epoch: 1... Training loss: 0.02199... Test loss: 0.02002\n",
      "Epoch: 1... Training loss: 0.02121... Test loss: 0.00925\n",
      "Epoch: 1... Training loss: 0.02054... Test loss: 0.01594\n",
      "Epoch: 1... Training loss: 0.01946... Test loss: 0.01845\n",
      "Epoch: 1... Training loss: 0.01877... Test loss: 0.01381\n",
      "Epoch: 1... Training loss: 0.01805... Test loss: 0.01701\n",
      "Epoch: 1... Training loss: 0.0173... Test loss: 0.01358\n",
      "Epoch: 1... Training loss: 0.01632... Test loss: 0.01732\n",
      "Epoch: 1... Training loss: 0.016... Test loss: 0.01177\n",
      "Epoch: 1... Training loss: 0.01533... Test loss: 0.01493\n",
      "Epoch: 1... Training loss: 0.01469... Test loss: 0.01037\n",
      "Epoch: 1... Training loss: 0.01434... Test loss: 0.01879\n",
      "Epoch: 1... Training loss: 0.01385... Test loss: 0.00588\n",
      "Epoch: 1... Training loss: 0.01355... Test loss: 0.01598\n",
      "Epoch: 1... Training loss: 0.01308... Test loss: 0.00695\n",
      "Epoch: 1... Training loss: 0.01248... Test loss: 0.01407\n",
      "Epoch: 1... Training loss: 0.01249... Test loss: 0.00849\n",
      "Epoch: 1... Training loss: 0.01173... Test loss: 0.01252\n",
      "Epoch: 1... Training loss: 0.01129... Test loss: 0.00811\n",
      "Epoch: 1... Training loss: 0.01097... Test loss: 0.01183\n",
      "Epoch: 1... Training loss: 0.0108... Test loss: 0.00803\n",
      "Epoch: 1... Training loss: 0.01026... Test loss: 0.01107\n",
      "Epoch: 1... Training loss: 0.01001... Test loss: 0.00772\n",
      "Epoch: 1... Training loss: 0.00958... Test loss: 0.01101\n",
      "Epoch: 1... Training loss: 0.00941... Test loss: 0.00634\n",
      "Epoch: 1... Training loss: 0.00916... Test loss: 0.00915\n",
      "Epoch: 1... Training loss: 0.00884... Test loss: 0.0062\n",
      "Epoch: 1... Training loss: 0.00861... Test loss: 0.00845\n",
      "Epoch: 1... Training loss: 0.00843... Test loss: 0.00623\n",
      "Epoch: 1... Training loss: 0.00808... Test loss: 0.00742\n",
      "Epoch: 1... Training loss: 0.00794... Test loss: 0.0073\n",
      "Epoch: 1... Training loss: 0.0076... Test loss: 0.00639\n",
      "Epoch: 1... Training loss: 0.00747... Test loss: 0.00709\n",
      "Epoch: 1... Training loss: 0.00731... Test loss: 0.00487\n",
      "Epoch: 1... Training loss: 0.00699... Test loss: 0.0075\n",
      "Epoch: 1... Training loss: 0.00684... Test loss: 0.0045\n",
      "Epoch: 1... Training loss: 0.00666... Test loss: 0.00713\n",
      "Epoch: 1... Training loss: 0.00655... Test loss: 0.00485\n",
      "Epoch: 1... Training loss: 0.00635... Test loss: 0.00643\n",
      "Epoch: 1... Training loss: 0.00615... Test loss: 0.00503\n",
      "Epoch: 1... Training loss: 0.00597... Test loss: 0.00629\n",
      "Epoch: 1... Training loss: 0.00589... Test loss: 0.0054\n",
      "Epoch: 1... Training loss: 0.00575... Test loss: 0.00606\n",
      "Epoch: 1... Training loss: 0.01406... Test loss: 0.01177\n",
      "Epoch: 1... Training loss: 0.01063... Test loss: 0.01083\n",
      "Epoch: 1... Training loss: 0.01318... Test loss: 0.01108\n",
      "Epoch: 1... Training loss: 0.00961... Test loss: 0.01208\n",
      "Epoch: 1... Training loss: 0.01049... Test loss: 0.0089\n",
      "Epoch: 1... Training loss: 0.00885... Test loss: 0.01113\n",
      "Epoch: 1... Training loss: 0.00953... Test loss: 0.01066\n",
      "Epoch: 1... Training loss: 0.00912... Test loss: 0.01254\n",
      "Epoch: 1... Training loss: 0.00868... Test loss: 0.00936\n",
      "Epoch: 1... Training loss: 0.00877... Test loss: 0.00846\n",
      "Epoch: 1... Training loss: 0.00832... Test loss: 0.01174\n",
      "Epoch: 1... Training loss: 0.00781... Test loss: 0.00797\n",
      "Epoch: 1... Training loss: 0.00752... Test loss: 0.01078\n",
      "Epoch: 1... Training loss: 0.00701... Test loss: 0.00825\n",
      "Epoch: 1... Training loss: 0.00699... Test loss: 0.00779\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1... Training loss: 0.007... Test loss: 0.00697\n",
      "Epoch: 1... Training loss: 0.00676... Test loss: 0.00642\n",
      "Epoch: 1... Training loss: 0.00641... Test loss: 0.00652\n",
      "Epoch: 1... Training loss: 0.00637... Test loss: 0.00616\n",
      "Epoch: 1... Training loss: 0.00609... Test loss: 0.00672\n",
      "Epoch: 1... Training loss: 0.00617... Test loss: 0.00673\n",
      "Epoch: 1... Training loss: 0.00573... Test loss: 0.00759\n",
      "Epoch: 1... Training loss: 0.00587... Test loss: 0.00526\n",
      "Epoch: 1... Training loss: 0.00529... Test loss: 0.00901\n",
      "Epoch: 1... Training loss: 0.00532... Test loss: 0.00552\n",
      "Epoch: 1... Training loss: 0.00523... Test loss: 0.00741\n",
      "Epoch: 1... Training loss: 0.00493... Test loss: 0.00513\n",
      "Epoch: 1... Training loss: 0.00496... Test loss: 0.00742\n",
      "Epoch: 1... Training loss: 0.00498... Test loss: 0.00479\n",
      "Epoch: 1... Training loss: 0.00443... Test loss: 0.00632\n",
      "Epoch: 1... Training loss: 0.00454... Test loss: 0.00419\n",
      "Epoch: 1... Training loss: 0.00472... Test loss: 0.00556\n",
      "Epoch: 1... Training loss: 0.00448... Test loss: 0.00382\n",
      "Epoch: 1... Training loss: 0.00435... Test loss: 0.00456\n",
      "Epoch: 1... Training loss: 0.00411... Test loss: 0.00406\n",
      "Epoch: 1... Training loss: 0.00387... Test loss: 0.00406\n",
      "Epoch: 1... Training loss: 0.00408... Test loss: 0.0034\n",
      "Epoch: 1... Training loss: 0.00391... Test loss: 0.00418\n",
      "Epoch: 1... Training loss: 0.00383... Test loss: 0.00352\n",
      "Epoch: 1... Training loss: 0.00385... Test loss: 0.00431\n",
      "Epoch: 1... Training loss: 0.00372... Test loss: 0.00399\n",
      "Epoch: 1... Training loss: 0.00367... Test loss: 0.00437\n",
      "Epoch: 1... Training loss: 0.00361... Test loss: 0.00423\n",
      "Epoch: 1... Training loss: 0.00342... Test loss: 0.00333\n",
      "Epoch: 1... Training loss: 0.00352... Test loss: 0.00385\n",
      "Epoch: 1... Training loss: 0.00345... Test loss: 0.00318\n",
      "Epoch: 1... Training loss: 0.00341... Test loss: 0.00339\n",
      "Epoch: 1... Training loss: 0.00346... Test loss: 0.00369\n",
      "Epoch: 1... Training loss: 0.00319... Test loss: 0.00346\n",
      "Epoch: 1... Training loss: 0.0032... Test loss: 0.00361\n",
      "Epoch: 1... Training loss: 0.00313... Test loss: 0.00336\n",
      "Epoch: 1... Training loss: 0.00293... Test loss: 0.00365\n",
      "Epoch: 1... Training loss: 0.00278... Test loss: 0.00339\n",
      "Epoch: 1... Training loss: 0.00297... Test loss: 0.00337\n",
      "Epoch: 1... Training loss: 0.00274... Test loss: 0.00306\n",
      "Epoch: 1... Training loss: 0.00278... Test loss: 0.00344\n",
      "Epoch: 1... Training loss: 0.00261... Test loss: 0.00294\n",
      "Epoch: 1... Training loss: 0.00257... Test loss: 0.00272\n",
      "Epoch: 1... Training loss: 0.00256... Test loss: 0.00302\n",
      "Epoch: 1... Training loss: 0.00235... Test loss: 0.00279\n",
      "Epoch: 1... Training loss: 0.00229... Test loss: 0.00253\n",
      "Epoch: 1... Training loss: 0.00234... Test loss: 0.00214\n",
      "Epoch: 1... Training loss: 0.00216... Test loss: 0.00239\n",
      "Epoch: 1... Training loss: 0.0021... Test loss: 0.00211\n",
      "Epoch: 1... Training loss: 0.00205... Test loss: 0.00217\n",
      "Epoch: 1... Training loss: 0.00194... Test loss: 0.00202\n",
      "Epoch: 1... Training loss: 0.00195... Test loss: 0.00207\n",
      "Epoch: 1... Training loss: 0.00182... Test loss: 0.00175\n",
      "Epoch: 1... Training loss: 0.00183... Test loss: 0.00205\n",
      "Epoch: 1... Training loss: 0.0018... Test loss: 0.00178\n",
      "Epoch: 1... Training loss: 0.00176... Test loss: 0.00184\n",
      "Epoch: 1... Training loss: 0.00166... Test loss: 0.00189\n",
      "Epoch: 1... Training loss: 0.00167... Test loss: 0.00185\n",
      "Epoch: 1... Training loss: 0.00158... Test loss: 0.00178\n",
      "Epoch: 1... Training loss: 0.00159... Test loss: 0.00171\n",
      "Epoch: 1... Training loss: 0.00149... Test loss: 0.00162\n",
      "Epoch: 1... Training loss: 0.00145... Test loss: 0.0016\n",
      "Epoch: 1... Training loss: 0.00144... Test loss: 0.00173\n",
      "Epoch: 1... Training loss: 0.00143... Test loss: 0.00174\n",
      "Epoch: 1... Training loss: 0.00136... Test loss: 0.00143\n",
      "Epoch: 1... Training loss: 0.00136... Test loss: 0.00173\n",
      "Epoch: 1... Training loss: 0.00138... Test loss: 0.00139\n",
      "Epoch: 1... Training loss: 0.00134... Test loss: 0.0016\n",
      "Epoch: 1... Training loss: 0.00136... Test loss: 0.00109\n",
      "Epoch: 1... Training loss: 0.00127... Test loss: 0.00149\n",
      "Epoch: 1... Training loss: 0.00118... Test loss: 0.00115\n",
      "Epoch: 1... Training loss: 0.00117... Test loss: 0.00126\n",
      "Epoch: 1... Training loss: 0.00115... Test loss: 0.00111\n",
      "Epoch: 1... Training loss: 0.0011... Test loss: 0.00115\n",
      "Epoch: 1... Training loss: 0.00107... Test loss: 0.00118\n",
      "Epoch: 1... Training loss: 0.00101... Test loss: 0.00114\n",
      "Epoch: 1... Training loss: 0.0011... Test loss: 0.00104\n",
      "Epoch: 1... Training loss: 0.00102... Test loss: 0.0013\n",
      "Epoch: 1... Training loss: 0.00101... Test loss: 0.00103\n",
      "Epoch: 1... Training loss: 0.00092... Test loss: 0.00111\n",
      "Epoch: 1... Training loss: 0.00093... Test loss: 0.00085\n",
      "Epoch: 1... Training loss: 0.0009... Test loss: 0.00092\n",
      "Epoch: 1... Training loss: 0.00097... Test loss: 0.00078\n",
      "Epoch: 1... Training loss: 0.00087... Test loss: 0.00097\n",
      "Epoch: 1... Training loss: 0.00088... Test loss: 0.00069\n",
      "Epoch: 1... Training loss: 0.00086... Test loss: 0.00098\n",
      "Epoch: 1... Training loss: 0.00083... Test loss: 0.00068\n",
      "Epoch: 1... Training loss: 0.00082... Test loss: 0.00104\n",
      "Epoch: 1... Training loss: 0.00077... Test loss: 0.00066\n",
      "Epoch: 1... Training loss: 0.00072... Test loss: 0.0009\n",
      "Epoch: 1... Training loss: 0.00078... Test loss: 0.00065\n",
      "Epoch: 1... Training loss: 0.00075... Test loss: 0.00081\n",
      "Epoch: 1... Training loss: 0.00071... Test loss: 0.00068\n",
      "Epoch: 1... Training loss: 0.00074... Test loss: 0.00067\n",
      "Epoch: 1... Training loss: 0.00064... Test loss: 0.00073\n",
      "Epoch: 1... Training loss: 0.00063... Test loss: 0.00072\n",
      "Epoch: 1... Training loss: 0.00061... Test loss: 0.00066\n",
      "Epoch: 1... Training loss: 0.00059... Test loss: 0.00069\n",
      "Epoch: 1... Training loss: 0.0006... Test loss: 0.00055\n",
      "Epoch: 1... Training loss: 0.00053... Test loss: 0.00063\n",
      "Epoch: 1... Training loss: 0.00052... Test loss: 0.00057\n",
      "Epoch: 1... Training loss: 0.00056... Test loss: 0.00055\n",
      "Epoch: 1... Training loss: 0.00051... Test loss: 0.00056\n",
      "Epoch: 1... Training loss: 0.00051... Test loss: 0.00054\n",
      "Epoch: 1... Training loss: 0.00045... Test loss: 0.00056\n",
      "Epoch: 1... Training loss: 0.00046... Test loss: 0.00045\n",
      "Epoch: 1... Training loss: 0.00046... Test loss: 0.00044\n",
      "Epoch: 1... Training loss: 0.00041... Test loss: 0.00049\n",
      "Epoch: 1... Training loss: 0.00039... Test loss: 0.00042\n",
      "Epoch: 1... Training loss: 0.00038... Test loss: 0.00052\n",
      "Epoch: 1... Training loss: 0.00041... Test loss: 0.00036\n",
      "Epoch: 1... Training loss: 0.00034... Test loss: 0.00045\n",
      "Epoch: 1... Training loss: 0.00033... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.00032... Test loss: 0.00036\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.00028\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.0003\n",
      "302.103672760888\n",
      "Epoch: 1... Training loss: 0.89194... Test loss: 0.24099\n",
      "Epoch: 1... Training loss: 0.44674... Test loss: 0.13162\n",
      "Epoch: 1... Training loss: 0.25286... Test loss: 0.07108\n",
      "Epoch: 1... Training loss: 0.17221... Test loss: 0.0479\n",
      "Epoch: 1... Training loss: 0.13632... Test loss: 0.03818\n",
      "Epoch: 1... Training loss: 0.10325... Test loss: 0.02646\n",
      "Epoch: 1... Training loss: 0.08698... Test loss: 0.03217\n",
      "Epoch: 1... Training loss: 0.07422... Test loss: 0.01482\n",
      "Epoch: 1... Training loss: 0.06266... Test loss: 0.01639\n",
      "Epoch: 1... Training loss: 0.05464... Test loss: 0.01018\n",
      "Epoch: 1... Training loss: 0.05257... Test loss: 0.01861\n",
      "Epoch: 1... Training loss: 0.04736... Test loss: 0.00811\n",
      "Epoch: 1... Training loss: 0.04414... Test loss: 0.01207\n",
      "Epoch: 1... Training loss: 0.03979... Test loss: 0.00911\n",
      "Epoch: 1... Training loss: 0.03742... Test loss: 0.01767\n",
      "Epoch: 1... Training loss: 0.03438... Test loss: 0.01091\n",
      "Epoch: 1... Training loss: 0.03246... Test loss: 0.01956\n",
      "Epoch: 1... Training loss: 0.03031... Test loss: 0.00865\n",
      "Epoch: 1... Training loss: 0.02941... Test loss: 0.0261\n",
      "Epoch: 1... Training loss: 0.02719... Test loss: 0.00948\n",
      "Epoch: 1... Training loss: 0.02564... Test loss: 0.02109\n",
      "Epoch: 1... Training loss: 0.02439... Test loss: 0.00978\n",
      "Epoch: 1... Training loss: 0.02322... Test loss: 0.01989\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1... Training loss: 0.02276... Test loss: 0.00904\n",
      "Epoch: 1... Training loss: 0.02135... Test loss: 0.01911\n",
      "Epoch: 1... Training loss: 0.02011... Test loss: 0.00883\n",
      "Epoch: 1... Training loss: 0.01933... Test loss: 0.01966\n",
      "Epoch: 1... Training loss: 0.01823... Test loss: 0.00972\n",
      "Epoch: 1... Training loss: 0.01764... Test loss: 0.01572\n",
      "Epoch: 1... Training loss: 0.01663... Test loss: 0.01454\n",
      "Epoch: 1... Training loss: 0.01625... Test loss: 0.01289\n",
      "Epoch: 1... Training loss: 0.01549... Test loss: 0.01511\n",
      "Epoch: 1... Training loss: 0.0148... Test loss: 0.01119\n",
      "Epoch: 1... Training loss: 0.01411... Test loss: 0.01313\n",
      "Epoch: 1... Training loss: 0.01386... Test loss: 0.01052\n",
      "Epoch: 1... Training loss: 0.01314... Test loss: 0.01223\n",
      "Epoch: 1... Training loss: 0.01294... Test loss: 0.01203\n",
      "Epoch: 1... Training loss: 0.01248... Test loss: 0.00821\n",
      "Epoch: 1... Training loss: 0.01203... Test loss: 0.01266\n",
      "Epoch: 1... Training loss: 0.01164... Test loss: 0.00724\n",
      "Epoch: 1... Training loss: 0.01141... Test loss: 0.01114\n",
      "Epoch: 1... Training loss: 0.01098... Test loss: 0.0068\n",
      "Epoch: 1... Training loss: 0.01078... Test loss: 0.01091\n",
      "Epoch: 1... Training loss: 0.01064... Test loss: 0.0078\n",
      "Epoch: 1... Training loss: 0.01004... Test loss: 0.01\n",
      "Epoch: 1... Training loss: 0.00982... Test loss: 0.00833\n",
      "Epoch: 1... Training loss: 0.00958... Test loss: 0.00797\n",
      "Epoch: 1... Training loss: 0.00943... Test loss: 0.0097\n",
      "Epoch: 1... Training loss: 0.00896... Test loss: 0.00666\n",
      "Epoch: 1... Training loss: 0.00858... Test loss: 0.00878\n",
      "Epoch: 1... Training loss: 0.00834... Test loss: 0.00608\n",
      "Epoch: 1... Training loss: 0.0082... Test loss: 0.0079\n",
      "Epoch: 1... Training loss: 0.008... Test loss: 0.00722\n",
      "Epoch: 1... Training loss: 0.00786... Test loss: 0.00614\n",
      "Epoch: 1... Training loss: 0.00768... Test loss: 0.00704\n",
      "Epoch: 1... Training loss: 0.00749... Test loss: 0.00606\n",
      "Epoch: 1... Training loss: 0.0074... Test loss: 0.00687\n",
      "Epoch: 1... Training loss: 0.00711... Test loss: 0.00657\n",
      "Epoch: 1... Training loss: 0.00701... Test loss: 0.00627\n",
      "Epoch: 1... Training loss: 0.00682... Test loss: 0.00709\n",
      "Epoch: 1... Training loss: 0.00661... Test loss: 0.00588\n",
      "Epoch: 1... Training loss: 0.00648... Test loss: 0.00656\n",
      "Epoch: 1... Training loss: 0.00626... Test loss: 0.00608\n",
      "Epoch: 1... Training loss: 0.00616... Test loss: 0.00598\n",
      "Epoch: 1... Training loss: 0.01134... Test loss: 0.01401\n",
      "Epoch: 1... Training loss: 0.014... Test loss: 0.01066\n",
      "Epoch: 1... Training loss: 0.0096... Test loss: 0.01519\n",
      "Epoch: 1... Training loss: 0.01087... Test loss: 0.0119\n",
      "Epoch: 1... Training loss: 0.01045... Test loss: 0.01252\n",
      "Epoch: 1... Training loss: 0.01066... Test loss: 0.01265\n",
      "Epoch: 1... Training loss: 0.01012... Test loss: 0.01452\n",
      "Epoch: 1... Training loss: 0.01053... Test loss: 0.01227\n",
      "Epoch: 1... Training loss: 0.00886... Test loss: 0.01402\n",
      "Epoch: 1... Training loss: 0.00868... Test loss: 0.01028\n",
      "Epoch: 1... Training loss: 0.00868... Test loss: 0.012\n",
      "Epoch: 1... Training loss: 0.00829... Test loss: 0.01082\n",
      "Epoch: 1... Training loss: 0.00811... Test loss: 0.01067\n",
      "Epoch: 1... Training loss: 0.00798... Test loss: 0.00874\n",
      "Epoch: 1... Training loss: 0.00767... Test loss: 0.00923\n",
      "Epoch: 1... Training loss: 0.00727... Test loss: 0.00833\n",
      "Epoch: 1... Training loss: 0.00719... Test loss: 0.00929\n",
      "Epoch: 1... Training loss: 0.00726... Test loss: 0.00855\n",
      "Epoch: 1... Training loss: 0.00682... Test loss: 0.00848\n",
      "Epoch: 1... Training loss: 0.00662... Test loss: 0.00789\n",
      "Epoch: 1... Training loss: 0.00646... Test loss: 0.00722\n",
      "Epoch: 1... Training loss: 0.00613... Test loss: 0.00713\n",
      "Epoch: 1... Training loss: 0.00623... Test loss: 0.00792\n",
      "Epoch: 1... Training loss: 0.00589... Test loss: 0.00669\n",
      "Epoch: 1... Training loss: 0.00572... Test loss: 0.00598\n",
      "Epoch: 1... Training loss: 0.00536... Test loss: 0.0061\n",
      "Epoch: 1... Training loss: 0.00522... Test loss: 0.00571\n",
      "Epoch: 1... Training loss: 0.00524... Test loss: 0.00555\n",
      "Epoch: 1... Training loss: 0.00491... Test loss: 0.00519\n",
      "Epoch: 1... Training loss: 0.00491... Test loss: 0.00501\n",
      "Epoch: 1... Training loss: 0.00478... Test loss: 0.00513\n",
      "Epoch: 1... Training loss: 0.00472... Test loss: 0.00498\n",
      "Epoch: 1... Training loss: 0.00462... Test loss: 0.00496\n",
      "Epoch: 1... Training loss: 0.0044... Test loss: 0.00529\n",
      "Epoch: 1... Training loss: 0.00434... Test loss: 0.00456\n",
      "Epoch: 1... Training loss: 0.00433... Test loss: 0.00463\n",
      "Epoch: 1... Training loss: 0.00428... Test loss: 0.00378\n",
      "Epoch: 1... Training loss: 0.00405... Test loss: 0.00471\n",
      "Epoch: 1... Training loss: 0.00417... Test loss: 0.00335\n",
      "Epoch: 1... Training loss: 0.0039... Test loss: 0.00441\n",
      "Epoch: 1... Training loss: 0.00383... Test loss: 0.00418\n",
      "Epoch: 1... Training loss: 0.00391... Test loss: 0.00402\n",
      "Epoch: 1... Training loss: 0.00373... Test loss: 0.00372\n",
      "Epoch: 1... Training loss: 0.00375... Test loss: 0.00382\n",
      "Epoch: 1... Training loss: 0.00371... Test loss: 0.00368\n",
      "Epoch: 1... Training loss: 0.00345... Test loss: 0.0035\n",
      "Epoch: 1... Training loss: 0.00351... Test loss: 0.0035\n",
      "Epoch: 1... Training loss: 0.00335... Test loss: 0.00396\n",
      "Epoch: 1... Training loss: 0.00321... Test loss: 0.00378\n",
      "Epoch: 1... Training loss: 0.00317... Test loss: 0.00349\n",
      "Epoch: 1... Training loss: 0.00301... Test loss: 0.00369\n",
      "Epoch: 1... Training loss: 0.00312... Test loss: 0.0036\n",
      "Epoch: 1... Training loss: 0.0029... Test loss: 0.00354\n",
      "Epoch: 1... Training loss: 0.0028... Test loss: 0.00301\n",
      "Epoch: 1... Training loss: 0.00269... Test loss: 0.00373\n",
      "Epoch: 1... Training loss: 0.00276... Test loss: 0.00288\n",
      "Epoch: 1... Training loss: 0.00264... Test loss: 0.00322\n",
      "Epoch: 1... Training loss: 0.00257... Test loss: 0.00269\n",
      "Epoch: 1... Training loss: 0.00245... Test loss: 0.00276\n",
      "Epoch: 1... Training loss: 0.00237... Test loss: 0.00258\n",
      "Epoch: 1... Training loss: 0.00245... Test loss: 0.00272\n",
      "Epoch: 1... Training loss: 0.00229... Test loss: 0.00239\n",
      "Epoch: 1... Training loss: 0.00229... Test loss: 0.00263\n",
      "Epoch: 1... Training loss: 0.00216... Test loss: 0.00202\n",
      "Epoch: 1... Training loss: 0.00211... Test loss: 0.00247\n",
      "Epoch: 1... Training loss: 0.00206... Test loss: 0.00183\n",
      "Epoch: 1... Training loss: 0.00206... Test loss: 0.00243\n",
      "Epoch: 1... Training loss: 0.00199... Test loss: 0.00193\n",
      "Epoch: 1... Training loss: 0.00197... Test loss: 0.00227\n",
      "Epoch: 1... Training loss: 0.0019... Test loss: 0.00208\n",
      "Epoch: 1... Training loss: 0.00181... Test loss: 0.00183\n",
      "Epoch: 1... Training loss: 0.00177... Test loss: 0.00216\n",
      "Epoch: 1... Training loss: 0.00165... Test loss: 0.00182\n",
      "Epoch: 1... Training loss: 0.00154... Test loss: 0.00194\n",
      "Epoch: 1... Training loss: 0.0016... Test loss: 0.0018\n",
      "Epoch: 1... Training loss: 0.00151... Test loss: 0.00164\n",
      "Epoch: 1... Training loss: 0.00155... Test loss: 0.00161\n",
      "Epoch: 1... Training loss: 0.00142... Test loss: 0.00172\n",
      "Epoch: 1... Training loss: 0.00138... Test loss: 0.0014\n",
      "Epoch: 1... Training loss: 0.00131... Test loss: 0.00142\n",
      "Epoch: 1... Training loss: 0.00128... Test loss: 0.00131\n",
      "Epoch: 1... Training loss: 0.0013... Test loss: 0.00159\n",
      "Epoch: 1... Training loss: 0.0012... Test loss: 0.00117\n",
      "Epoch: 1... Training loss: 0.00118... Test loss: 0.00142\n",
      "Epoch: 1... Training loss: 0.00119... Test loss: 0.00122\n",
      "Epoch: 1... Training loss: 0.00114... Test loss: 0.00128\n",
      "Epoch: 1... Training loss: 0.00113... Test loss: 0.00114\n",
      "Epoch: 1... Training loss: 0.0011... Test loss: 0.00112\n",
      "Epoch: 1... Training loss: 0.00113... Test loss: 0.00124\n",
      "Epoch: 1... Training loss: 0.00103... Test loss: 0.00121\n",
      "Epoch: 1... Training loss: 0.00098... Test loss: 0.00099\n",
      "Epoch: 1... Training loss: 0.00101... Test loss: 0.00107\n",
      "Epoch: 1... Training loss: 0.00091... Test loss: 0.00099\n",
      "Epoch: 1... Training loss: 0.00088... Test loss: 0.00099\n",
      "Epoch: 1... Training loss: 0.00087... Test loss: 0.0009\n",
      "Epoch: 1... Training loss: 0.00082... Test loss: 0.00086\n",
      "Epoch: 1... Training loss: 0.00088... Test loss: 0.00076\n",
      "Epoch: 1... Training loss: 0.0008... Test loss: 0.00087\n",
      "Epoch: 1... Training loss: 0.0008... Test loss: 0.00075\n",
      "Epoch: 1... Training loss: 0.00079... Test loss: 0.00067\n",
      "Epoch: 1... Training loss: 0.00073... Test loss: 0.00081\n",
      "Epoch: 1... Training loss: 0.00075... Test loss: 0.00074\n",
      "Epoch: 1... Training loss: 0.0007... Test loss: 0.00068\n",
      "Epoch: 1... Training loss: 0.00065... Test loss: 0.00064\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1... Training loss: 0.0007... Test loss: 0.00069\n",
      "Epoch: 1... Training loss: 0.00064... Test loss: 0.00059\n",
      "Epoch: 1... Training loss: 0.00066... Test loss: 0.00062\n",
      "Epoch: 1... Training loss: 0.0006... Test loss: 0.00056\n",
      "Epoch: 1... Training loss: 0.00056... Test loss: 0.00065\n",
      "Epoch: 1... Training loss: 0.00057... Test loss: 0.0006\n",
      "Epoch: 1... Training loss: 0.0006... Test loss: 0.00067\n",
      "Epoch: 1... Training loss: 0.00052... Test loss: 0.00053\n",
      "Epoch: 1... Training loss: 0.00057... Test loss: 0.00053\n",
      "Epoch: 1... Training loss: 0.0005... Test loss: 0.00046\n",
      "Epoch: 1... Training loss: 0.00045... Test loss: 0.0005\n",
      "Epoch: 1... Training loss: 0.00046... Test loss: 0.00042\n",
      "Epoch: 1... Training loss: 0.0004... Test loss: 0.00047\n",
      "Epoch: 1... Training loss: 0.00038... Test loss: 0.00046\n",
      "Epoch: 1... Training loss: 0.00036... Test loss: 0.0004\n",
      "Epoch: 1... Training loss: 0.00034... Test loss: 0.00039\n",
      "Epoch: 1... Training loss: 0.00034... Test loss: 0.00033\n",
      "Epoch: 1... Training loss: 0.00038... Test loss: 0.00035\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00034\n",
      "Epoch: 1... Training loss: 0.00035... Test loss: 0.00037\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.00034\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00031\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.00033\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.00024... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00017\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00021\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00016\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00015\n",
      "Epoch: 1... Training loss: 0.00014... Test loss: 0.00011\n",
      "Epoch: 1... Training loss: 0.00013... Test loss: 0.00016\n",
      "288.2953125364147\n",
      "Epoch: 1... Training loss: 1.01032... Test loss: 0.43086\n",
      "Epoch: 1... Training loss: 0.48863... Test loss: 0.18057\n",
      "Epoch: 1... Training loss: 0.26261... Test loss: 0.10228\n",
      "Epoch: 1... Training loss: 0.20374... Test loss: 0.06526\n",
      "Epoch: 1... Training loss: 0.14189... Test loss: 0.04439\n",
      "Epoch: 1... Training loss: 0.10715... Test loss: 0.03442\n",
      "Epoch: 1... Training loss: 0.09242... Test loss: 0.03018\n",
      "Epoch: 1... Training loss: 0.07204... Test loss: 0.02434\n",
      "Epoch: 1... Training loss: 0.05849... Test loss: 0.0164\n",
      "Epoch: 1... Training loss: 0.05021... Test loss: 0.0179\n",
      "Epoch: 1... Training loss: 0.04279... Test loss: 0.01728\n",
      "Epoch: 1... Training loss: 0.0383... Test loss: 0.01125\n",
      "Epoch: 1... Training loss: 0.0364... Test loss: 0.01149\n",
      "Epoch: 1... Training loss: 0.03311... Test loss: 0.01156\n",
      "Epoch: 1... Training loss: 0.03026... Test loss: 0.01564\n",
      "Epoch: 1... Training loss: 0.02859... Test loss: 0.00749\n",
      "Epoch: 1... Training loss: 0.02712... Test loss: 0.01614\n",
      "Epoch: 1... Training loss: 0.02526... Test loss: 0.00692\n",
      "Epoch: 1... Training loss: 0.02401... Test loss: 0.01873\n",
      "Epoch: 1... Training loss: 0.02206... Test loss: 0.00494\n",
      "Epoch: 1... Training loss: 0.02042... Test loss: 0.01503\n",
      "Epoch: 1... Training loss: 0.0197... Test loss: 0.00722\n",
      "Epoch: 1... Training loss: 0.01923... Test loss: 0.00895\n",
      "Epoch: 1... Training loss: 0.01882... Test loss: 0.00932\n",
      "Epoch: 1... Training loss: 0.01713... Test loss: 0.00648\n",
      "Epoch: 1... Training loss: 0.01619... Test loss: 0.01132\n",
      "Epoch: 1... Training loss: 0.01547... Test loss: 0.00595\n",
      "Epoch: 1... Training loss: 0.01458... Test loss: 0.01119\n",
      "Epoch: 1... Training loss: 0.01408... Test loss: 0.00593\n",
      "Epoch: 1... Training loss: 0.01332... Test loss: 0.00726\n",
      "Epoch: 1... Training loss: 0.01289... Test loss: 0.00717\n",
      "Epoch: 1... Training loss: 0.01246... Test loss: 0.0053\n",
      "Epoch: 1... Training loss: 0.01212... Test loss: 0.01117\n",
      "Epoch: 1... Training loss: 0.01188... Test loss: 0.0045\n",
      "Epoch: 1... Training loss: 0.01143... Test loss: 0.01043\n",
      "Epoch: 1... Training loss: 0.01119... Test loss: 0.00455\n",
      "Epoch: 1... Training loss: 0.01087... Test loss: 0.00921\n",
      "Epoch: 1... Training loss: 0.01044... Test loss: 0.00445\n",
      "Epoch: 1... Training loss: 0.01026... Test loss: 0.00925\n",
      "Epoch: 1... Training loss: 0.00986... Test loss: 0.00388\n",
      "Epoch: 1... Training loss: 0.00942... Test loss: 0.00837\n",
      "Epoch: 1... Training loss: 0.00903... Test loss: 0.00375\n",
      "Epoch: 1... Training loss: 0.00882... Test loss: 0.00845\n",
      "Epoch: 1... Training loss: 0.0085... Test loss: 0.00411\n",
      "Epoch: 1... Training loss: 0.00819... Test loss: 0.00732\n",
      "Epoch: 1... Training loss: 0.00797... Test loss: 0.00458\n",
      "Epoch: 1... Training loss: 0.00781... Test loss: 0.00637\n",
      "Epoch: 1... Training loss: 0.00761... Test loss: 0.0055\n",
      "Epoch: 1... Training loss: 0.00722... Test loss: 0.00589\n",
      "Epoch: 1... Training loss: 0.00703... Test loss: 0.00517\n",
      "Epoch: 1... Training loss: 0.00691... Test loss: 0.00554\n",
      "Epoch: 1... Training loss: 0.00678... Test loss: 0.00531\n",
      "Epoch: 1... Training loss: 0.00664... Test loss: 0.00418\n",
      "Epoch: 1... Training loss: 0.00645... Test loss: 0.00552\n",
      "Epoch: 1... Training loss: 0.00633... Test loss: 0.0046\n",
      "Epoch: 1... Training loss: 0.00604... Test loss: 0.00436\n",
      "Epoch: 1... Training loss: 0.00598... Test loss: 0.00459\n",
      "Epoch: 1... Training loss: 0.00572... Test loss: 0.00448\n",
      "Epoch: 1... Training loss: 0.00569... Test loss: 0.00473\n",
      "Epoch: 1... Training loss: 0.00544... Test loss: 0.00489\n",
      "Epoch: 1... Training loss: 0.00537... Test loss: 0.00441\n",
      "Epoch: 1... Training loss: 0.00513... Test loss: 0.00473\n",
      "Epoch: 1... Training loss: 0.00506... Test loss: 0.00428\n",
      "Epoch: 1... Training loss: 0.00484... Test loss: 0.00434\n",
      "Epoch: 1... Training loss: 0.01078... Test loss: 0.00797\n",
      "Epoch: 1... Training loss: 0.01267... Test loss: 0.00777\n",
      "Epoch: 1... Training loss: 0.00868... Test loss: 0.01044\n",
      "Epoch: 1... Training loss: 0.01161... Test loss: 0.01113\n",
      "Epoch: 1... Training loss: 0.00809... Test loss: 0.00878\n",
      "Epoch: 1... Training loss: 0.00832... Test loss: 0.00691\n",
      "Epoch: 1... Training loss: 0.00814... Test loss: 0.01041\n",
      "Epoch: 1... Training loss: 0.00821... Test loss: 0.00759\n",
      "Epoch: 1... Training loss: 0.00749... Test loss: 0.00775\n",
      "Epoch: 1... Training loss: 0.00754... Test loss: 0.00828\n",
      "Epoch: 1... Training loss: 0.00731... Test loss: 0.00743\n",
      "Epoch: 1... Training loss: 0.00658... Test loss: 0.00606\n",
      "Epoch: 1... Training loss: 0.00699... Test loss: 0.00701\n",
      "Epoch: 1... Training loss: 0.00636... Test loss: 0.00817\n",
      "Epoch: 1... Training loss: 0.00594... Test loss: 0.00677\n",
      "Epoch: 1... Training loss: 0.00587... Test loss: 0.00758\n",
      "Epoch: 1... Training loss: 0.00567... Test loss: 0.00607\n",
      "Epoch: 1... Training loss: 0.00614... Test loss: 0.00673\n",
      "Epoch: 1... Training loss: 0.00577... Test loss: 0.00527\n",
      "Epoch: 1... Training loss: 0.0059... Test loss: 0.00626\n",
      "Epoch: 1... Training loss: 0.00545... Test loss: 0.00637\n",
      "Epoch: 1... Training loss: 0.00519... Test loss: 0.00506\n",
      "Epoch: 1... Training loss: 0.00513... Test loss: 0.00615\n",
      "Epoch: 1... Training loss: 0.00488... Test loss: 0.00504\n",
      "Epoch: 1... Training loss: 0.00467... Test loss: 0.00628\n",
      "Epoch: 1... Training loss: 0.00484... Test loss: 0.0046\n",
      "Epoch: 1... Training loss: 0.00435... Test loss: 0.00518\n",
      "Epoch: 1... Training loss: 0.00428... Test loss: 0.0048\n",
      "Epoch: 1... Training loss: 0.0041... Test loss: 0.00542\n",
      "Epoch: 1... Training loss: 0.00411... Test loss: 0.00458\n",
      "Epoch: 1... Training loss: 0.00382... Test loss: 0.00533\n",
      "Epoch: 1... Training loss: 0.00402... Test loss: 0.00469\n",
      "Epoch: 1... Training loss: 0.00383... Test loss: 0.00415\n",
      "Epoch: 1... Training loss: 0.00371... Test loss: 0.00461\n",
      "Epoch: 1... Training loss: 0.00354... Test loss: 0.00358\n",
      "Epoch: 1... Training loss: 0.00343... Test loss: 0.00424\n",
      "Epoch: 1... Training loss: 0.00332... Test loss: 0.00362\n",
      "Epoch: 1... Training loss: 0.0033... Test loss: 0.00338\n",
      "Epoch: 1... Training loss: 0.00341... Test loss: 0.00344\n",
      "Epoch: 1... Training loss: 0.00316... Test loss: 0.00328\n",
      "Epoch: 1... Training loss: 0.00314... Test loss: 0.00349\n",
      "Epoch: 1... Training loss: 0.00311... Test loss: 0.00336\n",
      "Epoch: 1... Training loss: 0.00304... Test loss: 0.00315\n",
      "Epoch: 1... Training loss: 0.00309... Test loss: 0.00285\n",
      "Epoch: 1... Training loss: 0.0029... Test loss: 0.00293\n",
      "Epoch: 1... Training loss: 0.00282... Test loss: 0.00288\n",
      "Epoch: 1... Training loss: 0.00307... Test loss: 0.00287\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1... Training loss: 0.00284... Test loss: 0.00274\n",
      "Epoch: 1... Training loss: 0.00272... Test loss: 0.00291\n",
      "Epoch: 1... Training loss: 0.00267... Test loss: 0.00302\n",
      "Epoch: 1... Training loss: 0.00269... Test loss: 0.00234\n",
      "Epoch: 1... Training loss: 0.00268... Test loss: 0.00307\n",
      "Epoch: 1... Training loss: 0.0025... Test loss: 0.00258\n",
      "Epoch: 1... Training loss: 0.00255... Test loss: 0.00256\n",
      "Epoch: 1... Training loss: 0.00241... Test loss: 0.00277\n",
      "Epoch: 1... Training loss: 0.00244... Test loss: 0.00243\n",
      "Epoch: 1... Training loss: 0.00237... Test loss: 0.00258\n",
      "Epoch: 1... Training loss: 0.00244... Test loss: 0.00228\n",
      "Epoch: 1... Training loss: 0.00229... Test loss: 0.00254\n",
      "Epoch: 1... Training loss: 0.00219... Test loss: 0.00217\n",
      "Epoch: 1... Training loss: 0.00234... Test loss: 0.00217\n",
      "Epoch: 1... Training loss: 0.00221... Test loss: 0.00206\n",
      "Epoch: 1... Training loss: 0.00215... Test loss: 0.0022\n",
      "Epoch: 1... Training loss: 0.00207... Test loss: 0.00189\n",
      "Epoch: 1... Training loss: 0.002... Test loss: 0.00222\n",
      "Epoch: 1... Training loss: 0.00201... Test loss: 0.00183\n",
      "Epoch: 1... Training loss: 0.00185... Test loss: 0.0021\n",
      "Epoch: 1... Training loss: 0.00183... Test loss: 0.00188\n",
      "Epoch: 1... Training loss: 0.00184... Test loss: 0.00221\n",
      "Epoch: 1... Training loss: 0.0017... Test loss: 0.00188\n",
      "Epoch: 1... Training loss: 0.00182... Test loss: 0.00209\n",
      "Epoch: 1... Training loss: 0.00174... Test loss: 0.00173\n",
      "Epoch: 1... Training loss: 0.00167... Test loss: 0.0019\n",
      "Epoch: 1... Training loss: 0.00157... Test loss: 0.00161\n",
      "Epoch: 1... Training loss: 0.00164... Test loss: 0.00166\n",
      "Epoch: 1... Training loss: 0.00151... Test loss: 0.0016\n",
      "Epoch: 1... Training loss: 0.00157... Test loss: 0.00148\n",
      "Epoch: 1... Training loss: 0.00147... Test loss: 0.00129\n",
      "Epoch: 1... Training loss: 0.00142... Test loss: 0.00153\n",
      "Epoch: 1... Training loss: 0.00145... Test loss: 0.00144\n",
      "Epoch: 1... Training loss: 0.00142... Test loss: 0.00144\n",
      "Epoch: 1... Training loss: 0.00131... Test loss: 0.00118\n",
      "Epoch: 1... Training loss: 0.00131... Test loss: 0.00132\n",
      "Epoch: 1... Training loss: 0.0013... Test loss: 0.00134\n",
      "Epoch: 1... Training loss: 0.00125... Test loss: 0.00131\n",
      "Epoch: 1... Training loss: 0.0012... Test loss: 0.0012\n",
      "Epoch: 1... Training loss: 0.00115... Test loss: 0.00133\n",
      "Epoch: 1... Training loss: 0.0012... Test loss: 0.00115\n",
      "Epoch: 1... Training loss: 0.00106... Test loss: 0.00119\n",
      "Epoch: 1... Training loss: 0.00109... Test loss: 0.00114\n",
      "Epoch: 1... Training loss: 0.00111... Test loss: 0.0011\n",
      "Epoch: 1... Training loss: 0.00101... Test loss: 0.00107\n",
      "Epoch: 1... Training loss: 0.00095... Test loss: 0.00108\n",
      "Epoch: 1... Training loss: 0.00098... Test loss: 0.0011\n",
      "Epoch: 1... Training loss: 0.00091... Test loss: 0.00107\n",
      "Epoch: 1... Training loss: 0.00089... Test loss: 0.00101\n",
      "Epoch: 1... Training loss: 0.00085... Test loss: 0.00103\n",
      "Epoch: 1... Training loss: 0.00085... Test loss: 0.00086\n",
      "Epoch: 1... Training loss: 0.00092... Test loss: 0.00062\n",
      "Epoch: 1... Training loss: 0.0008... Test loss: 0.00078\n",
      "Epoch: 1... Training loss: 0.00082... Test loss: 0.00078\n",
      "Epoch: 1... Training loss: 0.00076... Test loss: 0.00083\n",
      "Epoch: 1... Training loss: 0.00071... Test loss: 0.00077\n",
      "Epoch: 1... Training loss: 0.00075... Test loss: 0.00077\n",
      "Epoch: 1... Training loss: 0.00067... Test loss: 0.00072\n",
      "Epoch: 1... Training loss: 0.00064... Test loss: 0.00071\n",
      "Epoch: 1... Training loss: 0.00062... Test loss: 0.0006\n",
      "Epoch: 1... Training loss: 0.00058... Test loss: 0.00057\n",
      "Epoch: 1... Training loss: 0.00059... Test loss: 0.00055\n",
      "Epoch: 1... Training loss: 0.00056... Test loss: 0.00053\n",
      "Epoch: 1... Training loss: 0.00054... Test loss: 0.00057\n",
      "Epoch: 1... Training loss: 0.00053... Test loss: 0.0006\n",
      "Epoch: 1... Training loss: 0.00053... Test loss: 0.00051\n",
      "Epoch: 1... Training loss: 0.00055... Test loss: 0.00057\n",
      "Epoch: 1... Training loss: 0.00048... Test loss: 0.00044\n",
      "Epoch: 1... Training loss: 0.0005... Test loss: 0.00051\n",
      "Epoch: 1... Training loss: 0.00045... Test loss: 0.0005\n",
      "Epoch: 1... Training loss: 0.00048... Test loss: 0.00044\n",
      "Epoch: 1... Training loss: 0.00041... Test loss: 0.00047\n",
      "Epoch: 1... Training loss: 0.00037... Test loss: 0.00039\n",
      "Epoch: 1... Training loss: 0.00039... Test loss: 0.00043\n",
      "Epoch: 1... Training loss: 0.00038... Test loss: 0.00032\n",
      "Epoch: 1... Training loss: 0.00037... Test loss: 0.00034\n",
      "Epoch: 1... Training loss: 0.0004... Test loss: 0.00033\n",
      "Epoch: 1... Training loss: 0.00033... Test loss: 0.00036\n",
      "Epoch: 1... Training loss: 0.00034... Test loss: 0.00031\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00034\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.0003\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00032... Test loss: 0.0003\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.00021... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00022... Test loss: 0.00019\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00024\n",
      "301.6006810015533\n",
      "Epoch: 1... Training loss: 1.2092... Test loss: 0.53532\n",
      "Epoch: 1... Training loss: 0.59351... Test loss: 0.23606\n",
      "Epoch: 1... Training loss: 0.31959... Test loss: 0.12747\n",
      "Epoch: 1... Training loss: 0.20183... Test loss: 0.09494\n",
      "Epoch: 1... Training loss: 0.15585... Test loss: 0.07177\n",
      "Epoch: 1... Training loss: 0.11856... Test loss: 0.07323\n",
      "Epoch: 1... Training loss: 0.10018... Test loss: 0.02919\n",
      "Epoch: 1... Training loss: 0.08219... Test loss: 0.04603\n",
      "Epoch: 1... Training loss: 0.07164... Test loss: 0.02189\n",
      "Epoch: 1... Training loss: 0.05767... Test loss: 0.03308\n",
      "Epoch: 1... Training loss: 0.05317... Test loss: 0.01448\n",
      "Epoch: 1... Training loss: 0.0475... Test loss: 0.02518\n",
      "Epoch: 1... Training loss: 0.04489... Test loss: 0.01344\n",
      "Epoch: 1... Training loss: 0.0398... Test loss: 0.01668\n",
      "Epoch: 1... Training loss: 0.0359... Test loss: 0.01975\n",
      "Epoch: 1... Training loss: 0.03339... Test loss: 0.01752\n",
      "Epoch: 1... Training loss: 0.03267... Test loss: 0.01029\n",
      "Epoch: 1... Training loss: 0.0308... Test loss: 0.01871\n",
      "Epoch: 1... Training loss: 0.02926... Test loss: 0.00966\n",
      "Epoch: 1... Training loss: 0.02737... Test loss: 0.01852\n",
      "Epoch: 1... Training loss: 0.02557... Test loss: 0.01482\n",
      "Epoch: 1... Training loss: 0.02473... Test loss: 0.01508\n",
      "Epoch: 1... Training loss: 0.02338... Test loss: 0.01903\n",
      "Epoch: 1... Training loss: 0.02232... Test loss: 0.01382\n",
      "Epoch: 1... Training loss: 0.02135... Test loss: 0.0194\n",
      "Epoch: 1... Training loss: 0.02036... Test loss: 0.01455\n",
      "Epoch: 1... Training loss: 0.01933... Test loss: 0.01758\n",
      "Epoch: 1... Training loss: 0.01856... Test loss: 0.01669\n",
      "Epoch: 1... Training loss: 0.01738... Test loss: 0.01301\n",
      "Epoch: 1... Training loss: 0.01682... Test loss: 0.01817\n",
      "Epoch: 1... Training loss: 0.01564... Test loss: 0.01099\n",
      "Epoch: 1... Training loss: 0.01503... Test loss: 0.01905\n",
      "Epoch: 1... Training loss: 0.01439... Test loss: 0.01162\n",
      "Epoch: 1... Training loss: 0.01383... Test loss: 0.01685\n",
      "Epoch: 1... Training loss: 0.01321... Test loss: 0.01162\n",
      "Epoch: 1... Training loss: 0.01281... Test loss: 0.01495\n",
      "Epoch: 1... Training loss: 0.01209... Test loss: 0.01406\n",
      "Epoch: 1... Training loss: 0.01176... Test loss: 0.01212\n",
      "Epoch: 1... Training loss: 0.0114... Test loss: 0.01075\n",
      "Epoch: 1... Training loss: 0.0107... Test loss: 0.01237\n",
      "Epoch: 1... Training loss: 0.01037... Test loss: 0.00955\n",
      "Epoch: 1... Training loss: 0.01008... Test loss: 0.01134\n",
      "Epoch: 1... Training loss: 0.00975... Test loss: 0.00979\n",
      "Epoch: 1... Training loss: 0.00942... Test loss: 0.00922\n",
      "Epoch: 1... Training loss: 0.00924... Test loss: 0.00934\n",
      "Epoch: 1... Training loss: 0.00893... Test loss: 0.00794\n",
      "Epoch: 1... Training loss: 0.00879... Test loss: 0.00777\n",
      "Epoch: 1... Training loss: 0.00851... Test loss: 0.00832\n",
      "Epoch: 1... Training loss: 0.00832... Test loss: 0.00677\n",
      "Epoch: 1... Training loss: 0.00811... Test loss: 0.0074\n",
      "Epoch: 1... Training loss: 0.00796... Test loss: 0.00721\n",
      "Epoch: 1... Training loss: 0.00773... Test loss: 0.00549\n",
      "Epoch: 1... Training loss: 0.00743... Test loss: 0.00856\n",
      "Epoch: 1... Training loss: 0.00715... Test loss: 0.00469\n",
      "Epoch: 1... Training loss: 0.00693... Test loss: 0.00765\n",
      "Epoch: 1... Training loss: 0.00682... Test loss: 0.00545\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1... Training loss: 0.00669... Test loss: 0.00637\n",
      "Epoch: 1... Training loss: 0.00649... Test loss: 0.00657\n",
      "Epoch: 1... Training loss: 0.00632... Test loss: 0.00642\n",
      "Epoch: 1... Training loss: 0.00599... Test loss: 0.00672\n",
      "Epoch: 1... Training loss: 0.00594... Test loss: 0.00536\n",
      "Epoch: 1... Training loss: 0.00578... Test loss: 0.00602\n",
      "Epoch: 1... Training loss: 0.00576... Test loss: 0.00486\n",
      "Epoch: 1... Training loss: 0.00556... Test loss: 0.00631\n",
      "Epoch: 1... Training loss: 0.01328... Test loss: 0.01682\n",
      "Epoch: 1... Training loss: 0.00934... Test loss: 0.01901\n",
      "Epoch: 1... Training loss: 0.01082... Test loss: 0.01312\n",
      "Epoch: 1... Training loss: 0.01162... Test loss: 0.01753\n",
      "Epoch: 1... Training loss: 0.0085... Test loss: 0.0129\n",
      "Epoch: 1... Training loss: 0.00942... Test loss: 0.01677\n",
      "Epoch: 1... Training loss: 0.00835... Test loss: 0.0104\n",
      "Epoch: 1... Training loss: 0.00805... Test loss: 0.01183\n",
      "Epoch: 1... Training loss: 0.00828... Test loss: 0.01005\n",
      "Epoch: 1... Training loss: 0.00834... Test loss: 0.00766\n",
      "Epoch: 1... Training loss: 0.00842... Test loss: 0.00889\n",
      "Epoch: 1... Training loss: 0.00761... Test loss: 0.0107\n",
      "Epoch: 1... Training loss: 0.00767... Test loss: 0.00907\n",
      "Epoch: 1... Training loss: 0.00705... Test loss: 0.00846\n",
      "Epoch: 1... Training loss: 0.00664... Test loss: 0.00791\n",
      "Epoch: 1... Training loss: 0.00627... Test loss: 0.00781\n",
      "Epoch: 1... Training loss: 0.00656... Test loss: 0.00648\n",
      "Epoch: 1... Training loss: 0.00641... Test loss: 0.00861\n",
      "Epoch: 1... Training loss: 0.00611... Test loss: 0.00695\n",
      "Epoch: 1... Training loss: 0.00575... Test loss: 0.00642\n",
      "Epoch: 1... Training loss: 0.00593... Test loss: 0.00543\n",
      "Epoch: 1... Training loss: 0.00523... Test loss: 0.00668\n",
      "Epoch: 1... Training loss: 0.00531... Test loss: 0.00547\n",
      "Epoch: 1... Training loss: 0.00492... Test loss: 0.00677\n",
      "Epoch: 1... Training loss: 0.00489... Test loss: 0.00554\n",
      "Epoch: 1... Training loss: 0.00476... Test loss: 0.00749\n",
      "Epoch: 1... Training loss: 0.00478... Test loss: 0.00534\n",
      "Epoch: 1... Training loss: 0.00439... Test loss: 0.00571\n",
      "Epoch: 1... Training loss: 0.00437... Test loss: 0.0055\n",
      "Epoch: 1... Training loss: 0.0042... Test loss: 0.00554\n",
      "Epoch: 1... Training loss: 0.00402... Test loss: 0.00573\n",
      "Epoch: 1... Training loss: 0.00394... Test loss: 0.0047\n",
      "Epoch: 1... Training loss: 0.00396... Test loss: 0.00447\n",
      "Epoch: 1... Training loss: 0.00379... Test loss: 0.00443\n",
      "Epoch: 1... Training loss: 0.00367... Test loss: 0.00364\n",
      "Epoch: 1... Training loss: 0.00356... Test loss: 0.00397\n",
      "Epoch: 1... Training loss: 0.00352... Test loss: 0.00338\n",
      "Epoch: 1... Training loss: 0.00348... Test loss: 0.00384\n",
      "Epoch: 1... Training loss: 0.00336... Test loss: 0.0034\n",
      "Epoch: 1... Training loss: 0.00324... Test loss: 0.0038\n",
      "Epoch: 1... Training loss: 0.0032... Test loss: 0.00277\n",
      "Epoch: 1... Training loss: 0.00324... Test loss: 0.00401\n",
      "Epoch: 1... Training loss: 0.00308... Test loss: 0.00324\n",
      "Epoch: 1... Training loss: 0.0031... Test loss: 0.00342\n",
      "Epoch: 1... Training loss: 0.00294... Test loss: 0.00354\n",
      "Epoch: 1... Training loss: 0.00299... Test loss: 0.00322\n",
      "Epoch: 1... Training loss: 0.00295... Test loss: 0.00309\n",
      "Epoch: 1... Training loss: 0.00276... Test loss: 0.00319\n",
      "Epoch: 1... Training loss: 0.00272... Test loss: 0.00325\n",
      "Epoch: 1... Training loss: 0.00269... Test loss: 0.0027\n",
      "Epoch: 1... Training loss: 0.00265... Test loss: 0.00293\n",
      "Epoch: 1... Training loss: 0.00261... Test loss: 0.00254\n",
      "Epoch: 1... Training loss: 0.00249... Test loss: 0.00293\n",
      "Epoch: 1... Training loss: 0.00248... Test loss: 0.00248\n",
      "Epoch: 1... Training loss: 0.00237... Test loss: 0.00271\n",
      "Epoch: 1... Training loss: 0.00225... Test loss: 0.00238\n",
      "Epoch: 1... Training loss: 0.0022... Test loss: 0.00282\n",
      "Epoch: 1... Training loss: 0.00233... Test loss: 0.00205\n",
      "Epoch: 1... Training loss: 0.00205... Test loss: 0.00268\n",
      "Epoch: 1... Training loss: 0.00207... Test loss: 0.00194\n",
      "Epoch: 1... Training loss: 0.002... Test loss: 0.00236\n",
      "Epoch: 1... Training loss: 0.00201... Test loss: 0.00191\n",
      "Epoch: 1... Training loss: 0.00193... Test loss: 0.0023\n",
      "Epoch: 1... Training loss: 0.00182... Test loss: 0.00157\n",
      "Epoch: 1... Training loss: 0.00182... Test loss: 0.00192\n",
      "Epoch: 1... Training loss: 0.00188... Test loss: 0.00173\n",
      "Epoch: 1... Training loss: 0.00173... Test loss: 0.00207\n",
      "Epoch: 1... Training loss: 0.00171... Test loss: 0.00173\n",
      "Epoch: 1... Training loss: 0.00166... Test loss: 0.00191\n",
      "Epoch: 1... Training loss: 0.00158... Test loss: 0.00156\n",
      "Epoch: 1... Training loss: 0.00163... Test loss: 0.0017\n",
      "Epoch: 1... Training loss: 0.00155... Test loss: 0.00149\n",
      "Epoch: 1... Training loss: 0.00152... Test loss: 0.0013\n",
      "Epoch: 1... Training loss: 0.00147... Test loss: 0.0015\n",
      "Epoch: 1... Training loss: 0.00147... Test loss: 0.00144\n",
      "Epoch: 1... Training loss: 0.00152... Test loss: 0.00151\n",
      "Epoch: 1... Training loss: 0.00146... Test loss: 0.00124\n",
      "Epoch: 1... Training loss: 0.00134... Test loss: 0.00135\n",
      "Epoch: 1... Training loss: 0.00139... Test loss: 0.00109\n",
      "Epoch: 1... Training loss: 0.00134... Test loss: 0.00143\n",
      "Epoch: 1... Training loss: 0.00128... Test loss: 0.00126\n",
      "Epoch: 1... Training loss: 0.00128... Test loss: 0.00153\n",
      "Epoch: 1... Training loss: 0.0012... Test loss: 0.00123\n",
      "Epoch: 1... Training loss: 0.00124... Test loss: 0.00115\n",
      "Epoch: 1... Training loss: 0.00114... Test loss: 0.00114\n",
      "Epoch: 1... Training loss: 0.00109... Test loss: 0.0012\n",
      "Epoch: 1... Training loss: 0.00108... Test loss: 0.00116\n",
      "Epoch: 1... Training loss: 0.00107... Test loss: 0.00104\n",
      "Epoch: 1... Training loss: 0.00098... Test loss: 0.00121\n",
      "Epoch: 1... Training loss: 0.00099... Test loss: 0.00097\n",
      "Epoch: 1... Training loss: 0.00098... Test loss: 0.00109\n",
      "Epoch: 1... Training loss: 0.00093... Test loss: 0.00096\n",
      "Epoch: 1... Training loss: 0.0009... Test loss: 0.00096\n",
      "Epoch: 1... Training loss: 0.0009... Test loss: 0.00098\n",
      "Epoch: 1... Training loss: 0.00088... Test loss: 0.00094\n",
      "Epoch: 1... Training loss: 0.00092... Test loss: 0.00093\n",
      "Epoch: 1... Training loss: 0.00081... Test loss: 0.00087\n",
      "Epoch: 1... Training loss: 0.00088... Test loss: 0.00089\n",
      "Epoch: 1... Training loss: 0.00092... Test loss: 0.00077\n",
      "Epoch: 1... Training loss: 0.00081... Test loss: 0.00072\n",
      "Epoch: 1... Training loss: 0.00083... Test loss: 0.00065\n",
      "Epoch: 1... Training loss: 0.00077... Test loss: 0.00078\n",
      "Epoch: 1... Training loss: 0.00076... Test loss: 0.00074\n",
      "Epoch: 1... Training loss: 0.00073... Test loss: 0.00078\n",
      "Epoch: 1... Training loss: 0.00069... Test loss: 0.00071\n",
      "Epoch: 1... Training loss: 0.00072... Test loss: 0.00069\n",
      "Epoch: 1... Training loss: 0.0007... Test loss: 0.00073\n",
      "Epoch: 1... Training loss: 0.00072... Test loss: 0.00065\n",
      "Epoch: 1... Training loss: 0.00067... Test loss: 0.00061\n",
      "Epoch: 1... Training loss: 0.00071... Test loss: 0.00071\n",
      "Epoch: 1... Training loss: 0.00059... Test loss: 0.00065\n",
      "Epoch: 1... Training loss: 0.00058... Test loss: 0.00064\n",
      "Epoch: 1... Training loss: 0.00063... Test loss: 0.0006\n",
      "Epoch: 1... Training loss: 0.00055... Test loss: 0.00058\n",
      "Epoch: 1... Training loss: 0.00053... Test loss: 0.00052\n",
      "Epoch: 1... Training loss: 0.00049... Test loss: 0.00056\n",
      "Epoch: 1... Training loss: 0.00049... Test loss: 0.00059\n",
      "Epoch: 1... Training loss: 0.00058... Test loss: 0.00046\n",
      "Epoch: 1... Training loss: 0.00046... Test loss: 0.00044\n",
      "Epoch: 1... Training loss: 0.00046... Test loss: 0.00039\n",
      "Epoch: 1... Training loss: 0.00045... Test loss: 0.00045\n",
      "Epoch: 1... Training loss: 0.00045... Test loss: 0.00042\n",
      "Epoch: 1... Training loss: 0.0004... Test loss: 0.00043\n",
      "Epoch: 1... Training loss: 0.0004... Test loss: 0.00044\n",
      "Epoch: 1... Training loss: 0.00039... Test loss: 0.00037\n",
      "Epoch: 1... Training loss: 0.00037... Test loss: 0.00039\n",
      "Epoch: 1... Training loss: 0.00036... Test loss: 0.00034\n",
      "Epoch: 1... Training loss: 0.00033... Test loss: 0.00042\n",
      "Epoch: 1... Training loss: 0.00034... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.00032... Test loss: 0.00037\n",
      "Epoch: 1... Training loss: 0.00032... Test loss: 0.00029\n",
      "Epoch: 1... Training loss: 0.00034... Test loss: 0.00035\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00031\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00031\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00023\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "264.17167634447105\n",
      "Epoch: 1... Training loss: 1.36245... Test loss: 0.64593\n",
      "Epoch: 1... Training loss: 0.58113... Test loss: 0.24045\n",
      "Epoch: 1... Training loss: 0.3165... Test loss: 0.12825\n",
      "Epoch: 1... Training loss: 0.21595... Test loss: 0.07136\n",
      "Epoch: 1... Training loss: 0.14957... Test loss: 0.07627\n",
      "Epoch: 1... Training loss: 0.10365... Test loss: 0.04998\n",
      "Epoch: 1... Training loss: 0.08484... Test loss: 0.07333\n",
      "Epoch: 1... Training loss: 0.06138... Test loss: 0.05803\n",
      "Epoch: 1... Training loss: 0.0566... Test loss: 0.04891\n",
      "Epoch: 1... Training loss: 0.04775... Test loss: 0.04537\n",
      "Epoch: 1... Training loss: 0.04716... Test loss: 0.02658\n",
      "Epoch: 1... Training loss: 0.04201... Test loss: 0.05696\n",
      "Epoch: 1... Training loss: 0.03927... Test loss: 0.02163\n",
      "Epoch: 1... Training loss: 0.03626... Test loss: 0.04026\n",
      "Epoch: 1... Training loss: 0.03313... Test loss: 0.01752\n",
      "Epoch: 1... Training loss: 0.03078... Test loss: 0.04921\n",
      "Epoch: 1... Training loss: 0.02885... Test loss: 0.01395\n",
      "Epoch: 1... Training loss: 0.02793... Test loss: 0.03665\n",
      "Epoch: 1... Training loss: 0.02616... Test loss: 0.0191\n",
      "Epoch: 1... Training loss: 0.02493... Test loss: 0.03209\n",
      "Epoch: 1... Training loss: 0.02431... Test loss: 0.01146\n",
      "Epoch: 1... Training loss: 0.02257... Test loss: 0.0359\n",
      "Epoch: 1... Training loss: 0.02223... Test loss: 0.00755\n",
      "Epoch: 1... Training loss: 0.02097... Test loss: 0.02537\n",
      "Epoch: 1... Training loss: 0.02031... Test loss: 0.0076\n",
      "Epoch: 1... Training loss: 0.01832... Test loss: 0.02169\n",
      "Epoch: 1... Training loss: 0.0181... Test loss: 0.01169\n",
      "Epoch: 1... Training loss: 0.01716... Test loss: 0.01849\n",
      "Epoch: 1... Training loss: 0.01668... Test loss: 0.01023\n",
      "Epoch: 1... Training loss: 0.01599... Test loss: 0.01545\n",
      "Epoch: 1... Training loss: 0.01557... Test loss: 0.00913\n",
      "Epoch: 1... Training loss: 0.01463... Test loss: 0.01983\n",
      "Epoch: 1... Training loss: 0.01417... Test loss: 0.0102\n",
      "Epoch: 1... Training loss: 0.01376... Test loss: 0.01825\n",
      "Epoch: 1... Training loss: 0.01301... Test loss: 0.01501\n",
      "Epoch: 1... Training loss: 0.01245... Test loss: 0.00745\n",
      "Epoch: 1... Training loss: 0.01206... Test loss: 0.01873\n",
      "Epoch: 1... Training loss: 0.01168... Test loss: 0.00801\n",
      "Epoch: 1... Training loss: 0.01142... Test loss: 0.01688\n",
      "Epoch: 1... Training loss: 0.01103... Test loss: 0.00623\n",
      "Epoch: 1... Training loss: 0.01077... Test loss: 0.01582\n",
      "Epoch: 1... Training loss: 0.01052... Test loss: 0.00646\n",
      "Epoch: 1... Training loss: 0.0103... Test loss: 0.01383\n",
      "Epoch: 1... Training loss: 0.00994... Test loss: 0.00613\n",
      "Epoch: 1... Training loss: 0.00981... Test loss: 0.01102\n",
      "Epoch: 1... Training loss: 0.00934... Test loss: 0.00812\n",
      "Epoch: 1... Training loss: 0.00921... Test loss: 0.01066\n",
      "Epoch: 1... Training loss: 0.00889... Test loss: 0.00756\n",
      "Epoch: 1... Training loss: 0.00873... Test loss: 0.0107\n",
      "Epoch: 1... Training loss: 0.00835... Test loss: 0.00715\n",
      "Epoch: 1... Training loss: 0.00826... Test loss: 0.00918\n",
      "Epoch: 1... Training loss: 0.00807... Test loss: 0.00628\n",
      "Epoch: 1... Training loss: 0.00774... Test loss: 0.00838\n",
      "Epoch: 1... Training loss: 0.00754... Test loss: 0.00511\n",
      "Epoch: 1... Training loss: 0.00729... Test loss: 0.00789\n",
      "Epoch: 1... Training loss: 0.0072... Test loss: 0.00616\n",
      "Epoch: 1... Training loss: 0.00702... Test loss: 0.00693\n",
      "Epoch: 1... Training loss: 0.0068... Test loss: 0.00734\n",
      "Epoch: 1... Training loss: 0.0066... Test loss: 0.00709\n",
      "Epoch: 1... Training loss: 0.00648... Test loss: 0.00816\n",
      "Epoch: 1... Training loss: 0.00625... Test loss: 0.00549\n",
      "Epoch: 1... Training loss: 0.0061... Test loss: 0.00704\n",
      "Epoch: 1... Training loss: 0.00598... Test loss: 0.0058\n",
      "Epoch: 1... Training loss: 0.00593... Test loss: 0.00664\n",
      "Epoch: 1... Training loss: 0.00934... Test loss: 0.0081\n",
      "Epoch: 1... Training loss: 0.01534... Test loss: 0.01217\n",
      "Epoch: 1... Training loss: 0.01049... Test loss: 0.01248\n",
      "Epoch: 1... Training loss: 0.0107... Test loss: 0.01363\n",
      "Epoch: 1... Training loss: 0.01139... Test loss: 0.00728\n",
      "Epoch: 1... Training loss: 0.00956... Test loss: 0.01393\n",
      "Epoch: 1... Training loss: 0.01104... Test loss: 0.00927\n",
      "Epoch: 1... Training loss: 0.00987... Test loss: 0.0145\n",
      "Epoch: 1... Training loss: 0.00943... Test loss: 0.01075\n",
      "Epoch: 1... Training loss: 0.0084... Test loss: 0.0111\n",
      "Epoch: 1... Training loss: 0.00861... Test loss: 0.00972\n",
      "Epoch: 1... Training loss: 0.00757... Test loss: 0.01023\n",
      "Epoch: 1... Training loss: 0.0086... Test loss: 0.0081\n",
      "Epoch: 1... Training loss: 0.00718... Test loss: 0.01305\n",
      "Epoch: 1... Training loss: 0.00743... Test loss: 0.00745\n",
      "Epoch: 1... Training loss: 0.00669... Test loss: 0.01231\n",
      "Epoch: 1... Training loss: 0.00699... Test loss: 0.00792\n",
      "Epoch: 1... Training loss: 0.00654... Test loss: 0.00935\n",
      "Epoch: 1... Training loss: 0.00672... Test loss: 0.00639\n",
      "Epoch: 1... Training loss: 0.00632... Test loss: 0.00887\n",
      "Epoch: 1... Training loss: 0.00638... Test loss: 0.00698\n",
      "Epoch: 1... Training loss: 0.00607... Test loss: 0.00647\n",
      "Epoch: 1... Training loss: 0.00557... Test loss: 0.00627\n",
      "Epoch: 1... Training loss: 0.00541... Test loss: 0.00651\n",
      "Epoch: 1... Training loss: 0.0056... Test loss: 0.00667\n",
      "Epoch: 1... Training loss: 0.00508... Test loss: 0.00667\n",
      "Epoch: 1... Training loss: 0.00486... Test loss: 0.00593\n",
      "Epoch: 1... Training loss: 0.00489... Test loss: 0.00567\n",
      "Epoch: 1... Training loss: 0.0049... Test loss: 0.00534\n",
      "Epoch: 1... Training loss: 0.00454... Test loss: 0.00624\n",
      "Epoch: 1... Training loss: 0.0046... Test loss: 0.00466\n",
      "Epoch: 1... Training loss: 0.00437... Test loss: 0.00592\n",
      "Epoch: 1... Training loss: 0.0044... Test loss: 0.0043\n",
      "Epoch: 1... Training loss: 0.00419... Test loss: 0.00589\n",
      "Epoch: 1... Training loss: 0.00406... Test loss: 0.00367\n",
      "Epoch: 1... Training loss: 0.00387... Test loss: 0.00524\n",
      "Epoch: 1... Training loss: 0.00388... Test loss: 0.00382\n",
      "Epoch: 1... Training loss: 0.00368... Test loss: 0.00486\n",
      "Epoch: 1... Training loss: 0.00367... Test loss: 0.00395\n",
      "Epoch: 1... Training loss: 0.00366... Test loss: 0.00374\n",
      "Epoch: 1... Training loss: 0.00352... Test loss: 0.00331\n",
      "Epoch: 1... Training loss: 0.00354... Test loss: 0.00382\n",
      "Epoch: 1... Training loss: 0.00348... Test loss: 0.00352\n",
      "Epoch: 1... Training loss: 0.00335... Test loss: 0.00384\n",
      "Epoch: 1... Training loss: 0.00336... Test loss: 0.00345\n",
      "Epoch: 1... Training loss: 0.00323... Test loss: 0.00392\n",
      "Epoch: 1... Training loss: 0.00322... Test loss: 0.00342\n",
      "Epoch: 1... Training loss: 0.00324... Test loss: 0.00364\n",
      "Epoch: 1... Training loss: 0.00301... Test loss: 0.00339\n",
      "Epoch: 1... Training loss: 0.00291... Test loss: 0.00316\n",
      "Epoch: 1... Training loss: 0.00283... Test loss: 0.00288\n",
      "Epoch: 1... Training loss: 0.00288... Test loss: 0.00366\n",
      "Epoch: 1... Training loss: 0.00273... Test loss: 0.00283\n",
      "Epoch: 1... Training loss: 0.00267... Test loss: 0.00298\n",
      "Epoch: 1... Training loss: 0.00266... Test loss: 0.00288\n",
      "Epoch: 1... Training loss: 0.0027... Test loss: 0.0025\n",
      "Epoch: 1... Training loss: 0.0025... Test loss: 0.00311\n",
      "Epoch: 1... Training loss: 0.00249... Test loss: 0.00267\n",
      "Epoch: 1... Training loss: 0.00235... Test loss: 0.00242\n",
      "Epoch: 1... Training loss: 0.0023... Test loss: 0.00265\n",
      "Epoch: 1... Training loss: 0.00222... Test loss: 0.00251\n",
      "Epoch: 1... Training loss: 0.0023... Test loss: 0.00254\n",
      "Epoch: 1... Training loss: 0.00219... Test loss: 0.00213\n",
      "Epoch: 1... Training loss: 0.00213... Test loss: 0.00238\n",
      "Epoch: 1... Training loss: 0.00212... Test loss: 0.00222\n",
      "Epoch: 1... Training loss: 0.00206... Test loss: 0.0024\n",
      "Epoch: 1... Training loss: 0.00201... Test loss: 0.00232\n",
      "Epoch: 1... Training loss: 0.00196... Test loss: 0.00216\n",
      "Epoch: 1... Training loss: 0.00194... Test loss: 0.00204\n",
      "Epoch: 1... Training loss: 0.00188... Test loss: 0.00232\n",
      "Epoch: 1... Training loss: 0.00186... Test loss: 0.00203\n",
      "Epoch: 1... Training loss: 0.00184... Test loss: 0.00214\n",
      "Epoch: 1... Training loss: 0.00185... Test loss: 0.00164\n",
      "Epoch: 1... Training loss: 0.00178... Test loss: 0.00217\n",
      "Epoch: 1... Training loss: 0.00175... Test loss: 0.0017\n",
      "Epoch: 1... Training loss: 0.00163... Test loss: 0.00181\n",
      "Epoch: 1... Training loss: 0.00163... Test loss: 0.00154\n",
      "Epoch: 1... Training loss: 0.00158... Test loss: 0.00172\n",
      "Epoch: 1... Training loss: 0.00152... Test loss: 0.00158\n",
      "Epoch: 1... Training loss: 0.00147... Test loss: 0.00166\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1... Training loss: 0.00143... Test loss: 0.00146\n",
      "Epoch: 1... Training loss: 0.00143... Test loss: 0.0016\n",
      "Epoch: 1... Training loss: 0.00133... Test loss: 0.00125\n",
      "Epoch: 1... Training loss: 0.00129... Test loss: 0.00146\n",
      "Epoch: 1... Training loss: 0.00122... Test loss: 0.00129\n",
      "Epoch: 1... Training loss: 0.00121... Test loss: 0.00151\n",
      "Epoch: 1... Training loss: 0.00126... Test loss: 0.00099\n",
      "Epoch: 1... Training loss: 0.00119... Test loss: 0.00133\n",
      "Epoch: 1... Training loss: 0.0011... Test loss: 0.00116\n",
      "Epoch: 1... Training loss: 0.00107... Test loss: 0.00133\n",
      "Epoch: 1... Training loss: 0.00101... Test loss: 0.00098\n",
      "Epoch: 1... Training loss: 0.00104... Test loss: 0.00119\n",
      "Epoch: 1... Training loss: 0.0009... Test loss: 0.00109\n",
      "Epoch: 1... Training loss: 0.00093... Test loss: 0.00104\n",
      "Epoch: 1... Training loss: 0.00088... Test loss: 0.00103\n",
      "Epoch: 1... Training loss: 0.0009... Test loss: 0.00084\n",
      "Epoch: 1... Training loss: 0.00085... Test loss: 0.00084\n",
      "Epoch: 1... Training loss: 0.00085... Test loss: 0.00081\n",
      "Epoch: 1... Training loss: 0.00077... Test loss: 0.00105\n",
      "Epoch: 1... Training loss: 0.00077... Test loss: 0.00076\n",
      "Epoch: 1... Training loss: 0.00072... Test loss: 0.00086\n",
      "Epoch: 1... Training loss: 0.00073... Test loss: 0.0007\n",
      "Epoch: 1... Training loss: 0.00067... Test loss: 0.00076\n",
      "Epoch: 1... Training loss: 0.0007... Test loss: 0.00073\n",
      "Epoch: 1... Training loss: 0.00061... Test loss: 0.00066\n",
      "Epoch: 1... Training loss: 0.0006... Test loss: 0.00069\n",
      "Epoch: 1... Training loss: 0.00063... Test loss: 0.00065\n",
      "Epoch: 1... Training loss: 0.00057... Test loss: 0.00055\n",
      "Epoch: 1... Training loss: 0.00057... Test loss: 0.00061\n",
      "Epoch: 1... Training loss: 0.0005... Test loss: 0.00054\n",
      "Epoch: 1... Training loss: 0.0006... Test loss: 0.00052\n",
      "Epoch: 1... Training loss: 0.00051... Test loss: 0.00053\n",
      "Epoch: 1... Training loss: 0.00048... Test loss: 0.00045\n",
      "Epoch: 1... Training loss: 0.00045... Test loss: 0.00057\n",
      "Epoch: 1... Training loss: 0.00048... Test loss: 0.00038\n",
      "Epoch: 1... Training loss: 0.00046... Test loss: 0.00057\n",
      "Epoch: 1... Training loss: 0.00055... Test loss: 0.00045\n",
      "Epoch: 1... Training loss: 0.00042... Test loss: 0.00057\n",
      "Epoch: 1... Training loss: 0.00045... Test loss: 0.00045\n",
      "Epoch: 1... Training loss: 0.00041... Test loss: 0.00046\n",
      "Epoch: 1... Training loss: 0.00042... Test loss: 0.00038\n",
      "Epoch: 1... Training loss: 0.00036... Test loss: 0.00043\n",
      "Epoch: 1... Training loss: 0.00037... Test loss: 0.00034\n",
      "Epoch: 1... Training loss: 0.00035... Test loss: 0.00045\n",
      "Epoch: 1... Training loss: 0.00037... Test loss: 0.00034\n",
      "Epoch: 1... Training loss: 0.00034... Test loss: 0.00038\n",
      "Epoch: 1... Training loss: 0.00034... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00036... Test loss: 0.00031\n",
      "Epoch: 1... Training loss: 0.00029... Test loss: 0.0003\n",
      "Epoch: 1... Training loss: 0.00033... Test loss: 0.0003\n",
      "Epoch: 1... Training loss: 0.00029... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.0003... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00033... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.00023... Test loss: 0.00023\n",
      "296.18397455022205\n",
      "Epoch: 1... Training loss: 0.87713... Test loss: 0.16582\n",
      "Epoch: 1... Training loss: 0.39346... Test loss: 0.10822\n",
      "Epoch: 1... Training loss: 0.25745... Test loss: 0.0938\n",
      "Epoch: 1... Training loss: 0.17487... Test loss: 0.05958\n",
      "Epoch: 1... Training loss: 0.12997... Test loss: 0.04131\n",
      "Epoch: 1... Training loss: 0.11463... Test loss: 0.03504\n",
      "Epoch: 1... Training loss: 0.08658... Test loss: 0.02638\n",
      "Epoch: 1... Training loss: 0.07889... Test loss: 0.02278\n",
      "Epoch: 1... Training loss: 0.06942... Test loss: 0.01822\n",
      "Epoch: 1... Training loss: 0.06244... Test loss: 0.0153\n",
      "Epoch: 1... Training loss: 0.05443... Test loss: 0.01463\n",
      "Epoch: 1... Training loss: 0.0485... Test loss: 0.00986\n",
      "Epoch: 1... Training loss: 0.04424... Test loss: 0.01333\n",
      "Epoch: 1... Training loss: 0.0406... Test loss: 0.00843\n",
      "Epoch: 1... Training loss: 0.03898... Test loss: 0.01236\n",
      "Epoch: 1... Training loss: 0.03547... Test loss: 0.00688\n",
      "Epoch: 1... Training loss: 0.03351... Test loss: 0.01166\n",
      "Epoch: 1... Training loss: 0.03063... Test loss: 0.00601\n",
      "Epoch: 1... Training loss: 0.02934... Test loss: 0.00985\n",
      "Epoch: 1... Training loss: 0.02669... Test loss: 0.01143\n",
      "Epoch: 1... Training loss: 0.02586... Test loss: 0.0065\n",
      "Epoch: 1... Training loss: 0.02432... Test loss: 0.01217\n",
      "Epoch: 1... Training loss: 0.02308... Test loss: 0.00772\n",
      "Epoch: 1... Training loss: 0.02203... Test loss: 0.01087\n",
      "Epoch: 1... Training loss: 0.02068... Test loss: 0.01101\n",
      "Epoch: 1... Training loss: 0.02001... Test loss: 0.0064\n",
      "Epoch: 1... Training loss: 0.01967... Test loss: 0.01316\n",
      "Epoch: 1... Training loss: 0.018... Test loss: 0.00597\n",
      "Epoch: 1... Training loss: 0.01728... Test loss: 0.01709\n",
      "Epoch: 1... Training loss: 0.01658... Test loss: 0.00757\n",
      "Epoch: 1... Training loss: 0.01594... Test loss: 0.01163\n",
      "Epoch: 1... Training loss: 0.01481... Test loss: 0.01103\n",
      "Epoch: 1... Training loss: 0.01411... Test loss: 0.02004\n",
      "Epoch: 1... Training loss: 0.01351... Test loss: 0.00881\n",
      "Epoch: 1... Training loss: 0.0133... Test loss: 0.01385\n",
      "Epoch: 1... Training loss: 0.01256... Test loss: 0.00751\n",
      "Epoch: 1... Training loss: 0.01231... Test loss: 0.01573\n",
      "Epoch: 1... Training loss: 0.01177... Test loss: 0.00762\n",
      "Epoch: 1... Training loss: 0.01159... Test loss: 0.01213\n",
      "Epoch: 1... Training loss: 0.01089... Test loss: 0.01014\n",
      "Epoch: 1... Training loss: 0.01082... Test loss: 0.00974\n",
      "Epoch: 1... Training loss: 0.0102... Test loss: 0.00845\n",
      "Epoch: 1... Training loss: 0.01001... Test loss: 0.01062\n",
      "Epoch: 1... Training loss: 0.00972... Test loss: 0.0068\n",
      "Epoch: 1... Training loss: 0.00938... Test loss: 0.01033\n",
      "Epoch: 1... Training loss: 0.00896... Test loss: 0.00766\n",
      "Epoch: 1... Training loss: 0.0089... Test loss: 0.0085\n",
      "Epoch: 1... Training loss: 0.00859... Test loss: 0.00648\n",
      "Epoch: 1... Training loss: 0.00828... Test loss: 0.00783\n",
      "Epoch: 1... Training loss: 0.00815... Test loss: 0.00692\n",
      "Epoch: 1... Training loss: 0.00814... Test loss: 0.00837\n",
      "Epoch: 1... Training loss: 0.00774... Test loss: 0.00562\n",
      "Epoch: 1... Training loss: 0.00755... Test loss: 0.00797\n",
      "Epoch: 1... Training loss: 0.00733... Test loss: 0.00562\n",
      "Epoch: 1... Training loss: 0.00721... Test loss: 0.00673\n",
      "Epoch: 1... Training loss: 0.00703... Test loss: 0.00679\n",
      "Epoch: 1... Training loss: 0.00677... Test loss: 0.00636\n",
      "Epoch: 1... Training loss: 0.00659... Test loss: 0.00673\n",
      "Epoch: 1... Training loss: 0.00641... Test loss: 0.00681\n",
      "Epoch: 1... Training loss: 0.00622... Test loss: 0.00555\n",
      "Epoch: 1... Training loss: 0.00609... Test loss: 0.0067\n",
      "Epoch: 1... Training loss: 0.00594... Test loss: 0.00483\n",
      "Epoch: 1... Training loss: 0.00577... Test loss: 0.00612\n",
      "Epoch: 1... Training loss: 0.00559... Test loss: 0.00521\n",
      "Epoch: 1... Training loss: 0.0098... Test loss: 0.01468\n",
      "Epoch: 1... Training loss: 0.01132... Test loss: 0.00736\n",
      "Epoch: 1... Training loss: 0.00961... Test loss: 0.01059\n",
      "Epoch: 1... Training loss: 0.00964... Test loss: 0.0081\n",
      "Epoch: 1... Training loss: 0.00991... Test loss: 0.00917\n",
      "Epoch: 1... Training loss: 0.00958... Test loss: 0.00727\n",
      "Epoch: 1... Training loss: 0.01046... Test loss: 0.00936\n",
      "Epoch: 1... Training loss: 0.00862... Test loss: 0.00865\n",
      "Epoch: 1... Training loss: 0.00908... Test loss: 0.00993\n",
      "Epoch: 1... Training loss: 0.00878... Test loss: 0.00923\n",
      "Epoch: 1... Training loss: 0.00764... Test loss: 0.00916\n",
      "Epoch: 1... Training loss: 0.00796... Test loss: 0.01008\n",
      "Epoch: 1... Training loss: 0.00803... Test loss: 0.00743\n",
      "Epoch: 1... Training loss: 0.00769... Test loss: 0.00765\n",
      "Epoch: 1... Training loss: 0.00757... Test loss: 0.00785\n",
      "Epoch: 1... Training loss: 0.00714... Test loss: 0.00824\n",
      "Epoch: 1... Training loss: 0.00715... Test loss: 0.00729\n",
      "Epoch: 1... Training loss: 0.00669... Test loss: 0.0087\n",
      "Epoch: 1... Training loss: 0.00658... Test loss: 0.00738\n",
      "Epoch: 1... Training loss: 0.00617... Test loss: 0.00752\n",
      "Epoch: 1... Training loss: 0.00634... Test loss: 0.00675\n",
      "Epoch: 1... Training loss: 0.00598... Test loss: 0.00761\n",
      "Epoch: 1... Training loss: 0.00607... Test loss: 0.00593\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1... Training loss: 0.00582... Test loss: 0.00706\n",
      "Epoch: 1... Training loss: 0.00558... Test loss: 0.00635\n",
      "Epoch: 1... Training loss: 0.00526... Test loss: 0.00673\n",
      "Epoch: 1... Training loss: 0.00511... Test loss: 0.00587\n",
      "Epoch: 1... Training loss: 0.00496... Test loss: 0.00575\n",
      "Epoch: 1... Training loss: 0.00474... Test loss: 0.00564\n",
      "Epoch: 1... Training loss: 0.0047... Test loss: 0.00527\n",
      "Epoch: 1... Training loss: 0.00467... Test loss: 0.00506\n",
      "Epoch: 1... Training loss: 0.00439... Test loss: 0.00568\n",
      "Epoch: 1... Training loss: 0.00417... Test loss: 0.00437\n",
      "Epoch: 1... Training loss: 0.0041... Test loss: 0.00476\n",
      "Epoch: 1... Training loss: 0.00401... Test loss: 0.00392\n",
      "Epoch: 1... Training loss: 0.00392... Test loss: 0.00416\n",
      "Epoch: 1... Training loss: 0.00375... Test loss: 0.00404\n",
      "Epoch: 1... Training loss: 0.00371... Test loss: 0.00419\n",
      "Epoch: 1... Training loss: 0.00372... Test loss: 0.00402\n",
      "Epoch: 1... Training loss: 0.00355... Test loss: 0.00411\n",
      "Epoch: 1... Training loss: 0.0034... Test loss: 0.00365\n",
      "Epoch: 1... Training loss: 0.00334... Test loss: 0.00375\n",
      "Epoch: 1... Training loss: 0.00344... Test loss: 0.00367\n",
      "Epoch: 1... Training loss: 0.0033... Test loss: 0.00383\n",
      "Epoch: 1... Training loss: 0.00328... Test loss: 0.00349\n",
      "Epoch: 1... Training loss: 0.00316... Test loss: 0.0035\n",
      "Epoch: 1... Training loss: 0.00313... Test loss: 0.00324\n",
      "Epoch: 1... Training loss: 0.00295... Test loss: 0.0033\n",
      "Epoch: 1... Training loss: 0.00285... Test loss: 0.00328\n",
      "Epoch: 1... Training loss: 0.00287... Test loss: 0.00311\n",
      "Epoch: 1... Training loss: 0.00274... Test loss: 0.00284\n",
      "Epoch: 1... Training loss: 0.0027... Test loss: 0.00283\n",
      "Epoch: 1... Training loss: 0.00279... Test loss: 0.00276\n",
      "Epoch: 1... Training loss: 0.00265... Test loss: 0.00294\n",
      "Epoch: 1... Training loss: 0.00264... Test loss: 0.00282\n",
      "Epoch: 1... Training loss: 0.0025... Test loss: 0.00268\n",
      "Epoch: 1... Training loss: 0.00251... Test loss: 0.0027\n",
      "Epoch: 1... Training loss: 0.00241... Test loss: 0.00244\n",
      "Epoch: 1... Training loss: 0.0025... Test loss: 0.00277\n",
      "Epoch: 1... Training loss: 0.00228... Test loss: 0.00231\n",
      "Epoch: 1... Training loss: 0.00234... Test loss: 0.00288\n",
      "Epoch: 1... Training loss: 0.00222... Test loss: 0.00224\n",
      "Epoch: 1... Training loss: 0.00216... Test loss: 0.00234\n",
      "Epoch: 1... Training loss: 0.00209... Test loss: 0.00201\n",
      "Epoch: 1... Training loss: 0.00214... Test loss: 0.00204\n",
      "Epoch: 1... Training loss: 0.00213... Test loss: 0.00225\n",
      "Epoch: 1... Training loss: 0.002... Test loss: 0.00238\n",
      "Epoch: 1... Training loss: 0.00196... Test loss: 0.00218\n",
      "Epoch: 1... Training loss: 0.00195... Test loss: 0.00204\n",
      "Epoch: 1... Training loss: 0.00184... Test loss: 0.00194\n",
      "Epoch: 1... Training loss: 0.00184... Test loss: 0.00191\n",
      "Epoch: 1... Training loss: 0.00178... Test loss: 0.00179\n",
      "Epoch: 1... Training loss: 0.00179... Test loss: 0.00169\n",
      "Epoch: 1... Training loss: 0.00164... Test loss: 0.00154\n",
      "Epoch: 1... Training loss: 0.00175... Test loss: 0.0017\n",
      "Epoch: 1... Training loss: 0.00158... Test loss: 0.00198\n",
      "Epoch: 1... Training loss: 0.00156... Test loss: 0.00176\n",
      "Epoch: 1... Training loss: 0.0015... Test loss: 0.00162\n",
      "Epoch: 1... Training loss: 0.00158... Test loss: 0.00161\n",
      "Epoch: 1... Training loss: 0.00151... Test loss: 0.00156\n",
      "Epoch: 1... Training loss: 0.00141... Test loss: 0.00141\n",
      "Epoch: 1... Training loss: 0.00134... Test loss: 0.0014\n",
      "Epoch: 1... Training loss: 0.00139... Test loss: 0.00125\n",
      "Epoch: 1... Training loss: 0.00133... Test loss: 0.0014\n",
      "Epoch: 1... Training loss: 0.00128... Test loss: 0.00135\n",
      "Epoch: 1... Training loss: 0.00126... Test loss: 0.00143\n",
      "Epoch: 1... Training loss: 0.00125... Test loss: 0.0011\n",
      "Epoch: 1... Training loss: 0.00114... Test loss: 0.00121\n",
      "Epoch: 1... Training loss: 0.00122... Test loss: 0.00107\n",
      "Epoch: 1... Training loss: 0.00106... Test loss: 0.00106\n",
      "Epoch: 1... Training loss: 0.00111... Test loss: 0.00107\n",
      "Epoch: 1... Training loss: 0.00102... Test loss: 0.00108\n",
      "Epoch: 1... Training loss: 0.00099... Test loss: 0.001\n",
      "Epoch: 1... Training loss: 0.00104... Test loss: 0.0011\n",
      "Epoch: 1... Training loss: 0.00093... Test loss: 0.001\n",
      "Epoch: 1... Training loss: 0.00091... Test loss: 0.00089\n",
      "Epoch: 1... Training loss: 0.00088... Test loss: 0.00083\n",
      "Epoch: 1... Training loss: 0.00086... Test loss: 0.00085\n",
      "Epoch: 1... Training loss: 0.00085... Test loss: 0.00078\n",
      "Epoch: 1... Training loss: 0.00085... Test loss: 0.0008\n",
      "Epoch: 1... Training loss: 0.00081... Test loss: 0.00078\n",
      "Epoch: 1... Training loss: 0.00081... Test loss: 0.00076\n",
      "Epoch: 1... Training loss: 0.00073... Test loss: 0.00084\n",
      "Epoch: 1... Training loss: 0.00068... Test loss: 0.00075\n",
      "Epoch: 1... Training loss: 0.0007... Test loss: 0.00074\n",
      "Epoch: 1... Training loss: 0.00065... Test loss: 0.00068\n",
      "Epoch: 1... Training loss: 0.0006... Test loss: 0.00065\n",
      "Epoch: 1... Training loss: 0.00063... Test loss: 0.00072\n",
      "Epoch: 1... Training loss: 0.0006... Test loss: 0.00074\n",
      "Epoch: 1... Training loss: 0.0006... Test loss: 0.00059\n",
      "Epoch: 1... Training loss: 0.00049... Test loss: 0.00062\n",
      "Epoch: 1... Training loss: 0.00052... Test loss: 0.00052\n",
      "Epoch: 1... Training loss: 0.00046... Test loss: 0.00053\n",
      "Epoch: 1... Training loss: 0.00044... Test loss: 0.00044\n",
      "Epoch: 1... Training loss: 0.0004... Test loss: 0.0005\n",
      "Epoch: 1... Training loss: 0.00045... Test loss: 0.00039\n",
      "Epoch: 1... Training loss: 0.00039... Test loss: 0.0005\n",
      "Epoch: 1... Training loss: 0.00035... Test loss: 0.00037\n",
      "Epoch: 1... Training loss: 0.00035... Test loss: 0.00045\n",
      "Epoch: 1... Training loss: 0.00038... Test loss: 0.00038\n",
      "Epoch: 1... Training loss: 0.00035... Test loss: 0.00037\n",
      "Epoch: 1... Training loss: 0.00035... Test loss: 0.00034\n",
      "Epoch: 1... Training loss: 0.00035... Test loss: 0.00034\n",
      "Epoch: 1... Training loss: 0.00029... Test loss: 0.00038\n",
      "Epoch: 1... Training loss: 0.00033... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00031\n",
      "Epoch: 1... Training loss: 0.00028... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00026... Test loss: 0.0003\n",
      "Epoch: 1... Training loss: 0.00029... Test loss: 0.00024\n",
      "Epoch: 1... Training loss: 0.00027... Test loss: 0.00026\n",
      "Epoch: 1... Training loss: 0.00025... Test loss: 0.00025\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00028\n",
      "Epoch: 1... Training loss: 0.0002... Test loss: 0.00023\n",
      "Epoch: 1... Training loss: 0.00019... Test loss: 0.00027\n",
      "Epoch: 1... Training loss: 0.00018... Test loss: 0.0002\n",
      "Epoch: 1... Training loss: 0.00017... Test loss: 0.00022\n",
      "Epoch: 1... Training loss: 0.00016... Test loss: 0.00016\n",
      "260.85901153681334\n"
     ]
    }
   ],
   "source": [
    "rand_loss_list = []\n",
    "\n",
    "for k in range(50):\n",
    "\n",
    "    model = im2spec((image_patch, image_patch), 64, 10)\n",
    "    \n",
    "    env = environment(image, spectra, model, start, image_patch)\n",
    "\n",
    "\n",
    "\n",
    "    for i in range(initialize):\n",
    "        env.update_pos()\n",
    "        env.render()\n",
    "        env.step(1, False)\n",
    "\n",
    "    while env.num_measure < 200:\n",
    "        env.update_pos()\n",
    "        env.render()\n",
    "        action = 1\n",
    "        env.step(action, True)\n",
    "        \n",
    "    \n",
    "    y_pred = model(torch.tensor(X))\n",
    "    \n",
    "    err = np.zeros([100 - 2*radius, 100 - 2*radius])\n",
    "    \n",
    "    for i in range(len(pos_X)):\n",
    "        err[pos_X[i][0]-radius, pos_X[i][1]-radius] = (((y_pred - torch.tensor(y))**2).sum(axis = 2)/y.shape[2]).reshape((100 - 2*radius)**2)[i]\n",
    "    \n",
    "    loss = err.sum()\n",
    "    print(loss)\n",
    "    \n",
    "    rand_loss_list.append(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(234.18890596711134, 20.335992158164792)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_list = np.array(loss_list)\n",
    "loss_list.mean(), loss_list.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(290.5521834754309, 30.744169314734062)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_loss_list = np.array(rand_loss_list)\n",
    "rand_loss_list.mean(), rand_loss_list.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkAAAAGwCAYAAABB4NqyAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAdvElEQVR4nO3df5BV9Xn48ecicF11oSLL/pB1Aw1aFSQdcHBpooiVcVOtqam1iZPCGJ2oYLJBB7NxjJhJWetMLE2YkGgbaiaxZKZRYysxbCosidQUSRiIWsVmK6SyswkBFhEWgfP9I1/uuPwQs+zuvbuf12vmznDPOXd5Lp857HvOPbC5LMuyAABIyJBiDwAA0N8EEACQHAEEACRHAAEAyRFAAEByBBAAkBwBBAAkZ2ixB+hrhw4dijfeeCPKy8sjl8sVexwA4D3Isix2794dNTU1MWRI71+vGfQB9MYbb0RtbW2xxwAAemDr1q0xduzYXv+6gz6AysvLI+J3f4AjRowo8jQAwHvR2dkZtbW1he/jvW3QB9Dhj71GjBghgABggOmr21fcBA0AJEcAAQDJEUAAQHIEEACQHAEEACRHAAEAyRFAAEByBBAAkBwBBAAkRwABAMkRQABAcgQQAJAcAQQAJEcAAQDJEUAAQHKGFnsA6G1/3/JqsUc4oc9eeW6xRwBImitAAEByBBAAkBwBBAAkRwABAMkRQABAcgQQAJAcAQQAJEcAAQDJEUAAQHIEEACQHAEEACRHAAEAyRFAAEByBBAAkBwBBAAkRwABAMkRQABAcgQQAJAcAQQAJEcAAQDJEUAAQHIEEACQHAEEACRHAAEAyRFAAEByBBAAkBwBBAAkRwABAMkRQABAcgQQAJAcAQQAJEcAAQDJEUAAQHIEEACQHAEEACRHAAEAyRFAAEByBBAAkBwBBAAkRwABAMkRQABAcooaQM3NzXHxxRdHeXl5jBkzJj7ykY/EK6+80u2YLMti4cKFUVNTE2VlZTFjxox48cUXizQxADAYFDWAWltbY+7cufH8889HS0tLHDhwIGbNmhV79uwpHPPggw/GQw89FEuWLIl169ZFVVVVXHnllbF79+4iTg4ADGRDi/mbP/PMM92eL1u2LMaMGRPr16+PSy+9NLIsi8WLF8c999wT1113XUREPProo1FZWRmPPfZYfOpTnyrG2ADAAFdS9wDt2rUrIiJGjRoVERFtbW3R3t4es2bNKhyTz+fjsssui7Vr1x7za3R1dUVnZ2e3BwDAO5VMAGVZFvPnz48PfvCDMXHixIiIaG9vj4iIysrKbsdWVlYW9h2pubk5Ro4cWXjU1tb27eAAwIBTMgE0b9682LhxY/zLv/zLUftyuVy351mWHbXtsKampti1a1fhsXXr1j6ZFwAYuIp6D9Bhd9xxRzz11FOxZs2aGDt2bGF7VVVVRPzuSlB1dXVhe0dHx1FXhQ7L5/ORz+f7dmAAYEAr6hWgLMti3rx58fjjj8ezzz4b48aN67Z/3LhxUVVVFS0tLYVt+/fvj9bW1pg+fXp/jwsADBJFvQI0d+7ceOyxx+L73/9+lJeXF+7rGTlyZJSVlUUul4vGxsZYtGhRTJgwISZMmBCLFi2K0047LT7+8Y8Xc3QAYAAragAtXbo0IiJmzJjRbfuyZctizpw5ERGxYMGC2Lt3b9x+++2xY8eOmDZtWqxcuTLKy8v7eVoAYLAoagBlWXbCY3K5XCxcuDAWLlzY9wMBAEkomX8FBgDQXwQQAJAcAQQAJEcAAQDJEUAAQHIEEACQHAEEACRHAAEAyRFAAEByBBAAkBwBBAAkRwABAMkRQABAcgQQAJAcAQQAJEcAAQDJEUAAQHIEEACQHAEEACRHAAEAyRFAAEByBBAAkBwBBAAkRwABAMkRQABAcgQQAJAcAQQAJEcAAQDJEUAAQHIEEACQHAEEACRHAAEAyRFAAEByBBAAkBwBBAAkRwABAMkRQABAcgQQAJAcAQQAJEcAAQDJEUAAQHIEEACQHAEEACRHAAEAyRFAAEByBBAAkBwBBAAkRwABAMkRQABAcgQQAJAcAQQAJEcAAQDJEUAAQHIEEACQHAEEACRHAAEAyRFAAEByBBAAkBwBBAAkRwABAMkRQABAcgQQAJAcAQQAJEcAAQDJEUAAQHIEEACQnKIG0Jo1a+Kaa66JmpqayOVy8eSTT3bbP2fOnMjlct0el1xySXGGBQAGjaIG0J49e2Ly5MmxZMmS4x5z1VVXxbZt2wqPFStW9OOEAMBgNLSYv3lDQ0M0NDS86zH5fD6qqqre89fs6uqKrq6uwvPOzs4ezwcADE4lfw/Q6tWrY8yYMXHuuefGLbfcEh0dHe96fHNzc4wcObLwqK2t7adJAYCBoqQDqKGhIb7zne/Es88+G1/+8pdj3bp1MXPmzG5XeI7U1NQUu3btKjy2bt3ajxMDAANBUT8CO5Ebbrih8OuJEyfG1KlTo66uLp5++um47rrrjvmafD4f+Xy+v0YEAAagkr4CdKTq6uqoq6uLzZs3F3sUAGAAG1ABtH379ti6dWtUV1cXexQAYAAr6kdgb775Zrz22muF521tbbFhw4YYNWpUjBo1KhYuXBgf/ehHo7q6Ov73f/83Pv/5z8fo0aPjL/7iL4o4NQAw0BU1gF544YW4/PLLC8/nz58fERGzZ8+OpUuXxqZNm+Jb3/pW7Ny5M6qrq+Pyyy+P7373u1FeXl6skQGAQaCoATRjxozIsuy4+3/4wx/24zQAQCoG1D1AAAC9QQABAMkRQABAcgQQAJAcAQQAJEcAAQDJEUAAQHIEEACQHAEEACRHAAEAyRFAAEByBBAAkBwBBAAkRwABAMkRQABAcgQQAJAcAQQAJEcAAQDJEUAAQHIEEACQnB4F0MyZM2Pnzp1Hbe/s7IyZM2ee7EwAAH2qRwG0evXq2L9//1Hb9+3bFz/+8Y9PeigAgL409Pc5eOPGjYVfv/TSS9He3l54fvDgwXjmmWfi7LPP7r3pAAD6wO8VQB/4wAcil8tFLpc75kddZWVl8dWvfrXXhgM4oVXNxZ7gxC5vKvYEwBF+rwBqa2uLLMti/Pjx8V//9V9RUVFR2Dd8+PAYM2ZMnHLKKb0+JABAb/q9Aqiuri4iIg4dOtQnwwAA9IffK4De6dVXX43Vq1dHR0fHUUH0hS984aQHAwDoKz0KoEceeSRuu+22GD16dFRVVUUulyvsy+VyAggAKGk9CqAvfelL8bd/+7dx99139/Y8AAB9rkf/D9COHTvi+uuv7+1ZAAD6RY8C6Prrr4+VK1f29iwAAP2iRx+Bvf/974977703nn/++Zg0aVIMGzas2/5Pf/rTvTIcAEBf6FEAPfzww3HGGWdEa2trtLa2dtuXy+UEEABQ0noUQG1tbb09BwBAv+nRPUAAAANZj64A3XTTTe+6/5vf/GaPhgEA6A89CqAdO3Z0e/7222/HL37xi9i5c+cxf0gqAEAp6VEAPfHEE0dtO3ToUNx+++0xfvz4kx4KAKAv9fhngR1pyJAh8dnPfjZmzJgRCxYs6K0vCxTTquZiTwDQJ3r1Juj/+Z//iQMHDvTmlwQA6HU9ugI0f/78bs+zLItt27bF008/HbNnz+6VwQAA+kqPAujnP/95t+dDhgyJioqK+PKXv3zCfyEGAFBsPQqgVatW9fYcAAD95qRugv71r38dr7zySuRyuTj33HOjoqKit+YCAOgzPboJes+ePXHTTTdFdXV1XHrppfGhD30oampq4pOf/GS89dZbvT0jAECv6lEAzZ8/P1pbW+Pf/u3fYufOnbFz5874/ve/H62trXHnnXf29owAAL2qRx+Bfe9734t//dd/jRkzZhS2ffjDH46ysrL4q7/6q1i6dGlvzQcA0Ot6dAXorbfeisrKyqO2jxkzxkdgAEDJ61EA1dfXx3333Rf79u0rbNu7d2/cf//9UV9f32vDAQD0hR59BLZ48eJoaGiIsWPHxuTJkyOXy8WGDRsin8/HypUre3tGAIBe1aMAmjRpUmzevDm+/e1vx3//939HlmXx13/913HjjTdGWVlZb88IANCrehRAzc3NUVlZGbfccku37d/85jfj17/+ddx99929MhwAQF/o0T1A3/jGN+KP/uiPjtp+4YUXxte//vWTHgoAoC/1KIDa29ujurr6qO0VFRWxbdu2kx4KAKAv9SiAamtr47nnnjtq+3PPPRc1NTUnPRQAQF/q0T1AN998czQ2Nsbbb78dM2fOjIiI//iP/4gFCxb4n6ABgJLXowBasGBB/Pa3v43bb7899u/fHxERp556atx9993R1NTUqwMCAPS2HgVQLpeLv/u7v4t77703Xn755SgrK4sJEyZEPp/v7fkAAHpdjwLosDPOOCMuvvji3poFAKBf9OgmaACAgUwAAQDJEUAAQHIEEACQHAEEACRHAAEAySlqAK1ZsyauueaaqKmpiVwuF08++WS3/VmWxcKFC6OmpibKyspixowZ8eKLLxZnWABg0ChqAO3ZsycmT54cS5YsOeb+Bx98MB566KFYsmRJrFu3LqqqquLKK6+M3bt39/OkAMBgclL/EeLJamhoiIaGhmPuy7IsFi9eHPfcc09cd911ERHx6KOPRmVlZTz22GPxqU99qj9HBQAGkZK9B6itrS3a29tj1qxZhW35fD4uu+yyWLt27XFf19XVFZ2dnd0eAADvVNQrQO+mvb09IiIqKyu7ba+srIzXX3/9uK9rbm6O+++/v09nS9nft7xa7BEA4KSV7BWgw3K5XLfnWZYdte2dmpqaYteuXYXH1q1b+3pEAGCAKdkrQFVVVRHxuytB1dXVhe0dHR1HXRV6p3w+76fSAwDvqmSvAI0bNy6qqqqipaWlsG3//v3R2toa06dPL+JkAMBAV9QrQG+++Wa89tprhedtbW2xYcOGGDVqVJxzzjnR2NgYixYtigkTJsSECRNi0aJFcdppp8XHP/7xIk4NAAx0RQ2gF154IS6//PLC8/nz50dExOzZs+Of//mfY8GCBbF37964/fbbY8eOHTFt2rRYuXJllJeXF2tkAGAQKGoAzZgxI7IsO+7+XC4XCxcujIULF/bfUADAoFey9wABAPQVAQQAJEcAAQDJEUAAQHIEEACQHAEEACRHAAEAyRFAAEBySvaHocJg9p//dFexR3hP6sefVewRAPqEK0AAQHIEEACQHAEEACRHAAEAyRFAAEByBBAAkBwBBAAkRwABAMkRQABAcgQQAJAcAQQAJEcAAQDJEUAAQHIEEACQHAEEACRHAAEAyRFAAEByBBAAkBwBBAAkRwABAMkRQABAcgQQAJAcAQQAJEcAAQDJEUAAQHIEEACQHAEEACRHAAEAyRFAAEByBBAAkJyhxR4AgBKxqrnYE5zY5U3FnoBBwhUgACA5AggASI4AAgCSI4AAgOQIIAAgOQIIAEiOAAIAkiOAAIDkCCAAIDkCCABIjgACAJIjgACA5AggACA5AggASM7QYg8AMOitai72BMARXAECAJIjgACA5AggACA5AggASI4AAgCSI4AAgOQIIAAgOQIIAEiOAAIAkiOAAIDkCCAAIDklHUALFy6MXC7X7VFVVVXssQCAAa7kfxjqhRdeGD/60Y8Kz0855ZQiTgMADAYlH0BDhw79va76dHV1RVdXV+F5Z2dnX4wFAAxgJR9Amzdvjpqamsjn8zFt2rRYtGhRjB8//rjHNzc3x/3339+PE8Lg9Z+/3F7sEU6ofvxZxR4BGIBK+h6gadOmxbe+9a344Q9/GI888ki0t7fH9OnTY/v24/+l3NTUFLt27So8tm7d2o8TAwADQUlfAWpoaCj8etKkSVFfXx9/+Id/GI8++mjMnz//mK/J5/ORz+f7a0QAYAAq6StARzr99NNj0qRJsXnz5mKPAgAMYAMqgLq6uuLll1+O6urqYo8CAAxgJR1Ad911V7S2tkZbW1v89Kc/jb/8y7+Mzs7OmD17drFHAwAGsJK+B+hXv/pVfOxjH4vf/OY3UVFREZdcckk8//zzUVdXV+zRAIABrKQDaPny5cUeAQAYhEr6IzAAgL4ggACA5AggACA5AggASI4AAgCSI4AAgOQIIAAgOQIIAEiOAAIAkiOAAIDkCCAAIDkCCABIjgACAJIjgACA5AggACA5AggASI4AAgCSI4AAgOQIIAAgOQIIAEiOAAIAkiOAAIDkCCAAIDkCCABIjgACAJIjgACA5AggACA5AggASI4AAgCSI4AAgOQIIAAgOQIIAEiOAAIAkiOAAIDkCCAAIDkCCABIjgACAJIjgACA5Awt9gD8zt+3vFrsEQBK36rmYk9wYpc3FXsC3gNXgACA5AggACA5AggASI4AAgCSI4AAgOQIIAAgOQIIAEiOAAIAkiOAAIDkCCAAIDkCCABIjgACAJIjgACA5AggACA5Q4s9AMDJ+M9fbi/2CCdUP/6sYo9Af1rVXOwJ3pvLm4o9QVG5AgQAJEcAAQDJEUAAQHIEEACQHAEEACRHAAEAyRFAAEByBBAAkBwBBAAkRwABAMkRQABAcgZEAH3ta1+LcePGxamnnhpTpkyJH//4x8UeCQAYwEo+gL773e9GY2Nj3HPPPfHzn/88PvShD0VDQ0Ns2bKl2KMBAANUyQfQQw89FJ/85Cfj5ptvjvPPPz8WL14ctbW1sXTp0mKPBgAMUEOLPcC72b9/f6xfvz4+97nPdds+a9asWLt27TFf09XVFV1dXYXnu3btioiIzs7Ovhu0F+zb82axR6Af7dnbdeKDGDQ69+wr9ghwtBL/vnj4+3aWZX3y9Us6gH7zm9/EwYMHo7Kystv2ysrKaG9vP+Zrmpub4/777z9qe21tbZ/MCAAD0xeLPcB7sn379hg5cmSvf92SDqDDcrlct+dZlh217bCmpqaYP39+4fmhQ4fit7/9bZx11lnHfQ3vTWdnZ9TW1sbWrVtjxIgRxR6Hd7A2pcvalDbrU7p27doV55xzTowaNapPvn5JB9Do0aPjlFNOOepqT0dHx1FXhQ7L5/ORz+e7bfuDP/iDvhoxSSNGjPAXRYmyNqXL2pQ261O6hgzpm9uVS/om6OHDh8eUKVOipaWl2/aWlpaYPn16kaYCAAa6kr4CFBExf/78+MQnPhFTp06N+vr6ePjhh2PLli1x6623Fns0AGCAKvkAuuGGG2L79u3xxS9+MbZt2xYTJ06MFStWRF1dXbFHS04+n4/77rvvqI8YKT5rU7qsTWmzPqWrr9cml/XVvy8DAChRJX0PEABAXxBAAEByBBAAkBwBBAAkRwAlrLm5OS6++OIoLy+PMWPGxEc+8pF45ZVXuh2TZVksXLgwampqoqysLGbMmBEvvvhit2O6urrijjvuiNGjR8fpp58ef/7nfx6/+tWv+vOtDErvZX3mzJkTuVyu2+OSSy7pdoz16X1Lly6Niy66qPCf59XX18cPfvCDwn7nTfGcaG2cM6Wjubk5crlcNDY2Frb157kjgBLW2toac+fOjeeffz5aWlriwIEDMWvWrNizZ0/hmAcffDAeeuihWLJkSaxbty6qqqriyiuvjN27dxeOaWxsjCeeeCKWL18eP/nJT+LNN9+Mq6++Og4ePFiMtzVovJf1iYi46qqrYtu2bYXHihUruu23Pr1v7Nix8cADD8QLL7wQL7zwQsycOTOuvfbawl/UzpviOdHaRDhnSsG6devi4Ycfjosuuqjb9n49dzL4/zo6OrKIyFpbW7Msy7JDhw5lVVVV2QMPPFA4Zt++fdnIkSOzr3/961mWZdnOnTuzYcOGZcuXLy8c83//93/ZkCFDsmeeeaZ/38Agd+T6ZFmWzZ49O7v22muP+xrr03/OPPPM7B//8R+dNyXo8NpkmXOmFOzevTubMGFC1tLSkl122WXZZz7zmSzL+v97jitAFOzatSsiovCD59ra2qK9vT1mzZpVOCafz8dll10Wa9eujYiI9evXx9tvv93tmJqampg4cWLhGHrHketz2OrVq2PMmDFx7rnnxi233BIdHR2Ffdan7x08eDCWL18ee/bsifr6eudNCTlybQ5zzhTX3Llz48/+7M/iT//0T7tt7+9zp+T/J2j6R5ZlMX/+/PjgBz8YEydOjIgo/BDaI3/wbGVlZbz++uuFY4YPHx5nnnnmUccc+UNs6bljrU9ERENDQ1x//fVRV1cXbW1tce+998bMmTNj/fr1kc/nrU8f2rRpU9TX18e+ffvijDPOiCeeeCIuuOCCwl/CzpviOd7aRDhnim358uXxs5/9LNatW3fUvv7+niOAiIiIefPmxcaNG+MnP/nJUftyuVy351mWHbXtSO/lGN67463PDTfcUPj1xIkTY+rUqVFXVxdPP/10XHfddcf9etbn5J133nmxYcOG2LlzZ3zve9+L2bNnR2tra2G/86Z4jrc2F1xwgXOmiLZu3Rqf+cxnYuXKlXHqqace97j+Ond8BEbccccd8dRTT8WqVati7Nixhe1VVVUREUdVdUdHR6HQq6qqYv/+/bFjx47jHsPJOd76HEt1dXXU1dXF5s2bI8L69KXhw4fH+9///pg6dWo0NzfH5MmT4x/+4R+cNyXgeGtzLM6Z/rN+/fro6OiIKVOmxNChQ2Po0KHR2toaX/nKV2Lo0KGFP9/+OncEUMKyLIt58+bF448/Hs8++2yMGzeu2/5x48ZFVVVVtLS0FLbt378/WltbY/r06RERMWXKlBg2bFi3Y7Zt2xa/+MUvCsfQMydan2PZvn17bN26NaqrqyPC+vSnLMuiq6vLeVOCDq/NsThn+s8VV1wRmzZtig0bNhQeU6dOjRtvvDE2bNgQ48eP799zpyd3cDM43HbbbdnIkSOz1atXZ9u2bSs83nrrrcIxDzzwQDZy5Mjs8ccfzzZt2pR97GMfy6qrq7POzs7CMbfeems2duzY7Ec/+lH2s5/9LJs5c2Y2efLk7MCBA8V4W4PGidZn9+7d2Z133pmtXbs2a2try1atWpXV19dnZ599tvXpY01NTdmaNWuytra2bOPGjdnnP//5bMiQIdnKlSuzLHPeFNO7rY1zpvS881+BZVn/njsCKGERcczHsmXLCsccOnQou++++7Kqqqosn89nl156abZp06ZuX2fv3r3ZvHnzslGjRmVlZWXZ1VdfnW3ZsqWf383gc6L1eeutt7JZs2ZlFRUV2bBhw7Jzzjknmz179lF/9tan9910001ZXV1dNnz48KyioiK74oorCvGTZc6bYnq3tXHOlJ4jA6g/z51clmVZj69nAQAMQO4BAgCSI4AAgOQIIAAgOQIIAEiOAAIAkiOAAIDkCCAAIDkCCABIjgACSsqMGTOisbGx2GMAg5wAAgCSI4AAgOQIIKBk7dixI/7mb/4mzjzzzDjttNOioaEhNm/eXNj/+uuvxzXXXBNnnnlmnH766XHhhRfGihUrCq+98cYbo6KiIsrKymLChAmxbNmyYr0VoMQMLfYAAMczZ86c2Lx5czz11FMxYsSIuPvuu+PDH/5wvPTSSzFs2LCYO3du7N+/P9asWROnn356vPTSS3HGGWdERMS9994bL730UvzgBz+I0aNHx2uvvRZ79+4t8jsCSoUAAkrS4fB57rnnYvr06RER8Z3vfCdqa2vjySefjOuvvz62bNkSH/3oR2PSpEkRETF+/PjC67ds2RJ//Md/HFOnTo2IiPe97339/h6A0uUjMKAkvfzyyzF06NCYNm1aYdtZZ50V5513Xrz88ssREfHpT386vvSlL8Wf/MmfxH333RcbN24sHHvbbbfF8uXL4wMf+EAsWLAg1q5d2+/vAShdAggoSVmWHXd7LpeLiIibb745fvnLX8YnPvGJ2LRpU0ydOjW++tWvRkREQ0NDvP7669HY2BhvvPFGXHHFFXHXXXf12/xAaRNAQEm64IIL4sCBA/HTn/60sG379u3x6quvxvnnn1/YVltbG7feems8/vjjceedd8YjjzxS2FdRURFz5syJb3/727F48eJ4+OGH+/U9AKXLPUBASZowYUJce+21ccstt8Q3vvGNKC8vj8997nNx9tlnx7XXXhsREY2NjdHQ0BDnnntu7NixI5599tlCHH3hC1+IKVOmxIUXXhhdXV3x7//+793CCUibK0BAyVq2bFlMmTIlrr766qivr48sy2LFihUxbNiwiIg4ePBgzJ07N84///y46qqr4rzzzouvfe1rERExfPjwaGpqiosuuiguvfTSOOWUU2L58uXFfDtACcllx/ugHQBgkHIFCABIjgACAJIjgACA5AggACA5AggASI4AAgCSI4AAgOQIIAAgOQIIAEiOAAIAkiOAAIDk/D+b5FIWrHe0mQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bins = np.arange(160,400,20) # fixed bin size\n",
    "\n",
    "plt.xlim([160, 400])\n",
    "\n",
    "plt.hist(loss_list, bins=bins, alpha=0.5)\n",
    "plt.hist(rand_loss_list, bins=bins, alpha=0.5)\n",
    "\n",
    "\n",
    "\n",
    "plt.xlabel('loss')\n",
    "plt.ylabel('count')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 6000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7ffe6be45690>]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred_loop = predict(model, np.array(X[i]).reshape([1, 1, image_patch, image_patch])).reshape(64)\n",
    "plt.plot(spec, pred_loop)\n",
    "plt.plot(spec, y[i][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_im = predict(autoencoder, X[i].reshape([1, 1, image_patch, image_patch])).reshape([image_patch, image_patch])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show(close=None, block=None)>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(pred_im)\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7ffe69278890>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZgAAAGdCAYAAAAv9mXmAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAAASIUlEQVR4nO3dX2jehb3H8W/amifSJsGqLZZGV3BnTksdpgoR3Zx1gSBFGRx2IaXsz0Ux7WnpxdmqF2ODEXezM6Gz2LnjLoZLz3BVL2YxMNs4PIU0GiyFI3hwJzmndsFxTNKIT9f0d25mOFk1yxP7ze952tcLnovn4Rd+H36mefvLk6ZNRVEUAQCX2LKyBwBweRIYAFIIDAApBAaAFAIDQAqBASCFwACQQmAASLFiqU944cKFOH36dLS2tkZTU9NSnx6Az6Aoipiamop169bFsmXz36MseWBOnz4dHR0dS31aAC6hsbGxWL9+/bzHLHlgWltbIyJi3Y/3xbKWlqU+fUP53Ibxsic0hOJfrit7QkO46tWRsic0hJkv3172hLp2/nw1/v31H89+LZ/Pkgfm42+LLWtpiWVXC8x8VqyslD2hIRQrfB4txIqmq8qe0BCafD4tyELe4vAmPwApBAaAFAIDQAqBASCFwACQQmAASCEwAKQQGABSCAwAKQQGgBQCA0AKgQEghcAAkEJgAEghMACkEBgAUggMACkEBoAUAgNACoEBIIXAAJBCYABIITAApBAYAFIIDAApBAaAFAIDQAqBASCFwACQYlGBeeqpp2LDhg3R0tISnZ2d8dprr13qXQA0uJoDc+jQodizZ088/vjj8eabb8a9994bPT09MTo6mrEPgAZVc2B+8pOfxLe//e34zne+E1/84hfjpz/9aXR0dMSBAwcy9gHQoGoKzLlz52J4eDi6u7vnvN7d3R2vv/76JR0GQGNbUcvB77//fszMzMTatWvnvL527do4c+bMJ35MtVqNarU6+3xycnIRMwFoNIt6k7+pqWnO86IoLnrtY319fdHe3j776OjoWMwpAWgwNQXmuuuui+XLl190tzI+Pn7RXc3H9u3bFxMTE7OPsbGxxa8FoGHUFJjm5ubo7OyMgYGBOa8PDAzE3Xff/YkfU6lUoq2tbc4DgMtfTe/BRETs3bs3tm3bFps3b46urq44ePBgjI6Oxo4dOzL2AdCgag7MN77xjfjzn/8cP/zhD+O9996LjRs3xu9+97u46aabMvYB0KBqDkxExKOPPhqPPvropd4CwGXE7yIDIIXAAJBCYABIITAApBAYAFIIDAApBAaAFAIDQAqBASCFwACQQmAASCEwAKQQGABSCAwAKQQGgBQCA0AKgQEghcAAkEJgAEghMACkEBgAUggMACkEBoAUAgNACoEBIIXAAJBCYABIITAApBAYAFIIDAApVpR14sMPPBWrWvVtPv/8x6+XPaEh/Pfnmsue0BCu/9KtZU9oCO//Q6XsCXVt5lwRMbiwY32FByCFwACQQmAASCEwAKQQGABSCAwAKQQGgBQCA0AKgQEghcAAkEJgAEghMACkEBgAUggMACkEBoAUAgNACoEBIIXAAJBCYABIITAApBAYAFIIDAApBAaAFAIDQAqBASCFwACQQmAASCEwAKQQGABSCAwAKQQGgBQCA0CKmgMzODgYW7dujXXr1kVTU1O88MILCbMAaHQ1B2Z6ejpuv/322L9/f8YeAC4TK2r9gJ6enujp6cnYAsBlxHswAKSo+Q6mVtVqNarV6uzzycnJ7FMCUAfS72D6+vqivb199tHR0ZF9SgDqQHpg9u3bFxMTE7OPsbGx7FMCUAfSv0VWqVSiUqlknwaAOlNzYM6ePRvvvPPO7PN33303RkZGYvXq1XHjjTde0nEANK6aA3PixIn46le/Ovt87969ERGxffv2+OUvf3nJhgHQ2GoOzH333RdFUWRsAeAy4u/BAJBCYABIITAApBAYAFIIDAApBAaAFAIDQAqBASCFwACQQmAASCEwAKQQGABSCAwAKQQGgBQCA0AKgQEghcAAkEJgAEghMACkEBgAUggMACkEBoAUAgNACoEBIIXAAJBCYABIITAApBAYAFIIDAApBAaAFCvKOvFfimXxl0Lf5vP1tcNlT2gIo//0X2VPaAj973SWPaEh3HHDqbIn1LW/TJ+Lk/+6sGN9hQcghcAAkEJgAEghMACkEBgAUggMACkEBoAUAgNACoEBIIXAAJBCYABIITAApBAYAFIIDAApBAaAFAIDQAqBASCFwACQQmAASCEwAKQQGABSCAwAKQQGgBQCA0AKgQEghcAAkEJgAEghMACkEBgAUggMACkEBoAUAgNAipoC09fXF3feeWe0trbGmjVr4uGHH4633347axsADaymwBw7dix6e3vj+PHjMTAwEOfPn4/u7u6Ynp7O2gdAg1pRy8FHjhyZ8/zZZ5+NNWvWxPDwcHz5y1++pMMAaGw1BeZvTUxMRETE6tWrP/WYarUa1Wp19vnk5ORnOSUADWLRb/IXRRF79+6Ne+65JzZu3Pipx/X19UV7e/vso6OjY7GnBKCBLDowO3fujLfeeit+/etfz3vcvn37YmJiYvYxNja22FMC0EAW9S2yXbt2xUsvvRSDg4Oxfv36eY+tVCpRqVQWNQ6AxlVTYIqiiF27dsXhw4fj6NGjsWHDhqxdADS4mgLT29sbzz33XLz44ovR2toaZ86ciYiI9vb2uPrqq1MGAtCYanoP5sCBAzExMRH33Xdf3HDDDbOPQ4cOZe0DoEHV/C0yAFgIv4sMgBQCA0AKgQEghcAAkEJgAEghMACkEBgAUggMACkEBoAUAgNACoEBIIXAAJBCYABIITAApBAYAFIIDAApBAaAFAIDQAqBASCFwACQQmAASCEwAKQQGABSCAwAKQQGgBQCA0AKgQEghcAAkEJgAEghMACkWFHWia9quhBXNZV19sZwW+V02RMaQmfLWNkTGsJdm/6z7AkN4YL/757Xhy0z8W8LPNaVBCCFwACQQmAASCEwAKQQGABSCAwAKQQGgBQCA0AKgQEghcAAkEJgAEghMACkEBgAUggMACkEBoAUAgNACoEBIIXAAJBCYABIITAApBAYAFIIDAApBAaAFAIDQAqBASCFwACQQmAASCEwAKQQGABSCAwAKQQGgBQCA0CKmgJz4MCB2LRpU7S1tUVbW1t0dXXFyy+/nLUNgAZWU2DWr18fTzzxRJw4cSJOnDgR999/fzz00ENx6tSprH0ANKgVtRy8devWOc9/9KMfxYEDB+L48eNx2223XdJhADS2mgLz/83MzMRvfvObmJ6ejq6urk89rlqtRrVanX0+OTm52FMC0EBqfpP/5MmTsWrVqqhUKrFjx444fPhw3HrrrZ96fF9fX7S3t88+Ojo6PtNgABpDU1EURS0fcO7cuRgdHY0PPvggnn/++XjmmWfi2LFjnxqZT7qD6ejoiKFTa2NVqx9im8/UhavKntAQWppmyp7QEP7nfFvZExrCBT9cO68Pp2biH7/0HzExMRFtbfN/TtX8LbLm5ua4+eabIyJi8+bNMTQ0FE8++WQ8/fTTn3h8pVKJSqVS62kAaHCfOdVFUcy5QwGAiBrvYB577LHo6emJjo6OmJqaiv7+/jh69GgcOXIkax8ADaqmwPzpT3+Kbdu2xXvvvRft7e2xadOmOHLkSHzta1/L2gdAg6opML/4xS+ydgBwmfHjEgCkEBgAUggMACkEBoAUAgNACoEBIIXAAJBCYABIITAApBAYAFIIDAApBAaAFAIDQAqBASCFwACQQmAASCEwAKQQGABSCAwAKQQGgBQCA0AKgQEghcAAkEJgAEghMACkEBgAUggMACkEBoAUAgNACoEBIMWKsk5881Uro+0qfZvPhxfOlT2hIZwtLpQ9oSG0Lvvfsic0hD+eX1X2hLpWLFv4nzdf4QFIITAApBAYAFIIDAApBAaAFAIDQAqBASCFwACQQmAASCEwAKQQGABSCAwAKQQGgBQCA0AKgQEghcAAkEJgAEghMACkEBgAUggMACkEBoAUAgNACoEBIIXAAJBCYABIITAApBAYAFIIDAApBAaAFAIDQAqBASCFwACQ4jMFpq+vL5qammLPnj2XaA4Al4tFB2ZoaCgOHjwYmzZtupR7ALhMLCowZ8+ejUceeSR+/vOfxzXXXHOpNwFwGVhUYHp7e+PBBx+MBx544O8eW61WY3Jycs4DgMvfilo/oL+/P954440YGhpa0PF9fX3xgx/8oOZhADS2mu5gxsbGYvfu3fGrX/0qWlpaFvQx+/bti4mJidnH2NjYooYC0FhquoMZHh6O8fHx6OzsnH1tZmYmBgcHY//+/VGtVmP58uVzPqZSqUSlUrk0awFoGDUFZsuWLXHy5Mk5r33zm9+MW265Jb773e9eFBcArlw1Baa1tTU2btw457WVK1fGtddee9HrAFzZ/E1+AFLU/FNkf+vo0aOXYAYAlxt3MACkEBgAUggMACkEBoAUAgNACoEBIIXAAJBCYABIITAApBAYAFIIDAApBAaAFAIDQAqBASCFwACQQmAASCEwAKQQGABSCAwAKQQGgBQCA0AKgQEghcAAkEJgAEghMACkEBgAUggMACkEBoAUAgNAihVLfcKiKCIiYvLshaU+dcP58IJrtBDTheu0EB/99c8e85s+7/NpPh/+9Wt3sYDPpyUPzNTUVERE3HTHH5f61AALMF72gIYwNTUV7e3t8x7TVCwkQ5fQhQsX4vTp09Ha2hpNTU1LeepPNTk5GR0dHTE2NhZtbW1lz6lLrtHCuE4L4zotTD1ep6IoYmpqKtatWxfLls3/LsuS38EsW7Ys1q9fv9SnXZC2tra6+Y9Yr1yjhXGdFsZ1Wph6u05/787lY97kByCFwACQQmAiolKpxPe///2oVCplT6lbrtHCuE4L4zotTKNfpyV/kx+AK4M7GABSCAwAKQQGgBQCA0CKKz4wTz31VGzYsCFaWlqis7MzXnvttbIn1Z3BwcHYunVrrFu3LpqamuKFF14oe1Ld6evrizvvvDNaW1tjzZo18fDDD8fbb79d9qy6c+DAgdi0adPsXxzs6uqKl19+uexZda2vry+amppiz549ZU+p2RUdmEOHDsWePXvi8ccfjzfffDPuvffe6OnpidHR0bKn1ZXp6em4/fbbY//+/WVPqVvHjh2L3t7eOH78eAwMDMT58+eju7s7pqeny55WV9avXx9PPPFEnDhxIk6cOBH3339/PPTQQ3Hq1Kmyp9WloaGhOHjwYGzatKnsKYtTXMHuuuuuYseOHXNeu+WWW4rvfe97JS2qfxFRHD58uOwZdW98fLyIiOLYsWNlT6l711xzTfHMM8+UPaPuTE1NFZ///OeLgYGB4itf+Uqxe/fusifV7Iq9gzl37lwMDw9Hd3f3nNe7u7vj9ddfL2kVl4uJiYmIiFi9enXJS+rXzMxM9Pf3x/T0dHR1dZU9p+709vbGgw8+GA888EDZUxZtyX/ZZb14//33Y2ZmJtauXTvn9bVr18aZM2dKWsXloCiK2Lt3b9xzzz2xcePGsufUnZMnT0ZXV1d89NFHsWrVqjh8+HDceuutZc+qK/39/fHGG2/E0NBQ2VM+kys2MB/7238yoCiKuvlnBGhMO3fujLfeeiv+8Ic/lD2lLn3hC1+IkZGR+OCDD+L555+P7du3x7Fjx0Tmr8bGxmL37t3xyiuvREtLS9lzPpMrNjDXXXddLF++/KK7lfHx8YvuamChdu3aFS+99FIMDg7W7T9LUbbm5ua4+eabIyJi8+bNMTQ0FE8++WQ8/fTTJS+rD8PDwzE+Ph6dnZ2zr83MzMTg4GDs378/qtVqLF++vMSFC3fFvgfT3NwcnZ2dMTAwMOf1gYGBuPvuu0taRaMqiiJ27twZv/3tb+P3v/99bNiwoexJDaMoiqhWq2XPqBtbtmyJkydPxsjIyOxj8+bN8cgjj8TIyEjDxCXiCr6DiYjYu3dvbNu2LTZv3hxdXV1x8ODBGB0djR07dpQ9ra6cPXs23nnnndnn7777boyMjMTq1avjxhtvLHFZ/ejt7Y3nnnsuXnzxxWhtbZ29M25vb4+rr7665HX147HHHouenp7o6OiIqamp6O/vj6NHj8aRI0fKnlY3WltbL3rvbuXKlXHttdc23nt65f4QW/l+9rOfFTfddFPR3Nxc3HHHHX6s9BO8+uqrRURc9Ni+fXvZ0+rGJ12fiCieffbZsqfVlW9961uzf96uv/76YsuWLcUrr7xS9qy616g/puzX9QOQ4op9DwaAXAIDQAqBASCFwACQQmAASCEwAKQQGABSCAwAKQQGgBQCA0AKgQEghcAAkOL/AAyA8yvsOkVeAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X[i].reshape([image_patch, image_patch]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
